(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(n){function e(e){for(var r,a,s=e[0],c=e[1],l=e[2],p=0,d=[];p<s.length;p++)a=s[p],Object.prototype.hasOwnProperty.call(o,a)&&o[a]&&d.push(o[a][0]),o[a]=0;for(r in c)Object.prototype.hasOwnProperty.call(c,r)&&(n[r]=c[r]);for(u&&u(e);d.length;)d.shift()();return i.push.apply(i,l||[]),t()}function t(){for(var n,e=0;e<i.length;e++){for(var t=i[e],r=!0,s=1;s<t.length;s++){var c=t[s];0!==o[c]&&(r=!1)}r&&(i.splice(e--,1),n=a(a.s=t[0]))}return n}var r={},o={1:0},i=[];function a(e){if(r[e])return r[e].exports;var t=r[e]={i:e,l:!1,exports:{}};return n[e].call(t.exports,t,t.exports,a),t.l=!0,t.exports}a.e=function(n){var e=[],t=o[n];if(0!==t)if(t)e.push(t[2]);else{var r=new Promise((function(e,r){t=o[n]=[e,r]}));e.push(t[2]=r);var i,s=document.createElement("script");s.charset="utf-8",s.timeout=120,a.nc&&s.setAttribute("nonce",a.nc),s.src=function(n){return a.p+"assets/js/"+({}[n]||n)+"."+{2:"f6f8ee30",3:"24ac7792",4:"f1bc7974",5:"407395b9",6:"78117502",7:"56a055b6",8:"0e58efd7",9:"1baf3037",10:"cf34be2f",11:"d0c564e8",12:"5702c746",13:"ef1064ab",14:"d4bbe0f4",15:"187f2bbe",16:"81ec7462",17:"78492a55",18:"f2257de3",19:"89ad1690",20:"17a31e9f",21:"5f2d65e5",22:"8245079c",23:"9d7097f3",24:"98301950",25:"d33c847e",26:"9ac08ddd",27:"dfdd9bfa",28:"fdb03a82",29:"fa740f14",30:"69ec3d25",31:"ebfbea07",32:"0fbcae90",33:"b19156eb",34:"b59bceb5",35:"e6df671c",36:"3dcdb6f7",37:"02f43a78",38:"c7124ea4",39:"34dae690",40:"2d1e38dc",41:"6528ef5b",42:"245ad245",43:"12eda987",44:"4a6daf4a"}[n]+".js"}(n);var c=new Error;i=function(e){s.onerror=s.onload=null,clearTimeout(l);var t=o[n];if(0!==t){if(t){var r=e&&("load"===e.type?"missing":e.type),i=e&&e.target&&e.target.src;c.message="Loading chunk "+n+" failed.\n("+r+": "+i+")",c.name="ChunkLoadError",c.type=r,c.request=i,t[1](c)}o[n]=void 0}};var l=setTimeout((function(){i({type:"timeout",target:s})}),12e4);s.onerror=s.onload=i,document.head.appendChild(s)}return Promise.all(e)},a.m=n,a.c=r,a.d=function(n,e,t){a.o(n,e)||Object.defineProperty(n,e,{enumerable:!0,get:t})},a.r=function(n){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(n,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(n,"__esModule",{value:!0})},a.t=function(n,e){if(1&e&&(n=a(n)),8&e)return n;if(4&e&&"object"==typeof n&&n&&n.__esModule)return n;var t=Object.create(null);if(a.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:n}),2&e&&"string"!=typeof n)for(var r in n)a.d(t,r,function(e){return n[e]}.bind(null,r));return t},a.n=function(n){var e=n&&n.__esModule?function(){return n.default}:function(){return n};return a.d(e,"a",e),e},a.o=function(n,e){return Object.prototype.hasOwnProperty.call(n,e)},a.p="/",a.oe=function(n){throw console.error(n),n};var s=window.webpackJsonp=window.webpackJsonp||[],c=s.push.bind(s);s.push=e,s=s.slice();for(var l=0;l<s.length;l++)e(s[l]);var u=c;i.push([237,0]),t()}([function(n,e){var t=function(n){return n&&n.Math==Math&&n};n.exports=t("object"==typeof globalThis&&globalThis)||t("object"==typeof window&&window)||t("object"==typeof self&&self)||t("object"==typeof global&&global)||function(){return this}()||Function("return this")()},function(n,e,t){var r=t(0),o=t(38).f,i=t(27),a=t(14),s=t(112),c=t(119),l=t(105);n.exports=function(n,e){var t,u,p,d,f,h=n.target,m=n.global,v=n.stat;if(t=m?r:v?r[h]||s(h,{}):(r[h]||{}).prototype)for(u in e){if(d=e[u],p=n.noTargetGet?(f=o(t,u))&&f.value:t[u],!l(m?u:h+(v?".":"#")+u,n.forced)&&void 0!==p){if(typeof d==typeof p)continue;c(d,p)}(n.sham||p&&p.sham)&&i(d,"sham",!0),a(t,u,d,n)}}},function(n,e,t){var r=t(64),o=Function.prototype,i=o.bind,a=o.call,s=r&&i.bind(a,a);n.exports=r?function(n){return n&&s(n)}:function(n){return n&&function(){return a.apply(n,arguments)}}},function(n,e){n.exports=function(n){try{return!!n()}catch(n){return!0}}},function(n,e,t){var r=t(123),o=t(14),i=t(253);r||o(Object.prototype,"toString",i,{unsafe:!0})},function(n,e){n.exports=function(n){return"function"==typeof n}},function(n,e,t){var r=t(0),o=t(79),i=t(10),a=t(80),s=t(113),c=t(156),l=o("wks"),u=r.Symbol,p=u&&u.for,d=c?u:u&&u.withoutSetter||a;n.exports=function(n){if(!i(l,n)||!s&&"string"!=typeof l[n]){var e="Symbol."+n;s&&i(u,n)?l[n]=u[n]:l[n]=c&&p?p(e):d(e)}return l[n]}},function(n,e,t){var r=t(3);n.exports=!r((function(){return 7!=Object.defineProperty({},1,{get:function(){return 7}})[1]}))},function(n,e,t){var r=t(0),o=t(9),i=r.String,a=r.TypeError;n.exports=function(n){if(o(n))return n;throw a(i(n)+" is not an object")}},function(n,e,t){var r=t(5);n.exports=function(n){return"object"==typeof n?null!==n:r(n)}},function(n,e,t){var r=t(2),o=t(16),i=r({}.hasOwnProperty);n.exports=Object.hasOwn||function(n,e){return i(o(n),e)}},function(n,e,t){var r=t(64),o=Function.prototype.call;n.exports=r?o.bind(o):function(){return o.apply(o,arguments)}},function(n,e,t){var r=t(0),o=t(77),i=r.String;n.exports=function(n){if("Symbol"===o(n))throw TypeError("Cannot convert a Symbol value to a string");return i(n)}},function(n,e,t){var r=t(0),o=t(7),i=t(158),a=t(157),s=t(8),c=t(82),l=r.TypeError,u=Object.defineProperty,p=Object.getOwnPropertyDescriptor;e.f=o?a?function(n,e,t){if(s(n),e=c(e),s(t),"function"==typeof n&&"prototype"===e&&"value"in t&&"writable"in t&&!t.writable){var r=p(n,e);r&&r.writable&&(n[e]=t.value,t={configurable:"configurable"in t?t.configurable:r.configurable,enumerable:"enumerable"in t?t.enumerable:r.enumerable,writable:!1})}return u(n,e,t)}:u:function(n,e,t){if(s(n),e=c(e),s(t),i)try{return u(n,e,t)}catch(n){}if("get"in t||"set"in t)throw l("Accessors not supported");return"value"in t&&(n[e]=t.value),n}},function(n,e,t){var r=t(0),o=t(5),i=t(10),a=t(27),s=t(112),c=t(87),l=t(39),u=t(67).CONFIGURABLE,p=l.get,d=l.enforce,f=String(String).split("String");(n.exports=function(n,e,t,c){var l,p=!!c&&!!c.unsafe,h=!!c&&!!c.enumerable,m=!!c&&!!c.noTargetGet,v=c&&void 0!==c.name?c.name:e;o(t)&&("Symbol("===String(v).slice(0,7)&&(v="["+String(v).replace(/^Symbol\(([^)]*)\)/,"$1")+"]"),(!i(t,"name")||u&&t.name!==v)&&a(t,"name",v),(l=d(t)).source||(l.source=f.join("string"==typeof v?v:""))),n!==r?(p?!m&&n[e]&&(h=!0):delete n[e],h?n[e]=t:a(n,e,t)):h?n[e]=t:s(e,t)})(Function.prototype,"toString",(function(){return o(this)&&p(this).source||c(this)}))},function(n,e,t){"use strict";function r(n,e,t,r,o,i,a,s){var c,l="function"==typeof n?n.options:n;if(e&&(l.render=e,l.staticRenderFns=t,l._compiled=!0),r&&(l.functional=!0),i&&(l._scopeId="data-v-"+i),a?(c=function(n){(n=n||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(n=__VUE_SSR_CONTEXT__),o&&o.call(this,n),n&&n._registeredComponents&&n._registeredComponents.add(a)},l._ssrRegister=c):o&&(c=s?function(){o.call(this,(l.functional?this.parent:this).$root.$options.shadowRoot)}:o),c)if(l.functional){l._injectStyles=c;var u=l.render;l.render=function(n,e){return c.call(e),u(n,e)}}else{var p=l.beforeCreate;l.beforeCreate=p?[].concat(p,c):[c]}return{exports:n,options:l}}t.d(e,"a",(function(){return r}))},function(n,e,t){var r=t(0),o=t(19),i=r.Object;n.exports=function(n){return i(o(n))}},function(n,e,t){var r=t(0),o=t(5),i=function(n){return o(n)?n:void 0};n.exports=function(n,e){return arguments.length<2?i(r[n]):r[n]&&r[n][e]}},function(n,e,t){"use strict";var r=t(1),o=t(93);r({target:"RegExp",proto:!0,forced:/./.exec!==o},{exec:o})},function(n,e,t){var r=t(0).TypeError;n.exports=function(n){if(null==n)throw r("Can't call method on "+n);return n}},function(n,e,t){var r=t(63),o=t(19);n.exports=function(n){return r(o(n))}},function(n,e,t){"use strict";var r=t(174).charAt,o=t(12),i=t(39),a=t(162),s=i.set,c=i.getterFor("String Iterator");a(String,"String",(function(n){s(this,{type:"String Iterator",string:o(n),index:0})}),(function(){var n,e=c(this),t=e.string,o=e.index;return o>=t.length?{value:void 0,done:!0}:(n=r(t,o),e.index+=n.length,{value:n,done:!1})}))},function(n,e,t){var r=t(0),o=t(175),i=t(176),a=t(144),s=t(27),c=t(6),l=c("iterator"),u=c("toStringTag"),p=a.values,d=function(n,e){if(n){if(n[l]!==p)try{s(n,l,p)}catch(e){n[l]=p}if(n[u]||s(n,u,e),o[e])for(var t in a)if(n[t]!==a[t])try{s(n,t,a[t])}catch(e){n[t]=a[t]}}};for(var f in o)d(r[f]&&r[f].prototype,f);d(i,"DOMTokenList")},function(n,e,t){var r=t(53);n.exports=function(n){return r(n.length)}},function(n,e,t){"use strict";var r=t(1),o=t(57).filter;r({target:"Array",proto:!0,forced:!t(91)("filter")},{filter:function(n){return o(this,n,arguments.length>1?arguments[1]:void 0)}})},function(n,e,t){var r=t(2),o=r({}.toString),i=r("".slice);n.exports=function(n){return i(o(n),8,-1)}},function(n,e){n.exports=!1},function(n,e,t){var r=t(7),o=t(13),i=t(49);n.exports=r?function(n,e,t){return o.f(n,e,i(1,t))}:function(n,e,t){return n[e]=t,n}},function(n,e,t){"use strict";var r=t(1),o=t(182);r({target:"Array",proto:!0,forced:[].forEach!=o},{forEach:o})},function(n,e,t){var r=t(0),o=t(175),i=t(176),a=t(182),s=t(27),c=function(n){if(n&&n.forEach!==a)try{s(n,"forEach",a)}catch(e){n.forEach=a}};for(var l in o)o[l]&&c(r[l]&&r[l].prototype);c(i)},function(n,e,t){var r=t(14),o=t(268),i=Error.prototype;i.toString!==o&&r(i,"toString",o)},function(n,e){var t=Array.isArray;n.exports=t},function(n,e,t){var r=t(17);n.exports=r("navigator","userAgent")||""},function(n,e,t){var r=t(192),o="object"==typeof self&&self&&self.Object===Object&&self,i=r||o||Function("return this")();n.exports=i},function(n,e,t){var r,o=t(8),i=t(114),a=t(117),s=t(65),c=t(161),l=t(81),u=t(86),p=u("IE_PROTO"),d=function(){},f=function(n){return"<script>"+n+"<\/script>"},h=function(n){n.write(f("")),n.close();var e=n.parentWindow.Object;return n=null,e},m=function(){try{r=new ActiveXObject("htmlfile")}catch(n){}var n,e;m="undefined"!=typeof document?document.domain&&r?h(r):((e=l("iframe")).style.display="none",c.appendChild(e),e.src=String("javascript:"),(n=e.contentWindow.document).open(),n.write(f("document.F=Object")),n.close(),n.F):h(r);for(var t=a.length;t--;)delete m.prototype[a[t]];return m()};s[p]=!0,n.exports=Object.create||function(n,e){var t;return null!==n?(d.prototype=o(n),t=new d,d.prototype=null,t[p]=n):t=m(),void 0===e?t:i.f(t,e)}},function(n,e,t){var r=t(2);n.exports=r({}.isPrototypeOf)},function(n,e,t){var r=t(64),o=Function.prototype,i=o.apply,a=o.call;n.exports="object"==typeof Reflect&&Reflect.apply||(r?a.bind(i):function(){return a.apply(i,arguments)})},function(n,e,t){var r=t(0),o=t(5),i=t(84),a=r.TypeError;n.exports=function(n){if(o(n))return n;throw a(i(n)+" is not a function")}},function(n,e,t){var r=t(7),o=t(11),i=t(118),a=t(49),s=t(20),c=t(82),l=t(10),u=t(158),p=Object.getOwnPropertyDescriptor;e.f=r?p:function(n,e){if(n=s(n),e=c(e),u)try{return p(n,e)}catch(n){}if(l(n,e))return a(!o(i.f,n,e),n[e])}},function(n,e,t){var r,o,i,a=t(239),s=t(0),c=t(2),l=t(9),u=t(27),p=t(10),d=t(111),f=t(86),h=t(65),m=s.TypeError,v=s.WeakMap;if(a||d.state){var g=d.state||(d.state=new v),y=c(g.get),b=c(g.has),x=c(g.set);r=function(n,e){if(b(g,n))throw new m("Object already initialized");return e.facade=n,x(g,n,e),e},o=function(n){return y(g,n)||{}},i=function(n){return b(g,n)}}else{var _=f("state");h[_]=!0,r=function(n,e){if(p(n,_))throw new m("Object already initialized");return e.facade=n,u(n,_,e),e},o=function(n){return p(n,_)?n[_]:{}},i=function(n){return p(n,_)}}n.exports={set:r,get:o,has:i,enforce:function(n){return i(n)?o(n):r(n,{})},getterFor:function(n){return function(e){var t;if(!l(e)||(t=o(e)).type!==n)throw m("Incompatible receiver, "+n+" required");return t}}}},function(n,e,t){var r=t(1),o=t(0),i=t(36),a=t(264),s=o.WebAssembly,c=7!==Error("e",{cause:7}).cause,l=function(n,e){var t={};t[n]=a(n,e,c),r({global:!0,forced:c},t)},u=function(n,e){if(s&&s[n]){var t={};t[n]=a("WebAssembly."+n,e,c),r({target:"WebAssembly",stat:!0,forced:c},t)}};l("Error",(function(n){return function(e){return i(n,this,arguments)}})),l("EvalError",(function(n){return function(e){return i(n,this,arguments)}})),l("RangeError",(function(n){return function(e){return i(n,this,arguments)}})),l("ReferenceError",(function(n){return function(e){return i(n,this,arguments)}})),l("SyntaxError",(function(n){return function(e){return i(n,this,arguments)}})),l("TypeError",(function(n){return function(e){return i(n,this,arguments)}})),l("URIError",(function(n){return function(e){return i(n,this,arguments)}})),u("CompileError",(function(n){return function(e){return i(n,this,arguments)}})),u("LinkError",(function(n){return function(e){return i(n,this,arguments)}})),u("RuntimeError",(function(n){return function(e){return i(n,this,arguments)}}))},function(n,e,t){var r=t(288),o=t(291);n.exports=function(n,e){var t=o(n,e);return r(t)?t:void 0}},function(n,e,t){"use strict";var r=t(1),o=t(0),i=t(60),a=t(88),s=t(9),c=t(116),l=t(23),u=t(20),p=t(70),d=t(6),f=t(91),h=t(69),m=f("slice"),v=d("species"),g=o.Array,y=Math.max;r({target:"Array",proto:!0,forced:!m},{slice:function(n,e){var t,r,o,d=u(this),f=l(d),m=c(n,f),b=c(void 0===e?f:e,f);if(i(d)&&(t=d.constructor,(a(t)&&(t===g||i(t.prototype))||s(t)&&null===(t=t[v]))&&(t=void 0),t===g||void 0===t))return h(d,m,b);for(r=new(void 0===t?g:t)(y(b-m,0)),o=0;m<b;m++,o++)m in d&&p(r,o,d[m]);return r.length=o,r}})},function(n,e,t){var r=t(1),o=t(0),i=t(36),a=t(5),s=t(32),c=t(69),l=t(146),u=/MSIE .\./.test(s),p=o.Function,d=function(n){return function(e,t){var r=l(arguments.length,1)>2,o=a(e)?e:p(e),s=r?c(arguments,2):void 0;return n(r?function(){i(o,this,s)}:o,t)}};r({global:!0,bind:!0,forced:u},{setTimeout:d(o.setTimeout),setInterval:d(o.setInterval)})},function(n,e,t){"use strict";t.d(e,"e",(function(){return r})),t.d(e,"b",(function(){return i})),t.d(e,"j",(function(){return a})),t.d(e,"g",(function(){return c})),t.d(e,"h",(function(){return l})),t.d(e,"i",(function(){return u})),t.d(e,"c",(function(){return p})),t.d(e,"f",(function(){return d})),t.d(e,"l",(function(){return f})),t.d(e,"m",(function(){return h})),t.d(e,"d",(function(){return v})),t.d(e,"k",(function(){return g})),t.d(e,"n",(function(){return y})),t.d(e,"a",(function(){return x}));t(18),t(46),t(140),t(75),t(103),t(110),t(45),t(28),t(4),t(29),t(24),t(78),t(104),t(155),t(54),t(212),t(30),t(143);var r=/#.*$/,o=/\.(md|html)$/,i=/\/$/,a=/^[a-z]+:/i;function s(n){return decodeURI(n).replace(r,"").replace(o,"")}function c(n){return a.test(n)}function l(n){return/^mailto:/.test(n)}function u(n){return/^tel:/.test(n)}function p(n){if(c(n))return n;var e=n.match(r),t=e?e[0]:"",o=s(n);return i.test(o)?n:o+".html"+t}function d(n,e){var t=n.hash,o=function(n){var e=n.match(r);if(e)return e[0]}(e);return(!o||t===o)&&s(n.path)===s(e)}function f(n,e,t){if(c(e))return{type:"external",path:e};t&&(e=function(n,e,t){var r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;var o=e.split("/");t&&o[o.length-1]||o.pop();for(var i=n.replace(/^\//,"").split("/"),a=0;a<i.length;a++){var s=i[a];".."===s?o.pop():"."!==s&&o.push(s)}""!==o[0]&&o.unshift("");return o.join("/")}(e,t));for(var r=s(e),o=0;o<n.length;o++)if(s(n[o].regularPath)===r)return Object.assign({},n[o],{type:"page",path:p(n[o].path)});return console.error('[vuepress] No matching page found for sidebar item "'.concat(e,'"')),{}}function h(n,e,t,r){var o=t.pages,i=t.themeConfig,a=r&&i.locales&&i.locales[r]||i;if("auto"===(n.frontmatter.sidebar||a.sidebar||i.sidebar))return m(n);var s=a.sidebar||i.sidebar;if(s){var c=function(n,e){if(Array.isArray(e))return{base:"/",config:e};for(var t in e)if(0===(r=n,/(\.html|\/)$/.test(r)?r:r+"/").indexOf(encodeURI(t)))return{base:t,config:e[t]};var r;return{}}(e,s),l=c.base,u=c.config;return"auto"===u?m(n):u?u.map((function(n){return function n(e,t,r){var o=arguments.length>3&&void 0!==arguments[3]?arguments[3]:1;if("string"==typeof e)return f(t,e,r);if(Array.isArray(e))return Object.assign(f(t,e[0],r),{title:e[1]});o>3&&console.error("[vuepress] detected a too deep nested sidebar group.");var i=e.children||[];return 0===i.length&&e.path?Object.assign(f(t,e.path,r),{title:e.title}):{type:"group",path:e.path,title:e.title,sidebarDepth:e.sidebarDepth,initialOpenGroupIndex:e.initialOpenGroupIndex,children:i.map((function(e){return n(e,t,r,o+1)})),collapsable:!1!==e.collapsable}}(n,o,l)})):[]}return[]}function m(n){var e=v(n.headers||[]);return[{type:"group",collapsable:!1,title:n.title,path:null,children:e.map((function(e){return{type:"auto",title:e.title,basePath:n.path,path:n.path+"#"+e.slug,children:e.children||[]}}))}]}function v(n){var e;return(n=n.map((function(n){return Object.assign({},n)}))).forEach((function(n){2===n.level?e=n:e&&(e.children||(e.children=[])).push(n)})),n.filter((function(n){return 2===n.level}))}function g(n){return Object.assign(n,{type:n.items&&n.items.length?"links":"link"})}function y(n){return Object.prototype.toString.call(n).match(/\[object (.*?)\]/)[1].toLowerCase()}function b(n){var e=n.frontmatter.date||n.lastUpdated||new Date,t=new Date(e);return"Invalid Date"==t&&e&&(t=new Date(e.replace(/-/g,"/"))),t.getTime()}function x(n,e){return b(e)-b(n)}},function(n,e,t){"use strict";var r=t(1),o=t(57).map;r({target:"Array",proto:!0,forced:!t(91)("map")},{map:function(n){return o(this,n,arguments.length>1?arguments[1]:void 0)}})},function(n,e,t){"use strict";var r=t(36),o=t(11),i=t(2),a=t(108),s=t(3),c=t(8),l=t(5),u=t(55),p=t(53),d=t(12),f=t(19),h=t(127),m=t(48),v=t(269),g=t(109),y=t(6)("replace"),b=Math.max,x=Math.min,_=i([].concat),w=i([].push),E=i("".indexOf),k=i("".slice),C="$0"==="a".replace(/./,"$0"),T=!!/./[y]&&""===/./[y]("a","$0");a("replace",(function(n,e,t){var i=T?"$":"$0";return[function(n,t){var r=f(this),i=null==n?void 0:m(n,y);return i?o(i,n,r,t):o(e,d(r),n,t)},function(n,o){var a=c(this),s=d(n);if("string"==typeof o&&-1===E(o,i)&&-1===E(o,"$<")){var f=t(e,a,s,o);if(f.done)return f.value}var m=l(o);m||(o=d(o));var y=a.global;if(y){var C=a.unicode;a.lastIndex=0}for(var T=[];;){var S=g(a,s);if(null===S)break;if(w(T,S),!y)break;""===d(S[0])&&(a.lastIndex=h(s,p(a.lastIndex),C))}for(var A,O="",j=0,I=0;I<T.length;I++){for(var P=d((S=T[I])[0]),z=b(x(u(S.index),s.length),0),D=[],L=1;L<S.length;L++)w(D,void 0===(A=S[L])?A:String(A));var N=S.groups;if(m){var B=_([P],D,z,s);void 0!==N&&w(B,N);var R=d(r(o,void 0,B))}else R=v(P,s,z,D,N,o);z>=j&&(O+=k(s,j,z)+R,j=z+P.length)}return O+k(s,j)}]}),!!s((function(){var n=/./;return n.exec=function(){var n=[];return n.groups={a:"7"},n},"7"!=="".replace(n,"$<a>")}))||!C||T)},function(n,e,t){"use strict";var r=t(3);n.exports=function(n,e){var t=[][n];return!!t&&r((function(){t.call(null,e||function(){return 1},1)}))}},function(n,e,t){var r=t(37);n.exports=function(n,e){var t=n[e];return null==t?void 0:r(t)}},function(n,e){n.exports=function(n,e){return{enumerable:!(1&n),configurable:!(2&n),writable:!(4&n),value:e}}},function(n,e){n.exports=function(n){return null!=n&&"object"==typeof n}},function(n,e,t){"use strict";t.d(e,"a",(function(){return i}));t(76),t(71),t(24),t(4),t(380),t(28),t(29),t(177),t(381),t(99);function r(n,e,t){return e in n?Object.defineProperty(n,e,{value:t,enumerable:!0,configurable:!0,writable:!0}):n[e]=t,n}function o(n,e){var t=Object.keys(n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(n);e&&(r=r.filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable}))),t.push.apply(t,r)}return t}function i(n){for(var e=1;e<arguments.length;e++){var t=null!=arguments[e]?arguments[e]:{};e%2?o(Object(t),!0).forEach((function(e){r(n,e,t[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(n,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(e){Object.defineProperty(n,e,Object.getOwnPropertyDescriptor(t,e))}))}return n}},function(n,e,t){var r,o,i=t(0),a=t(32),s=i.process,c=i.Deno,l=s&&s.versions||c&&c.version,u=l&&l.v8;u&&(o=(r=u.split("."))[0]>0&&r[0]<4?1:+(r[0]+r[1])),!o&&a&&(!(r=a.match(/Edge\/(\d+)/))||r[1]>=74)&&(r=a.match(/Chrome\/(\d+)/))&&(o=+r[1]),n.exports=o},function(n,e,t){var r=t(55),o=Math.min;n.exports=function(n){return n>0?o(r(n),9007199254740991):0}},function(n,e,t){"use strict";var r=t(1),o=t(0),i=t(3),a=t(60),s=t(9),c=t(16),l=t(23),u=t(70),p=t(147),d=t(91),f=t(6),h=t(52),m=f("isConcatSpreadable"),v=o.TypeError,g=h>=51||!i((function(){var n=[];return n[m]=!1,n.concat()[0]!==n})),y=d("concat"),b=function(n){if(!s(n))return!1;var e=n[m];return void 0!==e?!!e:a(n)};r({target:"Array",proto:!0,forced:!g||!y},{concat:function(n){var e,t,r,o,i,a=c(this),s=p(a,0),d=0;for(e=-1,r=arguments.length;e<r;e++)if(b(i=-1===e?a:arguments[e])){if(d+(o=l(i))>9007199254740991)throw v("Maximum allowed index exceeded");for(t=0;t<o;t++,d++)t in i&&u(s,d,i[t])}else{if(d>=9007199254740991)throw v("Maximum allowed index exceeded");u(s,d++,i)}return s.length=d,s}})},function(n,e){var t=Math.ceil,r=Math.floor;n.exports=function(n){var e=+n;return e!=e||0===e?0:(e>0?r:t)(e)}},function(n,e,t){var r=t(2),o=t(37),i=t(64),a=r(r.bind);n.exports=function(n,e){return o(n),void 0===e?n:i?a(n,e):function(){return n.apply(e,arguments)}}},function(n,e,t){var r=t(56),o=t(2),i=t(63),a=t(16),s=t(23),c=t(147),l=o([].push),u=function(n){var e=1==n,t=2==n,o=3==n,u=4==n,p=6==n,d=7==n,f=5==n||p;return function(h,m,v,g){for(var y,b,x=a(h),_=i(x),w=r(m,v),E=s(_),k=0,C=g||c,T=e?C(h,E):t||d?C(h,0):void 0;E>k;k++)if((f||k in _)&&(b=w(y=_[k],k,x),n))if(e)T[k]=b;else if(b)switch(n){case 3:return!0;case 5:return y;case 6:return k;case 2:l(T,y)}else switch(n){case 4:return!1;case 7:l(T,y)}return p?-1:o||u?u:T}};n.exports={forEach:u(0),map:u(1),filter:u(2),some:u(3),every:u(4),find:u(5),findIndex:u(6),filterReject:u(7)}},function(n,e,t){var r=t(160),o=t(117).concat("length","prototype");e.f=Object.getOwnPropertyNames||function(n){return r(n,o)}},function(n,e,t){var r=t(13).f,o=t(10),i=t(6)("toStringTag");n.exports=function(n,e,t){n&&!t&&(n=n.prototype),n&&!o(n,i)&&r(n,i,{configurable:!0,value:e})}},function(n,e,t){var r=t(25);n.exports=Array.isArray||function(n){return"Array"==r(n)}},function(n,e,t){var r=t(7),o=t(67).EXISTS,i=t(2),a=t(13).f,s=Function.prototype,c=i(s.toString),l=/function\b(?:\s|\/\*[\S\s]*?\*\/|\/\/[^\n\r]*[\n\r]+)*([^\s(/]*)/,u=i(l.exec);r&&!o&&a(s,"name",{configurable:!0,get:function(){try{return u(l,c(this))[1]}catch(n){return""}}})},function(n,e,t){var r=t(72),o=t(273),i=t(274),a=r?r.toStringTag:void 0;n.exports=function(n){return null==n?void 0===n?"[object Undefined]":"[object Null]":a&&a in Object(n)?o(n):i(n)}},function(n,e,t){var r=t(0),o=t(2),i=t(3),a=t(25),s=r.Object,c=o("".split);n.exports=i((function(){return!s("z").propertyIsEnumerable(0)}))?function(n){return"String"==a(n)?c(n,""):s(n)}:s},function(n,e,t){var r=t(3);n.exports=!r((function(){var n=function(){}.bind();return"function"!=typeof n||n.hasOwnProperty("prototype")}))},function(n,e){n.exports={}},function(n,e){n.exports={}},function(n,e,t){var r=t(7),o=t(10),i=Function.prototype,a=r&&Object.getOwnPropertyDescriptor,s=o(i,"name"),c=s&&"something"===function(){}.name,l=s&&(!r||r&&a(i,"name").configurable);n.exports={EXISTS:s,PROPER:c,CONFIGURABLE:l}},function(n,e,t){var r=t(2),o=t(8),i=t(240);n.exports=Object.setPrototypeOf||("__proto__"in{}?function(){var n,e=!1,t={};try{(n=r(Object.getOwnPropertyDescriptor(Object.prototype,"__proto__").set))(t,[]),e=t instanceof Array}catch(n){}return function(t,r){return o(t),i(r),e?n(t,r):t.__proto__=r,t}}():void 0)},function(n,e,t){var r=t(2);n.exports=r([].slice)},function(n,e,t){"use strict";var r=t(82),o=t(13),i=t(49);n.exports=function(n,e,t){var a=r(e);a in n?o.f(n,a,i(0,t)):n[a]=t}},function(n,e,t){"use strict";var r=t(1),o=t(0),i=t(17),a=t(36),s=t(11),c=t(2),l=t(26),u=t(7),p=t(113),d=t(3),f=t(10),h=t(60),m=t(5),v=t(9),g=t(35),y=t(83),b=t(8),x=t(16),_=t(20),w=t(82),E=t(12),k=t(49),C=t(34),T=t(85),S=t(58),A=t(184),O=t(121),j=t(38),I=t(13),P=t(114),z=t(118),D=t(69),L=t(14),N=t(79),B=t(86),R=t(65),$=t(80),M=t(6),F=t(185),G=t(186),U=t(59),V=t(39),H=t(57).forEach,q=B("hidden"),X=M("toPrimitive"),J=V.set,Y=V.getterFor("Symbol"),W=Object.prototype,Z=o.Symbol,K=Z&&Z.prototype,Q=o.TypeError,nn=o.QObject,en=i("JSON","stringify"),tn=j.f,rn=I.f,on=A.f,an=z.f,sn=c([].push),cn=N("symbols"),ln=N("op-symbols"),un=N("string-to-symbol-registry"),pn=N("symbol-to-string-registry"),dn=N("wks"),fn=!nn||!nn.prototype||!nn.prototype.findChild,hn=u&&d((function(){return 7!=C(rn({},"a",{get:function(){return rn(this,"a",{value:7}).a}})).a}))?function(n,e,t){var r=tn(W,e);r&&delete W[e],rn(n,e,t),r&&n!==W&&rn(W,e,r)}:rn,mn=function(n,e){var t=cn[n]=C(K);return J(t,{type:"Symbol",tag:n,description:e}),u||(t.description=e),t},vn=function(n,e,t){n===W&&vn(ln,e,t),b(n);var r=w(e);return b(t),f(cn,r)?(t.enumerable?(f(n,q)&&n[q][r]&&(n[q][r]=!1),t=C(t,{enumerable:k(0,!1)})):(f(n,q)||rn(n,q,k(1,{})),n[q][r]=!0),hn(n,r,t)):rn(n,r,t)},gn=function(n,e){b(n);var t=_(e),r=T(t).concat(_n(t));return H(r,(function(e){u&&!s(yn,t,e)||vn(n,e,t[e])})),n},yn=function(n){var e=w(n),t=s(an,this,e);return!(this===W&&f(cn,e)&&!f(ln,e))&&(!(t||!f(this,e)||!f(cn,e)||f(this,q)&&this[q][e])||t)},bn=function(n,e){var t=_(n),r=w(e);if(t!==W||!f(cn,r)||f(ln,r)){var o=tn(t,r);return!o||!f(cn,r)||f(t,q)&&t[q][r]||(o.enumerable=!0),o}},xn=function(n){var e=on(_(n)),t=[];return H(e,(function(n){f(cn,n)||f(R,n)||sn(t,n)})),t},_n=function(n){var e=n===W,t=on(e?ln:_(n)),r=[];return H(t,(function(n){!f(cn,n)||e&&!f(W,n)||sn(r,cn[n])})),r};(p||(L(K=(Z=function(){if(g(K,this))throw Q("Symbol is not a constructor");var n=arguments.length&&void 0!==arguments[0]?E(arguments[0]):void 0,e=$(n),t=function(n){this===W&&s(t,ln,n),f(this,q)&&f(this[q],e)&&(this[q][e]=!1),hn(this,e,k(1,n))};return u&&fn&&hn(W,e,{configurable:!0,set:t}),mn(e,n)}).prototype,"toString",(function(){return Y(this).tag})),L(Z,"withoutSetter",(function(n){return mn($(n),n)})),z.f=yn,I.f=vn,P.f=gn,j.f=bn,S.f=A.f=xn,O.f=_n,F.f=function(n){return mn(M(n),n)},u&&(rn(K,"description",{configurable:!0,get:function(){return Y(this).description}}),l||L(W,"propertyIsEnumerable",yn,{unsafe:!0}))),r({global:!0,wrap:!0,forced:!p,sham:!p},{Symbol:Z}),H(T(dn),(function(n){G(n)})),r({target:"Symbol",stat:!0,forced:!p},{for:function(n){var e=E(n);if(f(un,e))return un[e];var t=Z(e);return un[e]=t,pn[t]=e,t},keyFor:function(n){if(!y(n))throw Q(n+" is not a symbol");if(f(pn,n))return pn[n]},useSetter:function(){fn=!0},useSimple:function(){fn=!1}}),r({target:"Object",stat:!0,forced:!p,sham:!u},{create:function(n,e){return void 0===e?C(n):gn(C(n),e)},defineProperty:vn,defineProperties:gn,getOwnPropertyDescriptor:bn}),r({target:"Object",stat:!0,forced:!p},{getOwnPropertyNames:xn,getOwnPropertySymbols:_n}),r({target:"Object",stat:!0,forced:d((function(){O.f(1)}))},{getOwnPropertySymbols:function(n){return O.f(x(n))}}),en)&&r({target:"JSON",stat:!0,forced:!p||d((function(){var n=Z();return"[null]"!=en([n])||"{}"!=en({a:n})||"{}"!=en(Object(n))}))},{stringify:function(n,e,t){var r=D(arguments),o=e;if((v(e)||void 0!==n)&&!y(n))return h(e)||(e=function(n,e){if(m(o)&&(e=s(o,this,n,e)),!y(e))return e}),r[1]=e,a(en,null,r)}});if(!K[X]){var wn=K.valueOf;L(K,X,(function(n){return s(wn,this)}))}U(Z,"Symbol"),R[q]=!0},function(n,e,t){var r=t(33).Symbol;n.exports=r},function(n,e,t){"use strict";t.d(e,"a",(function(){return i}));t(78);var r=t(74);t(71),t(92),t(4),t(126),t(21),t(22),t(187);var o=t(100);t(40),t(30);function i(n){return function(n){if(Array.isArray(n))return Object(r.a)(n)}(n)||function(n){if("undefined"!=typeof Symbol&&null!=n[Symbol.iterator]||null!=n["@@iterator"])return Array.from(n)}(n)||Object(o.a)(n)||function(){throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}},function(n,e,t){"use strict";function r(n,e){(null==e||e>n.length)&&(e=n.length);for(var t=0,r=new Array(e);t<e;t++)r[t]=n[t];return r}t.d(e,"a",(function(){return r}))},function(n,e,t){"use strict";t(18);var r,o,i=t(1),a=t(0),s=t(11),c=t(2),l=t(5),u=t(9),p=(r=!1,(o=/[ac]/).exec=function(){return r=!0,/./.exec.apply(this,arguments)},!0===o.test("abc")&&r),d=a.Error,f=c(/./.test);i({target:"RegExp",proto:!0,forced:!p},{test:function(n){var e=this.exec;if(!l(e))return f(this,n);var t=s(e,this,n);if(null!==t&&!u(t))throw new d("RegExp exec method returned something other than an Object or null");return!!t}})},function(n,e,t){var r=t(1),o=t(16),i=t(85);r({target:"Object",stat:!0,forced:t(3)((function(){i(1)}))},{keys:function(n){return i(o(n))}})},function(n,e,t){var r=t(0),o=t(123),i=t(5),a=t(25),s=t(6)("toStringTag"),c=r.Object,l="Arguments"==a(function(){return arguments}());n.exports=o?a:function(n){var e,t,r;return void 0===n?"Undefined":null===n?"Null":"string"==typeof(t=function(n,e){try{return n[e]}catch(n){}}(e=c(n),s))?t:l?a(e):"Object"==(r=a(e))&&i(e.callee)?"Arguments":r}},function(n,e,t){t(1)({target:"Array",stat:!0},{isArray:t(60)})},function(n,e,t){var r=t(26),o=t(111);(n.exports=function(n,e){return o[n]||(o[n]=void 0!==e?e:{})})("versions",[]).push({version:"3.21.1",mode:r?"pure":"global",copyright:"© 2014-2022 Denis Pushkarev (zloirock.ru)",license:"https://github.com/zloirock/core-js/blob/v3.21.1/LICENSE",source:"https://github.com/zloirock/core-js"})},function(n,e,t){var r=t(2),o=0,i=Math.random(),a=r(1..toString);n.exports=function(n){return"Symbol("+(void 0===n?"":n)+")_"+a(++o+i,36)}},function(n,e,t){var r=t(0),o=t(9),i=r.document,a=o(i)&&o(i.createElement);n.exports=function(n){return a?i.createElement(n):{}}},function(n,e,t){var r=t(159),o=t(83);n.exports=function(n){var e=r(n,"string");return o(e)?e:e+""}},function(n,e,t){var r=t(0),o=t(17),i=t(5),a=t(35),s=t(156),c=r.Object;n.exports=s?function(n){return"symbol"==typeof n}:function(n){var e=o("Symbol");return i(e)&&a(e.prototype,c(n))}},function(n,e,t){var r=t(0).String;n.exports=function(n){try{return r(n)}catch(n){return"Object"}}},function(n,e,t){var r=t(160),o=t(117);n.exports=Object.keys||function(n){return r(n,o)}},function(n,e,t){var r=t(79),o=t(80),i=r("keys");n.exports=function(n){return i[n]||(i[n]=o(n))}},function(n,e,t){var r=t(2),o=t(5),i=t(111),a=r(Function.toString);o(i.inspectSource)||(i.inspectSource=function(n){return a(n)}),n.exports=i.inspectSource},function(n,e,t){var r=t(2),o=t(3),i=t(5),a=t(77),s=t(17),c=t(87),l=function(){},u=[],p=s("Reflect","construct"),d=/^\s*(?:class|function)\b/,f=r(d.exec),h=!d.exec(l),m=function(n){if(!i(n))return!1;try{return p(l,u,n),!0}catch(n){return!1}},v=function(n){if(!i(n))return!1;switch(a(n)){case"AsyncFunction":case"GeneratorFunction":case"AsyncGeneratorFunction":return!1}try{return h||!!f(d,c(n))}catch(n){return!0}};v.sham=!0,n.exports=!p||o((function(){var n;return m(m.call)||!m(Object)||!m((function(){n=!0}))||n}))?v:m},function(n,e,t){var r=t(25),o=t(0);n.exports="process"==r(o.process)},function(n,e,t){"use strict";t.d(e,"a",(function(){return o}));t(4);function r(n,e,t,r,o,i,a){try{var s=n[i](a),c=s.value}catch(n){return void t(n)}s.done?e(c):Promise.resolve(c).then(r,o)}function o(n){return function(){var e=this,t=arguments;return new Promise((function(o,i){var a=n.apply(e,t);function s(n){r(a,o,i,s,c,"next",n)}function c(n){r(a,o,i,s,c,"throw",n)}s(void 0)}))}}},function(n,e,t){var r=t(3),o=t(6),i=t(52),a=o("species");n.exports=function(n){return i>=51||!r((function(){var e=[];return(e.constructor={})[a]=function(){return{foo:1}},1!==e[n](Boolean).foo}))}},function(n,e,t){"use strict";var r=t(1),o=t(7),i=t(0),a=t(2),s=t(10),c=t(5),l=t(35),u=t(12),p=t(13).f,d=t(119),f=i.Symbol,h=f&&f.prototype;if(o&&c(f)&&(!("description"in h)||void 0!==f().description)){var m={},v=function(){var n=arguments.length<1||void 0===arguments[0]?void 0:u(arguments[0]),e=l(h,this)?new f(n):void 0===n?f():f(n);return""===n&&(m[e]=!0),e};d(v,f),v.prototype=h,h.constructor=v;var g="Symbol(test)"==String(f("test")),y=a(h.toString),b=a(h.valueOf),x=/^Symbol\((.*)\)[^)]+$/,_=a("".replace),w=a("".slice);p(h,"description",{configurable:!0,get:function(){var n=b(this),e=y(n);if(s(m,n))return"";var t=g?w(e,7,-1):_(e,x,"$1");return""===t?void 0:t}}),r({global:!0,forced:!0},{Symbol:v})}},function(n,e,t){"use strict";var r,o,i=t(11),a=t(2),s=t(12),c=t(149),l=t(107),u=t(79),p=t(34),d=t(39).get,f=t(225),h=t(230),m=u("native-string-replace",String.prototype.replace),v=RegExp.prototype.exec,g=v,y=a("".charAt),b=a("".indexOf),x=a("".replace),_=a("".slice),w=(o=/b*/g,i(v,r=/a/,"a"),i(v,o,"a"),0!==r.lastIndex||0!==o.lastIndex),E=l.BROKEN_CARET,k=void 0!==/()??/.exec("")[1];(w||k||E||f||h)&&(g=function(n){var e,t,r,o,a,l,u,f=this,h=d(f),C=s(n),T=h.raw;if(T)return T.lastIndex=f.lastIndex,e=i(g,T,C),f.lastIndex=T.lastIndex,e;var S=h.groups,A=E&&f.sticky,O=i(c,f),j=f.source,I=0,P=C;if(A&&(O=x(O,"y",""),-1===b(O,"g")&&(O+="g"),P=_(C,f.lastIndex),f.lastIndex>0&&(!f.multiline||f.multiline&&"\n"!==y(C,f.lastIndex-1))&&(j="(?: "+j+")",P=" "+P,I++),t=new RegExp("^(?:"+j+")",O)),k&&(t=new RegExp("^"+j+"$(?!\\s)",O)),w&&(r=f.lastIndex),o=i(v,A?t:f,P),A?o?(o.input=_(o.input,I),o[0]=_(o[0],I),o.index=f.lastIndex,f.lastIndex+=o[0].length):f.lastIndex=0:w&&o&&(f.lastIndex=f.global?o.index+o[0].length:r),k&&o&&o.length>1&&i(m,o[0],t,(function(){for(a=1;a<arguments.length-2;a++)void 0===arguments[a]&&(o[a]=void 0)})),o&&S)for(o.groups=l=p(null),a=0;a<S.length;a++)l[(u=S[a])[0]]=o[u[1]];return o}),n.exports=g},function(n,e,t){var r=t(278),o=t(279),i=t(280),a=t(281),s=t(282);function c(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}c.prototype.clear=r,c.prototype.delete=o,c.prototype.get=i,c.prototype.has=a,c.prototype.set=s,n.exports=c},function(n,e,t){var r=t(194);n.exports=function(n,e){for(var t=n.length;t--;)if(r(n[t][0],e))return t;return-1}},function(n,e,t){var r=t(41)(Object,"create");n.exports=r},function(n,e,t){var r=t(300);n.exports=function(n,e){var t=n.__data__;return r(e)?t["string"==typeof e?"string":"hash"]:t.map}},function(n,e,t){var r=t(135);n.exports=function(n){if("string"==typeof n||r(n))return n;var e=n+"";return"0"==e&&1/n==-1/0?"-0":e}},function(n,e,t){var r=t(1),o=t(7),i=t(13).f;r({target:"Object",stat:!0,forced:Object.defineProperty!==i,sham:!o},{defineProperty:i})},function(n,e,t){"use strict";t.d(e,"a",(function(){return o}));t(42),t(4),t(61),t(187),t(21),t(18),t(75);var r=t(74);function o(n,e){if(n){if("string"==typeof n)return Object(r.a)(n,e);var t=Object.prototype.toString.call(n).slice(8,-1);return"Object"===t&&n.constructor&&(t=n.constructor.name),"Map"===t||"Set"===t?Array.from(n):"Arguments"===t||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t)?Object(r.a)(n,e):void 0}}},function(n,e,t){var r,o;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(o="function"==typeof(r=function(){var n,e,t={version:"0.2.0"},r=t.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function o(n,e,t){return n<e?e:n>t?t:n}function i(n){return 100*(-1+n)}t.configure=function(n){var e,t;for(e in n)void 0!==(t=n[e])&&n.hasOwnProperty(e)&&(r[e]=t);return this},t.status=null,t.set=function(n){var e=t.isStarted();n=o(n,r.minimum,1),t.status=1===n?null:n;var c=t.render(!e),l=c.querySelector(r.barSelector),u=r.speed,p=r.easing;return c.offsetWidth,a((function(e){""===r.positionUsing&&(r.positionUsing=t.getPositioningCSS()),s(l,function(n,e,t){var o;return(o="translate3d"===r.positionUsing?{transform:"translate3d("+i(n)+"%,0,0)"}:"translate"===r.positionUsing?{transform:"translate("+i(n)+"%,0)"}:{"margin-left":i(n)+"%"}).transition="all "+e+"ms "+t,o}(n,u,p)),1===n?(s(c,{transition:"none",opacity:1}),c.offsetWidth,setTimeout((function(){s(c,{transition:"all "+u+"ms linear",opacity:0}),setTimeout((function(){t.remove(),e()}),u)}),u)):setTimeout(e,u)})),this},t.isStarted=function(){return"number"==typeof t.status},t.start=function(){t.status||t.set(0);var n=function(){setTimeout((function(){t.status&&(t.trickle(),n())}),r.trickleSpeed)};return r.trickle&&n(),this},t.done=function(n){return n||t.status?t.inc(.3+.5*Math.random()).set(1):this},t.inc=function(n){var e=t.status;return e?("number"!=typeof n&&(n=(1-e)*o(Math.random()*e,.1,.95)),e=o(e+n,0,.994),t.set(e)):t.start()},t.trickle=function(){return t.inc(Math.random()*r.trickleRate)},n=0,e=0,t.promise=function(r){return r&&"resolved"!==r.state()?(0===e&&t.start(),n++,e++,r.always((function(){0==--e?(n=0,t.done()):t.set((n-e)/n)})),this):this},t.render=function(n){if(t.isRendered())return document.getElementById("nprogress");l(document.documentElement,"nprogress-busy");var e=document.createElement("div");e.id="nprogress",e.innerHTML=r.template;var o,a=e.querySelector(r.barSelector),c=n?"-100":i(t.status||0),u=document.querySelector(r.parent);return s(a,{transition:"all 0 linear",transform:"translate3d("+c+"%,0,0)"}),r.showSpinner||(o=e.querySelector(r.spinnerSelector))&&d(o),u!=document.body&&l(u,"nprogress-custom-parent"),u.appendChild(e),e},t.remove=function(){u(document.documentElement,"nprogress-busy"),u(document.querySelector(r.parent),"nprogress-custom-parent");var n=document.getElementById("nprogress");n&&d(n)},t.isRendered=function(){return!!document.getElementById("nprogress")},t.getPositioningCSS=function(){var n=document.body.style,e="WebkitTransform"in n?"Webkit":"MozTransform"in n?"Moz":"msTransform"in n?"ms":"OTransform"in n?"O":"";return e+"Perspective"in n?"translate3d":e+"Transform"in n?"translate":"margin"};var a=function(){var n=[];function e(){var t=n.shift();t&&t(e)}return function(t){n.push(t),1==n.length&&e()}}(),s=function(){var n=["Webkit","O","Moz","ms"],e={};function t(t){return t=t.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(n,e){return e.toUpperCase()})),e[t]||(e[t]=function(e){var t=document.body.style;if(e in t)return e;for(var r,o=n.length,i=e.charAt(0).toUpperCase()+e.slice(1);o--;)if((r=n[o]+i)in t)return r;return e}(t))}function r(n,e,r){e=t(e),n.style[e]=r}return function(n,e){var t,o,i=arguments;if(2==i.length)for(t in e)void 0!==(o=e[t])&&e.hasOwnProperty(t)&&r(n,t,o);else r(n,i[1],i[2])}}();function c(n,e){return("string"==typeof n?n:p(n)).indexOf(" "+e+" ")>=0}function l(n,e){var t=p(n),r=t+e;c(t,e)||(n.className=r.substring(1))}function u(n,e){var t,r=p(n);c(n,e)&&(t=r.replace(" "+e+" "," "),n.className=t.substring(1,t.length-1))}function p(n){return(" "+(n.className||"")+" ").replace(/\s+/gi," ")}function d(n){n&&n.parentNode&&n.parentNode.removeChild(n)}return t})?r.call(e,t,e,n):r)||(n.exports=o)},function(n){n.exports=JSON.parse('{"name":"vuepress-plugin-comment","version":"0.7.3","description":"Comment plugin in vuepress, such as Gitalk, Valine...","main":"index.js","scripts":{"test":"echo \\"Error: no test specified\\" && exit 1"},"repository":{"type":"git","url":"git+ssh://git@github.com/dongyuanxin/vuepress-plugin-comment.git"},"keywords":["vuepress","comment","plugin","vue","gitalk","valine"],"author":"dongyuanxin","license":"MIT","bugs":{"url":"https://github.com/dongyuanxin/vuepress-plugin-comment/issues"},"homepage":"https://github.com/dongyuanxin/vuepress-plugin-comment#readme","dependencies":{"ejs":"^2.6.1","gitalk":"^1.5.0","gitalk-fix":"^1.5.2","i":"^0.3.6","npm":"^6.9.0","valine":"^1.3.9"}}')},function(n,e,t){"use strict";var r=t(36),o=t(11),i=t(2),a=t(108),s=t(148),c=t(8),l=t(19),u=t(124),p=t(127),d=t(53),f=t(12),h=t(48),m=t(125),v=t(109),g=t(93),y=t(107),b=t(3),x=y.UNSUPPORTED_Y,_=Math.min,w=[].push,E=i(/./.exec),k=i(w),C=i("".slice);a("split",(function(n,e,t){var i;return i="c"=="abbc".split(/(b)*/)[1]||4!="test".split(/(?:)/,-1).length||2!="ab".split(/(?:ab)*/).length||4!=".".split(/(.?)(.?)/).length||".".split(/()()/).length>1||"".split(/.?/).length?function(n,t){var i=f(l(this)),a=void 0===t?4294967295:t>>>0;if(0===a)return[];if(void 0===n)return[i];if(!s(n))return o(e,i,n,a);for(var c,u,p,d=[],h=(n.ignoreCase?"i":"")+(n.multiline?"m":"")+(n.unicode?"u":"")+(n.sticky?"y":""),v=0,y=new RegExp(n.source,h+"g");(c=o(g,y,i))&&!((u=y.lastIndex)>v&&(k(d,C(i,v,c.index)),c.length>1&&c.index<i.length&&r(w,d,m(c,1)),p=c[0].length,v=u,d.length>=a));)y.lastIndex===c.index&&y.lastIndex++;return v===i.length?!p&&E(y,"")||k(d,""):k(d,C(i,v)),d.length>a?m(d,0,a):d}:"0".split(void 0,0).length?function(n,t){return void 0===n&&0===t?[]:o(e,this,n,t)}:e,[function(e,t){var r=l(this),a=null==e?void 0:h(e,n);return a?o(a,e,r,t):o(i,f(r),e,t)},function(n,r){var o=c(this),a=f(n),s=t(i,o,a,r,i!==e);if(s.done)return s.value;var l=u(o,RegExp),h=o.unicode,m=(o.ignoreCase?"i":"")+(o.multiline?"m":"")+(o.unicode?"u":"")+(x?"g":"y"),g=new l(x?"^(?:"+o.source+")":o,m),y=void 0===r?4294967295:r>>>0;if(0===y)return[];if(0===a.length)return null===v(g,a)?[a]:[];for(var b=0,w=0,E=[];w<a.length;){g.lastIndex=x?0:w;var T,S=v(g,x?C(a,w):a);if(null===S||(T=_(d(g.lastIndex+(x?w:0)),a.length))===b)w=p(a,w,h);else{if(k(E,C(a,b,w)),E.length===y)return E;for(var A=1;A<=S.length-1;A++)if(k(E,S[A]),E.length===y)return E;w=b=T}}return k(E,C(a,b)),E}]}),!!b((function(){var n=/(?:)/,e=n.exec;n.exec=function(){return e.apply(this,arguments)};var t="ab".split(n);return 2!==t.length||"a"!==t[0]||"b"!==t[1]})),x)},function(n,e,t){"use strict";var r=t(1),o=t(2),i=t(115).indexOf,a=t(47),s=o([].indexOf),c=!!s&&1/s([1],1,-0)<0,l=a("indexOf");r({target:"Array",proto:!0,forced:c||!l},{indexOf:function(n){var e=arguments.length>1?arguments[1]:void 0;return c?s(this,n,e)||0:i(this,n,e)}})},function(n,e,t){var r=t(3),o=t(5),i=/#|\.prototype\./,a=function(n,e){var t=c[s(n)];return t==u||t!=l&&(o(e)?r(e):!!e)},s=a.normalize=function(n){return String(n).replace(i,".").toLowerCase()},c=a.data={},l=a.NATIVE="N",u=a.POLYFILL="P";n.exports=a},function(n,e,t){var r=t(77),o=t(48),i=t(66),a=t(6)("iterator");n.exports=function(n){if(null!=n)return o(n,a)||o(n,"@@iterator")||i[r(n)]}},function(n,e,t){var r=t(3),o=t(0).RegExp,i=r((function(){var n=o("a","y");return n.lastIndex=2,null!=n.exec("abcd")})),a=i||r((function(){return!o("a","y").sticky})),s=i||r((function(){var n=o("^r","gy");return n.lastIndex=2,null!=n.exec("str")}));n.exports={BROKEN_CARET:s,MISSED_STICKY:a,UNSUPPORTED_Y:i}},function(n,e,t){"use strict";t(18);var r=t(2),o=t(14),i=t(93),a=t(3),s=t(6),c=t(27),l=s("species"),u=RegExp.prototype;n.exports=function(n,e,t,p){var d=s(n),f=!a((function(){var e={};return e[d]=function(){return 7},7!=""[n](e)})),h=f&&!a((function(){var e=!1,t=/a/;return"split"===n&&((t={}).constructor={},t.constructor[l]=function(){return t},t.flags="",t[d]=/./[d]),t.exec=function(){return e=!0,null},t[d](""),!e}));if(!f||!h||t){var m=r(/./[d]),v=e(d,""[n],(function(n,e,t,o,a){var s=r(n),c=e.exec;return c===i||c===u.exec?f&&!a?{done:!0,value:m(e,t,o)}:{done:!0,value:s(t,e,o)}:{done:!1}}));o(String.prototype,n,v[0]),o(u,d,v[1])}p&&c(u[d],"sham",!0)}},function(n,e,t){var r=t(0),o=t(11),i=t(8),a=t(5),s=t(25),c=t(93),l=r.TypeError;n.exports=function(n,e){var t=n.exec;if(a(t)){var r=o(t,n,e);return null!==r&&i(r),r}if("RegExp"===s(n))return o(c,n,e);throw l("RegExp#exec called on incompatible receiver")}},function(n,e,t){"use strict";var r=t(1),o=t(2),i=t(63),a=t(20),s=t(47),c=o([].join),l=i!=Object,u=s("join",",");r({target:"Array",proto:!0,forced:l||!u},{join:function(n){return c(a(this),void 0===n?",":n)}})},function(n,e,t){var r=t(0),o=t(112),i=r["__core-js_shared__"]||o("__core-js_shared__",{});n.exports=i},function(n,e,t){var r=t(0),o=Object.defineProperty;n.exports=function(n,e){try{o(r,n,{value:e,configurable:!0,writable:!0})}catch(t){r[n]=e}return e}},function(n,e,t){var r=t(52),o=t(3);n.exports=!!Object.getOwnPropertySymbols&&!o((function(){var n=Symbol();return!String(n)||!(Object(n)instanceof Symbol)||!Symbol.sham&&r&&r<41}))},function(n,e,t){var r=t(7),o=t(157),i=t(13),a=t(8),s=t(20),c=t(85);e.f=r&&!o?Object.defineProperties:function(n,e){a(n);for(var t,r=s(e),o=c(e),l=o.length,u=0;l>u;)i.f(n,t=o[u++],r[t]);return n}},function(n,e,t){var r=t(20),o=t(116),i=t(23),a=function(n){return function(e,t,a){var s,c=r(e),l=i(c),u=o(a,l);if(n&&t!=t){for(;l>u;)if((s=c[u++])!=s)return!0}else for(;l>u;u++)if((n||u in c)&&c[u]===t)return n||u||0;return!n&&-1}};n.exports={includes:a(!0),indexOf:a(!1)}},function(n,e,t){var r=t(55),o=Math.max,i=Math.min;n.exports=function(n,e){var t=r(n);return t<0?o(t+e,0):i(t,e)}},function(n,e){n.exports=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"]},function(n,e,t){"use strict";var r={}.propertyIsEnumerable,o=Object.getOwnPropertyDescriptor,i=o&&!r.call({1:2},1);e.f=i?function(n){var e=o(this,n);return!!e&&e.enumerable}:r},function(n,e,t){var r=t(10),o=t(120),i=t(38),a=t(13);n.exports=function(n,e,t){for(var s=o(e),c=a.f,l=i.f,u=0;u<s.length;u++){var p=s[u];r(n,p)||t&&r(t,p)||c(n,p,l(e,p))}}},function(n,e,t){var r=t(17),o=t(2),i=t(58),a=t(121),s=t(8),c=o([].concat);n.exports=r("Reflect","ownKeys")||function(n){var e=i.f(s(n)),t=a.f;return t?c(e,t(n)):e}},function(n,e){e.f=Object.getOwnPropertySymbols},function(n,e,t){var r=t(0),o=t(10),i=t(5),a=t(16),s=t(86),c=t(164),l=s("IE_PROTO"),u=r.Object,p=u.prototype;n.exports=c?u.getPrototypeOf:function(n){var e=a(n);if(o(e,l))return e[l];var t=e.constructor;return i(t)&&e instanceof t?t.prototype:e instanceof u?p:null}},function(n,e,t){var r={};r[t(6)("toStringTag")]="z",n.exports="[object z]"===String(r)},function(n,e,t){var r=t(8),o=t(169),i=t(6)("species");n.exports=function(n,e){var t,a=r(n).constructor;return void 0===a||null==(t=r(a)[i])?e:o(t)}},function(n,e,t){var r=t(0),o=t(116),i=t(23),a=t(70),s=r.Array,c=Math.max;n.exports=function(n,e,t){for(var r=i(n),l=o(e,r),u=o(void 0===t?r:t,r),p=s(c(u-l,0)),d=0;l<u;l++,d++)a(p,d,n[l]);return p.length=d,p}},function(n,e,t){t(186)("iterator")},function(n,e,t){"use strict";var r=t(174).charAt;n.exports=function(n,e,t){return e+(t?r(n,e).length:1)}},function(n,e,t){var r=t(272),o=t(50),i=Object.prototype,a=i.hasOwnProperty,s=i.propertyIsEnumerable,c=r(function(){return arguments}())?r:function(n){return o(n)&&a.call(n,"callee")&&!s.call(n,"callee")};n.exports=c},function(n,e,t){var r=t(41)(t(33),"Map");n.exports=r},function(n,e){n.exports=function(n){var e=typeof n;return null!=n&&("object"==e||"function"==e)}},function(n,e,t){var r=t(292),o=t(299),i=t(301),a=t(302),s=t(303);function c(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}c.prototype.clear=r,c.prototype.delete=o,c.prototype.get=i,c.prototype.has=a,c.prototype.set=s,n.exports=c},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n){t[++e]=n})),t}},function(n,e){n.exports=function(n){return"number"==typeof n&&n>-1&&n%1==0&&n<=9007199254740991}},function(n,e,t){var r=t(31),o=t(135),i=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,a=/^\w*$/;n.exports=function(n,e){if(r(n))return!1;var t=typeof n;return!("number"!=t&&"symbol"!=t&&"boolean"!=t&&null!=n&&!o(n))||(a.test(n)||!i.test(n)||null!=e&&n in Object(e))}},function(n,e,t){var r=t(62),o=t(50);n.exports=function(n){return"symbol"==typeof n||o(n)&&"[object Symbol]"==r(n)}},function(n,e){n.exports=function(n){return n}},function(n,e,t){var r=t(1),o=t(0),i=t(59);r({global:!0},{Reflect:{}}),i(o.Reflect,"Reflect",!0)},function(n,e,t){"use strict";t.d(e,"a",(function(){return o}));t(78);t(71),t(92),t(4),t(126),t(21),t(22);var r=t(100);t(40),t(30);function o(n,e){return function(n){if(Array.isArray(n))return n}(n)||function(n,e){var t=null==n?null:"undefined"!=typeof Symbol&&n[Symbol.iterator]||n["@@iterator"];if(null!=t){var r,o,i=[],a=!0,s=!1;try{for(t=t.call(n);!(a=(r=t.next()).done)&&(i.push(r.value),!e||i.length!==e);a=!0);}catch(n){s=!0,o=n}finally{try{a||null==t.return||t.return()}finally{if(s)throw o}}return i}}(n,e)||Object(r.a)(n,e)||function(){throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}},function(n,e,t){"use strict";var r=t(1),o=t(57).some;r({target:"Array",proto:!0,forced:!t(47)("some")},{some:function(n){return o(this,n,arguments.length>1?arguments[1]:void 0)}})},function(n,e,t){"use strict";var r=t(11),o=t(108),i=t(8),a=t(53),s=t(12),c=t(19),l=t(48),u=t(127),p=t(109);o("match",(function(n,e,t){return[function(e){var t=c(this),o=null==e?void 0:l(e,n);return o?r(o,e,t):new RegExp(e)[n](s(t))},function(n){var r=i(this),o=s(n),c=t(e,r,o);if(c.done)return c.value;if(!r.global)return p(r,o);var l=r.unicode;r.lastIndex=0;for(var d,f=[],h=0;null!==(d=p(r,o));){var m=s(d[0]);f[h]=m,""===m&&(r.lastIndex=u(o,a(r.lastIndex),l)),h++}return 0===h?null:f}]}))},function(n,e,t){var r=t(6),o=t(34),i=t(13),a=r("unscopables"),s=Array.prototype;null==s[a]&&i.f(s,a,{configurable:!0,value:o(null)}),n.exports=function(n){s[a][n]=!0}},function(n,e,t){var r=function(n){"use strict";var e=Object.prototype,t=e.hasOwnProperty,r="function"==typeof Symbol?Symbol:{},o=r.iterator||"@@iterator",i=r.asyncIterator||"@@asyncIterator",a=r.toStringTag||"@@toStringTag";function s(n,e,t){return Object.defineProperty(n,e,{value:t,enumerable:!0,configurable:!0,writable:!0}),n[e]}try{s({},"")}catch(n){s=function(n,e,t){return n[e]=t}}function c(n,e,t,r){var o=e&&e.prototype instanceof p?e:p,i=Object.create(o.prototype),a=new E(r||[]);return i._invoke=function(n,e,t){var r="suspendedStart";return function(o,i){if("executing"===r)throw new Error("Generator is already running");if("completed"===r){if("throw"===o)throw i;return C()}for(t.method=o,t.arg=i;;){var a=t.delegate;if(a){var s=x(a,t);if(s){if(s===u)continue;return s}}if("next"===t.method)t.sent=t._sent=t.arg;else if("throw"===t.method){if("suspendedStart"===r)throw r="completed",t.arg;t.dispatchException(t.arg)}else"return"===t.method&&t.abrupt("return",t.arg);r="executing";var c=l(n,e,t);if("normal"===c.type){if(r=t.done?"completed":"suspendedYield",c.arg===u)continue;return{value:c.arg,done:t.done}}"throw"===c.type&&(r="completed",t.method="throw",t.arg=c.arg)}}}(n,t,a),i}function l(n,e,t){try{return{type:"normal",arg:n.call(e,t)}}catch(n){return{type:"throw",arg:n}}}n.wrap=c;var u={};function p(){}function d(){}function f(){}var h={};s(h,o,(function(){return this}));var m=Object.getPrototypeOf,v=m&&m(m(k([])));v&&v!==e&&t.call(v,o)&&(h=v);var g=f.prototype=p.prototype=Object.create(h);function y(n){["next","throw","return"].forEach((function(e){s(n,e,(function(n){return this._invoke(e,n)}))}))}function b(n,e){var r;this._invoke=function(o,i){function a(){return new e((function(r,a){!function r(o,i,a,s){var c=l(n[o],n,i);if("throw"!==c.type){var u=c.arg,p=u.value;return p&&"object"==typeof p&&t.call(p,"__await")?e.resolve(p.__await).then((function(n){r("next",n,a,s)}),(function(n){r("throw",n,a,s)})):e.resolve(p).then((function(n){u.value=n,a(u)}),(function(n){return r("throw",n,a,s)}))}s(c.arg)}(o,i,r,a)}))}return r=r?r.then(a,a):a()}}function x(n,e){var t=n.iterator[e.method];if(void 0===t){if(e.delegate=null,"throw"===e.method){if(n.iterator.return&&(e.method="return",e.arg=void 0,x(n,e),"throw"===e.method))return u;e.method="throw",e.arg=new TypeError("The iterator does not provide a 'throw' method")}return u}var r=l(t,n.iterator,e.arg);if("throw"===r.type)return e.method="throw",e.arg=r.arg,e.delegate=null,u;var o=r.arg;return o?o.done?(e[n.resultName]=o.value,e.next=n.nextLoc,"return"!==e.method&&(e.method="next",e.arg=void 0),e.delegate=null,u):o:(e.method="throw",e.arg=new TypeError("iterator result is not an object"),e.delegate=null,u)}function _(n){var e={tryLoc:n[0]};1 in n&&(e.catchLoc=n[1]),2 in n&&(e.finallyLoc=n[2],e.afterLoc=n[3]),this.tryEntries.push(e)}function w(n){var e=n.completion||{};e.type="normal",delete e.arg,n.completion=e}function E(n){this.tryEntries=[{tryLoc:"root"}],n.forEach(_,this),this.reset(!0)}function k(n){if(n){var e=n[o];if(e)return e.call(n);if("function"==typeof n.next)return n;if(!isNaN(n.length)){var r=-1,i=function e(){for(;++r<n.length;)if(t.call(n,r))return e.value=n[r],e.done=!1,e;return e.value=void 0,e.done=!0,e};return i.next=i}}return{next:C}}function C(){return{value:void 0,done:!0}}return d.prototype=f,s(g,"constructor",f),s(f,"constructor",d),d.displayName=s(f,a,"GeneratorFunction"),n.isGeneratorFunction=function(n){var e="function"==typeof n&&n.constructor;return!!e&&(e===d||"GeneratorFunction"===(e.displayName||e.name))},n.mark=function(n){return Object.setPrototypeOf?Object.setPrototypeOf(n,f):(n.__proto__=f,s(n,a,"GeneratorFunction")),n.prototype=Object.create(g),n},n.awrap=function(n){return{__await:n}},y(b.prototype),s(b.prototype,i,(function(){return this})),n.AsyncIterator=b,n.async=function(e,t,r,o,i){void 0===i&&(i=Promise);var a=new b(c(e,t,r,o),i);return n.isGeneratorFunction(t)?a:a.next().then((function(n){return n.done?n.value:a.next()}))},y(g),s(g,a,"Generator"),s(g,o,(function(){return this})),s(g,"toString",(function(){return"[object Generator]"})),n.keys=function(n){var e=[];for(var t in n)e.push(t);return e.reverse(),function t(){for(;e.length;){var r=e.pop();if(r in n)return t.value=r,t.done=!1,t}return t.done=!0,t}},n.values=k,E.prototype={constructor:E,reset:function(n){if(this.prev=0,this.next=0,this.sent=this._sent=void 0,this.done=!1,this.delegate=null,this.method="next",this.arg=void 0,this.tryEntries.forEach(w),!n)for(var e in this)"t"===e.charAt(0)&&t.call(this,e)&&!isNaN(+e.slice(1))&&(this[e]=void 0)},stop:function(){this.done=!0;var n=this.tryEntries[0].completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(n){if(this.done)throw n;var e=this;function r(t,r){return a.type="throw",a.arg=n,e.next=t,r&&(e.method="next",e.arg=void 0),!!r}for(var o=this.tryEntries.length-1;o>=0;--o){var i=this.tryEntries[o],a=i.completion;if("root"===i.tryLoc)return r("end");if(i.tryLoc<=this.prev){var s=t.call(i,"catchLoc"),c=t.call(i,"finallyLoc");if(s&&c){if(this.prev<i.catchLoc)return r(i.catchLoc,!0);if(this.prev<i.finallyLoc)return r(i.finallyLoc)}else if(s){if(this.prev<i.catchLoc)return r(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return r(i.finallyLoc)}}}},abrupt:function(n,e){for(var r=this.tryEntries.length-1;r>=0;--r){var o=this.tryEntries[r];if(o.tryLoc<=this.prev&&t.call(o,"finallyLoc")&&this.prev<o.finallyLoc){var i=o;break}}i&&("break"===n||"continue"===n)&&i.tryLoc<=e&&e<=i.finallyLoc&&(i=null);var a=i?i.completion:{};return a.type=n,a.arg=e,i?(this.method="next",this.next=i.finallyLoc,u):this.complete(a)},complete:function(n,e){if("throw"===n.type)throw n.arg;return"break"===n.type||"continue"===n.type?this.next=n.arg:"return"===n.type?(this.rval=this.arg=n.arg,this.method="return",this.next="end"):"normal"===n.type&&e&&(this.next=e),u},finish:function(n){for(var e=this.tryEntries.length-1;e>=0;--e){var t=this.tryEntries[e];if(t.finallyLoc===n)return this.complete(t.completion,t.afterLoc),w(t),u}},catch:function(n){for(var e=this.tryEntries.length-1;e>=0;--e){var t=this.tryEntries[e];if(t.tryLoc===n){var r=t.completion;if("throw"===r.type){var o=r.arg;w(t)}return o}}throw new Error("illegal catch attempt")},delegateYield:function(n,e,t){return this.delegate={iterator:k(n),resultName:e,nextLoc:t},"next"===this.method&&(this.arg=void 0),u}},n}(n.exports);try{regeneratorRuntime=r}catch(n){"object"==typeof globalThis?globalThis.regeneratorRuntime=r:Function("r","regeneratorRuntime = r")(r)}},function(n,e,t){"use strict";var r=t(2),o=t(67).PROPER,i=t(14),a=t(8),s=t(35),c=t(12),l=t(3),u=t(149),p=RegExp.prototype,d=p.toString,f=r(u),h=l((function(){return"/a/b"!=d.call({source:"a",flags:"b"})})),m=o&&"toString"!=d.name;(h||m)&&i(RegExp.prototype,"toString",(function(){var n=a(this),e=c(n.source),t=n.flags;return"/"+e+"/"+c(void 0===t&&s(p,n)&&!("flags"in p)?f(n):t)}),{unsafe:!0})},function(n,e,t){"use strict";var r=t(20),o=t(141),i=t(66),a=t(39),s=t(13).f,c=t(162),l=t(26),u=t(7),p=a.set,d=a.getterFor("Array Iterator");n.exports=c(Array,"Array",(function(n,e){p(this,{type:"Array Iterator",target:r(n),index:0,kind:e})}),(function(){var n=d(this),e=n.target,t=n.kind,r=n.index++;return!e||r>=e.length?(n.target=void 0,{value:void 0,done:!0}):"keys"==t?{value:r,done:!1}:"values"==t?{value:e[r],done:!1}:{value:[r,e[r]],done:!1}}),"values");var f=i.Arguments=i.Array;if(o("keys"),o("values"),o("entries"),!l&&u&&"values"!==f.name)try{s(f,"name",{value:"values"})}catch(n){}},function(n,e,t){var r=t(0),o=t(11),i=t(37),a=t(8),s=t(84),c=t(106),l=r.TypeError;n.exports=function(n,e){var t=arguments.length<2?c(n):e;if(i(t))return a(o(t,n));throw l(s(n)+" is not iterable")}},function(n,e,t){var r=t(0).TypeError;n.exports=function(n,e){if(n<e)throw r("Not enough arguments");return n}},function(n,e,t){var r=t(254);n.exports=function(n,e){return new(r(n))(0===e?0:e)}},function(n,e,t){var r=t(9),o=t(25),i=t(6)("match");n.exports=function(n){var e;return r(n)&&(void 0!==(e=n[i])?!!e:"RegExp"==o(n))}},function(n,e,t){"use strict";var r=t(8);n.exports=function(){var n=r(this),e="";return n.global&&(e+="g"),n.ignoreCase&&(e+="i"),n.multiline&&(e+="m"),n.dotAll&&(e+="s"),n.unicode&&(e+="u"),n.sticky&&(e+="y"),e}},function(n,e,t){var r=t(5),o=t(9),i=t(68);n.exports=function(n,e,t){var a,s;return i&&r(a=e.constructor)&&a!==t&&o(s=a.prototype)&&s!==t.prototype&&i(n,s),n}},function(n,e){n.exports=function(n){return n.webpackPolyfill||(n.deprecate=function(){},n.paths=[],n.children||(n.children=[]),Object.defineProperty(n,"loaded",{enumerable:!0,get:function(){return n.l}}),Object.defineProperty(n,"id",{enumerable:!0,get:function(){return n.i}}),n.webpackPolyfill=1),n}},function(n,e){var t=/^\s+|\s+$/g,r=/^[-+]0x[0-9a-f]+$/i,o=/^0b[01]+$/i,i=/^0o[0-7]+$/i,a=parseInt,s="object"==typeof global&&global&&global.Object===Object&&global,c="object"==typeof self&&self&&self.Object===Object&&self,l=s||c||Function("return this")(),u=Object.prototype.toString,p=Math.max,d=Math.min,f=function(){return l.Date.now()};function h(n){var e=typeof n;return!!n&&("object"==e||"function"==e)}function m(n){if("number"==typeof n)return n;if(function(n){return"symbol"==typeof n||function(n){return!!n&&"object"==typeof n}(n)&&"[object Symbol]"==u.call(n)}(n))return NaN;if(h(n)){var e="function"==typeof n.valueOf?n.valueOf():n;n=h(e)?e+"":e}if("string"!=typeof n)return 0===n?n:+n;n=n.replace(t,"");var s=o.test(n);return s||i.test(n)?a(n.slice(2),s?2:8):r.test(n)?NaN:+n}n.exports=function(n,e,t){var r,o,i,a,s,c,l=0,u=!1,v=!1,g=!0;if("function"!=typeof n)throw new TypeError("Expected a function");function y(e){var t=r,i=o;return r=o=void 0,l=e,a=n.apply(i,t)}function b(n){return l=n,s=setTimeout(_,e),u?y(n):a}function x(n){var t=n-c;return void 0===c||t>=e||t<0||v&&n-l>=i}function _(){var n=f();if(x(n))return w(n);s=setTimeout(_,function(n){var t=e-(n-c);return v?d(t,i-(n-l)):t}(n))}function w(n){return s=void 0,g&&r?y(n):(r=o=void 0,a)}function E(){var n=f(),t=x(n);if(r=arguments,o=this,c=n,t){if(void 0===s)return b(c);if(v)return s=setTimeout(_,e),y(c)}return void 0===s&&(s=setTimeout(_,e)),a}return e=m(e)||0,h(t)&&(u=!!t.leading,i=(v="maxWait"in t)?p(m(t.maxWait)||0,e):i,g="trailing"in t?!!t.trailing:g),E.cancel=function(){void 0!==s&&clearTimeout(s),l=0,r=c=o=s=void 0},E.flush=function(){return void 0===s?a:w(f())},E}},function(n,e,t){var r=t(2),o=t(19),i=t(12),a=t(154),s=r("".replace),c="["+a+"]",l=RegExp("^"+c+c+"*"),u=RegExp(c+c+"*$"),p=function(n){return function(e){var t=i(o(e));return 1&n&&(t=s(t,l,"")),2&n&&(t=s(t,u,"")),t}};n.exports={start:p(1),end:p(2),trim:p(3)}},function(n,e){n.exports="\t\n\v\f\r                　\u2028\u2029\ufeff"},function(n,e,t){var r=t(2),o=t(14),i=Date.prototype,a=r(i.toString),s=r(i.getTime);"Invalid Date"!=String(new Date(NaN))&&o(i,"toString",(function(){var n=s(this);return n==n?a(this):"Invalid Date"}))},function(n,e,t){var r=t(113);n.exports=r&&!Symbol.sham&&"symbol"==typeof Symbol.iterator},function(n,e,t){var r=t(7),o=t(3);n.exports=r&&o((function(){return 42!=Object.defineProperty((function(){}),"prototype",{value:42,writable:!1}).prototype}))},function(n,e,t){var r=t(7),o=t(3),i=t(81);n.exports=!r&&!o((function(){return 7!=Object.defineProperty(i("div"),"a",{get:function(){return 7}}).a}))},function(n,e,t){var r=t(0),o=t(11),i=t(9),a=t(83),s=t(48),c=t(238),l=t(6),u=r.TypeError,p=l("toPrimitive");n.exports=function(n,e){if(!i(n)||a(n))return n;var t,r=s(n,p);if(r){if(void 0===e&&(e="default"),t=o(r,n,e),!i(t)||a(t))return t;throw u("Can't convert object to primitive value")}return void 0===e&&(e="number"),c(n,e)}},function(n,e,t){var r=t(2),o=t(10),i=t(20),a=t(115).indexOf,s=t(65),c=r([].push);n.exports=function(n,e){var t,r=i(n),l=0,u=[];for(t in r)!o(s,t)&&o(r,t)&&c(u,t);for(;e.length>l;)o(r,t=e[l++])&&(~a(u,t)||c(u,t));return u}},function(n,e,t){var r=t(17);n.exports=r("document","documentElement")},function(n,e,t){"use strict";var r=t(1),o=t(11),i=t(26),a=t(67),s=t(5),c=t(226),l=t(122),u=t(68),p=t(59),d=t(27),f=t(14),h=t(6),m=t(66),v=t(163),g=a.PROPER,y=a.CONFIGURABLE,b=v.IteratorPrototype,x=v.BUGGY_SAFARI_ITERATORS,_=h("iterator"),w=function(){return this};n.exports=function(n,e,t,a,h,v,E){c(t,e,a);var k,C,T,S=function(n){if(n===h&&P)return P;if(!x&&n in j)return j[n];switch(n){case"keys":case"values":case"entries":return function(){return new t(this,n)}}return function(){return new t(this)}},A=e+" Iterator",O=!1,j=n.prototype,I=j[_]||j["@@iterator"]||h&&j[h],P=!x&&I||S(h),z="Array"==e&&j.entries||I;if(z&&(k=l(z.call(new n)))!==Object.prototype&&k.next&&(i||l(k)===b||(u?u(k,b):s(k[_])||f(k,_,w)),p(k,A,!0,!0),i&&(m[A]=w)),g&&"values"==h&&I&&"values"!==I.name&&(!i&&y?d(j,"name","values"):(O=!0,P=function(){return o(I,this)})),h)if(C={values:S("values"),keys:v?P:S("keys"),entries:S("entries")},E)for(T in C)(x||O||!(T in j))&&f(j,T,C[T]);else r({target:e,proto:!0,forced:x||O},C);return i&&!E||j[_]===P||f(j,_,P,{name:h}),m[e]=P,C}},function(n,e,t){"use strict";var r,o,i,a=t(3),s=t(5),c=t(34),l=t(122),u=t(14),p=t(6),d=t(26),f=p("iterator"),h=!1;[].keys&&("next"in(i=[].keys())?(o=l(l(i)))!==Object.prototype&&(r=o):h=!0),null==r||a((function(){var n={};return r[f].call(n)!==n}))?r={}:d&&(r=c(r)),s(r[f])||u(r,f,(function(){return this})),n.exports={IteratorPrototype:r,BUGGY_SAFARI_ITERATORS:h}},function(n,e,t){var r=t(3);n.exports=!r((function(){function n(){}return n.prototype.constructor=null,Object.getPrototypeOf(new n)!==n.prototype}))},function(n,e,t){var r=t(0);n.exports=r.Promise},function(n,e,t){var r=t(6),o=t(66),i=r("iterator"),a=Array.prototype;n.exports=function(n){return void 0!==n&&(o.Array===n||a[i]===n)}},function(n,e,t){var r=t(11),o=t(8),i=t(48);n.exports=function(n,e,t){var a,s;o(n);try{if(!(a=i(n,"return"))){if("throw"===e)throw t;return t}a=r(a,n)}catch(n){s=!0,a=n}if("throw"===e)throw t;if(s)throw a;return o(a),t}},function(n,e,t){var r=t(6)("iterator"),o=!1;try{var i=0,a={next:function(){return{done:!!i++}},return:function(){o=!0}};a[r]=function(){return this},Array.from(a,(function(){throw 2}))}catch(n){}n.exports=function(n,e){if(!e&&!o)return!1;var t=!1;try{var i={};i[r]=function(){return{next:function(){return{done:t=!0}}}},n(i)}catch(n){}return t}},function(n,e,t){var r=t(0),o=t(88),i=t(84),a=r.TypeError;n.exports=function(n){if(o(n))return n;throw a(i(n)+" is not a constructor")}},function(n,e,t){var r,o,i,a,s=t(0),c=t(36),l=t(56),u=t(5),p=t(10),d=t(3),f=t(161),h=t(69),m=t(81),v=t(146),g=t(171),y=t(89),b=s.setImmediate,x=s.clearImmediate,_=s.process,w=s.Dispatch,E=s.Function,k=s.MessageChannel,C=s.String,T=0,S={};try{r=s.location}catch(n){}var A=function(n){if(p(S,n)){var e=S[n];delete S[n],e()}},O=function(n){return function(){A(n)}},j=function(n){A(n.data)},I=function(n){s.postMessage(C(n),r.protocol+"//"+r.host)};b&&x||(b=function(n){v(arguments.length,1);var e=u(n)?n:E(n),t=h(arguments,1);return S[++T]=function(){c(e,void 0,t)},o(T),T},x=function(n){delete S[n]},y?o=function(n){_.nextTick(O(n))}:w&&w.now?o=function(n){w.now(O(n))}:k&&!g?(a=(i=new k).port2,i.port1.onmessage=j,o=l(a.postMessage,a)):s.addEventListener&&u(s.postMessage)&&!s.importScripts&&r&&"file:"!==r.protocol&&!d(I)?(o=I,s.addEventListener("message",j,!1)):o="onreadystatechange"in m("script")?function(n){f.appendChild(m("script")).onreadystatechange=function(){f.removeChild(this),A(n)}}:function(n){setTimeout(O(n),0)}),n.exports={set:b,clear:x}},function(n,e,t){var r=t(32);n.exports=/(?:ipad|iphone|ipod).*applewebkit/i.test(r)},function(n,e,t){var r=t(8),o=t(9),i=t(173);n.exports=function(n,e){if(r(n),o(e)&&e.constructor===n)return e;var t=i.f(n);return(0,t.resolve)(e),t.promise}},function(n,e,t){"use strict";var r=t(37),o=function(n){var e,t;this.promise=new n((function(n,r){if(void 0!==e||void 0!==t)throw TypeError("Bad Promise constructor");e=n,t=r})),this.resolve=r(e),this.reject=r(t)};n.exports.f=function(n){return new o(n)}},function(n,e,t){var r=t(2),o=t(55),i=t(12),a=t(19),s=r("".charAt),c=r("".charCodeAt),l=r("".slice),u=function(n){return function(e,t){var r,u,p=i(a(e)),d=o(t),f=p.length;return d<0||d>=f?n?"":void 0:(r=c(p,d))<55296||r>56319||d+1===f||(u=c(p,d+1))<56320||u>57343?n?s(p,d):r:n?l(p,d,d+2):u-56320+(r-55296<<10)+65536}};n.exports={codeAt:u(!1),charAt:u(!0)}},function(n,e){n.exports={CSSRuleList:0,CSSStyleDeclaration:0,CSSValueList:0,ClientRectList:0,DOMRectList:0,DOMStringList:0,DOMTokenList:1,DataTransferItemList:0,FileList:0,HTMLAllCollection:0,HTMLCollection:0,HTMLFormElement:0,HTMLSelectElement:0,MediaList:0,MimeTypeArray:0,NamedNodeMap:0,NodeList:1,PaintRequestList:0,Plugin:0,PluginArray:0,SVGLengthList:0,SVGNumberList:0,SVGPathSegList:0,SVGPointList:0,SVGStringList:0,SVGTransformList:0,SourceBufferList:0,StyleSheetList:0,TextTrackCueList:0,TextTrackList:0,TouchList:0}},function(n,e,t){var r=t(81)("span").classList,o=r&&r.constructor&&r.constructor.prototype;n.exports=o===Object.prototype?void 0:o},function(n,e,t){var r=t(1),o=t(7),i=t(120),a=t(20),s=t(38),c=t(70);r({target:"Object",stat:!0,sham:!o},{getOwnPropertyDescriptors:function(n){for(var e,t,r=a(n),o=s.f,l=i(r),u={},p=0;l.length>p;)void 0!==(t=o(r,e=l[p++]))&&c(u,e,t);return u}})},function(n,e,t){var r=t(1),o=t(3),i=t(16),a=t(122),s=t(164);r({target:"Object",stat:!0,forced:o((function(){a(1)})),sham:!s},{getPrototypeOf:function(n){return a(i(n))}})},function(n,e,t){"use strict";var r,o=t(1),i=t(2),a=t(38).f,s=t(53),c=t(12),l=t(180),u=t(19),p=t(181),d=t(26),f=i("".startsWith),h=i("".slice),m=Math.min,v=p("startsWith");o({target:"String",proto:!0,forced:!!(d||v||(r=a(String.prototype,"startsWith"),!r||r.writable))&&!v},{startsWith:function(n){var e=c(u(this));l(n);var t=s(m(arguments.length>1?arguments[1]:void 0,e.length)),r=c(n);return f?f(e,r,t):h(e,t,t+r.length)===r}})},function(n,e,t){var r=t(0),o=t(148),i=r.TypeError;n.exports=function(n){if(o(n))throw i("The method doesn't accept regular expressions");return n}},function(n,e,t){var r=t(6)("match");n.exports=function(n){var e=/./;try{"/./"[n](e)}catch(t){try{return e[r]=!1,"/./"[n](e)}catch(n){}}return!1}},function(n,e,t){"use strict";var r=t(57).forEach,o=t(47)("forEach");n.exports=o?[].forEach:function(n){return r(this,n,arguments.length>1?arguments[1]:void 0)}},function(n,e,t){var r=t(3);n.exports=!r((function(){return Object.isExtensible(Object.preventExtensions({}))}))},function(n,e,t){var r=t(25),o=t(20),i=t(58).f,a=t(125),s="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[];n.exports.f=function(n){return s&&"Window"==r(n)?function(n){try{return i(n)}catch(n){return a(s)}}(n):i(o(n))}},function(n,e,t){var r=t(6);e.f=r},function(n,e,t){var r=t(261),o=t(10),i=t(185),a=t(13).f;n.exports=function(n){var e=r.Symbol||(r.Symbol={});o(e,n)||a(e,n,{value:i.f(n)})}},function(n,e,t){var r=t(1),o=t(262);r({target:"Array",stat:!0,forced:!t(168)((function(n){Array.from(n)}))},{from:o})},function(n,e,t){var r=t(12);n.exports=function(n,e){return void 0===n?arguments.length<2?"":e:r(n)}},function(n,e,t){t(1)({target:"Object",stat:!0,sham:!t(7)},{create:t(34)})},function(n,e,t){var r=t(1),o=t(0),i=t(17),a=t(36),s=t(2),c=t(3),l=o.Array,u=i("JSON","stringify"),p=s(/./.exec),d=s("".charAt),f=s("".charCodeAt),h=s("".replace),m=s(1..toString),v=/[\uD800-\uDFFF]/g,g=/^[\uD800-\uDBFF]$/,y=/^[\uDC00-\uDFFF]$/,b=function(n,e,t){var r=d(t,e-1),o=d(t,e+1);return p(g,n)&&!p(y,o)||p(y,n)&&!p(g,r)?"\\u"+m(f(n,0),16):n},x=c((function(){return'"\\udf06\\ud834"'!==u("\udf06\ud834")||'"\\udead"'!==u("\udead")}));u&&r({target:"JSON",stat:!0,forced:x},{stringify:function(n,e,t){for(var r=0,o=arguments.length,i=l(o);r<o;r++)i[r]=arguments[r];var s=a(u,null,i);return"string"==typeof s?h(s,v,b):s}})},function(n,e){n.exports=function(n,e){for(var t=-1,r=e.length,o=n.length;++t<r;)n[o+t]=e[t];return n}},function(n,e){var t="object"==typeof global&&global&&global.Object===Object&&global;n.exports=t},function(n,e,t){var r=t(94),o=t(283),i=t(284),a=t(285),s=t(286),c=t(287);function l(n){var e=this.__data__=new r(n);this.size=e.size}l.prototype.clear=o,l.prototype.delete=i,l.prototype.get=a,l.prototype.has=s,l.prototype.set=c,n.exports=l},function(n,e){n.exports=function(n,e){return n===e||n!=n&&e!=e}},function(n,e,t){var r=t(62),o=t(130);n.exports=function(n){if(!o(n))return!1;var e=r(n);return"[object Function]"==e||"[object GeneratorFunction]"==e||"[object AsyncFunction]"==e||"[object Proxy]"==e}},function(n,e){var t=Function.prototype.toString;n.exports=function(n){if(null!=n){try{return t.call(n)}catch(n){}try{return n+""}catch(n){}}return""}},function(n,e,t){var r=t(304),o=t(50);n.exports=function n(e,t,i,a,s){return e===t||(null==e||null==t||!o(e)&&!o(t)?e!=e&&t!=t:r(e,t,i,a,n,s))}},function(n,e,t){var r=t(199),o=t(307),i=t(200);n.exports=function(n,e,t,a,s,c){var l=1&t,u=n.length,p=e.length;if(u!=p&&!(l&&p>u))return!1;var d=c.get(n),f=c.get(e);if(d&&f)return d==e&&f==n;var h=-1,m=!0,v=2&t?new r:void 0;for(c.set(n,e),c.set(e,n);++h<u;){var g=n[h],y=e[h];if(a)var b=l?a(y,g,h,e,n,c):a(g,y,h,n,e,c);if(void 0!==b){if(b)continue;m=!1;break}if(v){if(!o(e,(function(n,e){if(!i(v,e)&&(g===n||s(g,n,t,a,c)))return v.push(e)}))){m=!1;break}}else if(g!==y&&!s(g,y,t,a,c)){m=!1;break}}return c.delete(n),c.delete(e),m}},function(n,e,t){var r=t(131),o=t(305),i=t(306);function a(n){var e=-1,t=null==n?0:n.length;for(this.__data__=new r;++e<t;)this.add(n[e])}a.prototype.add=a.prototype.push=o,a.prototype.has=i,n.exports=a},function(n,e){n.exports=function(n,e){return n.has(e)}},function(n,e,t){var r=t(317),o=t(323),i=t(205);n.exports=function(n){return i(n)?r(n):o(n)}},function(n,e,t){(function(n){var r=t(33),o=t(319),i=e&&!e.nodeType&&e,a=i&&"object"==typeof n&&n&&!n.nodeType&&n,s=a&&a.exports===i?r.Buffer:void 0,c=(s?s.isBuffer:void 0)||o;n.exports=c}).call(this,t(151)(n))},function(n,e){var t=/^(?:0|[1-9]\d*)$/;n.exports=function(n,e){var r=typeof n;return!!(e=null==e?9007199254740991:e)&&("number"==r||"symbol"!=r&&t.test(n))&&n>-1&&n%1==0&&n<e}},function(n,e,t){var r=t(320),o=t(321),i=t(322),a=i&&i.isTypedArray,s=a?o(a):r;n.exports=s},function(n,e,t){var r=t(195),o=t(133);n.exports=function(n){return null!=n&&o(n.length)&&!r(n)}},function(n,e,t){var r=t(41)(t(33),"Set");n.exports=r},function(n,e,t){var r=t(130);n.exports=function(n){return n==n&&!r(n)}},function(n,e){n.exports=function(n,e){return function(t){return null!=t&&(t[n]===e&&(void 0!==e||n in Object(t)))}}},function(n,e,t){var r=t(210),o=t(98);n.exports=function(n,e){for(var t=0,i=(e=r(e,n)).length;null!=n&&t<i;)n=n[o(e[t++])];return t&&t==i?n:void 0}},function(n,e,t){var r=t(31),o=t(134),i=t(334),a=t(337);n.exports=function(n,e){return r(n)?n:o(n,e)?[n]:i(a(n))}},function(n,e,t){"use strict";var r=t(0),o=t(2),i=t(37),a=t(9),s=t(10),c=t(69),l=t(64),u=r.Function,p=o([].concat),d=o([].join),f={},h=function(n,e,t){if(!s(f,e)){for(var r=[],o=0;o<e;o++)r[o]="a["+o+"]";f[e]=u("C,a","return new C("+d(r,",")+")")}return f[e](n,t)};n.exports=l?u.bind:function(n){var e=i(this),t=e.prototype,r=c(arguments,1),o=function(){var t=p(r,c(arguments));return this instanceof o?h(e,t.length,t):e.apply(n,t)};return a(t)&&(o.prototype=t),o}},function(n,e,t){"use strict";var r=t(1),o=t(369).start;r({target:"String",proto:!0,forced:t(371)},{padStart:function(n){return o(this,n,arguments.length>1?arguments[1]:void 0)}})},function(n,e,t){},function(n,e,t){},function(n,e,t){t(1)({target:"Object",stat:!0},{setPrototypeOf:t(68)})},function(n,e,t){var r=t(1),o=t(17),i=t(36),a=t(211),s=t(169),c=t(8),l=t(9),u=t(34),p=t(3),d=o("Reflect","construct"),f=Object.prototype,h=[].push,m=p((function(){function n(){}return!(d((function(){}),[],n)instanceof n)})),v=!p((function(){d((function(){}))})),g=m||v;r({target:"Reflect",stat:!0,forced:g,sham:g},{construct:function(n,e){s(n),c(e);var t=arguments.length<3?n:s(arguments[2]);if(v&&!m)return d(n,e,t);if(n==t){switch(e.length){case 0:return new n;case 1:return new n(e[0]);case 2:return new n(e[0],e[1]);case 3:return new n(e[0],e[1],e[2]);case 4:return new n(e[0],e[1],e[2],e[3])}var r=[null];return i(h,r,e),new(i(a,n,r))}var o=t.prototype,p=u(l(o)?o:f),g=i(n,p,e);return l(g)?g:p}})},function(n,e,t){},function(n,e,t){},function(n,e,t){var r=t(270),o=t(275),i=t(346),a=t(354),s=t(363),c=t(233),l=i((function(n){var e=c(n);return s(e)&&(e=void 0),a(r(n,1,s,!0),o(e,2))}));n.exports=l},function(n,e,t){"use strict";
/*!
 * escape-html
 * Copyright(c) 2012-2013 TJ Holowaychuk
 * Copyright(c) 2015 Andreas Lubbe
 * Copyright(c) 2015 Tiancheng "Timothy" Gu
 * MIT Licensed
 */var r=/["'&<>]/;n.exports=function(n){var e,t=""+n,o=r.exec(t);if(!o)return t;var i="",a=0,s=0;for(a=o.index;a<t.length;a++){switch(t.charCodeAt(a)){case 34:e="&quot;";break;case 38:e="&amp;";break;case 39:e="&#39;";break;case 60:e="&lt;";break;case 62:e="&gt;";break;default:continue}s!==a&&(i+=t.substring(s,a)),s=a+1,i+=e}return s!==a?i+t.substring(s,a):i}},function(n,e,t){"use strict";
/**
 * @file Embedded JavaScript templating engine. {@link http://ejs.co}
 * @author Matthew Eernisse <mde@fleegix.org>
 * @author Tiancheng "Timothy" Gu <timothygu99@gmail.com>
 * @project EJS
 * @license {@link http://www.apache.org/licenses/LICENSE-2.0 Apache License, Version 2.0}
 */var r=t(383),o=t(384),i=t(385),a=!1,s=t(386).version,c=["delimiter","scope","context","debug","compileDebug","client","_with","rmWhitespace","strict","filename","async"],l=c.concat("cache"),u=/^\uFEFF/;function p(n,t){var o,i,a=t.views,s=/^[A-Za-z]+:\\|^\//.exec(n);if(s&&s.length)o=e.resolveInclude(n.replace(/^\/*/,""),t.root||"/",!0);else if(t.filename&&(i=e.resolveInclude(n,t.filename),r.existsSync(i)&&(o=i)),o||Array.isArray(a)&&a.some((function(t){return i=e.resolveInclude(n,t,!0),r.existsSync(i)}))&&(o=i),!o)throw new Error('Could not find the include file "'+t.escapeFunction(n)+'"');return o}function d(n,t){var r,o=n.filename,i=arguments.length>1;if(n.cache){if(!o)throw new Error("cache option requires a filename");if(r=e.cache.get(o))return r;i||(t=h(o).toString().replace(u,""))}else if(!i){if(!o)throw new Error("Internal EJS error: no file name or template provided");t=h(o).toString().replace(u,"")}return r=e.compile(t,n),n.cache&&e.cache.set(o,r),r}function f(n,t,r){var o;if(!r){if("function"==typeof e.promiseImpl)return new e.promiseImpl((function(e,r){try{e(o=d(n)(t))}catch(n){r(n)}}));throw new Error("Please provide a callback function")}try{o=d(n)(t)}catch(n){return r(n)}r(null,o)}function h(n){return e.fileLoader(n)}function m(n,e,t,r,o){var i=e.split("\n"),a=Math.max(r-3,0),s=Math.min(i.length,r+3),c=o(t),l=i.slice(a,s).map((function(n,e){var t=e+a+1;return(t==r?" >> ":"    ")+t+"| "+n})).join("\n");throw n.path=c,n.message=(c||"ejs")+":"+r+"\n"+l+"\n\n"+n.message,n}function v(n){return n.replace(/;(\s*$)/,"$1")}function g(n,t){t=t||{};var r={};this.templateText=n,this.mode=null,this.truncate=!1,this.currentLine=1,this.source="",this.dependencies=[],r.client=t.client||!1,r.escapeFunction=t.escape||t.escapeFunction||i.escapeXML,r.compileDebug=!1!==t.compileDebug,r.debug=!!t.debug,r.filename=t.filename,r.openDelimiter=t.openDelimiter||e.openDelimiter||"<",r.closeDelimiter=t.closeDelimiter||e.closeDelimiter||">",r.delimiter=t.delimiter||e.delimiter||"%",r.strict=t.strict||!1,r.context=t.context,r.cache=t.cache||!1,r.rmWhitespace=t.rmWhitespace,r.root=t.root,r.outputFunctionName=t.outputFunctionName,r.localsName=t.localsName||e.localsName||"locals",r.views=t.views,r.async=t.async,r.destructuredLocals=t.destructuredLocals,r.legacyInclude=void 0===t.legacyInclude||!!t.legacyInclude,r.strict?r._with=!1:r._with=void 0===t._with||t._with,this.opts=r,this.regex=this.createRegex()}e.cache=i.cache,e.fileLoader=r.readFileSync,e.localsName="locals",e.promiseImpl=new Function("return this;")().Promise,e.resolveInclude=function(n,e,t){var r=o.dirname,i=o.extname,a=(0,o.resolve)(t?e:r(e),n);return i(n)||(a+=".ejs"),a},e.compile=function(n,e){return e&&e.scope&&(a||(console.warn("`scope` option is deprecated and will be removed in EJS 3"),a=!0),e.context||(e.context=e.scope),delete e.scope),new g(n,e).compile()},e.render=function(n,e,t){var r=e||{},o=t||{};return 2==arguments.length&&i.shallowCopyFromList(o,r,c),d(o,n)(r)},e.renderFile=function(){var n,e,t,r=Array.prototype.slice.call(arguments),o=r.shift(),a={filename:o};return"function"==typeof arguments[arguments.length-1]&&(n=r.pop()),r.length?(e=r.shift(),r.length?i.shallowCopy(a,r.pop()):(e.settings&&(e.settings.views&&(a.views=e.settings.views),e.settings["view cache"]&&(a.cache=!0),(t=e.settings["view options"])&&i.shallowCopy(a,t)),i.shallowCopyFromList(a,e,l)),a.filename=o):e={},f(a,e,n)},e.Template=g,e.clearCache=function(){e.cache.reset()},g.modes={EVAL:"eval",ESCAPED:"escaped",RAW:"raw",COMMENT:"comment",LITERAL:"literal"},g.prototype={createRegex:function(){var n="(<%%|%%>|<%=|<%-|<%_|<%#|<%|%>|-%>|_%>)",e=i.escapeRegExpChars(this.opts.delimiter),t=i.escapeRegExpChars(this.opts.openDelimiter),r=i.escapeRegExpChars(this.opts.closeDelimiter);return n=n.replace(/%/g,e).replace(/</g,t).replace(/>/g,r),new RegExp(n)},compile:function(){var n,e,t,r=this.opts,a="",s="",c=r.escapeFunction;if(!this.source){if(this.generateSource(),a+='  var __output = "";\n  function __append(s) { if (s !== undefined && s !== null) __output += s }\n',r.outputFunctionName&&(a+="  var "+r.outputFunctionName+" = __append;\n"),r.destructuredLocals&&r.destructuredLocals.length){for(var l="  var __locals = ("+r.localsName+" || {}),\n",u=0;u<r.destructuredLocals.length;u++){var f=r.destructuredLocals[u];u>0&&(l+=",\n  "),l+=f+" = __locals."+f}a+=l+";\n"}!1!==r._with&&(a+="  with ("+r.localsName+" || {}) {\n",s+="  }\n"),s+="  return __output;\n",this.source=a+this.source+s}n=r.compileDebug?"var __line = 1\n  , __lines = "+JSON.stringify(this.templateText)+"\n  , __filename = "+(r.filename?JSON.stringify(r.filename):"undefined")+";\ntry {\n"+this.source+"} catch (e) {\n  rethrow(e, __lines, __filename, __line, escapeFn);\n}\n":this.source,r.client&&(n="escapeFn = escapeFn || "+c.toString()+";\n"+n,r.compileDebug&&(n="rethrow = rethrow || "+m.toString()+";\n"+n)),r.strict&&(n='"use strict";\n'+n),r.debug&&console.log(n),r.compileDebug&&r.filename&&(n=n+"\n//# sourceURL="+r.filename+"\n");try{if(r.async)try{t=new Function("return (async function(){}).constructor;")()}catch(n){throw n instanceof SyntaxError?new Error("This environment does not support async/await"):n}else t=Function;e=new t(r.localsName+", escapeFn, include, rethrow",n)}catch(n){throw n instanceof SyntaxError&&(r.filename&&(n.message+=" in "+r.filename),n.message+=" while compiling ejs\n\n",n.message+="If the above error is not helpful, you may want to try EJS-Lint:\n",n.message+="https://github.com/RyanZim/EJS-Lint",r.async||(n.message+="\n",n.message+="Or, if you meant to create an async function, pass `async: true` as an option.")),n}var h=r.client?e:function(n){return e.apply(r.context,[n||{},c,function(e,t){var o=i.shallowCopy({},n);return t&&(o=i.shallowCopy(o,t)),function(n,e){var t=i.shallowCopy({},e);return t.filename=p(n,t),d(t)}(e,r)(o)},m])};if(h.dependencies=this.dependencies,r.filename&&"function"==typeof Object.defineProperty){var v=r.filename,g=o.basename(v,o.extname(v));try{Object.defineProperty(h,"name",{value:g,writable:!1,enumerable:!1,configurable:!0})}catch(n){}}return h},generateSource:function(){var n=this.opts;n.rmWhitespace&&(this.templateText=this.templateText.replace(/[\r\n]+/g,"\n").replace(/^\s+|\s+$/gm,"")),this.templateText=this.templateText.replace(/[ \t]*<%_/gm,"<%_").replace(/_%>[ \t]*/gm,"_%>");var t=this,r=this.parseTemplateText(),o=this.opts.delimiter,a=this.opts.openDelimiter,s=this.opts.closeDelimiter;r&&r.length&&r.forEach((function(c,l){var d,f,m,v,y,b;if(0===c.indexOf(a+o)&&0!==c.indexOf(a+o+o)&&(f=r[l+2])!=o+s&&f!="-"+o+s&&f!="_"+o+s)throw new Error('Could not find matching close tag for "'+c+'".');if(n.legacyInclude&&(m=c.match(/^\s*include\s+(\S+)/))&&(d=r[l-1])&&(d==a+o||d==a+o+"-"||d==a+o+"_"))return v=i.shallowCopy({},t.opts),y=function(n,e){var t,r,o=i.shallowCopy({},e);r=h(t=p(n,o)).toString().replace(u,""),o.filename=t;var a=new g(r,o);return a.generateSource(),{source:a.source,filename:t,template:r}}(m[1],v),b=t.opts.compileDebug?"    ; (function(){\n      var __line = 1\n      , __lines = "+JSON.stringify(y.template)+"\n      , __filename = "+JSON.stringify(y.filename)+";\n      try {\n"+y.source+"      } catch (e) {\n        rethrow(e, __lines, __filename, __line, escapeFn);\n      }\n    ; }).call(this)\n":"    ; (function(){\n"+y.source+"    ; }).call(this)\n",t.source+=b,void t.dependencies.push(e.resolveInclude(m[1],v.filename));t.scanLine(c)}))},parseTemplateText:function(){for(var n,e=this.templateText,t=this.regex,r=t.exec(e),o=[];r;)0!==(n=r.index)&&(o.push(e.substring(0,n)),e=e.slice(n)),o.push(r[0]),e=e.slice(r[0].length),r=t.exec(e);return e&&o.push(e),o},_addOutput:function(n){if(this.truncate&&(n=n.replace(/^(?:\r\n|\r|\n)/,""),this.truncate=!1),!n)return n;n=(n=(n=(n=n.replace(/\\/g,"\\\\")).replace(/\n/g,"\\n")).replace(/\r/g,"\\r")).replace(/"/g,'\\"'),this.source+='    ; __append("'+n+'")\n'},scanLine:function(n){var e,t=this.opts.delimiter,r=this.opts.openDelimiter,o=this.opts.closeDelimiter;switch(e=n.split("\n").length-1,n){case r+t:case r+t+"_":this.mode=g.modes.EVAL;break;case r+t+"=":this.mode=g.modes.ESCAPED;break;case r+t+"-":this.mode=g.modes.RAW;break;case r+t+"#":this.mode=g.modes.COMMENT;break;case r+t+t:this.mode=g.modes.LITERAL,this.source+='    ; __append("'+n.replace(r+t+t,r+t)+'")\n';break;case t+t+o:this.mode=g.modes.LITERAL,this.source+='    ; __append("'+n.replace(t+t+o,t+o)+'")\n';break;case t+o:case"-"+t+o:case"_"+t+o:this.mode==g.modes.LITERAL&&this._addOutput(n),this.mode=null,this.truncate=0===n.indexOf("-")||0===n.indexOf("_");break;default:if(this.mode){switch(this.mode){case g.modes.EVAL:case g.modes.ESCAPED:case g.modes.RAW:n.lastIndexOf("//")>n.lastIndexOf("\n")&&(n+="\n")}switch(this.mode){case g.modes.EVAL:this.source+="    ; "+n+"\n";break;case g.modes.ESCAPED:this.source+="    ; __append(escapeFn("+v(n)+"))\n";break;case g.modes.RAW:this.source+="    ; __append("+v(n)+")\n";break;case g.modes.COMMENT:break;case g.modes.LITERAL:this._addOutput(n)}}else this._addOutput(n)}this.opts.compileDebug&&e&&(this.currentLine+=e,this.source+="    ; __line = "+this.currentLine+"\n")}},e.escapeXML=i.escapeXML,e.__express=e.renderFile,e.VERSION=s,e.name="ejs","undefined"!=typeof window&&(window.ejs=e)},function(n,e,t){"use strict";t.r(e);var r={name:"CodeBlock",props:{title:{type:String,required:!0},active:{type:Boolean,default:!1}}},o=(t(372),t(15)),i=Object(o.a)(r,(function(){var n=this.$createElement;return(this._self._c||n)("div",{staticClass:"theme-code-block",class:{"theme-code-block__active":this.active}},[this._t("default")],2)}),[],!1,null,"4f1e9d0c",null);e.default=i.exports},function(n,e,t){"use strict";t.r(e);t(28),t(4),t(29),t(45),t(24);var r={name:"CodeGroup",data:function(){return{codeTabs:[],activeCodeTabIndex:-1}},watch:{activeCodeTabIndex:function(n){this.codeTabs.forEach((function(n){n.elm.classList.remove("theme-code-block__active")})),this.codeTabs[n].elm.classList.add("theme-code-block__active")}},mounted:function(){var n=this;this.codeTabs=(this.$slots.default||[]).filter((function(n){return Boolean(n.componentOptions)})).map((function(e,t){return""===e.componentOptions.propsData.active&&(n.activeCodeTabIndex=t),{title:e.componentOptions.propsData.title,elm:e.elm}})),-1===this.activeCodeTabIndex&&this.codeTabs.length>0&&(this.activeCodeTabIndex=0)},methods:{changeCodeTab:function(n){this.activeCodeTabIndex=n}}},o=(t(373),t(15)),i=Object(o.a)(r,(function(){var n=this,e=n.$createElement,t=n._self._c||e;return t("div",{staticClass:"theme-code-group"},[t("div",{staticClass:"theme-code-group__nav"},[t("ul",{staticClass:"theme-code-group__ul"},n._l(n.codeTabs,(function(e,r){return t("li",{key:e.title,staticClass:"theme-code-group__li"},[t("button",{staticClass:"theme-code-group__nav-tab",class:{"theme-code-group__nav-tab-active":r===n.activeCodeTabIndex},on:{click:function(e){return n.changeCodeTab(r)}}},[n._v("\n            "+n._s(e.title)+"\n          ")])])})),0)]),n._v(" "),n._t("default"),n._v(" "),n.codeTabs.length<1?t("pre",{staticClass:"pre-blank"},[n._v("// Make sure to add code blocks to your code group")]):n._e()],2)}),[],!1,null,"2f5f1757",null);e.default=i.exports},function(n,e,t){"use strict";var r=t(7),o=t(0),i=t(2),a=t(105),s=t(14),c=t(10),l=t(150),u=t(35),p=t(83),d=t(159),f=t(3),h=t(58).f,m=t(38).f,v=t(13).f,g=t(368),y=t(153).trim,b=o.Number,x=b.prototype,_=o.TypeError,w=i("".slice),E=i("".charCodeAt),k=function(n){var e=d(n,"number");return"bigint"==typeof e?e:C(e)},C=function(n){var e,t,r,o,i,a,s,c,l=d(n,"number");if(p(l))throw _("Cannot convert a Symbol value to a number");if("string"==typeof l&&l.length>2)if(l=y(l),43===(e=E(l,0))||45===e){if(88===(t=E(l,2))||120===t)return NaN}else if(48===e){switch(E(l,1)){case 66:case 98:r=2,o=49;break;case 79:case 111:r=8,o=55;break;default:return+l}for(a=(i=w(l,2)).length,s=0;s<a;s++)if((c=E(i,s))<48||c>o)return NaN;return parseInt(i,r)}return+l};if(a("Number",!b(" 0o1")||!b("0b1")||b("+0x1"))){for(var T,S=function(n){var e=arguments.length<1?0:b(k(n)),t=this;return u(x,t)&&f((function(){g(t)}))?l(Object(e),t,S):e},A=r?h(b):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,isFinite,isInteger,isNaN,isSafeInteger,parseFloat,parseInt,fromString,range".split(","),O=0;A.length>O;O++)c(b,T=A[O])&&!c(S,T)&&v(S,T,m(b,T));S.prototype=x,x.constructor=S,s(o,"Number",S)}},function(n,e,t){var r=t(3),o=t(0).RegExp;n.exports=r((function(){var n=o(".","s");return!(n.dotAll&&n.exec("\n")&&"s"===n.flags)}))},function(n,e,t){"use strict";var r=t(163).IteratorPrototype,o=t(34),i=t(49),a=t(59),s=t(66),c=function(){return this};n.exports=function(n,e,t,l){var u=e+" Iterator";return n.prototype=o(r,{next:i(+!l,t)}),a(n,u,!1,!0),s[u]=c,n}},function(n,e,t){var r=t(14);n.exports=function(n,e,t){for(var o in e)r(n,o,e[o],t);return n}},function(n,e,t){"use strict";var r=t(17),o=t(13),i=t(6),a=t(7),s=i("species");n.exports=function(n){var e=r(n),t=o.f;a&&e&&!e[s]&&t(e,s,{configurable:!0,get:function(){return this}})}},function(n,e,t){var r=t(0),o=t(35),i=r.TypeError;n.exports=function(n,e){if(o(e,n))return n;throw i("Incorrect invocation")}},function(n,e,t){var r=t(3),o=t(0).RegExp;n.exports=r((function(){var n=o("(?<a>b)","g");return"b"!==n.exec("b").groups.a||"bc"!=="b".replace(n,"$<a>c")}))},function(n,e,t){"use strict";var r=t(1),o=t(115).includes,i=t(141);r({target:"Array",proto:!0},{includes:function(n){return o(this,n,arguments.length>1?arguments[1]:void 0)}}),i("includes")},function(n,e,t){"use strict";var r=t(1),o=t(2),i=t(180),a=t(19),s=t(12),c=t(181),l=o("".indexOf);r({target:"String",proto:!0,forced:!c("includes")},{includes:function(n){return!!~l(s(a(this)),s(i(n)),arguments.length>1?arguments[1]:void 0)}})},function(n,e){n.exports=function(n){var e=null==n?0:n.length;return e?n[e-1]:void 0}},function(n,e,t){"use strict";var r=t(1),o=t(153).trim;r({target:"String",proto:!0,forced:t(366)("trim")},{trim:function(){return o(this)}})},function(n,e,t){var r=t(125),o=Math.floor,i=function(n,e){var t=n.length,c=o(t/2);return t<8?a(n,e):s(n,i(r(n,0,c),e),i(r(n,c),e),e)},a=function(n,e){for(var t,r,o=n.length,i=1;i<o;){for(r=i,t=n[i];r&&e(n[r-1],t)>0;)n[r]=n[--r];r!==i++&&(n[r]=t)}return n},s=function(n,e,t,r){for(var o=e.length,i=t.length,a=0,s=0;a<o||s<i;)n[a+s]=a<o&&s<i?r(e[a],t[s])<=0?e[a++]:t[s++]:a<o?e[a++]:t[s++];return n};n.exports=i},function(n,e,t){var r=t(0),o=t(7),i=t(107).MISSED_STICKY,a=t(25),s=t(13).f,c=t(39).get,l=RegExp.prototype,u=r.TypeError;o&&i&&s(l,"sticky",{configurable:!0,get:function(){if(this!==l){if("RegExp"===a(this))return!!c(this).sticky;throw u("Incompatible receiver, RegExp required")}}})},function(n,e,t){n.exports=t(389)},function(n,e,t){var r=t(0),o=t(11),i=t(5),a=t(9),s=r.TypeError;n.exports=function(n,e){var t,r;if("string"===e&&i(t=n.toString)&&!a(r=o(t,n)))return r;if(i(t=n.valueOf)&&!a(r=o(t,n)))return r;if("string"!==e&&i(t=n.toString)&&!a(r=o(t,n)))return r;throw s("Can't convert object to primitive value")}},function(n,e,t){var r=t(0),o=t(5),i=t(87),a=r.WeakMap;n.exports=o(a)&&/native code/.test(i(a))},function(n,e,t){var r=t(0),o=t(5),i=r.String,a=r.TypeError;n.exports=function(n){if("object"==typeof n||o(n))return n;throw a("Can't set "+i(n)+" as a prototype")}},function(n,e,t){"use strict";var r,o,i,a,s=t(1),c=t(26),l=t(0),u=t(17),p=t(11),d=t(165),f=t(14),h=t(227),m=t(68),v=t(59),g=t(228),y=t(37),b=t(5),x=t(9),_=t(229),w=t(87),E=t(242),k=t(168),C=t(124),T=t(170).set,S=t(243),A=t(172),O=t(246),j=t(173),I=t(247),P=t(248),z=t(39),D=t(105),L=t(6),N=t(249),B=t(89),R=t(52),$=L("species"),M="Promise",F=z.getterFor(M),G=z.set,U=z.getterFor(M),V=d&&d.prototype,H=d,q=V,X=l.TypeError,J=l.document,Y=l.process,W=j.f,Z=W,K=!!(J&&J.createEvent&&l.dispatchEvent),Q=b(l.PromiseRejectionEvent),nn=!1,en=D(M,(function(){var n=w(H),e=n!==String(H);if(!e&&66===R)return!0;if(c&&!q.finally)return!0;if(R>=51&&/native code/.test(n))return!1;var t=new H((function(n){n(1)})),r=function(n){n((function(){}),(function(){}))};return(t.constructor={})[$]=r,!(nn=t.then((function(){}))instanceof r)||!e&&N&&!Q})),tn=en||!k((function(n){H.all(n).catch((function(){}))})),rn=function(n){var e;return!(!x(n)||!b(e=n.then))&&e},on=function(n,e){var t,r,o,i=e.value,a=1==e.state,s=a?n.ok:n.fail,c=n.resolve,l=n.reject,u=n.domain;try{s?(a||(2===e.rejection&&un(e),e.rejection=1),!0===s?t=i:(u&&u.enter(),t=s(i),u&&(u.exit(),o=!0)),t===n.promise?l(X("Promise-chain cycle")):(r=rn(t))?p(r,t,c,l):c(t)):l(i)}catch(n){u&&!o&&u.exit(),l(n)}},an=function(n,e){n.notified||(n.notified=!0,S((function(){for(var t,r=n.reactions;t=r.get();)on(t,n);n.notified=!1,e&&!n.rejection&&cn(n)})))},sn=function(n,e,t){var r,o;K?((r=J.createEvent("Event")).promise=e,r.reason=t,r.initEvent(n,!1,!0),l.dispatchEvent(r)):r={promise:e,reason:t},!Q&&(o=l["on"+n])?o(r):"unhandledrejection"===n&&O("Unhandled promise rejection",t)},cn=function(n){p(T,l,(function(){var e,t=n.facade,r=n.value;if(ln(n)&&(e=I((function(){B?Y.emit("unhandledRejection",r,t):sn("unhandledrejection",t,r)})),n.rejection=B||ln(n)?2:1,e.error))throw e.value}))},ln=function(n){return 1!==n.rejection&&!n.parent},un=function(n){p(T,l,(function(){var e=n.facade;B?Y.emit("rejectionHandled",e):sn("rejectionhandled",e,n.value)}))},pn=function(n,e,t){return function(r){n(e,r,t)}},dn=function(n,e,t){n.done||(n.done=!0,t&&(n=t),n.value=e,n.state=2,an(n,!0))},fn=function(n,e,t){if(!n.done){n.done=!0,t&&(n=t);try{if(n.facade===e)throw X("Promise can't be resolved itself");var r=rn(e);r?S((function(){var t={done:!1};try{p(r,e,pn(fn,t,n),pn(dn,t,n))}catch(e){dn(t,e,n)}})):(n.value=e,n.state=1,an(n,!1))}catch(e){dn({done:!1},e,n)}}};if(en&&(q=(H=function(n){_(this,q),y(n),p(r,this);var e=F(this);try{n(pn(fn,e),pn(dn,e))}catch(n){dn(e,n)}}).prototype,(r=function(n){G(this,{type:M,done:!1,notified:!1,parent:!1,reactions:new P,rejection:!1,state:0,value:void 0})}).prototype=h(q,{then:function(n,e){var t=U(this),r=W(C(this,H));return t.parent=!0,r.ok=!b(n)||n,r.fail=b(e)&&e,r.domain=B?Y.domain:void 0,0==t.state?t.reactions.add(r):S((function(){on(r,t)})),r.promise},catch:function(n){return this.then(void 0,n)}}),o=function(){var n=new r,e=F(n);this.promise=n,this.resolve=pn(fn,e),this.reject=pn(dn,e)},j.f=W=function(n){return n===H||n===i?new o(n):Z(n)},!c&&b(d)&&V!==Object.prototype)){a=V.then,nn||(f(V,"then",(function(n,e){var t=this;return new H((function(n,e){p(a,t,n,e)})).then(n,e)}),{unsafe:!0}),f(V,"catch",q.catch,{unsafe:!0}));try{delete V.constructor}catch(n){}m&&m(V,q)}s({global:!0,wrap:!0,forced:en},{Promise:H}),v(H,M,!1,!0),g(M),i=u(M),s({target:M,stat:!0,forced:en},{reject:function(n){var e=W(this);return p(e.reject,void 0,n),e.promise}}),s({target:M,stat:!0,forced:c||en},{resolve:function(n){return A(c&&this===i?H:this,n)}}),s({target:M,stat:!0,forced:tn},{all:function(n){var e=this,t=W(e),r=t.resolve,o=t.reject,i=I((function(){var t=y(e.resolve),i=[],a=0,s=1;E(n,(function(n){var c=a++,l=!1;s++,p(t,e,n).then((function(n){l||(l=!0,i[c]=n,--s||r(i))}),o)})),--s||r(i)}));return i.error&&o(i.value),t.promise},race:function(n){var e=this,t=W(e),r=t.reject,o=I((function(){var o=y(e.resolve);E(n,(function(n){p(o,e,n).then(t.resolve,r)}))}));return o.error&&r(o.value),t.promise}})},function(n,e,t){var r=t(0),o=t(56),i=t(11),a=t(8),s=t(84),c=t(166),l=t(23),u=t(35),p=t(145),d=t(106),f=t(167),h=r.TypeError,m=function(n,e){this.stopped=n,this.result=e},v=m.prototype;n.exports=function(n,e,t){var r,g,y,b,x,_,w,E=t&&t.that,k=!(!t||!t.AS_ENTRIES),C=!(!t||!t.IS_ITERATOR),T=!(!t||!t.INTERRUPTED),S=o(e,E),A=function(n){return r&&f(r,"normal",n),new m(!0,n)},O=function(n){return k?(a(n),T?S(n[0],n[1],A):S(n[0],n[1])):T?S(n,A):S(n)};if(C)r=n;else{if(!(g=d(n)))throw h(s(n)+" is not iterable");if(c(g)){for(y=0,b=l(n);b>y;y++)if((x=O(n[y]))&&u(v,x))return x;return new m(!1)}r=p(n,g)}for(_=r.next;!(w=i(_,r)).done;){try{x=O(w.value)}catch(n){f(r,"throw",n)}if("object"==typeof x&&x&&u(v,x))return x}return new m(!1)}},function(n,e,t){var r,o,i,a,s,c,l,u,p=t(0),d=t(56),f=t(38).f,h=t(170).set,m=t(171),v=t(244),g=t(245),y=t(89),b=p.MutationObserver||p.WebKitMutationObserver,x=p.document,_=p.process,w=p.Promise,E=f(p,"queueMicrotask"),k=E&&E.value;k||(r=function(){var n,e;for(y&&(n=_.domain)&&n.exit();o;){e=o.fn,o=o.next;try{e()}catch(n){throw o?a():i=void 0,n}}i=void 0,n&&n.enter()},m||y||g||!b||!x?!v&&w&&w.resolve?((l=w.resolve(void 0)).constructor=w,u=d(l.then,l),a=function(){u(r)}):y?a=function(){_.nextTick(r)}:(h=d(h,p),a=function(){h(r)}):(s=!0,c=x.createTextNode(""),new b(r).observe(c,{characterData:!0}),a=function(){c.data=s=!s})),n.exports=k||function(n){var e={fn:n,next:void 0};i&&(i.next=e),o||(o=e,a()),i=e}},function(n,e,t){var r=t(32),o=t(0);n.exports=/ipad|iphone|ipod/i.test(r)&&void 0!==o.Pebble},function(n,e,t){var r=t(32);n.exports=/web0s(?!.*chrome)/i.test(r)},function(n,e,t){var r=t(0);n.exports=function(n,e){var t=r.console;t&&t.error&&(1==arguments.length?t.error(n):t.error(n,e))}},function(n,e){n.exports=function(n){try{return{error:!1,value:n()}}catch(n){return{error:!0,value:n}}}},function(n,e){var t=function(){this.head=null,this.tail=null};t.prototype={add:function(n){var e={item:n,next:null};this.head?this.tail.next=e:this.head=e,this.tail=e},get:function(){var n=this.head;if(n)return this.head=n.next,this.tail===n&&(this.tail=null),n.item}},n.exports=t},function(n,e){n.exports="object"==typeof window},function(n,e,t){var r=t(1),o=t(251);r({target:"Object",stat:!0,forced:Object.assign!==o},{assign:o})},function(n,e,t){"use strict";var r=t(7),o=t(2),i=t(11),a=t(3),s=t(85),c=t(121),l=t(118),u=t(16),p=t(63),d=Object.assign,f=Object.defineProperty,h=o([].concat);n.exports=!d||a((function(){if(r&&1!==d({b:1},d(f({},"a",{enumerable:!0,get:function(){f(this,"b",{value:3,enumerable:!1})}}),{b:2})).b)return!0;var n={},e={},t=Symbol();return n[t]=7,"abcdefghijklmnopqrst".split("").forEach((function(n){e[n]=n})),7!=d({},n)[t]||"abcdefghijklmnopqrst"!=s(d({},e)).join("")}))?function(n,e){for(var t=u(n),o=arguments.length,a=1,d=c.f,f=l.f;o>a;)for(var m,v=p(arguments[a++]),g=d?h(s(v),d(v)):s(v),y=g.length,b=0;y>b;)m=g[b++],r&&!i(f,v,m)||(t[m]=v[m]);return t}:d},function(n,e,t){"use strict";var r=t(1),o=t(26),i=t(165),a=t(3),s=t(17),c=t(5),l=t(124),u=t(172),p=t(14);if(r({target:"Promise",proto:!0,real:!0,forced:!!i&&a((function(){i.prototype.finally.call({then:function(){}},(function(){}))}))},{finally:function(n){var e=l(this,s("Promise")),t=c(n);return this.then(t?function(t){return u(e,n()).then((function(){return t}))}:n,t?function(t){return u(e,n()).then((function(){throw t}))}:n)}}),!o&&c(i)){var d=s("Promise").prototype.finally;i.prototype.finally!==d&&p(i.prototype,"finally",d,{unsafe:!0})}},function(n,e,t){"use strict";var r=t(123),o=t(77);n.exports=r?{}.toString:function(){return"[object "+o(this)+"]"}},function(n,e,t){var r=t(0),o=t(60),i=t(88),a=t(9),s=t(6)("species"),c=r.Array;n.exports=function(n){var e;return o(n)&&(e=n.constructor,(i(e)&&(e===c||o(e.prototype))||a(e)&&null===(e=e[s]))&&(e=void 0)),void 0===e?c:e}},function(n,e,t){"use strict";var r=t(1),o=t(256).left,i=t(47),a=t(52),s=t(89);r({target:"Array",proto:!0,forced:!i("reduce")||!s&&a>79&&a<83},{reduce:function(n){var e=arguments.length;return o(this,n,e,e>1?arguments[1]:void 0)}})},function(n,e,t){var r=t(0),o=t(37),i=t(16),a=t(63),s=t(23),c=r.TypeError,l=function(n){return function(e,t,r,l){o(t);var u=i(e),p=a(u),d=s(u),f=n?d-1:0,h=n?-1:1;if(r<2)for(;;){if(f in p){l=p[f],f+=h;break}if(f+=h,n?f<0:d<=f)throw c("Reduce of empty array with no initial value")}for(;n?f>=0:d>f;f+=h)f in p&&(l=t(l,p[f],f,u));return l}};n.exports={left:l(!1),right:l(!0)}},function(n,e,t){var r=t(1),o=t(183),i=t(3),a=t(9),s=t(258).onFreeze,c=Object.freeze;r({target:"Object",stat:!0,forced:i((function(){c(1)})),sham:!o},{freeze:function(n){return c&&a(n)?c(s(n)):n}})},function(n,e,t){var r=t(1),o=t(2),i=t(65),a=t(9),s=t(10),c=t(13).f,l=t(58),u=t(184),p=t(259),d=t(80),f=t(183),h=!1,m=d("meta"),v=0,g=function(n){c(n,m,{value:{objectID:"O"+v++,weakData:{}}})},y=n.exports={enable:function(){y.enable=function(){},h=!0;var n=l.f,e=o([].splice),t={};t[m]=1,n(t).length&&(l.f=function(t){for(var r=n(t),o=0,i=r.length;o<i;o++)if(r[o]===m){e(r,o,1);break}return r},r({target:"Object",stat:!0,forced:!0},{getOwnPropertyNames:u.f}))},fastKey:function(n,e){if(!a(n))return"symbol"==typeof n?n:("string"==typeof n?"S":"P")+n;if(!s(n,m)){if(!p(n))return"F";if(!e)return"E";g(n)}return n[m].objectID},getWeakData:function(n,e){if(!s(n,m)){if(!p(n))return!0;if(!e)return!1;g(n)}return n[m].weakData},onFreeze:function(n){return f&&h&&p(n)&&!s(n,m)&&g(n),n}};i[m]=!0},function(n,e,t){var r=t(3),o=t(9),i=t(25),a=t(260),s=Object.isExtensible,c=r((function(){s(1)}));n.exports=c||a?function(n){return!!o(n)&&((!a||"ArrayBuffer"!=i(n))&&(!s||s(n)))}:s},function(n,e,t){var r=t(3);n.exports=r((function(){if("function"==typeof ArrayBuffer){var n=new ArrayBuffer(8);Object.isExtensible(n)&&Object.defineProperty(n,"a",{value:8})}}))},function(n,e,t){var r=t(0);n.exports=r},function(n,e,t){"use strict";var r=t(0),o=t(56),i=t(11),a=t(16),s=t(263),c=t(166),l=t(88),u=t(23),p=t(70),d=t(145),f=t(106),h=r.Array;n.exports=function(n){var e=a(n),t=l(this),r=arguments.length,m=r>1?arguments[1]:void 0,v=void 0!==m;v&&(m=o(m,r>2?arguments[2]:void 0));var g,y,b,x,_,w,E=f(e),k=0;if(!E||this==h&&c(E))for(g=u(e),y=t?new this(g):h(g);g>k;k++)w=v?m(e[k],k):e[k],p(y,k,w);else for(_=(x=d(e,E)).next,y=t?new this:[];!(b=i(_,x)).done;k++)w=v?s(x,m,[b.value,k],!0):b.value,p(y,k,w);return y.length=k,y}},function(n,e,t){var r=t(8),o=t(167);n.exports=function(n,e,t,i){try{return i?e(r(t)[0],t[1]):e(t)}catch(e){o(n,"throw",e)}}},function(n,e,t){"use strict";var r=t(17),o=t(10),i=t(27),a=t(35),s=t(68),c=t(119),l=t(150),u=t(188),p=t(265),d=t(266),f=t(267),h=t(26);n.exports=function(n,e,t,m){var v=m?2:1,g=n.split("."),y=g[g.length-1],b=r.apply(null,g);if(b){var x=b.prototype;if(!h&&o(x,"cause")&&delete x.cause,!t)return b;var _=r("Error"),w=e((function(n,e){var t=u(m?e:n,void 0),r=m?new b(n):new b;return void 0!==t&&i(r,"message",t),f&&i(r,"stack",d(r.stack,2)),this&&a(x,this)&&l(r,this,w),arguments.length>v&&p(r,arguments[v]),r}));if(w.prototype=x,"Error"!==y&&(s?s(w,_):c(w,_,{name:!0})),c(w,b),!h)try{x.name!==y&&i(x,"name",y),x.constructor=w}catch(n){}return w}}},function(n,e,t){var r=t(9),o=t(27);n.exports=function(n,e){r(e)&&"cause"in e&&o(n,"cause",e.cause)}},function(n,e,t){var r=t(2)("".replace),o=String(Error("zxcasd").stack),i=/\n\s*at [^:]*:[^\n]*/,a=i.test(o);n.exports=function(n,e){if(a&&"string"==typeof n)for(;e--;)n=r(n,i,"");return n}},function(n,e,t){var r=t(3),o=t(49);n.exports=!r((function(){var n=Error("a");return!("stack"in n)||(Object.defineProperty(n,"stack",o(1,7)),7!==n.stack)}))},function(n,e,t){"use strict";var r=t(7),o=t(3),i=t(8),a=t(34),s=t(188),c=Error.prototype.toString,l=o((function(){if(r){var n=a(Object.defineProperty({},"name",{get:function(){return this===n}}));if("true"!==c.call(n))return!0}return"2: 1"!==c.call({message:1,name:2})||"Error"!==c.call({})}));n.exports=l?function(){var n=i(this),e=s(n.name,"Error"),t=s(n.message);return e?t?e+": "+t:e:t}:c},function(n,e,t){var r=t(2),o=t(16),i=Math.floor,a=r("".charAt),s=r("".replace),c=r("".slice),l=/\$([$&'`]|\d{1,2}|<[^>]*>)/g,u=/\$([$&'`]|\d{1,2})/g;n.exports=function(n,e,t,r,p,d){var f=t+n.length,h=r.length,m=u;return void 0!==p&&(p=o(p),m=l),s(d,m,(function(o,s){var l;switch(a(s,0)){case"$":return"$";case"&":return n;case"`":return c(e,0,t);case"'":return c(e,f);case"<":l=p[c(s,1,-1)];break;default:var u=+s;if(0===u)return o;if(u>h){var d=i(u/10);return 0===d?o:d<=h?void 0===r[d-1]?a(s,1):r[d-1]+a(s,1):o}l=r[u-1]}return void 0===l?"":l}))}},function(n,e,t){var r=t(191),o=t(271);n.exports=function n(e,t,i,a,s){var c=-1,l=e.length;for(i||(i=o),s||(s=[]);++c<l;){var u=e[c];t>0&&i(u)?t>1?n(u,t-1,i,a,s):r(s,u):a||(s[s.length]=u)}return s}},function(n,e,t){var r=t(72),o=t(128),i=t(31),a=r?r.isConcatSpreadable:void 0;n.exports=function(n){return i(n)||o(n)||!!(a&&n&&n[a])}},function(n,e,t){var r=t(62),o=t(50);n.exports=function(n){return o(n)&&"[object Arguments]"==r(n)}},function(n,e,t){var r=t(72),o=Object.prototype,i=o.hasOwnProperty,a=o.toString,s=r?r.toStringTag:void 0;n.exports=function(n){var e=i.call(n,s),t=n[s];try{n[s]=void 0;var r=!0}catch(n){}var o=a.call(n);return r&&(e?n[s]=t:delete n[s]),o}},function(n,e){var t=Object.prototype.toString;n.exports=function(n){return t.call(n)}},function(n,e,t){var r=t(276),o=t(332),i=t(136),a=t(31),s=t(343);n.exports=function(n){return"function"==typeof n?n:null==n?i:"object"==typeof n?a(n)?o(n[0],n[1]):r(n):s(n)}},function(n,e,t){var r=t(277),o=t(331),i=t(208);n.exports=function(n){var e=o(n);return 1==e.length&&e[0][2]?i(e[0][0],e[0][1]):function(t){return t===n||r(t,n,e)}}},function(n,e,t){var r=t(193),o=t(197);n.exports=function(n,e,t,i){var a=t.length,s=a,c=!i;if(null==n)return!s;for(n=Object(n);a--;){var l=t[a];if(c&&l[2]?l[1]!==n[l[0]]:!(l[0]in n))return!1}for(;++a<s;){var u=(l=t[a])[0],p=n[u],d=l[1];if(c&&l[2]){if(void 0===p&&!(u in n))return!1}else{var f=new r;if(i)var h=i(p,d,u,n,e,f);if(!(void 0===h?o(d,p,3,i,f):h))return!1}}return!0}},function(n,e){n.exports=function(){this.__data__=[],this.size=0}},function(n,e,t){var r=t(95),o=Array.prototype.splice;n.exports=function(n){var e=this.__data__,t=r(e,n);return!(t<0)&&(t==e.length-1?e.pop():o.call(e,t,1),--this.size,!0)}},function(n,e,t){var r=t(95);n.exports=function(n){var e=this.__data__,t=r(e,n);return t<0?void 0:e[t][1]}},function(n,e,t){var r=t(95);n.exports=function(n){return r(this.__data__,n)>-1}},function(n,e,t){var r=t(95);n.exports=function(n,e){var t=this.__data__,o=r(t,n);return o<0?(++this.size,t.push([n,e])):t[o][1]=e,this}},function(n,e,t){var r=t(94);n.exports=function(){this.__data__=new r,this.size=0}},function(n,e){n.exports=function(n){var e=this.__data__,t=e.delete(n);return this.size=e.size,t}},function(n,e){n.exports=function(n){return this.__data__.get(n)}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e,t){var r=t(94),o=t(129),i=t(131);n.exports=function(n,e){var t=this.__data__;if(t instanceof r){var a=t.__data__;if(!o||a.length<199)return a.push([n,e]),this.size=++t.size,this;t=this.__data__=new i(a)}return t.set(n,e),this.size=t.size,this}},function(n,e,t){var r=t(195),o=t(289),i=t(130),a=t(196),s=/^\[object .+?Constructor\]$/,c=Function.prototype,l=Object.prototype,u=c.toString,p=l.hasOwnProperty,d=RegExp("^"+u.call(p).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");n.exports=function(n){return!(!i(n)||o(n))&&(r(n)?d:s).test(a(n))}},function(n,e,t){var r,o=t(290),i=(r=/[^.]+$/.exec(o&&o.keys&&o.keys.IE_PROTO||""))?"Symbol(src)_1."+r:"";n.exports=function(n){return!!i&&i in n}},function(n,e,t){var r=t(33)["__core-js_shared__"];n.exports=r},function(n,e){n.exports=function(n,e){return null==n?void 0:n[e]}},function(n,e,t){var r=t(293),o=t(94),i=t(129);n.exports=function(){this.size=0,this.__data__={hash:new r,map:new(i||o),string:new r}}},function(n,e,t){var r=t(294),o=t(295),i=t(296),a=t(297),s=t(298);function c(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}c.prototype.clear=r,c.prototype.delete=o,c.prototype.get=i,c.prototype.has=a,c.prototype.set=s,n.exports=c},function(n,e,t){var r=t(96);n.exports=function(){this.__data__=r?r(null):{},this.size=0}},function(n,e){n.exports=function(n){var e=this.has(n)&&delete this.__data__[n];return this.size-=e?1:0,e}},function(n,e,t){var r=t(96),o=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;if(r){var t=e[n];return"__lodash_hash_undefined__"===t?void 0:t}return o.call(e,n)?e[n]:void 0}},function(n,e,t){var r=t(96),o=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;return r?void 0!==e[n]:o.call(e,n)}},function(n,e,t){var r=t(96);n.exports=function(n,e){var t=this.__data__;return this.size+=this.has(n)?0:1,t[n]=r&&void 0===e?"__lodash_hash_undefined__":e,this}},function(n,e,t){var r=t(97);n.exports=function(n){var e=r(this,n).delete(n);return this.size-=e?1:0,e}},function(n,e){n.exports=function(n){var e=typeof n;return"string"==e||"number"==e||"symbol"==e||"boolean"==e?"__proto__"!==n:null===n}},function(n,e,t){var r=t(97);n.exports=function(n){return r(this,n).get(n)}},function(n,e,t){var r=t(97);n.exports=function(n){return r(this,n).has(n)}},function(n,e,t){var r=t(97);n.exports=function(n,e){var t=r(this,n),o=t.size;return t.set(n,e),this.size+=t.size==o?0:1,this}},function(n,e,t){var r=t(193),o=t(198),i=t(308),a=t(311),s=t(327),c=t(31),l=t(202),u=t(204),p="[object Object]",d=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,f,h,m){var v=c(n),g=c(e),y=v?"[object Array]":s(n),b=g?"[object Array]":s(e),x=(y="[object Arguments]"==y?p:y)==p,_=(b="[object Arguments]"==b?p:b)==p,w=y==b;if(w&&l(n)){if(!l(e))return!1;v=!0,x=!1}if(w&&!x)return m||(m=new r),v||u(n)?o(n,e,t,f,h,m):i(n,e,y,t,f,h,m);if(!(1&t)){var E=x&&d.call(n,"__wrapped__"),k=_&&d.call(e,"__wrapped__");if(E||k){var C=E?n.value():n,T=k?e.value():e;return m||(m=new r),h(C,T,t,f,m)}}return!!w&&(m||(m=new r),a(n,e,t,f,h,m))}},function(n,e){n.exports=function(n){return this.__data__.set(n,"__lodash_hash_undefined__"),this}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length;++t<r;)if(e(n[t],t,n))return!0;return!1}},function(n,e,t){var r=t(72),o=t(309),i=t(194),a=t(198),s=t(310),c=t(132),l=r?r.prototype:void 0,u=l?l.valueOf:void 0;n.exports=function(n,e,t,r,l,p,d){switch(t){case"[object DataView]":if(n.byteLength!=e.byteLength||n.byteOffset!=e.byteOffset)return!1;n=n.buffer,e=e.buffer;case"[object ArrayBuffer]":return!(n.byteLength!=e.byteLength||!p(new o(n),new o(e)));case"[object Boolean]":case"[object Date]":case"[object Number]":return i(+n,+e);case"[object Error]":return n.name==e.name&&n.message==e.message;case"[object RegExp]":case"[object String]":return n==e+"";case"[object Map]":var f=s;case"[object Set]":var h=1&r;if(f||(f=c),n.size!=e.size&&!h)return!1;var m=d.get(n);if(m)return m==e;r|=2,d.set(n,e);var v=a(f(n),f(e),r,l,p,d);return d.delete(n),v;case"[object Symbol]":if(u)return u.call(n)==u.call(e)}return!1}},function(n,e,t){var r=t(33).Uint8Array;n.exports=r},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n,r){t[++e]=[r,n]})),t}},function(n,e,t){var r=t(312),o=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,i,a,s){var c=1&t,l=r(n),u=l.length;if(u!=r(e).length&&!c)return!1;for(var p=u;p--;){var d=l[p];if(!(c?d in e:o.call(e,d)))return!1}var f=s.get(n),h=s.get(e);if(f&&h)return f==e&&h==n;var m=!0;s.set(n,e),s.set(e,n);for(var v=c;++p<u;){var g=n[d=l[p]],y=e[d];if(i)var b=c?i(y,g,d,e,n,s):i(g,y,d,n,e,s);if(!(void 0===b?g===y||a(g,y,t,i,s):b)){m=!1;break}v||(v="constructor"==d)}if(m&&!v){var x=n.constructor,_=e.constructor;x==_||!("constructor"in n)||!("constructor"in e)||"function"==typeof x&&x instanceof x&&"function"==typeof _&&_ instanceof _||(m=!1)}return s.delete(n),s.delete(e),m}},function(n,e,t){var r=t(313),o=t(314),i=t(201);n.exports=function(n){return r(n,i,o)}},function(n,e,t){var r=t(191),o=t(31);n.exports=function(n,e,t){var i=e(n);return o(n)?i:r(i,t(n))}},function(n,e,t){var r=t(315),o=t(316),i=Object.prototype.propertyIsEnumerable,a=Object.getOwnPropertySymbols,s=a?function(n){return null==n?[]:(n=Object(n),r(a(n),(function(e){return i.call(n,e)})))}:o;n.exports=s},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,o=0,i=[];++t<r;){var a=n[t];e(a,t,n)&&(i[o++]=a)}return i}},function(n,e){n.exports=function(){return[]}},function(n,e,t){var r=t(318),o=t(128),i=t(31),a=t(202),s=t(203),c=t(204),l=Object.prototype.hasOwnProperty;n.exports=function(n,e){var t=i(n),u=!t&&o(n),p=!t&&!u&&a(n),d=!t&&!u&&!p&&c(n),f=t||u||p||d,h=f?r(n.length,String):[],m=h.length;for(var v in n)!e&&!l.call(n,v)||f&&("length"==v||p&&("offset"==v||"parent"==v)||d&&("buffer"==v||"byteLength"==v||"byteOffset"==v)||s(v,m))||h.push(v);return h}},function(n,e){n.exports=function(n,e){for(var t=-1,r=Array(n);++t<n;)r[t]=e(t);return r}},function(n,e){n.exports=function(){return!1}},function(n,e,t){var r=t(62),o=t(133),i=t(50),a={};a["[object Float32Array]"]=a["[object Float64Array]"]=a["[object Int8Array]"]=a["[object Int16Array]"]=a["[object Int32Array]"]=a["[object Uint8Array]"]=a["[object Uint8ClampedArray]"]=a["[object Uint16Array]"]=a["[object Uint32Array]"]=!0,a["[object Arguments]"]=a["[object Array]"]=a["[object ArrayBuffer]"]=a["[object Boolean]"]=a["[object DataView]"]=a["[object Date]"]=a["[object Error]"]=a["[object Function]"]=a["[object Map]"]=a["[object Number]"]=a["[object Object]"]=a["[object RegExp]"]=a["[object Set]"]=a["[object String]"]=a["[object WeakMap]"]=!1,n.exports=function(n){return i(n)&&o(n.length)&&!!a[r(n)]}},function(n,e){n.exports=function(n){return function(e){return n(e)}}},function(n,e,t){(function(n){var r=t(192),o=e&&!e.nodeType&&e,i=o&&"object"==typeof n&&n&&!n.nodeType&&n,a=i&&i.exports===o&&r.process,s=function(){try{var n=i&&i.require&&i.require("util").types;return n||a&&a.binding&&a.binding("util")}catch(n){}}();n.exports=s}).call(this,t(151)(n))},function(n,e,t){var r=t(324),o=t(325),i=Object.prototype.hasOwnProperty;n.exports=function(n){if(!r(n))return o(n);var e=[];for(var t in Object(n))i.call(n,t)&&"constructor"!=t&&e.push(t);return e}},function(n,e){var t=Object.prototype;n.exports=function(n){var e=n&&n.constructor;return n===("function"==typeof e&&e.prototype||t)}},function(n,e,t){var r=t(326)(Object.keys,Object);n.exports=r},function(n,e){n.exports=function(n,e){return function(t){return n(e(t))}}},function(n,e,t){var r=t(328),o=t(129),i=t(329),a=t(206),s=t(330),c=t(62),l=t(196),u=l(r),p=l(o),d=l(i),f=l(a),h=l(s),m=c;(r&&"[object DataView]"!=m(new r(new ArrayBuffer(1)))||o&&"[object Map]"!=m(new o)||i&&"[object Promise]"!=m(i.resolve())||a&&"[object Set]"!=m(new a)||s&&"[object WeakMap]"!=m(new s))&&(m=function(n){var e=c(n),t="[object Object]"==e?n.constructor:void 0,r=t?l(t):"";if(r)switch(r){case u:return"[object DataView]";case p:return"[object Map]";case d:return"[object Promise]";case f:return"[object Set]";case h:return"[object WeakMap]"}return e}),n.exports=m},function(n,e,t){var r=t(41)(t(33),"DataView");n.exports=r},function(n,e,t){var r=t(41)(t(33),"Promise");n.exports=r},function(n,e,t){var r=t(41)(t(33),"WeakMap");n.exports=r},function(n,e,t){var r=t(207),o=t(201);n.exports=function(n){for(var e=o(n),t=e.length;t--;){var i=e[t],a=n[i];e[t]=[i,a,r(a)]}return e}},function(n,e,t){var r=t(197),o=t(333),i=t(340),a=t(134),s=t(207),c=t(208),l=t(98);n.exports=function(n,e){return a(n)&&s(e)?c(l(n),e):function(t){var a=o(t,n);return void 0===a&&a===e?i(t,n):r(e,a,3)}}},function(n,e,t){var r=t(209);n.exports=function(n,e,t){var o=null==n?void 0:r(n,e);return void 0===o?t:o}},function(n,e,t){var r=t(335),o=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,i=/\\(\\)?/g,a=r((function(n){var e=[];return 46===n.charCodeAt(0)&&e.push(""),n.replace(o,(function(n,t,r,o){e.push(r?o.replace(i,"$1"):t||n)})),e}));n.exports=a},function(n,e,t){var r=t(336);n.exports=function(n){var e=r(n,(function(n){return 500===t.size&&t.clear(),n})),t=e.cache;return e}},function(n,e,t){var r=t(131);function o(n,e){if("function"!=typeof n||null!=e&&"function"!=typeof e)throw new TypeError("Expected a function");var t=function(){var r=arguments,o=e?e.apply(this,r):r[0],i=t.cache;if(i.has(o))return i.get(o);var a=n.apply(this,r);return t.cache=i.set(o,a)||i,a};return t.cache=new(o.Cache||r),t}o.Cache=r,n.exports=o},function(n,e,t){var r=t(338);n.exports=function(n){return null==n?"":r(n)}},function(n,e,t){var r=t(72),o=t(339),i=t(31),a=t(135),s=r?r.prototype:void 0,c=s?s.toString:void 0;n.exports=function n(e){if("string"==typeof e)return e;if(i(e))return o(e,n)+"";if(a(e))return c?c.call(e):"";var t=e+"";return"0"==t&&1/e==-1/0?"-0":t}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,o=Array(r);++t<r;)o[t]=e(n[t],t,n);return o}},function(n,e,t){var r=t(341),o=t(342);n.exports=function(n,e){return null!=n&&o(n,e,r)}},function(n,e){n.exports=function(n,e){return null!=n&&e in Object(n)}},function(n,e,t){var r=t(210),o=t(128),i=t(31),a=t(203),s=t(133),c=t(98);n.exports=function(n,e,t){for(var l=-1,u=(e=r(e,n)).length,p=!1;++l<u;){var d=c(e[l]);if(!(p=null!=n&&t(n,d)))break;n=n[d]}return p||++l!=u?p:!!(u=null==n?0:n.length)&&s(u)&&a(d,u)&&(i(n)||o(n))}},function(n,e,t){var r=t(344),o=t(345),i=t(134),a=t(98);n.exports=function(n){return i(n)?r(a(n)):o(n)}},function(n,e){n.exports=function(n){return function(e){return null==e?void 0:e[n]}}},function(n,e,t){var r=t(209);n.exports=function(n){return function(e){return r(e,n)}}},function(n,e,t){var r=t(136),o=t(347),i=t(349);n.exports=function(n,e){return i(o(n,e,r),n+"")}},function(n,e,t){var r=t(348),o=Math.max;n.exports=function(n,e,t){return e=o(void 0===e?n.length-1:e,0),function(){for(var i=arguments,a=-1,s=o(i.length-e,0),c=Array(s);++a<s;)c[a]=i[e+a];a=-1;for(var l=Array(e+1);++a<e;)l[a]=i[a];return l[e]=t(c),r(n,this,l)}}},function(n,e){n.exports=function(n,e,t){switch(t.length){case 0:return n.call(e);case 1:return n.call(e,t[0]);case 2:return n.call(e,t[0],t[1]);case 3:return n.call(e,t[0],t[1],t[2])}return n.apply(e,t)}},function(n,e,t){var r=t(350),o=t(353)(r);n.exports=o},function(n,e,t){var r=t(351),o=t(352),i=t(136),a=o?function(n,e){return o(n,"toString",{configurable:!0,enumerable:!1,value:r(e),writable:!0})}:i;n.exports=a},function(n,e){n.exports=function(n){return function(){return n}}},function(n,e,t){var r=t(41),o=function(){try{var n=r(Object,"defineProperty");return n({},"",{}),n}catch(n){}}();n.exports=o},function(n,e){var t=Date.now;n.exports=function(n){var e=0,r=0;return function(){var o=t(),i=16-(o-r);if(r=o,i>0){if(++e>=800)return arguments[0]}else e=0;return n.apply(void 0,arguments)}}},function(n,e,t){var r=t(199),o=t(355),i=t(360),a=t(200),s=t(361),c=t(132);n.exports=function(n,e,t){var l=-1,u=o,p=n.length,d=!0,f=[],h=f;if(t)d=!1,u=i;else if(p>=200){var m=e?null:s(n);if(m)return c(m);d=!1,u=a,h=new r}else h=e?[]:f;n:for(;++l<p;){var v=n[l],g=e?e(v):v;if(v=t||0!==v?v:0,d&&g==g){for(var y=h.length;y--;)if(h[y]===g)continue n;e&&h.push(g),f.push(v)}else u(h,g,t)||(h!==f&&h.push(g),f.push(v))}return f}},function(n,e,t){var r=t(356);n.exports=function(n,e){return!!(null==n?0:n.length)&&r(n,e,0)>-1}},function(n,e,t){var r=t(357),o=t(358),i=t(359);n.exports=function(n,e,t){return e==e?i(n,e,t):r(n,o,t)}},function(n,e){n.exports=function(n,e,t,r){for(var o=n.length,i=t+(r?1:-1);r?i--:++i<o;)if(e(n[i],i,n))return i;return-1}},function(n,e){n.exports=function(n){return n!=n}},function(n,e){n.exports=function(n,e,t){for(var r=t-1,o=n.length;++r<o;)if(n[r]===e)return r;return-1}},function(n,e){n.exports=function(n,e,t){for(var r=-1,o=null==n?0:n.length;++r<o;)if(t(e,n[r]))return!0;return!1}},function(n,e,t){var r=t(206),o=t(362),i=t(132),a=r&&1/i(new r([,-0]))[1]==1/0?function(n){return new r(n)}:o;n.exports=a},function(n,e){n.exports=function(){}},function(n,e,t){var r=t(205),o=t(50);n.exports=function(n){return o(n)&&r(n)}},function(n,e,t){},function(n,e,t){},function(n,e,t){var r=t(67).PROPER,o=t(3),i=t(154);n.exports=function(n){return o((function(){return!!i[n]()||"​᠎"!=="​᠎"[n]()||r&&i[n].name!==n}))}},function(n,e,t){var r=t(1),o=t(211);r({target:"Function",proto:!0,forced:Function.bind!==o},{bind:o})},function(n,e,t){var r=t(2);n.exports=r(1..valueOf)},function(n,e,t){var r=t(2),o=t(53),i=t(12),a=t(370),s=t(19),c=r(a),l=r("".slice),u=Math.ceil,p=function(n){return function(e,t,r){var a,p,d=i(s(e)),f=o(t),h=d.length,m=void 0===r?" ":i(r);return f<=h||""==m?d:((p=c(m,u((a=f-h)/m.length))).length>a&&(p=l(p,0,a)),n?d+p:p+d)}};n.exports={start:p(!1),end:p(!0)}},function(n,e,t){"use strict";var r=t(0),o=t(55),i=t(12),a=t(19),s=r.RangeError;n.exports=function(n){var e=i(a(this)),t="",r=o(n);if(r<0||r==1/0)throw s("Wrong number of repetitions");for(;r>0;(r>>>=1)&&(e+=e))1&r&&(t+=e);return t}},function(n,e,t){var r=t(32);n.exports=/Version\/10(?:\.\d+){1,2}(?: [\w./]+)?(?: Mobile\/\w+)? Safari\//.test(r)},function(n,e,t){"use strict";t(213)},function(n,e,t){"use strict";t(214)},function(n,e,t){"use strict";var r=t(1),o=t(2),i=t(37),a=t(16),s=t(23),c=t(12),l=t(3),u=t(235),p=t(47),d=t(375),f=t(376),h=t(52),m=t(377),v=[],g=o(v.sort),y=o(v.push),b=l((function(){v.sort(void 0)})),x=l((function(){v.sort(null)})),_=p("sort"),w=!l((function(){if(h)return h<70;if(!(d&&d>3)){if(f)return!0;if(m)return m<603;var n,e,t,r,o="";for(n=65;n<76;n++){switch(e=String.fromCharCode(n),n){case 66:case 69:case 70:case 72:t=3;break;case 68:case 71:t=4;break;default:t=2}for(r=0;r<47;r++)v.push({k:e+r,v:t})}for(v.sort((function(n,e){return e.v-n.v})),r=0;r<v.length;r++)e=v[r].k.charAt(0),o.charAt(o.length-1)!==e&&(o+=e);return"DGBEFHACIJK"!==o}}));r({target:"Array",proto:!0,forced:b||!x||!_||!w},{sort:function(n){void 0!==n&&i(n);var e=a(this);if(w)return void 0===n?g(e):g(e,n);var t,r,o=[],l=s(e);for(r=0;r<l;r++)r in e&&y(o,e[r]);for(u(o,function(n){return function(e,t){return void 0===t?-1:void 0===e?1:void 0!==n?+n(e,t)||0:c(e)>c(t)?1:-1}}(n)),t=o.length,r=0;r<t;)e[r]=o[r++];for(;r<l;)delete e[r++];return e}})},function(n,e,t){var r=t(32).match(/firefox\/(\d+)/i);n.exports=!!r&&+r[1]},function(n,e,t){var r=t(32);n.exports=/MSIE|Trident/.test(r)},function(n,e,t){var r=t(32).match(/AppleWebKit\/(\d+)\./);n.exports=!!r&&+r[1]},function(n,e,t){},function(n,e,t){},function(n,e,t){var r=t(1),o=t(3),i=t(20),a=t(38).f,s=t(7),c=o((function(){a(1)}));r({target:"Object",stat:!0,forced:!s||c,sham:!s},{getOwnPropertyDescriptor:function(n,e){return a(i(n),e)}})},function(n,e,t){var r=t(1),o=t(7),i=t(114).f;r({target:"Object",stat:!0,forced:Object.defineProperties!==i,sham:!o},{defineProperties:i})},function(n,e,t){t(1)({target:"Reflect",stat:!0},{ownKeys:t(120)})},function(n,e){},function(n,e){function t(n,e){for(var t=0,r=n.length-1;r>=0;r--){var o=n[r];"."===o?n.splice(r,1):".."===o?(n.splice(r,1),t++):t&&(n.splice(r,1),t--)}if(e)for(;t--;t)n.unshift("..");return n}function r(n,e){if(n.filter)return n.filter(e);for(var t=[],r=0;r<n.length;r++)e(n[r],r,n)&&t.push(n[r]);return t}e.resolve=function(){for(var n="",e=!1,o=arguments.length-1;o>=-1&&!e;o--){var i=o>=0?arguments[o]:process.cwd();if("string"!=typeof i)throw new TypeError("Arguments to path.resolve must be strings");i&&(n=i+"/"+n,e="/"===i.charAt(0))}return(e?"/":"")+(n=t(r(n.split("/"),(function(n){return!!n})),!e).join("/"))||"."},e.normalize=function(n){var i=e.isAbsolute(n),a="/"===o(n,-1);return(n=t(r(n.split("/"),(function(n){return!!n})),!i).join("/"))||i||(n="."),n&&a&&(n+="/"),(i?"/":"")+n},e.isAbsolute=function(n){return"/"===n.charAt(0)},e.join=function(){var n=Array.prototype.slice.call(arguments,0);return e.normalize(r(n,(function(n,e){if("string"!=typeof n)throw new TypeError("Arguments to path.join must be strings");return n})).join("/"))},e.relative=function(n,t){function r(n){for(var e=0;e<n.length&&""===n[e];e++);for(var t=n.length-1;t>=0&&""===n[t];t--);return e>t?[]:n.slice(e,t-e+1)}n=e.resolve(n).substr(1),t=e.resolve(t).substr(1);for(var o=r(n.split("/")),i=r(t.split("/")),a=Math.min(o.length,i.length),s=a,c=0;c<a;c++)if(o[c]!==i[c]){s=c;break}var l=[];for(c=s;c<o.length;c++)l.push("..");return(l=l.concat(i.slice(s))).join("/")},e.sep="/",e.delimiter=":",e.dirname=function(n){if("string"!=typeof n&&(n+=""),0===n.length)return".";for(var e=n.charCodeAt(0),t=47===e,r=-1,o=!0,i=n.length-1;i>=1;--i)if(47===(e=n.charCodeAt(i))){if(!o){r=i;break}}else o=!1;return-1===r?t?"/":".":t&&1===r?"/":n.slice(0,r)},e.basename=function(n,e){var t=function(n){"string"!=typeof n&&(n+="");var e,t=0,r=-1,o=!0;for(e=n.length-1;e>=0;--e)if(47===n.charCodeAt(e)){if(!o){t=e+1;break}}else-1===r&&(o=!1,r=e+1);return-1===r?"":n.slice(t,r)}(n);return e&&t.substr(-1*e.length)===e&&(t=t.substr(0,t.length-e.length)),t},e.extname=function(n){"string"!=typeof n&&(n+="");for(var e=-1,t=0,r=-1,o=!0,i=0,a=n.length-1;a>=0;--a){var s=n.charCodeAt(a);if(47!==s)-1===r&&(o=!1,r=a+1),46===s?-1===e?e=a:1!==i&&(i=1):-1!==e&&(i=-1);else if(!o){t=a+1;break}}return-1===e||-1===r||0===i||1===i&&e===r-1&&e===t+1?"":n.slice(e,r)};var o="b"==="ab".substr(-1)?function(n,e,t){return n.substr(e,t)}:function(n,e,t){return e<0&&(e=n.length+e),n.substr(e,t)}},function(n,e,t){"use strict";var r=/[|\\{}()[\]^$+*?.]/g;e.escapeRegExpChars=function(n){return n?String(n).replace(r,"\\$&"):""};var o={"&":"&amp;","<":"&lt;",">":"&gt;",'"':"&#34;","'":"&#39;"},i=/[&<>'"]/g;function a(n){return o[n]||n}e.escapeXML=function(n){return null==n?"":String(n).replace(i,a)},e.escapeXML.toString=function(){return Function.prototype.toString.call(this)+';\nvar _ENCODE_HTML_RULES = {\n      "&": "&amp;"\n    , "<": "&lt;"\n    , ">": "&gt;"\n    , \'"\': "&#34;"\n    , "\'": "&#39;"\n    }\n  , _MATCH_HTML = /[&<>\'"]/g;\nfunction encode_char(c) {\n  return _ENCODE_HTML_RULES[c] || c;\n};\n'},e.shallowCopy=function(n,e){for(var t in e=e||{})n[t]=e[t];return n},e.shallowCopyFromList=function(n,e,t){for(var r=0;r<t.length;r++){var o=t[r];void 0!==e[o]&&(n[o]=e[o])}return n},e.cache={_data:{},set:function(n,e){this._data[n]=e},get:function(n){return this._data[n]},remove:function(n){delete this._data[n]},reset:function(){this._data={}}}},function(n){n.exports=JSON.parse('{"name":"ejs","description":"Embedded JavaScript templates","keywords":["template","engine","ejs"],"version":"2.7.4","author":"Matthew Eernisse <mde@fleegix.org> (http://fleegix.org)","license":"Apache-2.0","main":"./lib/ejs.js","repository":{"type":"git","url":"git://github.com/mde/ejs.git"},"bugs":"https://github.com/mde/ejs/issues","homepage":"https://github.com/mde/ejs","dependencies":{},"devDependencies":{"browserify":"^13.1.1","eslint":"^4.14.0","git-directory-deploy":"^1.5.1","jake":"^10.3.1","jsdoc":"^3.4.0","lru-cache":"^4.0.1","mocha":"^5.0.5","uglify-js":"^3.3.16"},"engines":{"node":">=0.10.0"},"scripts":{"test":"mocha","postinstall":"node ./postinstall.js"}}')},function(n,e,t){"use strict";t(217)},function(n,e,t){"use strict";t(218)},function(n,e,t){"use strict";t.r(e);t(144),t(241),t(250),t(252);var r=t(90),o=(t(142),t(42),t(4),t(21),t(22),t(45),t(24),Object.freeze({}));function i(n){return null==n}function a(n){return null!=n}function s(n){return!0===n}function c(n){return"string"==typeof n||"number"==typeof n||"symbol"==typeof n||"boolean"==typeof n}function l(n){return null!==n&&"object"==typeof n}var u=Object.prototype.toString;function p(n){return"[object Object]"===u.call(n)}function d(n){return"[object RegExp]"===u.call(n)}function f(n){var e=parseFloat(String(n));return e>=0&&Math.floor(e)===e&&isFinite(n)}function h(n){return a(n)&&"function"==typeof n.then&&"function"==typeof n.catch}function m(n){return null==n?"":Array.isArray(n)||p(n)&&n.toString===u?JSON.stringify(n,null,2):String(n)}function v(n){var e=parseFloat(n);return isNaN(e)?n:e}function g(n,e){for(var t=Object.create(null),r=n.split(","),o=0;o<r.length;o++)t[r[o]]=!0;return e?function(n){return t[n.toLowerCase()]}:function(n){return t[n]}}g("slot,component",!0);var y=g("key,ref,slot,slot-scope,is");function b(n,e){if(n.length){var t=n.indexOf(e);if(t>-1)return n.splice(t,1)}}var x=Object.prototype.hasOwnProperty;function _(n,e){return x.call(n,e)}function w(n){var e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}var E=/-(\w)/g,k=w((function(n){return n.replace(E,(function(n,e){return e?e.toUpperCase():""}))})),C=w((function(n){return n.charAt(0).toUpperCase()+n.slice(1)})),T=/\B([A-Z])/g,S=w((function(n){return n.replace(T,"-$1").toLowerCase()}));var A=Function.prototype.bind?function(n,e){return n.bind(e)}:function(n,e){function t(t){var r=arguments.length;return r?r>1?n.apply(e,arguments):n.call(e,t):n.call(e)}return t._length=n.length,t};function O(n,e){e=e||0;for(var t=n.length-e,r=new Array(t);t--;)r[t]=n[t+e];return r}function j(n,e){for(var t in e)n[t]=e[t];return n}function I(n){for(var e={},t=0;t<n.length;t++)n[t]&&j(e,n[t]);return e}function P(n,e,t){}var z=function(n,e,t){return!1},D=function(n){return n};function L(n,e){if(n===e)return!0;var t=l(n),r=l(e);if(!t||!r)return!t&&!r&&String(n)===String(e);try{var o=Array.isArray(n),i=Array.isArray(e);if(o&&i)return n.length===e.length&&n.every((function(n,t){return L(n,e[t])}));if(n instanceof Date&&e instanceof Date)return n.getTime()===e.getTime();if(o||i)return!1;var a=Object.keys(n),s=Object.keys(e);return a.length===s.length&&a.every((function(t){return L(n[t],e[t])}))}catch(n){return!1}}function N(n,e){for(var t=0;t<n.length;t++)if(L(n[t],e))return t;return-1}function B(n){var e=!1;return function(){e||(e=!0,n.apply(this,arguments))}}var R=["component","directive","filter"],$=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch"],M={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:z,isReservedAttr:z,isUnknownElement:z,getTagNamespace:P,parsePlatformTagName:D,mustUseProp:z,async:!0,_lifecycleHooks:$},F=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function G(n,e,t,r){Object.defineProperty(n,e,{value:t,enumerable:!!r,writable:!0,configurable:!0})}var U=new RegExp("[^"+F.source+".$_\\d]");var V,H="__proto__"in{},q="undefined"!=typeof window,X="undefined"!=typeof WXEnvironment&&!!WXEnvironment.platform,J=X&&WXEnvironment.platform.toLowerCase(),Y=q&&window.navigator.userAgent.toLowerCase(),W=Y&&/msie|trident/.test(Y),Z=Y&&Y.indexOf("msie 9.0")>0,K=Y&&Y.indexOf("edge/")>0,Q=(Y&&Y.indexOf("android"),Y&&/iphone|ipad|ipod|ios/.test(Y)||"ios"===J),nn=(Y&&/chrome\/\d+/.test(Y),Y&&/phantomjs/.test(Y),Y&&Y.match(/firefox\/(\d+)/)),en={}.watch,tn=!1;if(q)try{var rn={};Object.defineProperty(rn,"passive",{get:function(){tn=!0}}),window.addEventListener("test-passive",null,rn)}catch(n){}var on=function(){return void 0===V&&(V=!q&&!X&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),V},an=q&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function sn(n){return"function"==typeof n&&/native code/.test(n.toString())}var cn,ln="undefined"!=typeof Symbol&&sn(Symbol)&&"undefined"!=typeof Reflect&&sn(Reflect.ownKeys);cn="undefined"!=typeof Set&&sn(Set)?Set:function(){function n(){this.set=Object.create(null)}return n.prototype.has=function(n){return!0===this.set[n]},n.prototype.add=function(n){this.set[n]=!0},n.prototype.clear=function(){this.set=Object.create(null)},n}();var un=P,pn=0,dn=function(){this.id=pn++,this.subs=[]};dn.prototype.addSub=function(n){this.subs.push(n)},dn.prototype.removeSub=function(n){b(this.subs,n)},dn.prototype.depend=function(){dn.target&&dn.target.addDep(this)},dn.prototype.notify=function(){var n=this.subs.slice();for(var e=0,t=n.length;e<t;e++)n[e].update()},dn.target=null;var fn=[];function hn(n){fn.push(n),dn.target=n}function mn(){fn.pop(),dn.target=fn[fn.length-1]}var vn=function(n,e,t,r,o,i,a,s){this.tag=n,this.data=e,this.children=t,this.text=r,this.elm=o,this.ns=void 0,this.context=i,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=e&&e.key,this.componentOptions=a,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=s,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1},gn={child:{configurable:!0}};gn.child.get=function(){return this.componentInstance},Object.defineProperties(vn.prototype,gn);var yn=function(n){void 0===n&&(n="");var e=new vn;return e.text=n,e.isComment=!0,e};function bn(n){return new vn(void 0,void 0,void 0,String(n))}function xn(n){var e=new vn(n.tag,n.data,n.children&&n.children.slice(),n.text,n.elm,n.context,n.componentOptions,n.asyncFactory);return e.ns=n.ns,e.isStatic=n.isStatic,e.key=n.key,e.isComment=n.isComment,e.fnContext=n.fnContext,e.fnOptions=n.fnOptions,e.fnScopeId=n.fnScopeId,e.asyncMeta=n.asyncMeta,e.isCloned=!0,e}var _n=Array.prototype,wn=Object.create(_n);["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(n){var e=_n[n];G(wn,n,(function(){for(var t=[],r=arguments.length;r--;)t[r]=arguments[r];var o,i=e.apply(this,t),a=this.__ob__;switch(n){case"push":case"unshift":o=t;break;case"splice":o=t.slice(2)}return o&&a.observeArray(o),a.dep.notify(),i}))}));var En=Object.getOwnPropertyNames(wn),kn=!0;function Cn(n){kn=n}var Tn=function(n){this.value=n,this.dep=new dn,this.vmCount=0,G(n,"__ob__",this),Array.isArray(n)?(H?function(n,e){n.__proto__=e}(n,wn):function(n,e,t){for(var r=0,o=t.length;r<o;r++){var i=t[r];G(n,i,e[i])}}(n,wn,En),this.observeArray(n)):this.walk(n)};function Sn(n,e){var t;if(l(n)&&!(n instanceof vn))return _(n,"__ob__")&&n.__ob__ instanceof Tn?t=n.__ob__:kn&&!on()&&(Array.isArray(n)||p(n))&&Object.isExtensible(n)&&!n._isVue&&(t=new Tn(n)),e&&t&&t.vmCount++,t}function An(n,e,t,r,o){var i=new dn,a=Object.getOwnPropertyDescriptor(n,e);if(!a||!1!==a.configurable){var s=a&&a.get,c=a&&a.set;s&&!c||2!==arguments.length||(t=n[e]);var l=!o&&Sn(t);Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){var e=s?s.call(n):t;return dn.target&&(i.depend(),l&&(l.dep.depend(),Array.isArray(e)&&In(e))),e},set:function(e){var r=s?s.call(n):t;e===r||e!=e&&r!=r||s&&!c||(c?c.call(n,e):t=e,l=!o&&Sn(e),i.notify())}})}}function On(n,e,t){if(Array.isArray(n)&&f(e))return n.length=Math.max(n.length,e),n.splice(e,1,t),t;if(e in n&&!(e in Object.prototype))return n[e]=t,t;var r=n.__ob__;return n._isVue||r&&r.vmCount?t:r?(An(r.value,e,t),r.dep.notify(),t):(n[e]=t,t)}function jn(n,e){if(Array.isArray(n)&&f(e))n.splice(e,1);else{var t=n.__ob__;n._isVue||t&&t.vmCount||_(n,e)&&(delete n[e],t&&t.dep.notify())}}function In(n){for(var e=void 0,t=0,r=n.length;t<r;t++)(e=n[t])&&e.__ob__&&e.__ob__.dep.depend(),Array.isArray(e)&&In(e)}Tn.prototype.walk=function(n){for(var e=Object.keys(n),t=0;t<e.length;t++)An(n,e[t])},Tn.prototype.observeArray=function(n){for(var e=0,t=n.length;e<t;e++)Sn(n[e])};var Pn=M.optionMergeStrategies;function zn(n,e){if(!e)return n;for(var t,r,o,i=ln?Reflect.ownKeys(e):Object.keys(e),a=0;a<i.length;a++)"__ob__"!==(t=i[a])&&(r=n[t],o=e[t],_(n,t)?r!==o&&p(r)&&p(o)&&zn(r,o):On(n,t,o));return n}function Dn(n,e,t){return t?function(){var r="function"==typeof e?e.call(t,t):e,o="function"==typeof n?n.call(t,t):n;return r?zn(r,o):o}:e?n?function(){return zn("function"==typeof e?e.call(this,this):e,"function"==typeof n?n.call(this,this):n)}:e:n}function Ln(n,e){var t=e?n?n.concat(e):Array.isArray(e)?e:[e]:n;return t?function(n){for(var e=[],t=0;t<n.length;t++)-1===e.indexOf(n[t])&&e.push(n[t]);return e}(t):t}function Nn(n,e,t,r){var o=Object.create(n||null);return e?j(o,e):o}Pn.data=function(n,e,t){return t?Dn(n,e,t):e&&"function"!=typeof e?n:Dn(n,e)},$.forEach((function(n){Pn[n]=Ln})),R.forEach((function(n){Pn[n+"s"]=Nn})),Pn.watch=function(n,e,t,r){if(n===en&&(n=void 0),e===en&&(e=void 0),!e)return Object.create(n||null);if(!n)return e;var o={};for(var i in j(o,n),e){var a=o[i],s=e[i];a&&!Array.isArray(a)&&(a=[a]),o[i]=a?a.concat(s):Array.isArray(s)?s:[s]}return o},Pn.props=Pn.methods=Pn.inject=Pn.computed=function(n,e,t,r){if(!n)return e;var o=Object.create(null);return j(o,n),e&&j(o,e),o},Pn.provide=Dn;var Bn=function(n,e){return void 0===e?n:e};function Rn(n,e,t){if("function"==typeof e&&(e=e.options),function(n,e){var t=n.props;if(t){var r,o,i={};if(Array.isArray(t))for(r=t.length;r--;)"string"==typeof(o=t[r])&&(i[k(o)]={type:null});else if(p(t))for(var a in t)o=t[a],i[k(a)]=p(o)?o:{type:o};else 0;n.props=i}}(e),function(n,e){var t=n.inject;if(t){var r=n.inject={};if(Array.isArray(t))for(var o=0;o<t.length;o++)r[t[o]]={from:t[o]};else if(p(t))for(var i in t){var a=t[i];r[i]=p(a)?j({from:i},a):{from:a}}else 0}}(e),function(n){var e=n.directives;if(e)for(var t in e){var r=e[t];"function"==typeof r&&(e[t]={bind:r,update:r})}}(e),!e._base&&(e.extends&&(n=Rn(n,e.extends,t)),e.mixins))for(var r=0,o=e.mixins.length;r<o;r++)n=Rn(n,e.mixins[r],t);var i,a={};for(i in n)s(i);for(i in e)_(n,i)||s(i);function s(r){var o=Pn[r]||Bn;a[r]=o(n[r],e[r],t,r)}return a}function $n(n,e,t,r){if("string"==typeof t){var o=n[e];if(_(o,t))return o[t];var i=k(t);if(_(o,i))return o[i];var a=C(i);return _(o,a)?o[a]:o[t]||o[i]||o[a]}}function Mn(n,e,t,r){var o=e[n],i=!_(t,n),a=t[n],s=Vn(Boolean,o.type);if(s>-1)if(i&&!_(o,"default"))a=!1;else if(""===a||a===S(n)){var c=Vn(String,o.type);(c<0||s<c)&&(a=!0)}if(void 0===a){a=function(n,e,t){if(!_(e,"default"))return;var r=e.default;0;if(n&&n.$options.propsData&&void 0===n.$options.propsData[t]&&void 0!==n._props[t])return n._props[t];return"function"==typeof r&&"Function"!==Gn(e.type)?r.call(n):r}(r,o,n);var l=kn;Cn(!0),Sn(a),Cn(l)}return a}var Fn=/^\s*function (\w+)/;function Gn(n){var e=n&&n.toString().match(Fn);return e?e[1]:""}function Un(n,e){return Gn(n)===Gn(e)}function Vn(n,e){if(!Array.isArray(e))return Un(e,n)?0:-1;for(var t=0,r=e.length;t<r;t++)if(Un(e[t],n))return t;return-1}function Hn(n,e,t){hn();try{if(e)for(var r=e;r=r.$parent;){var o=r.$options.errorCaptured;if(o)for(var i=0;i<o.length;i++)try{if(!1===o[i].call(r,n,e,t))return}catch(n){Xn(n,r,"errorCaptured hook")}}Xn(n,e,t)}finally{mn()}}function qn(n,e,t,r,o){var i;try{(i=t?n.apply(e,t):n.call(e))&&!i._isVue&&h(i)&&!i._handled&&(i.catch((function(n){return Hn(n,r,o+" (Promise/async)")})),i._handled=!0)}catch(n){Hn(n,r,o)}return i}function Xn(n,e,t){if(M.errorHandler)try{return M.errorHandler.call(null,n,e,t)}catch(e){e!==n&&Jn(e,null,"config.errorHandler")}Jn(n,e,t)}function Jn(n,e,t){if(!q&&!X||"undefined"==typeof console)throw n;console.error(n)}var Yn,Wn=!1,Zn=[],Kn=!1;function Qn(){Kn=!1;var n=Zn.slice(0);Zn.length=0;for(var e=0;e<n.length;e++)n[e]()}if("undefined"!=typeof Promise&&sn(Promise)){var ne=Promise.resolve();Yn=function(){ne.then(Qn),Q&&setTimeout(P)},Wn=!0}else if(W||"undefined"==typeof MutationObserver||!sn(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())Yn="undefined"!=typeof setImmediate&&sn(setImmediate)?function(){setImmediate(Qn)}:function(){setTimeout(Qn,0)};else{var ee=1,te=new MutationObserver(Qn),re=document.createTextNode(String(ee));te.observe(re,{characterData:!0}),Yn=function(){ee=(ee+1)%2,re.data=String(ee)},Wn=!0}function oe(n,e){var t;if(Zn.push((function(){if(n)try{n.call(e)}catch(n){Hn(n,e,"nextTick")}else t&&t(e)})),Kn||(Kn=!0,Yn()),!n&&"undefined"!=typeof Promise)return new Promise((function(n){t=n}))}var ie=new cn;function ae(n){!function n(e,t){var r,o,i=Array.isArray(e);if(!i&&!l(e)||Object.isFrozen(e)||e instanceof vn)return;if(e.__ob__){var a=e.__ob__.dep.id;if(t.has(a))return;t.add(a)}if(i)for(r=e.length;r--;)n(e[r],t);else for(o=Object.keys(e),r=o.length;r--;)n(e[o[r]],t)}(n,ie),ie.clear()}var se=w((function(n){var e="&"===n.charAt(0),t="~"===(n=e?n.slice(1):n).charAt(0),r="!"===(n=t?n.slice(1):n).charAt(0);return{name:n=r?n.slice(1):n,once:t,capture:r,passive:e}}));function ce(n,e){function t(){var n=arguments,r=t.fns;if(!Array.isArray(r))return qn(r,null,arguments,e,"v-on handler");for(var o=r.slice(),i=0;i<o.length;i++)qn(o[i],null,n,e,"v-on handler")}return t.fns=n,t}function le(n,e,t,r,o,a){var c,l,u,p;for(c in n)l=n[c],u=e[c],p=se(c),i(l)||(i(u)?(i(l.fns)&&(l=n[c]=ce(l,a)),s(p.once)&&(l=n[c]=o(p.name,l,p.capture)),t(p.name,l,p.capture,p.passive,p.params)):l!==u&&(u.fns=l,n[c]=u));for(c in e)i(n[c])&&r((p=se(c)).name,e[c],p.capture)}function ue(n,e,t){var r;n instanceof vn&&(n=n.data.hook||(n.data.hook={}));var o=n[e];function c(){t.apply(this,arguments),b(r.fns,c)}i(o)?r=ce([c]):a(o.fns)&&s(o.merged)?(r=o).fns.push(c):r=ce([o,c]),r.merged=!0,n[e]=r}function pe(n,e,t,r,o){if(a(e)){if(_(e,t))return n[t]=e[t],o||delete e[t],!0;if(_(e,r))return n[t]=e[r],o||delete e[r],!0}return!1}function de(n){return c(n)?[bn(n)]:Array.isArray(n)?function n(e,t){var r,o,l,u,p=[];for(r=0;r<e.length;r++)i(o=e[r])||"boolean"==typeof o||(l=p.length-1,u=p[l],Array.isArray(o)?o.length>0&&(fe((o=n(o,(t||"")+"_"+r))[0])&&fe(u)&&(p[l]=bn(u.text+o[0].text),o.shift()),p.push.apply(p,o)):c(o)?fe(u)?p[l]=bn(u.text+o):""!==o&&p.push(bn(o)):fe(o)&&fe(u)?p[l]=bn(u.text+o.text):(s(e._isVList)&&a(o.tag)&&i(o.key)&&a(t)&&(o.key="__vlist"+t+"_"+r+"__"),p.push(o)));return p}(n):void 0}function fe(n){return a(n)&&a(n.text)&&!1===n.isComment}function he(n,e){if(n){for(var t=Object.create(null),r=ln?Reflect.ownKeys(n):Object.keys(n),o=0;o<r.length;o++){var i=r[o];if("__ob__"!==i){for(var a=n[i].from,s=e;s;){if(s._provided&&_(s._provided,a)){t[i]=s._provided[a];break}s=s.$parent}if(!s)if("default"in n[i]){var c=n[i].default;t[i]="function"==typeof c?c.call(e):c}else 0}}return t}}function me(n,e){if(!n||!n.length)return{};for(var t={},r=0,o=n.length;r<o;r++){var i=n[r],a=i.data;if(a&&a.attrs&&a.attrs.slot&&delete a.attrs.slot,i.context!==e&&i.fnContext!==e||!a||null==a.slot)(t.default||(t.default=[])).push(i);else{var s=a.slot,c=t[s]||(t[s]=[]);"template"===i.tag?c.push.apply(c,i.children||[]):c.push(i)}}for(var l in t)t[l].every(ve)&&delete t[l];return t}function ve(n){return n.isComment&&!n.asyncFactory||" "===n.text}function ge(n){return n.isComment&&n.asyncFactory}function ye(n,e,t){var r,i=Object.keys(e).length>0,a=n?!!n.$stable:!i,s=n&&n.$key;if(n){if(n._normalized)return n._normalized;if(a&&t&&t!==o&&s===t.$key&&!i&&!t.$hasNormal)return t;for(var c in r={},n)n[c]&&"$"!==c[0]&&(r[c]=be(e,c,n[c]))}else r={};for(var l in e)l in r||(r[l]=xe(e,l));return n&&Object.isExtensible(n)&&(n._normalized=r),G(r,"$stable",a),G(r,"$key",s),G(r,"$hasNormal",i),r}function be(n,e,t){var r=function(){var n=arguments.length?t.apply(null,arguments):t({}),e=(n=n&&"object"==typeof n&&!Array.isArray(n)?[n]:de(n))&&n[0];return n&&(!e||1===n.length&&e.isComment&&!ge(e))?void 0:n};return t.proxy&&Object.defineProperty(n,e,{get:r,enumerable:!0,configurable:!0}),r}function xe(n,e){return function(){return n[e]}}function _e(n,e){var t,r,o,i,s;if(Array.isArray(n)||"string"==typeof n)for(t=new Array(n.length),r=0,o=n.length;r<o;r++)t[r]=e(n[r],r);else if("number"==typeof n)for(t=new Array(n),r=0;r<n;r++)t[r]=e(r+1,r);else if(l(n))if(ln&&n[Symbol.iterator]){t=[];for(var c=n[Symbol.iterator](),u=c.next();!u.done;)t.push(e(u.value,t.length)),u=c.next()}else for(i=Object.keys(n),t=new Array(i.length),r=0,o=i.length;r<o;r++)s=i[r],t[r]=e(n[s],s,r);return a(t)||(t=[]),t._isVList=!0,t}function we(n,e,t,r){var o,i=this.$scopedSlots[n];i?(t=t||{},r&&(t=j(j({},r),t)),o=i(t)||("function"==typeof e?e():e)):o=this.$slots[n]||("function"==typeof e?e():e);var a=t&&t.slot;return a?this.$createElement("template",{slot:a},o):o}function Ee(n){return $n(this.$options,"filters",n)||D}function ke(n,e){return Array.isArray(n)?-1===n.indexOf(e):n!==e}function Ce(n,e,t,r,o){var i=M.keyCodes[e]||t;return o&&r&&!M.keyCodes[e]?ke(o,r):i?ke(i,n):r?S(r)!==e:void 0===n}function Te(n,e,t,r,o){if(t)if(l(t)){var i;Array.isArray(t)&&(t=I(t));var a=function(a){if("class"===a||"style"===a||y(a))i=n;else{var s=n.attrs&&n.attrs.type;i=r||M.mustUseProp(e,s,a)?n.domProps||(n.domProps={}):n.attrs||(n.attrs={})}var c=k(a),l=S(a);c in i||l in i||(i[a]=t[a],o&&((n.on||(n.on={}))["update:"+a]=function(n){t[a]=n}))};for(var s in t)a(s)}else;return n}function Se(n,e){var t=this._staticTrees||(this._staticTrees=[]),r=t[n];return r&&!e||Oe(r=t[n]=this.$options.staticRenderFns[n].call(this._renderProxy,null,this),"__static__"+n,!1),r}function Ae(n,e,t){return Oe(n,"__once__"+e+(t?"_"+t:""),!0),n}function Oe(n,e,t){if(Array.isArray(n))for(var r=0;r<n.length;r++)n[r]&&"string"!=typeof n[r]&&je(n[r],e+"_"+r,t);else je(n,e,t)}function je(n,e,t){n.isStatic=!0,n.key=e,n.isOnce=t}function Ie(n,e){if(e)if(p(e)){var t=n.on=n.on?j({},n.on):{};for(var r in e){var o=t[r],i=e[r];t[r]=o?[].concat(o,i):i}}else;return n}function Pe(n,e,t,r){e=e||{$stable:!t};for(var o=0;o<n.length;o++){var i=n[o];Array.isArray(i)?Pe(i,e,t):i&&(i.proxy&&(i.fn.proxy=!0),e[i.key]=i.fn)}return r&&(e.$key=r),e}function ze(n,e){for(var t=0;t<e.length;t+=2){var r=e[t];"string"==typeof r&&r&&(n[e[t]]=e[t+1])}return n}function De(n,e){return"string"==typeof n?e+n:n}function Le(n){n._o=Ae,n._n=v,n._s=m,n._l=_e,n._t=we,n._q=L,n._i=N,n._m=Se,n._f=Ee,n._k=Ce,n._b=Te,n._v=bn,n._e=yn,n._u=Pe,n._g=Ie,n._d=ze,n._p=De}function Ne(n,e,t,r,i){var a,c=this,l=i.options;_(r,"_uid")?(a=Object.create(r))._original=r:(a=r,r=r._original);var u=s(l._compiled),p=!u;this.data=n,this.props=e,this.children=t,this.parent=r,this.listeners=n.on||o,this.injections=he(l.inject,r),this.slots=function(){return c.$slots||ye(n.scopedSlots,c.$slots=me(t,r)),c.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return ye(n.scopedSlots,this.slots())}}),u&&(this.$options=l,this.$slots=this.slots(),this.$scopedSlots=ye(n.scopedSlots,this.$slots)),l._scopeId?this._c=function(n,e,t,o){var i=Ue(a,n,e,t,o,p);return i&&!Array.isArray(i)&&(i.fnScopeId=l._scopeId,i.fnContext=r),i}:this._c=function(n,e,t,r){return Ue(a,n,e,t,r,p)}}function Be(n,e,t,r,o){var i=xn(n);return i.fnContext=t,i.fnOptions=r,e.slot&&((i.data||(i.data={})).slot=e.slot),i}function Re(n,e){for(var t in e)n[k(t)]=e[t]}Le(Ne.prototype);var $e={init:function(n,e){if(n.componentInstance&&!n.componentInstance._isDestroyed&&n.data.keepAlive){var t=n;$e.prepatch(t,t)}else{(n.componentInstance=function(n,e){var t={_isComponent:!0,_parentVnode:n,parent:e},r=n.data.inlineTemplate;a(r)&&(t.render=r.render,t.staticRenderFns=r.staticRenderFns);return new n.componentOptions.Ctor(t)}(n,Ke)).$mount(e?n.elm:void 0,e)}},prepatch:function(n,e){var t=e.componentOptions;!function(n,e,t,r,i){0;var a=r.data.scopedSlots,s=n.$scopedSlots,c=!!(a&&!a.$stable||s!==o&&!s.$stable||a&&n.$scopedSlots.$key!==a.$key||!a&&n.$scopedSlots.$key),l=!!(i||n.$options._renderChildren||c);n.$options._parentVnode=r,n.$vnode=r,n._vnode&&(n._vnode.parent=r);if(n.$options._renderChildren=i,n.$attrs=r.data.attrs||o,n.$listeners=t||o,e&&n.$options.props){Cn(!1);for(var u=n._props,p=n.$options._propKeys||[],d=0;d<p.length;d++){var f=p[d],h=n.$options.props;u[f]=Mn(f,h,e,n)}Cn(!0),n.$options.propsData=e}t=t||o;var m=n.$options._parentListeners;n.$options._parentListeners=t,Ze(n,t,m),l&&(n.$slots=me(i,r.context),n.$forceUpdate());0}(e.componentInstance=n.componentInstance,t.propsData,t.listeners,e,t.children)},insert:function(n){var e,t=n.context,r=n.componentInstance;r._isMounted||(r._isMounted=!0,tt(r,"mounted")),n.data.keepAlive&&(t._isMounted?((e=r)._inactive=!1,ot.push(e)):et(r,!0))},destroy:function(n){var e=n.componentInstance;e._isDestroyed||(n.data.keepAlive?function n(e,t){if(t&&(e._directInactive=!0,nt(e)))return;if(!e._inactive){e._inactive=!0;for(var r=0;r<e.$children.length;r++)n(e.$children[r]);tt(e,"deactivated")}}(e,!0):e.$destroy())}},Me=Object.keys($e);function Fe(n,e,t,r,c){if(!i(n)){var u=t.$options._base;if(l(n)&&(n=u.extend(n)),"function"==typeof n){var p;if(i(n.cid)&&void 0===(n=function(n,e){if(s(n.error)&&a(n.errorComp))return n.errorComp;if(a(n.resolved))return n.resolved;var t=He;t&&a(n.owners)&&-1===n.owners.indexOf(t)&&n.owners.push(t);if(s(n.loading)&&a(n.loadingComp))return n.loadingComp;if(t&&!a(n.owners)){var r=n.owners=[t],o=!0,c=null,u=null;t.$on("hook:destroyed",(function(){return b(r,t)}));var p=function(n){for(var e=0,t=r.length;e<t;e++)r[e].$forceUpdate();n&&(r.length=0,null!==c&&(clearTimeout(c),c=null),null!==u&&(clearTimeout(u),u=null))},d=B((function(t){n.resolved=qe(t,e),o?r.length=0:p(!0)})),f=B((function(e){a(n.errorComp)&&(n.error=!0,p(!0))})),m=n(d,f);return l(m)&&(h(m)?i(n.resolved)&&m.then(d,f):h(m.component)&&(m.component.then(d,f),a(m.error)&&(n.errorComp=qe(m.error,e)),a(m.loading)&&(n.loadingComp=qe(m.loading,e),0===m.delay?n.loading=!0:c=setTimeout((function(){c=null,i(n.resolved)&&i(n.error)&&(n.loading=!0,p(!1))}),m.delay||200)),a(m.timeout)&&(u=setTimeout((function(){u=null,i(n.resolved)&&f(null)}),m.timeout)))),o=!1,n.loading?n.loadingComp:n.resolved}}(p=n,u)))return function(n,e,t,r,o){var i=yn();return i.asyncFactory=n,i.asyncMeta={data:e,context:t,children:r,tag:o},i}(p,e,t,r,c);e=e||{},kt(n),a(e.model)&&function(n,e){var t=n.model&&n.model.prop||"value",r=n.model&&n.model.event||"input";(e.attrs||(e.attrs={}))[t]=e.model.value;var o=e.on||(e.on={}),i=o[r],s=e.model.callback;a(i)?(Array.isArray(i)?-1===i.indexOf(s):i!==s)&&(o[r]=[s].concat(i)):o[r]=s}(n.options,e);var d=function(n,e,t){var r=e.options.props;if(!i(r)){var o={},s=n.attrs,c=n.props;if(a(s)||a(c))for(var l in r){var u=S(l);pe(o,c,l,u,!0)||pe(o,s,l,u,!1)}return o}}(e,n);if(s(n.options.functional))return function(n,e,t,r,i){var s=n.options,c={},l=s.props;if(a(l))for(var u in l)c[u]=Mn(u,l,e||o);else a(t.attrs)&&Re(c,t.attrs),a(t.props)&&Re(c,t.props);var p=new Ne(t,c,i,r,n),d=s.render.call(null,p._c,p);if(d instanceof vn)return Be(d,t,p.parent,s,p);if(Array.isArray(d)){for(var f=de(d)||[],h=new Array(f.length),m=0;m<f.length;m++)h[m]=Be(f[m],t,p.parent,s,p);return h}}(n,d,e,t,r);var f=e.on;if(e.on=e.nativeOn,s(n.options.abstract)){var m=e.slot;e={},m&&(e.slot=m)}!function(n){for(var e=n.hook||(n.hook={}),t=0;t<Me.length;t++){var r=Me[t],o=e[r],i=$e[r];o===i||o&&o._merged||(e[r]=o?Ge(i,o):i)}}(e);var v=n.options.name||c;return new vn("vue-component-"+n.cid+(v?"-"+v:""),e,void 0,void 0,void 0,t,{Ctor:n,propsData:d,listeners:f,tag:c,children:r},p)}}}function Ge(n,e){var t=function(t,r){n(t,r),e(t,r)};return t._merged=!0,t}function Ue(n,e,t,r,o,u){return(Array.isArray(t)||c(t))&&(o=r,r=t,t=void 0),s(u)&&(o=2),function(n,e,t,r,o){if(a(t)&&a(t.__ob__))return yn();a(t)&&a(t.is)&&(e=t.is);if(!e)return yn();0;Array.isArray(r)&&"function"==typeof r[0]&&((t=t||{}).scopedSlots={default:r[0]},r.length=0);2===o?r=de(r):1===o&&(r=function(n){for(var e=0;e<n.length;e++)if(Array.isArray(n[e]))return Array.prototype.concat.apply([],n);return n}(r));var c,u;if("string"==typeof e){var p;u=n.$vnode&&n.$vnode.ns||M.getTagNamespace(e),c=M.isReservedTag(e)?new vn(M.parsePlatformTagName(e),t,r,void 0,void 0,n):t&&t.pre||!a(p=$n(n.$options,"components",e))?new vn(e,t,r,void 0,void 0,n):Fe(p,t,n,r,e)}else c=Fe(e,t,n,r);return Array.isArray(c)?c:a(c)?(a(u)&&function n(e,t,r){e.ns=t,"foreignObject"===e.tag&&(t=void 0,r=!0);if(a(e.children))for(var o=0,c=e.children.length;o<c;o++){var l=e.children[o];a(l.tag)&&(i(l.ns)||s(r)&&"svg"!==l.tag)&&n(l,t,r)}}(c,u),a(t)&&function(n){l(n.style)&&ae(n.style);l(n.class)&&ae(n.class)}(t),c):yn()}(n,e,t,r,o)}var Ve,He=null;function qe(n,e){return(n.__esModule||ln&&"Module"===n[Symbol.toStringTag])&&(n=n.default),l(n)?e.extend(n):n}function Xe(n){if(Array.isArray(n))for(var e=0;e<n.length;e++){var t=n[e];if(a(t)&&(a(t.componentOptions)||ge(t)))return t}}function Je(n,e){Ve.$on(n,e)}function Ye(n,e){Ve.$off(n,e)}function We(n,e){var t=Ve;return function r(){var o=e.apply(null,arguments);null!==o&&t.$off(n,r)}}function Ze(n,e,t){Ve=n,le(e,t||{},Je,Ye,We,n),Ve=void 0}var Ke=null;function Qe(n){var e=Ke;return Ke=n,function(){Ke=e}}function nt(n){for(;n&&(n=n.$parent);)if(n._inactive)return!0;return!1}function et(n,e){if(e){if(n._directInactive=!1,nt(n))return}else if(n._directInactive)return;if(n._inactive||null===n._inactive){n._inactive=!1;for(var t=0;t<n.$children.length;t++)et(n.$children[t]);tt(n,"activated")}}function tt(n,e){hn();var t=n.$options[e],r=e+" hook";if(t)for(var o=0,i=t.length;o<i;o++)qn(t[o],n,null,n,r);n._hasHookEvent&&n.$emit("hook:"+e),mn()}var rt=[],ot=[],it={},at=!1,st=!1,ct=0;var lt=0,ut=Date.now;if(q&&!W){var pt=window.performance;pt&&"function"==typeof pt.now&&ut()>document.createEvent("Event").timeStamp&&(ut=function(){return pt.now()})}function dt(){var n,e;for(lt=ut(),st=!0,rt.sort((function(n,e){return n.id-e.id})),ct=0;ct<rt.length;ct++)(n=rt[ct]).before&&n.before(),e=n.id,it[e]=null,n.run();var t=ot.slice(),r=rt.slice();ct=rt.length=ot.length=0,it={},at=st=!1,function(n){for(var e=0;e<n.length;e++)n[e]._inactive=!0,et(n[e],!0)}(t),function(n){var e=n.length;for(;e--;){var t=n[e],r=t.vm;r._watcher===t&&r._isMounted&&!r._isDestroyed&&tt(r,"updated")}}(r),an&&M.devtools&&an.emit("flush")}var ft=0,ht=function(n,e,t,r,o){this.vm=n,o&&(n._watcher=this),n._watchers.push(this),r?(this.deep=!!r.deep,this.user=!!r.user,this.lazy=!!r.lazy,this.sync=!!r.sync,this.before=r.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=t,this.id=++ft,this.active=!0,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new cn,this.newDepIds=new cn,this.expression="","function"==typeof e?this.getter=e:(this.getter=function(n){if(!U.test(n)){var e=n.split(".");return function(n){for(var t=0;t<e.length;t++){if(!n)return;n=n[e[t]]}return n}}}(e),this.getter||(this.getter=P)),this.value=this.lazy?void 0:this.get()};ht.prototype.get=function(){var n;hn(this);var e=this.vm;try{n=this.getter.call(e,e)}catch(n){if(!this.user)throw n;Hn(n,e,'getter for watcher "'+this.expression+'"')}finally{this.deep&&ae(n),mn(),this.cleanupDeps()}return n},ht.prototype.addDep=function(n){var e=n.id;this.newDepIds.has(e)||(this.newDepIds.add(e),this.newDeps.push(n),this.depIds.has(e)||n.addSub(this))},ht.prototype.cleanupDeps=function(){for(var n=this.deps.length;n--;){var e=this.deps[n];this.newDepIds.has(e.id)||e.removeSub(this)}var t=this.depIds;this.depIds=this.newDepIds,this.newDepIds=t,this.newDepIds.clear(),t=this.deps,this.deps=this.newDeps,this.newDeps=t,this.newDeps.length=0},ht.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():function(n){var e=n.id;if(null==it[e]){if(it[e]=!0,st){for(var t=rt.length-1;t>ct&&rt[t].id>n.id;)t--;rt.splice(t+1,0,n)}else rt.push(n);at||(at=!0,oe(dt))}}(this)},ht.prototype.run=function(){if(this.active){var n=this.get();if(n!==this.value||l(n)||this.deep){var e=this.value;if(this.value=n,this.user){var t='callback for watcher "'+this.expression+'"';qn(this.cb,this.vm,[n,e],this.vm,t)}else this.cb.call(this.vm,n,e)}}},ht.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},ht.prototype.depend=function(){for(var n=this.deps.length;n--;)this.deps[n].depend()},ht.prototype.teardown=function(){if(this.active){this.vm._isBeingDestroyed||b(this.vm._watchers,this);for(var n=this.deps.length;n--;)this.deps[n].removeSub(this);this.active=!1}};var mt={enumerable:!0,configurable:!0,get:P,set:P};function vt(n,e,t){mt.get=function(){return this[e][t]},mt.set=function(n){this[e][t]=n},Object.defineProperty(n,t,mt)}function gt(n){n._watchers=[];var e=n.$options;e.props&&function(n,e){var t=n.$options.propsData||{},r=n._props={},o=n.$options._propKeys=[];n.$parent&&Cn(!1);var i=function(i){o.push(i);var a=Mn(i,e,t,n);An(r,i,a),i in n||vt(n,"_props",i)};for(var a in e)i(a);Cn(!0)}(n,e.props),e.methods&&function(n,e){n.$options.props;for(var t in e)n[t]="function"!=typeof e[t]?P:A(e[t],n)}(n,e.methods),e.data?function(n){var e=n.$options.data;p(e=n._data="function"==typeof e?function(n,e){hn();try{return n.call(e,e)}catch(n){return Hn(n,e,"data()"),{}}finally{mn()}}(e,n):e||{})||(e={});var t=Object.keys(e),r=n.$options.props,o=(n.$options.methods,t.length);for(;o--;){var i=t[o];0,r&&_(r,i)||(a=void 0,36!==(a=(i+"").charCodeAt(0))&&95!==a&&vt(n,"_data",i))}var a;Sn(e,!0)}(n):Sn(n._data={},!0),e.computed&&function(n,e){var t=n._computedWatchers=Object.create(null),r=on();for(var o in e){var i=e[o],a="function"==typeof i?i:i.get;0,r||(t[o]=new ht(n,a||P,P,yt)),o in n||bt(n,o,i)}}(n,e.computed),e.watch&&e.watch!==en&&function(n,e){for(var t in e){var r=e[t];if(Array.isArray(r))for(var o=0;o<r.length;o++)wt(n,t,r[o]);else wt(n,t,r)}}(n,e.watch)}var yt={lazy:!0};function bt(n,e,t){var r=!on();"function"==typeof t?(mt.get=r?xt(e):_t(t),mt.set=P):(mt.get=t.get?r&&!1!==t.cache?xt(e):_t(t.get):P,mt.set=t.set||P),Object.defineProperty(n,e,mt)}function xt(n){return function(){var e=this._computedWatchers&&this._computedWatchers[n];if(e)return e.dirty&&e.evaluate(),dn.target&&e.depend(),e.value}}function _t(n){return function(){return n.call(this,this)}}function wt(n,e,t,r){return p(t)&&(r=t,t=t.handler),"string"==typeof t&&(t=n[t]),n.$watch(e,t,r)}var Et=0;function kt(n){var e=n.options;if(n.super){var t=kt(n.super);if(t!==n.superOptions){n.superOptions=t;var r=function(n){var e,t=n.options,r=n.sealedOptions;for(var o in t)t[o]!==r[o]&&(e||(e={}),e[o]=t[o]);return e}(n);r&&j(n.extendOptions,r),(e=n.options=Rn(t,n.extendOptions)).name&&(e.components[e.name]=n)}}return e}function Ct(n){this._init(n)}function Tt(n){n.cid=0;var e=1;n.extend=function(n){n=n||{};var t=this,r=t.cid,o=n._Ctor||(n._Ctor={});if(o[r])return o[r];var i=n.name||t.options.name;var a=function(n){this._init(n)};return(a.prototype=Object.create(t.prototype)).constructor=a,a.cid=e++,a.options=Rn(t.options,n),a.super=t,a.options.props&&function(n){var e=n.options.props;for(var t in e)vt(n.prototype,"_props",t)}(a),a.options.computed&&function(n){var e=n.options.computed;for(var t in e)bt(n.prototype,t,e[t])}(a),a.extend=t.extend,a.mixin=t.mixin,a.use=t.use,R.forEach((function(n){a[n]=t[n]})),i&&(a.options.components[i]=a),a.superOptions=t.options,a.extendOptions=n,a.sealedOptions=j({},a.options),o[r]=a,a}}function St(n){return n&&(n.Ctor.options.name||n.tag)}function At(n,e){return Array.isArray(n)?n.indexOf(e)>-1:"string"==typeof n?n.split(",").indexOf(e)>-1:!!d(n)&&n.test(e)}function Ot(n,e){var t=n.cache,r=n.keys,o=n._vnode;for(var i in t){var a=t[i];if(a){var s=a.name;s&&!e(s)&&jt(t,i,r,o)}}}function jt(n,e,t,r){var o=n[e];!o||r&&o.tag===r.tag||o.componentInstance.$destroy(),n[e]=null,b(t,e)}!function(n){n.prototype._init=function(n){var e=this;e._uid=Et++,e._isVue=!0,n&&n._isComponent?function(n,e){var t=n.$options=Object.create(n.constructor.options),r=e._parentVnode;t.parent=e.parent,t._parentVnode=r;var o=r.componentOptions;t.propsData=o.propsData,t._parentListeners=o.listeners,t._renderChildren=o.children,t._componentTag=o.tag,e.render&&(t.render=e.render,t.staticRenderFns=e.staticRenderFns)}(e,n):e.$options=Rn(kt(e.constructor),n||{},e),e._renderProxy=e,e._self=e,function(n){var e=n.$options,t=e.parent;if(t&&!e.abstract){for(;t.$options.abstract&&t.$parent;)t=t.$parent;t.$children.push(n)}n.$parent=t,n.$root=t?t.$root:n,n.$children=[],n.$refs={},n._watcher=null,n._inactive=null,n._directInactive=!1,n._isMounted=!1,n._isDestroyed=!1,n._isBeingDestroyed=!1}(e),function(n){n._events=Object.create(null),n._hasHookEvent=!1;var e=n.$options._parentListeners;e&&Ze(n,e)}(e),function(n){n._vnode=null,n._staticTrees=null;var e=n.$options,t=n.$vnode=e._parentVnode,r=t&&t.context;n.$slots=me(e._renderChildren,r),n.$scopedSlots=o,n._c=function(e,t,r,o){return Ue(n,e,t,r,o,!1)},n.$createElement=function(e,t,r,o){return Ue(n,e,t,r,o,!0)};var i=t&&t.data;An(n,"$attrs",i&&i.attrs||o,null,!0),An(n,"$listeners",e._parentListeners||o,null,!0)}(e),tt(e,"beforeCreate"),function(n){var e=he(n.$options.inject,n);e&&(Cn(!1),Object.keys(e).forEach((function(t){An(n,t,e[t])})),Cn(!0))}(e),gt(e),function(n){var e=n.$options.provide;e&&(n._provided="function"==typeof e?e.call(n):e)}(e),tt(e,"created"),e.$options.el&&e.$mount(e.$options.el)}}(Ct),function(n){var e={get:function(){return this._data}},t={get:function(){return this._props}};Object.defineProperty(n.prototype,"$data",e),Object.defineProperty(n.prototype,"$props",t),n.prototype.$set=On,n.prototype.$delete=jn,n.prototype.$watch=function(n,e,t){if(p(e))return wt(this,n,e,t);(t=t||{}).user=!0;var r=new ht(this,n,e,t);if(t.immediate){var o='callback for immediate watcher "'+r.expression+'"';hn(),qn(e,this,[r.value],this,o),mn()}return function(){r.teardown()}}}(Ct),function(n){var e=/^hook:/;n.prototype.$on=function(n,t){var r=this;if(Array.isArray(n))for(var o=0,i=n.length;o<i;o++)r.$on(n[o],t);else(r._events[n]||(r._events[n]=[])).push(t),e.test(n)&&(r._hasHookEvent=!0);return r},n.prototype.$once=function(n,e){var t=this;function r(){t.$off(n,r),e.apply(t,arguments)}return r.fn=e,t.$on(n,r),t},n.prototype.$off=function(n,e){var t=this;if(!arguments.length)return t._events=Object.create(null),t;if(Array.isArray(n)){for(var r=0,o=n.length;r<o;r++)t.$off(n[r],e);return t}var i,a=t._events[n];if(!a)return t;if(!e)return t._events[n]=null,t;for(var s=a.length;s--;)if((i=a[s])===e||i.fn===e){a.splice(s,1);break}return t},n.prototype.$emit=function(n){var e=this,t=e._events[n];if(t){t=t.length>1?O(t):t;for(var r=O(arguments,1),o='event handler for "'+n+'"',i=0,a=t.length;i<a;i++)qn(t[i],e,r,e,o)}return e}}(Ct),function(n){n.prototype._update=function(n,e){var t=this,r=t.$el,o=t._vnode,i=Qe(t);t._vnode=n,t.$el=o?t.__patch__(o,n):t.__patch__(t.$el,n,e,!1),i(),r&&(r.__vue__=null),t.$el&&(t.$el.__vue__=t),t.$vnode&&t.$parent&&t.$vnode===t.$parent._vnode&&(t.$parent.$el=t.$el)},n.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},n.prototype.$destroy=function(){var n=this;if(!n._isBeingDestroyed){tt(n,"beforeDestroy"),n._isBeingDestroyed=!0;var e=n.$parent;!e||e._isBeingDestroyed||n.$options.abstract||b(e.$children,n),n._watcher&&n._watcher.teardown();for(var t=n._watchers.length;t--;)n._watchers[t].teardown();n._data.__ob__&&n._data.__ob__.vmCount--,n._isDestroyed=!0,n.__patch__(n._vnode,null),tt(n,"destroyed"),n.$off(),n.$el&&(n.$el.__vue__=null),n.$vnode&&(n.$vnode.parent=null)}}}(Ct),function(n){Le(n.prototype),n.prototype.$nextTick=function(n){return oe(n,this)},n.prototype._render=function(){var n,e=this,t=e.$options,r=t.render,o=t._parentVnode;o&&(e.$scopedSlots=ye(o.data.scopedSlots,e.$slots,e.$scopedSlots)),e.$vnode=o;try{He=e,n=r.call(e._renderProxy,e.$createElement)}catch(t){Hn(t,e,"render"),n=e._vnode}finally{He=null}return Array.isArray(n)&&1===n.length&&(n=n[0]),n instanceof vn||(n=yn()),n.parent=o,n}}(Ct);var It=[String,RegExp,Array],Pt={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:It,exclude:It,max:[String,Number]},methods:{cacheVNode:function(){var n=this.cache,e=this.keys,t=this.vnodeToCache,r=this.keyToCache;if(t){var o=t.tag,i=t.componentInstance,a=t.componentOptions;n[r]={name:St(a),tag:o,componentInstance:i},e.push(r),this.max&&e.length>parseInt(this.max)&&jt(n,e[0],e,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var n in this.cache)jt(this.cache,n,this.keys)},mounted:function(){var n=this;this.cacheVNode(),this.$watch("include",(function(e){Ot(n,(function(n){return At(e,n)}))})),this.$watch("exclude",(function(e){Ot(n,(function(n){return!At(e,n)}))}))},updated:function(){this.cacheVNode()},render:function(){var n=this.$slots.default,e=Xe(n),t=e&&e.componentOptions;if(t){var r=St(t),o=this.include,i=this.exclude;if(o&&(!r||!At(o,r))||i&&r&&At(i,r))return e;var a=this.cache,s=this.keys,c=null==e.key?t.Ctor.cid+(t.tag?"::"+t.tag:""):e.key;a[c]?(e.componentInstance=a[c].componentInstance,b(s,c),s.push(c)):(this.vnodeToCache=e,this.keyToCache=c),e.data.keepAlive=!0}return e||n&&n[0]}}};!function(n){var e={get:function(){return M}};Object.defineProperty(n,"config",e),n.util={warn:un,extend:j,mergeOptions:Rn,defineReactive:An},n.set=On,n.delete=jn,n.nextTick=oe,n.observable=function(n){return Sn(n),n},n.options=Object.create(null),R.forEach((function(e){n.options[e+"s"]=Object.create(null)})),n.options._base=n,j(n.options.components,Pt),function(n){n.use=function(n){var e=this._installedPlugins||(this._installedPlugins=[]);if(e.indexOf(n)>-1)return this;var t=O(arguments,1);return t.unshift(this),"function"==typeof n.install?n.install.apply(n,t):"function"==typeof n&&n.apply(null,t),e.push(n),this}}(n),function(n){n.mixin=function(n){return this.options=Rn(this.options,n),this}}(n),Tt(n),function(n){R.forEach((function(e){n[e]=function(n,t){return t?("component"===e&&p(t)&&(t.name=t.name||n,t=this.options._base.extend(t)),"directive"===e&&"function"==typeof t&&(t={bind:t,update:t}),this.options[e+"s"][n]=t,t):this.options[e+"s"][n]}}))}(n)}(Ct),Object.defineProperty(Ct.prototype,"$isServer",{get:on}),Object.defineProperty(Ct.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty(Ct,"FunctionalRenderContext",{value:Ne}),Ct.version="2.6.14";var zt=g("style,class"),Dt=g("input,textarea,option,select,progress"),Lt=g("contenteditable,draggable,spellcheck"),Nt=g("events,caret,typing,plaintext-only"),Bt=g("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),Rt="http://www.w3.org/1999/xlink",$t=function(n){return":"===n.charAt(5)&&"xlink"===n.slice(0,5)},Mt=function(n){return $t(n)?n.slice(6,n.length):""},Ft=function(n){return null==n||!1===n};function Gt(n){for(var e=n.data,t=n,r=n;a(r.componentInstance);)(r=r.componentInstance._vnode)&&r.data&&(e=Ut(r.data,e));for(;a(t=t.parent);)t&&t.data&&(e=Ut(e,t.data));return function(n,e){if(a(n)||a(e))return Vt(n,Ht(e));return""}(e.staticClass,e.class)}function Ut(n,e){return{staticClass:Vt(n.staticClass,e.staticClass),class:a(n.class)?[n.class,e.class]:e.class}}function Vt(n,e){return n?e?n+" "+e:n:e||""}function Ht(n){return Array.isArray(n)?function(n){for(var e,t="",r=0,o=n.length;r<o;r++)a(e=Ht(n[r]))&&""!==e&&(t&&(t+=" "),t+=e);return t}(n):l(n)?function(n){var e="";for(var t in n)n[t]&&(e&&(e+=" "),e+=t);return e}(n):"string"==typeof n?n:""}var qt={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},Xt=g("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),Jt=g("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),Yt=function(n){return Xt(n)||Jt(n)};var Wt=Object.create(null);var Zt=g("text,number,password,search,email,tel,url");var Kt=Object.freeze({createElement:function(n,e){var t=document.createElement(n);return"select"!==n||e.data&&e.data.attrs&&void 0!==e.data.attrs.multiple&&t.setAttribute("multiple","multiple"),t},createElementNS:function(n,e){return document.createElementNS(qt[n],e)},createTextNode:function(n){return document.createTextNode(n)},createComment:function(n){return document.createComment(n)},insertBefore:function(n,e,t){n.insertBefore(e,t)},removeChild:function(n,e){n.removeChild(e)},appendChild:function(n,e){n.appendChild(e)},parentNode:function(n){return n.parentNode},nextSibling:function(n){return n.nextSibling},tagName:function(n){return n.tagName},setTextContent:function(n,e){n.textContent=e},setStyleScope:function(n,e){n.setAttribute(e,"")}}),Qt={create:function(n,e){nr(e)},update:function(n,e){n.data.ref!==e.data.ref&&(nr(n,!0),nr(e))},destroy:function(n){nr(n,!0)}};function nr(n,e){var t=n.data.ref;if(a(t)){var r=n.context,o=n.componentInstance||n.elm,i=r.$refs;e?Array.isArray(i[t])?b(i[t],o):i[t]===o&&(i[t]=void 0):n.data.refInFor?Array.isArray(i[t])?i[t].indexOf(o)<0&&i[t].push(o):i[t]=[o]:i[t]=o}}var er=new vn("",{},[]),tr=["create","activate","update","remove","destroy"];function rr(n,e){return n.key===e.key&&n.asyncFactory===e.asyncFactory&&(n.tag===e.tag&&n.isComment===e.isComment&&a(n.data)===a(e.data)&&function(n,e){if("input"!==n.tag)return!0;var t,r=a(t=n.data)&&a(t=t.attrs)&&t.type,o=a(t=e.data)&&a(t=t.attrs)&&t.type;return r===o||Zt(r)&&Zt(o)}(n,e)||s(n.isAsyncPlaceholder)&&i(e.asyncFactory.error))}function or(n,e,t){var r,o,i={};for(r=e;r<=t;++r)a(o=n[r].key)&&(i[o]=r);return i}var ir={create:ar,update:ar,destroy:function(n){ar(n,er)}};function ar(n,e){(n.data.directives||e.data.directives)&&function(n,e){var t,r,o,i=n===er,a=e===er,s=cr(n.data.directives,n.context),c=cr(e.data.directives,e.context),l=[],u=[];for(t in c)r=s[t],o=c[t],r?(o.oldValue=r.value,o.oldArg=r.arg,ur(o,"update",e,n),o.def&&o.def.componentUpdated&&u.push(o)):(ur(o,"bind",e,n),o.def&&o.def.inserted&&l.push(o));if(l.length){var p=function(){for(var t=0;t<l.length;t++)ur(l[t],"inserted",e,n)};i?ue(e,"insert",p):p()}u.length&&ue(e,"postpatch",(function(){for(var t=0;t<u.length;t++)ur(u[t],"componentUpdated",e,n)}));if(!i)for(t in s)c[t]||ur(s[t],"unbind",n,n,a)}(n,e)}var sr=Object.create(null);function cr(n,e){var t,r,o=Object.create(null);if(!n)return o;for(t=0;t<n.length;t++)(r=n[t]).modifiers||(r.modifiers=sr),o[lr(r)]=r,r.def=$n(e.$options,"directives",r.name);return o}function lr(n){return n.rawName||n.name+"."+Object.keys(n.modifiers||{}).join(".")}function ur(n,e,t,r,o){var i=n.def&&n.def[e];if(i)try{i(t.elm,n,t,r,o)}catch(r){Hn(r,t.context,"directive "+n.name+" "+e+" hook")}}var pr=[Qt,ir];function dr(n,e){var t=e.componentOptions;if(!(a(t)&&!1===t.Ctor.options.inheritAttrs||i(n.data.attrs)&&i(e.data.attrs))){var r,o,s=e.elm,c=n.data.attrs||{},l=e.data.attrs||{};for(r in a(l.__ob__)&&(l=e.data.attrs=j({},l)),l)o=l[r],c[r]!==o&&fr(s,r,o,e.data.pre);for(r in(W||K)&&l.value!==c.value&&fr(s,"value",l.value),c)i(l[r])&&($t(r)?s.removeAttributeNS(Rt,Mt(r)):Lt(r)||s.removeAttribute(r))}}function fr(n,e,t,r){r||n.tagName.indexOf("-")>-1?hr(n,e,t):Bt(e)?Ft(t)?n.removeAttribute(e):(t="allowfullscreen"===e&&"EMBED"===n.tagName?"true":e,n.setAttribute(e,t)):Lt(e)?n.setAttribute(e,function(n,e){return Ft(e)||"false"===e?"false":"contenteditable"===n&&Nt(e)?e:"true"}(e,t)):$t(e)?Ft(t)?n.removeAttributeNS(Rt,Mt(e)):n.setAttributeNS(Rt,e,t):hr(n,e,t)}function hr(n,e,t){if(Ft(t))n.removeAttribute(e);else{if(W&&!Z&&"TEXTAREA"===n.tagName&&"placeholder"===e&&""!==t&&!n.__ieph){var r=function(e){e.stopImmediatePropagation(),n.removeEventListener("input",r)};n.addEventListener("input",r),n.__ieph=!0}n.setAttribute(e,t)}}var mr={create:dr,update:dr};function vr(n,e){var t=e.elm,r=e.data,o=n.data;if(!(i(r.staticClass)&&i(r.class)&&(i(o)||i(o.staticClass)&&i(o.class)))){var s=Gt(e),c=t._transitionClasses;a(c)&&(s=Vt(s,Ht(c))),s!==t._prevClass&&(t.setAttribute("class",s),t._prevClass=s)}}var gr,yr={create:vr,update:vr};function br(n,e,t){var r=gr;return function o(){var i=e.apply(null,arguments);null!==i&&wr(n,o,t,r)}}var xr=Wn&&!(nn&&Number(nn[1])<=53);function _r(n,e,t,r){if(xr){var o=lt,i=e;e=i._wrapper=function(n){if(n.target===n.currentTarget||n.timeStamp>=o||n.timeStamp<=0||n.target.ownerDocument!==document)return i.apply(this,arguments)}}gr.addEventListener(n,e,tn?{capture:t,passive:r}:t)}function wr(n,e,t,r){(r||gr).removeEventListener(n,e._wrapper||e,t)}function Er(n,e){if(!i(n.data.on)||!i(e.data.on)){var t=e.data.on||{},r=n.data.on||{};gr=e.elm,function(n){if(a(n.__r)){var e=W?"change":"input";n[e]=[].concat(n.__r,n[e]||[]),delete n.__r}a(n.__c)&&(n.change=[].concat(n.__c,n.change||[]),delete n.__c)}(t),le(t,r,_r,wr,br,e.context),gr=void 0}}var kr,Cr={create:Er,update:Er};function Tr(n,e){if(!i(n.data.domProps)||!i(e.data.domProps)){var t,r,o=e.elm,s=n.data.domProps||{},c=e.data.domProps||{};for(t in a(c.__ob__)&&(c=e.data.domProps=j({},c)),s)t in c||(o[t]="");for(t in c){if(r=c[t],"textContent"===t||"innerHTML"===t){if(e.children&&(e.children.length=0),r===s[t])continue;1===o.childNodes.length&&o.removeChild(o.childNodes[0])}if("value"===t&&"PROGRESS"!==o.tagName){o._value=r;var l=i(r)?"":String(r);Sr(o,l)&&(o.value=l)}else if("innerHTML"===t&&Jt(o.tagName)&&i(o.innerHTML)){(kr=kr||document.createElement("div")).innerHTML="<svg>"+r+"</svg>";for(var u=kr.firstChild;o.firstChild;)o.removeChild(o.firstChild);for(;u.firstChild;)o.appendChild(u.firstChild)}else if(r!==s[t])try{o[t]=r}catch(n){}}}}function Sr(n,e){return!n.composing&&("OPTION"===n.tagName||function(n,e){var t=!0;try{t=document.activeElement!==n}catch(n){}return t&&n.value!==e}(n,e)||function(n,e){var t=n.value,r=n._vModifiers;if(a(r)){if(r.number)return v(t)!==v(e);if(r.trim)return t.trim()!==e.trim()}return t!==e}(n,e))}var Ar={create:Tr,update:Tr},Or=w((function(n){var e={},t=/:(.+)/;return n.split(/;(?![^(]*\))/g).forEach((function(n){if(n){var r=n.split(t);r.length>1&&(e[r[0].trim()]=r[1].trim())}})),e}));function jr(n){var e=Ir(n.style);return n.staticStyle?j(n.staticStyle,e):e}function Ir(n){return Array.isArray(n)?I(n):"string"==typeof n?Or(n):n}var Pr,zr=/^--/,Dr=/\s*!important$/,Lr=function(n,e,t){if(zr.test(e))n.style.setProperty(e,t);else if(Dr.test(t))n.style.setProperty(S(e),t.replace(Dr,""),"important");else{var r=Br(e);if(Array.isArray(t))for(var o=0,i=t.length;o<i;o++)n.style[r]=t[o];else n.style[r]=t}},Nr=["Webkit","Moz","ms"],Br=w((function(n){if(Pr=Pr||document.createElement("div").style,"filter"!==(n=k(n))&&n in Pr)return n;for(var e=n.charAt(0).toUpperCase()+n.slice(1),t=0;t<Nr.length;t++){var r=Nr[t]+e;if(r in Pr)return r}}));function Rr(n,e){var t=e.data,r=n.data;if(!(i(t.staticStyle)&&i(t.style)&&i(r.staticStyle)&&i(r.style))){var o,s,c=e.elm,l=r.staticStyle,u=r.normalizedStyle||r.style||{},p=l||u,d=Ir(e.data.style)||{};e.data.normalizedStyle=a(d.__ob__)?j({},d):d;var f=function(n,e){var t,r={};if(e)for(var o=n;o.componentInstance;)(o=o.componentInstance._vnode)&&o.data&&(t=jr(o.data))&&j(r,t);(t=jr(n.data))&&j(r,t);for(var i=n;i=i.parent;)i.data&&(t=jr(i.data))&&j(r,t);return r}(e,!0);for(s in p)i(f[s])&&Lr(c,s,"");for(s in f)(o=f[s])!==p[s]&&Lr(c,s,null==o?"":o)}}var $r={create:Rr,update:Rr},Mr=/\s+/;function Fr(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(Mr).forEach((function(e){return n.classList.add(e)})):n.classList.add(e);else{var t=" "+(n.getAttribute("class")||"")+" ";t.indexOf(" "+e+" ")<0&&n.setAttribute("class",(t+e).trim())}}function Gr(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(Mr).forEach((function(e){return n.classList.remove(e)})):n.classList.remove(e),n.classList.length||n.removeAttribute("class");else{for(var t=" "+(n.getAttribute("class")||"")+" ",r=" "+e+" ";t.indexOf(r)>=0;)t=t.replace(r," ");(t=t.trim())?n.setAttribute("class",t):n.removeAttribute("class")}}function Ur(n){if(n){if("object"==typeof n){var e={};return!1!==n.css&&j(e,Vr(n.name||"v")),j(e,n),e}return"string"==typeof n?Vr(n):void 0}}var Vr=w((function(n){return{enterClass:n+"-enter",enterToClass:n+"-enter-to",enterActiveClass:n+"-enter-active",leaveClass:n+"-leave",leaveToClass:n+"-leave-to",leaveActiveClass:n+"-leave-active"}})),Hr=q&&!Z,qr="transition",Xr="transitionend",Jr="animation",Yr="animationend";Hr&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(qr="WebkitTransition",Xr="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(Jr="WebkitAnimation",Yr="webkitAnimationEnd"));var Wr=q?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(n){return n()};function Zr(n){Wr((function(){Wr(n)}))}function Kr(n,e){var t=n._transitionClasses||(n._transitionClasses=[]);t.indexOf(e)<0&&(t.push(e),Fr(n,e))}function Qr(n,e){n._transitionClasses&&b(n._transitionClasses,e),Gr(n,e)}function no(n,e,t){var r=to(n,e),o=r.type,i=r.timeout,a=r.propCount;if(!o)return t();var s="transition"===o?Xr:Yr,c=0,l=function(){n.removeEventListener(s,u),t()},u=function(e){e.target===n&&++c>=a&&l()};setTimeout((function(){c<a&&l()}),i+1),n.addEventListener(s,u)}var eo=/\b(transform|all)(,|$)/;function to(n,e){var t,r=window.getComputedStyle(n),o=(r[qr+"Delay"]||"").split(", "),i=(r[qr+"Duration"]||"").split(", "),a=ro(o,i),s=(r[Jr+"Delay"]||"").split(", "),c=(r[Jr+"Duration"]||"").split(", "),l=ro(s,c),u=0,p=0;return"transition"===e?a>0&&(t="transition",u=a,p=i.length):"animation"===e?l>0&&(t="animation",u=l,p=c.length):p=(t=(u=Math.max(a,l))>0?a>l?"transition":"animation":null)?"transition"===t?i.length:c.length:0,{type:t,timeout:u,propCount:p,hasTransform:"transition"===t&&eo.test(r[qr+"Property"])}}function ro(n,e){for(;n.length<e.length;)n=n.concat(n);return Math.max.apply(null,e.map((function(e,t){return oo(e)+oo(n[t])})))}function oo(n){return 1e3*Number(n.slice(0,-1).replace(",","."))}function io(n,e){var t=n.elm;a(t._leaveCb)&&(t._leaveCb.cancelled=!0,t._leaveCb());var r=Ur(n.data.transition);if(!i(r)&&!a(t._enterCb)&&1===t.nodeType){for(var o=r.css,s=r.type,c=r.enterClass,u=r.enterToClass,p=r.enterActiveClass,d=r.appearClass,f=r.appearToClass,h=r.appearActiveClass,m=r.beforeEnter,g=r.enter,y=r.afterEnter,b=r.enterCancelled,x=r.beforeAppear,_=r.appear,w=r.afterAppear,E=r.appearCancelled,k=r.duration,C=Ke,T=Ke.$vnode;T&&T.parent;)C=T.context,T=T.parent;var S=!C._isMounted||!n.isRootInsert;if(!S||_||""===_){var A=S&&d?d:c,O=S&&h?h:p,j=S&&f?f:u,I=S&&x||m,P=S&&"function"==typeof _?_:g,z=S&&w||y,D=S&&E||b,L=v(l(k)?k.enter:k);0;var N=!1!==o&&!Z,R=co(P),$=t._enterCb=B((function(){N&&(Qr(t,j),Qr(t,O)),$.cancelled?(N&&Qr(t,A),D&&D(t)):z&&z(t),t._enterCb=null}));n.data.show||ue(n,"insert",(function(){var e=t.parentNode,r=e&&e._pending&&e._pending[n.key];r&&r.tag===n.tag&&r.elm._leaveCb&&r.elm._leaveCb(),P&&P(t,$)})),I&&I(t),N&&(Kr(t,A),Kr(t,O),Zr((function(){Qr(t,A),$.cancelled||(Kr(t,j),R||(so(L)?setTimeout($,L):no(t,s,$)))}))),n.data.show&&(e&&e(),P&&P(t,$)),N||R||$()}}}function ao(n,e){var t=n.elm;a(t._enterCb)&&(t._enterCb.cancelled=!0,t._enterCb());var r=Ur(n.data.transition);if(i(r)||1!==t.nodeType)return e();if(!a(t._leaveCb)){var o=r.css,s=r.type,c=r.leaveClass,u=r.leaveToClass,p=r.leaveActiveClass,d=r.beforeLeave,f=r.leave,h=r.afterLeave,m=r.leaveCancelled,g=r.delayLeave,y=r.duration,b=!1!==o&&!Z,x=co(f),_=v(l(y)?y.leave:y);0;var w=t._leaveCb=B((function(){t.parentNode&&t.parentNode._pending&&(t.parentNode._pending[n.key]=null),b&&(Qr(t,u),Qr(t,p)),w.cancelled?(b&&Qr(t,c),m&&m(t)):(e(),h&&h(t)),t._leaveCb=null}));g?g(E):E()}function E(){w.cancelled||(!n.data.show&&t.parentNode&&((t.parentNode._pending||(t.parentNode._pending={}))[n.key]=n),d&&d(t),b&&(Kr(t,c),Kr(t,p),Zr((function(){Qr(t,c),w.cancelled||(Kr(t,u),x||(so(_)?setTimeout(w,_):no(t,s,w)))}))),f&&f(t,w),b||x||w())}}function so(n){return"number"==typeof n&&!isNaN(n)}function co(n){if(i(n))return!1;var e=n.fns;return a(e)?co(Array.isArray(e)?e[0]:e):(n._length||n.length)>1}function lo(n,e){!0!==e.data.show&&io(e)}var uo=function(n){var e,t,r={},o=n.modules,l=n.nodeOps;for(e=0;e<tr.length;++e)for(r[tr[e]]=[],t=0;t<o.length;++t)a(o[t][tr[e]])&&r[tr[e]].push(o[t][tr[e]]);function u(n){var e=l.parentNode(n);a(e)&&l.removeChild(e,n)}function p(n,e,t,o,i,c,u){if(a(n.elm)&&a(c)&&(n=c[u]=xn(n)),n.isRootInsert=!i,!function(n,e,t,o){var i=n.data;if(a(i)){var c=a(n.componentInstance)&&i.keepAlive;if(a(i=i.hook)&&a(i=i.init)&&i(n,!1),a(n.componentInstance))return d(n,e),f(t,n.elm,o),s(c)&&function(n,e,t,o){var i,s=n;for(;s.componentInstance;)if(s=s.componentInstance._vnode,a(i=s.data)&&a(i=i.transition)){for(i=0;i<r.activate.length;++i)r.activate[i](er,s);e.push(s);break}f(t,n.elm,o)}(n,e,t,o),!0}}(n,e,t,o)){var p=n.data,m=n.children,g=n.tag;a(g)?(n.elm=n.ns?l.createElementNS(n.ns,g):l.createElement(g,n),y(n),h(n,m,e),a(p)&&v(n,e),f(t,n.elm,o)):s(n.isComment)?(n.elm=l.createComment(n.text),f(t,n.elm,o)):(n.elm=l.createTextNode(n.text),f(t,n.elm,o))}}function d(n,e){a(n.data.pendingInsert)&&(e.push.apply(e,n.data.pendingInsert),n.data.pendingInsert=null),n.elm=n.componentInstance.$el,m(n)?(v(n,e),y(n)):(nr(n),e.push(n))}function f(n,e,t){a(n)&&(a(t)?l.parentNode(t)===n&&l.insertBefore(n,e,t):l.appendChild(n,e))}function h(n,e,t){if(Array.isArray(e)){0;for(var r=0;r<e.length;++r)p(e[r],t,n.elm,null,!0,e,r)}else c(n.text)&&l.appendChild(n.elm,l.createTextNode(String(n.text)))}function m(n){for(;n.componentInstance;)n=n.componentInstance._vnode;return a(n.tag)}function v(n,t){for(var o=0;o<r.create.length;++o)r.create[o](er,n);a(e=n.data.hook)&&(a(e.create)&&e.create(er,n),a(e.insert)&&t.push(n))}function y(n){var e;if(a(e=n.fnScopeId))l.setStyleScope(n.elm,e);else for(var t=n;t;)a(e=t.context)&&a(e=e.$options._scopeId)&&l.setStyleScope(n.elm,e),t=t.parent;a(e=Ke)&&e!==n.context&&e!==n.fnContext&&a(e=e.$options._scopeId)&&l.setStyleScope(n.elm,e)}function b(n,e,t,r,o,i){for(;r<=o;++r)p(t[r],i,n,e,!1,t,r)}function x(n){var e,t,o=n.data;if(a(o))for(a(e=o.hook)&&a(e=e.destroy)&&e(n),e=0;e<r.destroy.length;++e)r.destroy[e](n);if(a(e=n.children))for(t=0;t<n.children.length;++t)x(n.children[t])}function _(n,e,t){for(;e<=t;++e){var r=n[e];a(r)&&(a(r.tag)?(w(r),x(r)):u(r.elm))}}function w(n,e){if(a(e)||a(n.data)){var t,o=r.remove.length+1;for(a(e)?e.listeners+=o:e=function(n,e){function t(){0==--t.listeners&&u(n)}return t.listeners=e,t}(n.elm,o),a(t=n.componentInstance)&&a(t=t._vnode)&&a(t.data)&&w(t,e),t=0;t<r.remove.length;++t)r.remove[t](n,e);a(t=n.data.hook)&&a(t=t.remove)?t(n,e):e()}else u(n.elm)}function E(n,e,t,r){for(var o=t;o<r;o++){var i=e[o];if(a(i)&&rr(n,i))return o}}function k(n,e,t,o,c,u){if(n!==e){a(e.elm)&&a(o)&&(e=o[c]=xn(e));var d=e.elm=n.elm;if(s(n.isAsyncPlaceholder))a(e.asyncFactory.resolved)?S(n.elm,e,t):e.isAsyncPlaceholder=!0;else if(s(e.isStatic)&&s(n.isStatic)&&e.key===n.key&&(s(e.isCloned)||s(e.isOnce)))e.componentInstance=n.componentInstance;else{var f,h=e.data;a(h)&&a(f=h.hook)&&a(f=f.prepatch)&&f(n,e);var v=n.children,g=e.children;if(a(h)&&m(e)){for(f=0;f<r.update.length;++f)r.update[f](n,e);a(f=h.hook)&&a(f=f.update)&&f(n,e)}i(e.text)?a(v)&&a(g)?v!==g&&function(n,e,t,r,o){var s,c,u,d=0,f=0,h=e.length-1,m=e[0],v=e[h],g=t.length-1,y=t[0],x=t[g],w=!o;for(0;d<=h&&f<=g;)i(m)?m=e[++d]:i(v)?v=e[--h]:rr(m,y)?(k(m,y,r,t,f),m=e[++d],y=t[++f]):rr(v,x)?(k(v,x,r,t,g),v=e[--h],x=t[--g]):rr(m,x)?(k(m,x,r,t,g),w&&l.insertBefore(n,m.elm,l.nextSibling(v.elm)),m=e[++d],x=t[--g]):rr(v,y)?(k(v,y,r,t,f),w&&l.insertBefore(n,v.elm,m.elm),v=e[--h],y=t[++f]):(i(s)&&(s=or(e,d,h)),i(c=a(y.key)?s[y.key]:E(y,e,d,h))?p(y,r,n,m.elm,!1,t,f):rr(u=e[c],y)?(k(u,y,r,t,f),e[c]=void 0,w&&l.insertBefore(n,u.elm,m.elm)):p(y,r,n,m.elm,!1,t,f),y=t[++f]);d>h?b(n,i(t[g+1])?null:t[g+1].elm,t,f,g,r):f>g&&_(e,d,h)}(d,v,g,t,u):a(g)?(a(n.text)&&l.setTextContent(d,""),b(d,null,g,0,g.length-1,t)):a(v)?_(v,0,v.length-1):a(n.text)&&l.setTextContent(d,""):n.text!==e.text&&l.setTextContent(d,e.text),a(h)&&a(f=h.hook)&&a(f=f.postpatch)&&f(n,e)}}}function C(n,e,t){if(s(t)&&a(n.parent))n.parent.data.pendingInsert=e;else for(var r=0;r<e.length;++r)e[r].data.hook.insert(e[r])}var T=g("attrs,class,staticClass,staticStyle,key");function S(n,e,t,r){var o,i=e.tag,c=e.data,l=e.children;if(r=r||c&&c.pre,e.elm=n,s(e.isComment)&&a(e.asyncFactory))return e.isAsyncPlaceholder=!0,!0;if(a(c)&&(a(o=c.hook)&&a(o=o.init)&&o(e,!0),a(o=e.componentInstance)))return d(e,t),!0;if(a(i)){if(a(l))if(n.hasChildNodes())if(a(o=c)&&a(o=o.domProps)&&a(o=o.innerHTML)){if(o!==n.innerHTML)return!1}else{for(var u=!0,p=n.firstChild,f=0;f<l.length;f++){if(!p||!S(p,l[f],t,r)){u=!1;break}p=p.nextSibling}if(!u||p)return!1}else h(e,l,t);if(a(c)){var m=!1;for(var g in c)if(!T(g)){m=!0,v(e,t);break}!m&&c.class&&ae(c.class)}}else n.data!==e.text&&(n.data=e.text);return!0}return function(n,e,t,o){if(!i(e)){var c,u=!1,d=[];if(i(n))u=!0,p(e,d);else{var f=a(n.nodeType);if(!f&&rr(n,e))k(n,e,d,null,null,o);else{if(f){if(1===n.nodeType&&n.hasAttribute("data-server-rendered")&&(n.removeAttribute("data-server-rendered"),t=!0),s(t)&&S(n,e,d))return C(e,d,!0),n;c=n,n=new vn(l.tagName(c).toLowerCase(),{},[],void 0,c)}var h=n.elm,v=l.parentNode(h);if(p(e,d,h._leaveCb?null:v,l.nextSibling(h)),a(e.parent))for(var g=e.parent,y=m(e);g;){for(var b=0;b<r.destroy.length;++b)r.destroy[b](g);if(g.elm=e.elm,y){for(var w=0;w<r.create.length;++w)r.create[w](er,g);var E=g.data.hook.insert;if(E.merged)for(var T=1;T<E.fns.length;T++)E.fns[T]()}else nr(g);g=g.parent}a(v)?_([n],0,0):a(n.tag)&&x(n)}}return C(e,d,u),e.elm}a(n)&&x(n)}}({nodeOps:Kt,modules:[mr,yr,Cr,Ar,$r,q?{create:lo,activate:lo,remove:function(n,e){!0!==n.data.show?ao(n,e):e()}}:{}].concat(pr)});Z&&document.addEventListener("selectionchange",(function(){var n=document.activeElement;n&&n.vmodel&&bo(n,"input")}));var po={inserted:function(n,e,t,r){"select"===t.tag?(r.elm&&!r.elm._vOptions?ue(t,"postpatch",(function(){po.componentUpdated(n,e,t)})):fo(n,e,t.context),n._vOptions=[].map.call(n.options,vo)):("textarea"===t.tag||Zt(n.type))&&(n._vModifiers=e.modifiers,e.modifiers.lazy||(n.addEventListener("compositionstart",go),n.addEventListener("compositionend",yo),n.addEventListener("change",yo),Z&&(n.vmodel=!0)))},componentUpdated:function(n,e,t){if("select"===t.tag){fo(n,e,t.context);var r=n._vOptions,o=n._vOptions=[].map.call(n.options,vo);if(o.some((function(n,e){return!L(n,r[e])})))(n.multiple?e.value.some((function(n){return mo(n,o)})):e.value!==e.oldValue&&mo(e.value,o))&&bo(n,"change")}}};function fo(n,e,t){ho(n,e,t),(W||K)&&setTimeout((function(){ho(n,e,t)}),0)}function ho(n,e,t){var r=e.value,o=n.multiple;if(!o||Array.isArray(r)){for(var i,a,s=0,c=n.options.length;s<c;s++)if(a=n.options[s],o)i=N(r,vo(a))>-1,a.selected!==i&&(a.selected=i);else if(L(vo(a),r))return void(n.selectedIndex!==s&&(n.selectedIndex=s));o||(n.selectedIndex=-1)}}function mo(n,e){return e.every((function(e){return!L(e,n)}))}function vo(n){return"_value"in n?n._value:n.value}function go(n){n.target.composing=!0}function yo(n){n.target.composing&&(n.target.composing=!1,bo(n.target,"input"))}function bo(n,e){var t=document.createEvent("HTMLEvents");t.initEvent(e,!0,!0),n.dispatchEvent(t)}function xo(n){return!n.componentInstance||n.data&&n.data.transition?n:xo(n.componentInstance._vnode)}var _o={model:po,show:{bind:function(n,e,t){var r=e.value,o=(t=xo(t)).data&&t.data.transition,i=n.__vOriginalDisplay="none"===n.style.display?"":n.style.display;r&&o?(t.data.show=!0,io(t,(function(){n.style.display=i}))):n.style.display=r?i:"none"},update:function(n,e,t){var r=e.value;!r!=!e.oldValue&&((t=xo(t)).data&&t.data.transition?(t.data.show=!0,r?io(t,(function(){n.style.display=n.__vOriginalDisplay})):ao(t,(function(){n.style.display="none"}))):n.style.display=r?n.__vOriginalDisplay:"none")},unbind:function(n,e,t,r,o){o||(n.style.display=n.__vOriginalDisplay)}}},wo={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function Eo(n){var e=n&&n.componentOptions;return e&&e.Ctor.options.abstract?Eo(Xe(e.children)):n}function ko(n){var e={},t=n.$options;for(var r in t.propsData)e[r]=n[r];var o=t._parentListeners;for(var i in o)e[k(i)]=o[i];return e}function Co(n,e){if(/\d-keep-alive$/.test(e.tag))return n("keep-alive",{props:e.componentOptions.propsData})}var To=function(n){return n.tag||ge(n)},So=function(n){return"show"===n.name},Ao={name:"transition",props:wo,abstract:!0,render:function(n){var e=this,t=this.$slots.default;if(t&&(t=t.filter(To)).length){0;var r=this.mode;0;var o=t[0];if(function(n){for(;n=n.parent;)if(n.data.transition)return!0}(this.$vnode))return o;var i=Eo(o);if(!i)return o;if(this._leaving)return Co(n,o);var a="__transition-"+this._uid+"-";i.key=null==i.key?i.isComment?a+"comment":a+i.tag:c(i.key)?0===String(i.key).indexOf(a)?i.key:a+i.key:i.key;var s=(i.data||(i.data={})).transition=ko(this),l=this._vnode,u=Eo(l);if(i.data.directives&&i.data.directives.some(So)&&(i.data.show=!0),u&&u.data&&!function(n,e){return e.key===n.key&&e.tag===n.tag}(i,u)&&!ge(u)&&(!u.componentInstance||!u.componentInstance._vnode.isComment)){var p=u.data.transition=j({},s);if("out-in"===r)return this._leaving=!0,ue(p,"afterLeave",(function(){e._leaving=!1,e.$forceUpdate()})),Co(n,o);if("in-out"===r){if(ge(i))return l;var d,f=function(){d()};ue(s,"afterEnter",f),ue(s,"enterCancelled",f),ue(p,"delayLeave",(function(n){d=n}))}}return o}}},Oo=j({tag:String,moveClass:String},wo);function jo(n){n.elm._moveCb&&n.elm._moveCb(),n.elm._enterCb&&n.elm._enterCb()}function Io(n){n.data.newPos=n.elm.getBoundingClientRect()}function Po(n){var e=n.data.pos,t=n.data.newPos,r=e.left-t.left,o=e.top-t.top;if(r||o){n.data.moved=!0;var i=n.elm.style;i.transform=i.WebkitTransform="translate("+r+"px,"+o+"px)",i.transitionDuration="0s"}}delete Oo.mode;var zo={Transition:Ao,TransitionGroup:{props:Oo,beforeMount:function(){var n=this,e=this._update;this._update=function(t,r){var o=Qe(n);n.__patch__(n._vnode,n.kept,!1,!0),n._vnode=n.kept,o(),e.call(n,t,r)}},render:function(n){for(var e=this.tag||this.$vnode.data.tag||"span",t=Object.create(null),r=this.prevChildren=this.children,o=this.$slots.default||[],i=this.children=[],a=ko(this),s=0;s<o.length;s++){var c=o[s];if(c.tag)if(null!=c.key&&0!==String(c.key).indexOf("__vlist"))i.push(c),t[c.key]=c,(c.data||(c.data={})).transition=a;else;}if(r){for(var l=[],u=[],p=0;p<r.length;p++){var d=r[p];d.data.transition=a,d.data.pos=d.elm.getBoundingClientRect(),t[d.key]?l.push(d):u.push(d)}this.kept=n(e,null,l),this.removed=u}return n(e,null,i)},updated:function(){var n=this.prevChildren,e=this.moveClass||(this.name||"v")+"-move";n.length&&this.hasMove(n[0].elm,e)&&(n.forEach(jo),n.forEach(Io),n.forEach(Po),this._reflow=document.body.offsetHeight,n.forEach((function(n){if(n.data.moved){var t=n.elm,r=t.style;Kr(t,e),r.transform=r.WebkitTransform=r.transitionDuration="",t.addEventListener(Xr,t._moveCb=function n(r){r&&r.target!==t||r&&!/transform$/.test(r.propertyName)||(t.removeEventListener(Xr,n),t._moveCb=null,Qr(t,e))})}})))},methods:{hasMove:function(n,e){if(!Hr)return!1;if(this._hasMove)return this._hasMove;var t=n.cloneNode();n._transitionClasses&&n._transitionClasses.forEach((function(n){Gr(t,n)})),Fr(t,e),t.style.display="none",this.$el.appendChild(t);var r=to(t);return this.$el.removeChild(t),this._hasMove=r.hasTransform}}}};Ct.config.mustUseProp=function(n,e,t){return"value"===t&&Dt(n)&&"button"!==e||"selected"===t&&"option"===n||"checked"===t&&"input"===n||"muted"===t&&"video"===n},Ct.config.isReservedTag=Yt,Ct.config.isReservedAttr=zt,Ct.config.getTagNamespace=function(n){return Jt(n)?"svg":"math"===n?"math":void 0},Ct.config.isUnknownElement=function(n){if(!q)return!0;if(Yt(n))return!1;if(n=n.toLowerCase(),null!=Wt[n])return Wt[n];var e=document.createElement(n);return n.indexOf("-")>-1?Wt[n]=e.constructor===window.HTMLUnknownElement||e.constructor===window.HTMLElement:Wt[n]=/HTMLUnknownElement/.test(e.toString())},j(Ct.options.directives,_o),j(Ct.options.components,zo),Ct.prototype.__patch__=q?uo:P,Ct.prototype.$mount=function(n,e){return function(n,e,t){var r;return n.$el=e,n.$options.render||(n.$options.render=yn),tt(n,"beforeMount"),r=function(){n._update(n._render(),t)},new ht(n,r,P,{before:function(){n._isMounted&&!n._isDestroyed&&tt(n,"beforeUpdate")}},!0),t=!1,null==n.$vnode&&(n._isMounted=!0,tt(n,"mounted")),n}(this,n=n&&q?function(n){if("string"==typeof n){var e=document.querySelector(n);return e||document.createElement("div")}return n}(n):void 0,e)},q&&setTimeout((function(){M.devtools&&an&&an.emit("init",Ct)}),0);var Do=Ct;
/*!
  * vue-router v3.5.3
  * (c) 2021 Evan You
  * @license MIT
  */function Lo(n,e){for(var t in e)n[t]=e[t];return n}var No=/[!'()*]/g,Bo=function(n){return"%"+n.charCodeAt(0).toString(16)},Ro=/%2C/g,$o=function(n){return encodeURIComponent(n).replace(No,Bo).replace(Ro,",")};function Mo(n){try{return decodeURIComponent(n)}catch(n){0}return n}var Fo=function(n){return null==n||"object"==typeof n?n:String(n)};function Go(n){var e={};return(n=n.trim().replace(/^(\?|#|&)/,""))?(n.split("&").forEach((function(n){var t=n.replace(/\+/g," ").split("="),r=Mo(t.shift()),o=t.length>0?Mo(t.join("=")):null;void 0===e[r]?e[r]=o:Array.isArray(e[r])?e[r].push(o):e[r]=[e[r],o]})),e):e}function Uo(n){var e=n?Object.keys(n).map((function(e){var t=n[e];if(void 0===t)return"";if(null===t)return $o(e);if(Array.isArray(t)){var r=[];return t.forEach((function(n){void 0!==n&&(null===n?r.push($o(e)):r.push($o(e)+"="+$o(n)))})),r.join("&")}return $o(e)+"="+$o(t)})).filter((function(n){return n.length>0})).join("&"):null;return e?"?"+e:""}var Vo=/\/?$/;function Ho(n,e,t,r){var o=r&&r.options.stringifyQuery,i=e.query||{};try{i=qo(i)}catch(n){}var a={name:e.name||n&&n.name,meta:n&&n.meta||{},path:e.path||"/",hash:e.hash||"",query:i,params:e.params||{},fullPath:Yo(e,o),matched:n?Jo(n):[]};return t&&(a.redirectedFrom=Yo(t,o)),Object.freeze(a)}function qo(n){if(Array.isArray(n))return n.map(qo);if(n&&"object"==typeof n){var e={};for(var t in n)e[t]=qo(n[t]);return e}return n}var Xo=Ho(null,{path:"/"});function Jo(n){for(var e=[];n;)e.unshift(n),n=n.parent;return e}function Yo(n,e){var t=n.path,r=n.query;void 0===r&&(r={});var o=n.hash;return void 0===o&&(o=""),(t||"/")+(e||Uo)(r)+o}function Wo(n,e,t){return e===Xo?n===e:!!e&&(n.path&&e.path?n.path.replace(Vo,"")===e.path.replace(Vo,"")&&(t||n.hash===e.hash&&Zo(n.query,e.query)):!(!n.name||!e.name)&&(n.name===e.name&&(t||n.hash===e.hash&&Zo(n.query,e.query)&&Zo(n.params,e.params))))}function Zo(n,e){if(void 0===n&&(n={}),void 0===e&&(e={}),!n||!e)return n===e;var t=Object.keys(n).sort(),r=Object.keys(e).sort();return t.length===r.length&&t.every((function(t,o){var i=n[t];if(r[o]!==t)return!1;var a=e[t];return null==i||null==a?i===a:"object"==typeof i&&"object"==typeof a?Zo(i,a):String(i)===String(a)}))}function Ko(n){for(var e=0;e<n.matched.length;e++){var t=n.matched[e];for(var r in t.instances){var o=t.instances[r],i=t.enteredCbs[r];if(o&&i){delete t.enteredCbs[r];for(var a=0;a<i.length;a++)o._isBeingDestroyed||i[a](o)}}}}var Qo={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(n,e){var t=e.props,r=e.children,o=e.parent,i=e.data;i.routerView=!0;for(var a=o.$createElement,s=t.name,c=o.$route,l=o._routerViewCache||(o._routerViewCache={}),u=0,p=!1;o&&o._routerRoot!==o;){var d=o.$vnode?o.$vnode.data:{};d.routerView&&u++,d.keepAlive&&o._directInactive&&o._inactive&&(p=!0),o=o.$parent}if(i.routerViewDepth=u,p){var f=l[s],h=f&&f.component;return h?(f.configProps&&ni(h,i,f.route,f.configProps),a(h,i,r)):a()}var m=c.matched[u],v=m&&m.components[s];if(!m||!v)return l[s]=null,a();l[s]={component:v},i.registerRouteInstance=function(n,e){var t=m.instances[s];(e&&t!==n||!e&&t===n)&&(m.instances[s]=e)},(i.hook||(i.hook={})).prepatch=function(n,e){m.instances[s]=e.componentInstance},i.hook.init=function(n){n.data.keepAlive&&n.componentInstance&&n.componentInstance!==m.instances[s]&&(m.instances[s]=n.componentInstance),Ko(c)};var g=m.props&&m.props[s];return g&&(Lo(l[s],{route:c,configProps:g}),ni(v,i,c,g)),a(v,i,r)}};function ni(n,e,t,r){var o=e.props=function(n,e){switch(typeof e){case"undefined":return;case"object":return e;case"function":return e(n);case"boolean":return e?n.params:void 0;default:0}}(t,r);if(o){o=e.props=Lo({},o);var i=e.attrs=e.attrs||{};for(var a in o)n.props&&a in n.props||(i[a]=o[a],delete o[a])}}function ei(n,e,t){var r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;var o=e.split("/");t&&o[o.length-1]||o.pop();for(var i=n.replace(/^\//,"").split("/"),a=0;a<i.length;a++){var s=i[a];".."===s?o.pop():"."!==s&&o.push(s)}return""!==o[0]&&o.unshift(""),o.join("/")}function ti(n){return n.replace(/\/+/g,"/")}var ri=Array.isArray||function(n){return"[object Array]"==Object.prototype.toString.call(n)},oi=yi,ii=ui,ai=function(n,e){return di(ui(n,e),e)},si=di,ci=gi,li=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function ui(n,e){for(var t,r=[],o=0,i=0,a="",s=e&&e.delimiter||"/";null!=(t=li.exec(n));){var c=t[0],l=t[1],u=t.index;if(a+=n.slice(i,u),i=u+c.length,l)a+=l[1];else{var p=n[i],d=t[2],f=t[3],h=t[4],m=t[5],v=t[6],g=t[7];a&&(r.push(a),a="");var y=null!=d&&null!=p&&p!==d,b="+"===v||"*"===v,x="?"===v||"*"===v,_=t[2]||s,w=h||m;r.push({name:f||o++,prefix:d||"",delimiter:_,optional:x,repeat:b,partial:y,asterisk:!!g,pattern:w?hi(w):g?".*":"[^"+fi(_)+"]+?"})}}return i<n.length&&(a+=n.substr(i)),a&&r.push(a),r}function pi(n){return encodeURI(n).replace(/[\/?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()}))}function di(n,e){for(var t=new Array(n.length),r=0;r<n.length;r++)"object"==typeof n[r]&&(t[r]=new RegExp("^(?:"+n[r].pattern+")$",vi(e)));return function(e,r){for(var o="",i=e||{},a=(r||{}).pretty?pi:encodeURIComponent,s=0;s<n.length;s++){var c=n[s];if("string"!=typeof c){var l,u=i[c.name];if(null==u){if(c.optional){c.partial&&(o+=c.prefix);continue}throw new TypeError('Expected "'+c.name+'" to be defined')}if(ri(u)){if(!c.repeat)throw new TypeError('Expected "'+c.name+'" to not repeat, but received `'+JSON.stringify(u)+"`");if(0===u.length){if(c.optional)continue;throw new TypeError('Expected "'+c.name+'" to not be empty')}for(var p=0;p<u.length;p++){if(l=a(u[p]),!t[s].test(l))throw new TypeError('Expected all "'+c.name+'" to match "'+c.pattern+'", but received `'+JSON.stringify(l)+"`");o+=(0===p?c.prefix:c.delimiter)+l}}else{if(l=c.asterisk?encodeURI(u).replace(/[?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()})):a(u),!t[s].test(l))throw new TypeError('Expected "'+c.name+'" to match "'+c.pattern+'", but received "'+l+'"');o+=c.prefix+l}}else o+=c}return o}}function fi(n){return n.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function hi(n){return n.replace(/([=!:$\/()])/g,"\\$1")}function mi(n,e){return n.keys=e,n}function vi(n){return n&&n.sensitive?"":"i"}function gi(n,e,t){ri(e)||(t=e||t,e=[]);for(var r=(t=t||{}).strict,o=!1!==t.end,i="",a=0;a<n.length;a++){var s=n[a];if("string"==typeof s)i+=fi(s);else{var c=fi(s.prefix),l="(?:"+s.pattern+")";e.push(s),s.repeat&&(l+="(?:"+c+l+")*"),i+=l=s.optional?s.partial?c+"("+l+")?":"(?:"+c+"("+l+"))?":c+"("+l+")"}}var u=fi(t.delimiter||"/"),p=i.slice(-u.length)===u;return r||(i=(p?i.slice(0,-u.length):i)+"(?:"+u+"(?=$))?"),i+=o?"$":r&&p?"":"(?="+u+"|$)",mi(new RegExp("^"+i,vi(t)),e)}function yi(n,e,t){return ri(e)||(t=e||t,e=[]),t=t||{},n instanceof RegExp?function(n,e){var t=n.source.match(/\((?!\?)/g);if(t)for(var r=0;r<t.length;r++)e.push({name:r,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return mi(n,e)}(n,e):ri(n)?function(n,e,t){for(var r=[],o=0;o<n.length;o++)r.push(yi(n[o],e,t).source);return mi(new RegExp("(?:"+r.join("|")+")",vi(t)),e)}(n,e,t):function(n,e,t){return gi(ui(n,t),e,t)}(n,e,t)}oi.parse=ii,oi.compile=ai,oi.tokensToFunction=si,oi.tokensToRegExp=ci;var bi=Object.create(null);function xi(n,e,t){e=e||{};try{var r=bi[n]||(bi[n]=oi.compile(n));return"string"==typeof e.pathMatch&&(e[0]=e.pathMatch),r(e,{pretty:!0})}catch(n){return""}finally{delete e[0]}}function _i(n,e,t,r){var o="string"==typeof n?{path:n}:n;if(o._normalized)return o;if(o.name){var i=(o=Lo({},n)).params;return i&&"object"==typeof i&&(o.params=Lo({},i)),o}if(!o.path&&o.params&&e){(o=Lo({},o))._normalized=!0;var a=Lo(Lo({},e.params),o.params);if(e.name)o.name=e.name,o.params=a;else if(e.matched.length){var s=e.matched[e.matched.length-1].path;o.path=xi(s,a,e.path)}else 0;return o}var c=function(n){var e="",t="",r=n.indexOf("#");r>=0&&(e=n.slice(r),n=n.slice(0,r));var o=n.indexOf("?");return o>=0&&(t=n.slice(o+1),n=n.slice(0,o)),{path:n,query:t,hash:e}}(o.path||""),l=e&&e.path||"/",u=c.path?ei(c.path,l,t||o.append):l,p=function(n,e,t){void 0===e&&(e={});var r,o=t||Go;try{r=o(n||"")}catch(n){r={}}for(var i in e){var a=e[i];r[i]=Array.isArray(a)?a.map(Fo):Fo(a)}return r}(c.query,o.query,r&&r.options.parseQuery),d=o.hash||c.hash;return d&&"#"!==d.charAt(0)&&(d="#"+d),{_normalized:!0,path:u,query:p,hash:d}}var wi,Ei=function(){},ki={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(n){var e=this,t=this.$router,r=this.$route,o=t.resolve(this.to,r,this.append),i=o.location,a=o.route,s=o.href,c={},l=t.options.linkActiveClass,u=t.options.linkExactActiveClass,p=null==l?"router-link-active":l,d=null==u?"router-link-exact-active":u,f=null==this.activeClass?p:this.activeClass,h=null==this.exactActiveClass?d:this.exactActiveClass,m=a.redirectedFrom?Ho(null,_i(a.redirectedFrom),null,t):a;c[h]=Wo(r,m,this.exactPath),c[f]=this.exact||this.exactPath?c[h]:function(n,e){return 0===n.path.replace(Vo,"/").indexOf(e.path.replace(Vo,"/"))&&(!e.hash||n.hash===e.hash)&&function(n,e){for(var t in e)if(!(t in n))return!1;return!0}(n.query,e.query)}(r,m);var v=c[h]?this.ariaCurrentValue:null,g=function(n){Ci(n)&&(e.replace?t.replace(i,Ei):t.push(i,Ei))},y={click:Ci};Array.isArray(this.event)?this.event.forEach((function(n){y[n]=g})):y[this.event]=g;var b={class:c},x=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:s,route:a,navigate:g,isActive:c[f],isExactActive:c[h]});if(x){if(1===x.length)return x[0];if(x.length>1||!x.length)return 0===x.length?n():n("span",{},x)}if("a"===this.tag)b.on=y,b.attrs={href:s,"aria-current":v};else{var _=function n(e){var t;if(e)for(var r=0;r<e.length;r++){if("a"===(t=e[r]).tag)return t;if(t.children&&(t=n(t.children)))return t}}(this.$slots.default);if(_){_.isStatic=!1;var w=_.data=Lo({},_.data);for(var E in w.on=w.on||{},w.on){var k=w.on[E];E in y&&(w.on[E]=Array.isArray(k)?k:[k])}for(var C in y)C in w.on?w.on[C].push(y[C]):w.on[C]=g;var T=_.data.attrs=Lo({},_.data.attrs);T.href=s,T["aria-current"]=v}else b.on=y}return n(this.tag,b,this.$slots.default)}};function Ci(n){if(!(n.metaKey||n.altKey||n.ctrlKey||n.shiftKey||n.defaultPrevented||void 0!==n.button&&0!==n.button)){if(n.currentTarget&&n.currentTarget.getAttribute){var e=n.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(e))return}return n.preventDefault&&n.preventDefault(),!0}}var Ti="undefined"!=typeof window;function Si(n,e,t,r,o){var i=e||[],a=t||Object.create(null),s=r||Object.create(null);n.forEach((function(n){!function n(e,t,r,o,i,a){var s=o.path,c=o.name;0;var l=o.pathToRegexpOptions||{},u=function(n,e,t){t||(n=n.replace(/\/$/,""));if("/"===n[0])return n;if(null==e)return n;return ti(e.path+"/"+n)}(s,i,l.strict);"boolean"==typeof o.caseSensitive&&(l.sensitive=o.caseSensitive);var p={path:u,regex:Ai(u,l),components:o.components||{default:o.component},alias:o.alias?"string"==typeof o.alias?[o.alias]:o.alias:[],instances:{},enteredCbs:{},name:c,parent:i,matchAs:a,redirect:o.redirect,beforeEnter:o.beforeEnter,meta:o.meta||{},props:null==o.props?{}:o.components?o.props:{default:o.props}};o.children&&o.children.forEach((function(o){var i=a?ti(a+"/"+o.path):void 0;n(e,t,r,o,p,i)}));t[p.path]||(e.push(p.path),t[p.path]=p);if(void 0!==o.alias)for(var d=Array.isArray(o.alias)?o.alias:[o.alias],f=0;f<d.length;++f){0;var h={path:d[f],children:o.children};n(e,t,r,h,i,p.path||"/")}c&&(r[c]||(r[c]=p))}(i,a,s,n,o)}));for(var c=0,l=i.length;c<l;c++)"*"===i[c]&&(i.push(i.splice(c,1)[0]),l--,c--);return{pathList:i,pathMap:a,nameMap:s}}function Ai(n,e){return oi(n,[],e)}function Oi(n,e){var t=Si(n),r=t.pathList,o=t.pathMap,i=t.nameMap;function a(n,t,a){var s=_i(n,t,!1,e),l=s.name;if(l){var u=i[l];if(!u)return c(null,s);var p=u.regex.keys.filter((function(n){return!n.optional})).map((function(n){return n.name}));if("object"!=typeof s.params&&(s.params={}),t&&"object"==typeof t.params)for(var d in t.params)!(d in s.params)&&p.indexOf(d)>-1&&(s.params[d]=t.params[d]);return s.path=xi(u.path,s.params),c(u,s,a)}if(s.path){s.params={};for(var f=0;f<r.length;f++){var h=r[f],m=o[h];if(ji(m.regex,s.path,s.params))return c(m,s,a)}}return c(null,s)}function s(n,t){var r=n.redirect,o="function"==typeof r?r(Ho(n,t,null,e)):r;if("string"==typeof o&&(o={path:o}),!o||"object"!=typeof o)return c(null,t);var s=o,l=s.name,u=s.path,p=t.query,d=t.hash,f=t.params;if(p=s.hasOwnProperty("query")?s.query:p,d=s.hasOwnProperty("hash")?s.hash:d,f=s.hasOwnProperty("params")?s.params:f,l){i[l];return a({_normalized:!0,name:l,query:p,hash:d,params:f},void 0,t)}if(u){var h=function(n,e){return ei(n,e.parent?e.parent.path:"/",!0)}(u,n);return a({_normalized:!0,path:xi(h,f),query:p,hash:d},void 0,t)}return c(null,t)}function c(n,t,r){return n&&n.redirect?s(n,r||t):n&&n.matchAs?function(n,e,t){var r=a({_normalized:!0,path:xi(t,e.params)});if(r){var o=r.matched,i=o[o.length-1];return e.params=r.params,c(i,e)}return c(null,e)}(0,t,n.matchAs):Ho(n,t,r,e)}return{match:a,addRoute:function(n,e){var t="object"!=typeof n?i[n]:void 0;Si([e||n],r,o,i,t),t&&t.alias.length&&Si(t.alias.map((function(n){return{path:n,children:[e]}})),r,o,i,t)},getRoutes:function(){return r.map((function(n){return o[n]}))},addRoutes:function(n){Si(n,r,o,i)}}}function ji(n,e,t){var r=e.match(n);if(!r)return!1;if(!t)return!0;for(var o=1,i=r.length;o<i;++o){var a=n.keys[o-1];a&&(t[a.name||"pathMatch"]="string"==typeof r[o]?Mo(r[o]):r[o])}return!0}var Ii=Ti&&window.performance&&window.performance.now?window.performance:Date;function Pi(){return Ii.now().toFixed(3)}var zi=Pi();function Di(){return zi}function Li(n){return zi=n}var Ni=Object.create(null);function Bi(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var n=window.location.protocol+"//"+window.location.host,e=window.location.href.replace(n,""),t=Lo({},window.history.state);return t.key=Di(),window.history.replaceState(t,"",e),window.addEventListener("popstate",Mi),function(){window.removeEventListener("popstate",Mi)}}function Ri(n,e,t,r){if(n.app){var o=n.options.scrollBehavior;o&&n.app.$nextTick((function(){var i=function(){var n=Di();if(n)return Ni[n]}(),a=o.call(n,e,t,r?i:null);a&&("function"==typeof a.then?a.then((function(n){Hi(n,i)})).catch((function(n){0})):Hi(a,i))}))}}function $i(){var n=Di();n&&(Ni[n]={x:window.pageXOffset,y:window.pageYOffset})}function Mi(n){$i(),n.state&&n.state.key&&Li(n.state.key)}function Fi(n){return Ui(n.x)||Ui(n.y)}function Gi(n){return{x:Ui(n.x)?n.x:window.pageXOffset,y:Ui(n.y)?n.y:window.pageYOffset}}function Ui(n){return"number"==typeof n}var Vi=/^#\d/;function Hi(n,e){var t,r="object"==typeof n;if(r&&"string"==typeof n.selector){var o=Vi.test(n.selector)?document.getElementById(n.selector.slice(1)):document.querySelector(n.selector);if(o){var i=n.offset&&"object"==typeof n.offset?n.offset:{};e=function(n,e){var t=document.documentElement.getBoundingClientRect(),r=n.getBoundingClientRect();return{x:r.left-t.left-e.x,y:r.top-t.top-e.y}}(o,i={x:Ui((t=i).x)?t.x:0,y:Ui(t.y)?t.y:0})}else Fi(n)&&(e=Gi(n))}else r&&Fi(n)&&(e=Gi(n));e&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:e.x,top:e.y,behavior:n.behavior}):window.scrollTo(e.x,e.y))}var qi,Xi=Ti&&((-1===(qi=window.navigator.userAgent).indexOf("Android 2.")&&-1===qi.indexOf("Android 4.0")||-1===qi.indexOf("Mobile Safari")||-1!==qi.indexOf("Chrome")||-1!==qi.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function Ji(n,e){$i();var t=window.history;try{if(e){var r=Lo({},t.state);r.key=Di(),t.replaceState(r,"",n)}else t.pushState({key:Li(Pi())},"",n)}catch(t){window.location[e?"replace":"assign"](n)}}function Yi(n){Ji(n,!0)}function Wi(n,e,t){var r=function(o){o>=n.length?t():n[o]?e(n[o],(function(){r(o+1)})):r(o+1)};r(0)}var Zi={redirected:2,aborted:4,cancelled:8,duplicated:16};function Ki(n,e){return na(n,e,Zi.redirected,'Redirected when going from "'+n.fullPath+'" to "'+function(n){if("string"==typeof n)return n;if("path"in n)return n.path;var e={};return ea.forEach((function(t){t in n&&(e[t]=n[t])})),JSON.stringify(e,null,2)}(e)+'" via a navigation guard.')}function Qi(n,e){return na(n,e,Zi.cancelled,'Navigation cancelled from "'+n.fullPath+'" to "'+e.fullPath+'" with a new navigation.')}function na(n,e,t,r){var o=new Error(r);return o._isRouter=!0,o.from=n,o.to=e,o.type=t,o}var ea=["params","query","hash"];function ta(n){return Object.prototype.toString.call(n).indexOf("Error")>-1}function ra(n,e){return ta(n)&&n._isRouter&&(null==e||n.type===e)}function oa(n){return function(e,t,r){var o=!1,i=0,a=null;ia(n,(function(n,e,t,s){if("function"==typeof n&&void 0===n.cid){o=!0,i++;var c,l=ca((function(e){var o;((o=e).__esModule||sa&&"Module"===o[Symbol.toStringTag])&&(e=e.default),n.resolved="function"==typeof e?e:wi.extend(e),t.components[s]=e,--i<=0&&r()})),u=ca((function(n){var e="Failed to resolve async component "+s+": "+n;a||(a=ta(n)?n:new Error(e),r(a))}));try{c=n(l,u)}catch(n){u(n)}if(c)if("function"==typeof c.then)c.then(l,u);else{var p=c.component;p&&"function"==typeof p.then&&p.then(l,u)}}})),o||r()}}function ia(n,e){return aa(n.map((function(n){return Object.keys(n.components).map((function(t){return e(n.components[t],n.instances[t],n,t)}))})))}function aa(n){return Array.prototype.concat.apply([],n)}var sa="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function ca(n){var e=!1;return function(){for(var t=[],r=arguments.length;r--;)t[r]=arguments[r];if(!e)return e=!0,n.apply(this,t)}}var la=function(n,e){this.router=n,this.base=function(n){if(!n)if(Ti){var e=document.querySelector("base");n=(n=e&&e.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else n="/";"/"!==n.charAt(0)&&(n="/"+n);return n.replace(/\/$/,"")}(e),this.current=Xo,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function ua(n,e,t,r){var o=ia(n,(function(n,r,o,i){var a=function(n,e){"function"!=typeof n&&(n=wi.extend(n));return n.options[e]}(n,e);if(a)return Array.isArray(a)?a.map((function(n){return t(n,r,o,i)})):t(a,r,o,i)}));return aa(r?o.reverse():o)}function pa(n,e){if(e)return function(){return n.apply(e,arguments)}}la.prototype.listen=function(n){this.cb=n},la.prototype.onReady=function(n,e){this.ready?n():(this.readyCbs.push(n),e&&this.readyErrorCbs.push(e))},la.prototype.onError=function(n){this.errorCbs.push(n)},la.prototype.transitionTo=function(n,e,t){var r,o=this;try{r=this.router.match(n,this.current)}catch(n){throw this.errorCbs.forEach((function(e){e(n)})),n}var i=this.current;this.confirmTransition(r,(function(){o.updateRoute(r),e&&e(r),o.ensureURL(),o.router.afterHooks.forEach((function(n){n&&n(r,i)})),o.ready||(o.ready=!0,o.readyCbs.forEach((function(n){n(r)})))}),(function(n){t&&t(n),n&&!o.ready&&(ra(n,Zi.redirected)&&i===Xo||(o.ready=!0,o.readyErrorCbs.forEach((function(e){e(n)}))))}))},la.prototype.confirmTransition=function(n,e,t){var r=this,o=this.current;this.pending=n;var i,a,s=function(n){!ra(n)&&ta(n)&&(r.errorCbs.length?r.errorCbs.forEach((function(e){e(n)})):console.error(n)),t&&t(n)},c=n.matched.length-1,l=o.matched.length-1;if(Wo(n,o)&&c===l&&n.matched[c]===o.matched[l])return this.ensureURL(),n.hash&&Ri(this.router,o,n,!1),s(((a=na(i=o,n,Zi.duplicated,'Avoided redundant navigation to current location: "'+i.fullPath+'".')).name="NavigationDuplicated",a));var u=function(n,e){var t,r=Math.max(n.length,e.length);for(t=0;t<r&&n[t]===e[t];t++);return{updated:e.slice(0,t),activated:e.slice(t),deactivated:n.slice(t)}}(this.current.matched,n.matched),p=u.updated,d=u.deactivated,f=u.activated,h=[].concat(function(n){return ua(n,"beforeRouteLeave",pa,!0)}(d),this.router.beforeHooks,function(n){return ua(n,"beforeRouteUpdate",pa)}(p),f.map((function(n){return n.beforeEnter})),oa(f)),m=function(e,t){if(r.pending!==n)return s(Qi(o,n));try{e(n,o,(function(e){!1===e?(r.ensureURL(!0),s(function(n,e){return na(n,e,Zi.aborted,'Navigation aborted from "'+n.fullPath+'" to "'+e.fullPath+'" via a navigation guard.')}(o,n))):ta(e)?(r.ensureURL(!0),s(e)):"string"==typeof e||"object"==typeof e&&("string"==typeof e.path||"string"==typeof e.name)?(s(Ki(o,n)),"object"==typeof e&&e.replace?r.replace(e):r.push(e)):t(e)}))}catch(n){s(n)}};Wi(h,m,(function(){Wi(function(n){return ua(n,"beforeRouteEnter",(function(n,e,t,r){return function(n,e,t){return function(r,o,i){return n(r,o,(function(n){"function"==typeof n&&(e.enteredCbs[t]||(e.enteredCbs[t]=[]),e.enteredCbs[t].push(n)),i(n)}))}}(n,t,r)}))}(f).concat(r.router.resolveHooks),m,(function(){if(r.pending!==n)return s(Qi(o,n));r.pending=null,e(n),r.router.app&&r.router.app.$nextTick((function(){Ko(n)}))}))}))},la.prototype.updateRoute=function(n){this.current=n,this.cb&&this.cb(n)},la.prototype.setupListeners=function(){},la.prototype.teardown=function(){this.listeners.forEach((function(n){n()})),this.listeners=[],this.current=Xo,this.pending=null};var da=function(n){function e(e,t){n.call(this,e,t),this._startLocation=fa(this.base)}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router,t=e.options.scrollBehavior,r=Xi&&t;r&&this.listeners.push(Bi());var o=function(){var t=n.current,o=fa(n.base);n.current===Xo&&o===n._startLocation||n.transitionTo(o,(function(n){r&&Ri(e,n,t,!0)}))};window.addEventListener("popstate",o),this.listeners.push((function(){window.removeEventListener("popstate",o)}))}},e.prototype.go=function(n){window.history.go(n)},e.prototype.push=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){Ji(ti(r.base+n.fullPath)),Ri(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){Yi(ti(r.base+n.fullPath)),Ri(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.ensureURL=function(n){if(fa(this.base)!==this.current.fullPath){var e=ti(this.base+this.current.fullPath);n?Ji(e):Yi(e)}},e.prototype.getCurrentLocation=function(){return fa(this.base)},e}(la);function fa(n){var e=window.location.pathname,t=e.toLowerCase(),r=n.toLowerCase();return!n||t!==r&&0!==t.indexOf(ti(r+"/"))||(e=e.slice(n.length)),(e||"/")+window.location.search+window.location.hash}var ha=function(n){function e(e,t,r){n.call(this,e,t),r&&function(n){var e=fa(n);if(!/^\/#/.test(e))return window.location.replace(ti(n+"/#"+e)),!0}(this.base)||ma()}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router.options.scrollBehavior,t=Xi&&e;t&&this.listeners.push(Bi());var r=function(){var e=n.current;ma()&&n.transitionTo(va(),(function(r){t&&Ri(n.router,r,e,!0),Xi||ba(r.fullPath)}))},o=Xi?"popstate":"hashchange";window.addEventListener(o,r),this.listeners.push((function(){window.removeEventListener(o,r)}))}},e.prototype.push=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){ya(n.fullPath),Ri(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,o=this.current;this.transitionTo(n,(function(n){ba(n.fullPath),Ri(r.router,n,o,!1),e&&e(n)}),t)},e.prototype.go=function(n){window.history.go(n)},e.prototype.ensureURL=function(n){var e=this.current.fullPath;va()!==e&&(n?ya(e):ba(e))},e.prototype.getCurrentLocation=function(){return va()},e}(la);function ma(){var n=va();return"/"===n.charAt(0)||(ba("/"+n),!1)}function va(){var n=window.location.href,e=n.indexOf("#");return e<0?"":n=n.slice(e+1)}function ga(n){var e=window.location.href,t=e.indexOf("#");return(t>=0?e.slice(0,t):e)+"#"+n}function ya(n){Xi?Ji(ga(n)):window.location.hash=n}function ba(n){Xi?Yi(ga(n)):window.location.replace(ga(n))}var xa=function(n){function e(e,t){n.call(this,e,t),this.stack=[],this.index=-1}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.push=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index+1).concat(n),r.index++,e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index).concat(n),e&&e(n)}),t)},e.prototype.go=function(n){var e=this,t=this.index+n;if(!(t<0||t>=this.stack.length)){var r=this.stack[t];this.confirmTransition(r,(function(){var n=e.current;e.index=t,e.updateRoute(r),e.router.afterHooks.forEach((function(e){e&&e(r,n)}))}),(function(n){ra(n,Zi.duplicated)&&(e.index=t)}))}},e.prototype.getCurrentLocation=function(){var n=this.stack[this.stack.length-1];return n?n.fullPath:"/"},e.prototype.ensureURL=function(){},e}(la),_a=function(n){void 0===n&&(n={}),this.app=null,this.apps=[],this.options=n,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Oi(n.routes||[],this);var e=n.mode||"hash";switch(this.fallback="history"===e&&!Xi&&!1!==n.fallback,this.fallback&&(e="hash"),Ti||(e="abstract"),this.mode=e,e){case"history":this.history=new da(this,n.base);break;case"hash":this.history=new ha(this,n.base,this.fallback);break;case"abstract":this.history=new xa(this,n.base);break;default:0}},wa={currentRoute:{configurable:!0}};function Ea(n,e){return n.push(e),function(){var t=n.indexOf(e);t>-1&&n.splice(t,1)}}_a.prototype.match=function(n,e,t){return this.matcher.match(n,e,t)},wa.currentRoute.get=function(){return this.history&&this.history.current},_a.prototype.init=function(n){var e=this;if(this.apps.push(n),n.$once("hook:destroyed",(function(){var t=e.apps.indexOf(n);t>-1&&e.apps.splice(t,1),e.app===n&&(e.app=e.apps[0]||null),e.app||e.history.teardown()})),!this.app){this.app=n;var t=this.history;if(t instanceof da||t instanceof ha){var r=function(n){t.setupListeners(),function(n){var r=t.current,o=e.options.scrollBehavior;Xi&&o&&"fullPath"in n&&Ri(e,n,r,!1)}(n)};t.transitionTo(t.getCurrentLocation(),r,r)}t.listen((function(n){e.apps.forEach((function(e){e._route=n}))}))}},_a.prototype.beforeEach=function(n){return Ea(this.beforeHooks,n)},_a.prototype.beforeResolve=function(n){return Ea(this.resolveHooks,n)},_a.prototype.afterEach=function(n){return Ea(this.afterHooks,n)},_a.prototype.onReady=function(n,e){this.history.onReady(n,e)},_a.prototype.onError=function(n){this.history.onError(n)},_a.prototype.push=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.push(n,e,t)}));this.history.push(n,e,t)},_a.prototype.replace=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.replace(n,e,t)}));this.history.replace(n,e,t)},_a.prototype.go=function(n){this.history.go(n)},_a.prototype.back=function(){this.go(-1)},_a.prototype.forward=function(){this.go(1)},_a.prototype.getMatchedComponents=function(n){var e=n?n.matched?n:this.resolve(n).route:this.currentRoute;return e?[].concat.apply([],e.matched.map((function(n){return Object.keys(n.components).map((function(e){return n.components[e]}))}))):[]},_a.prototype.resolve=function(n,e,t){var r=_i(n,e=e||this.history.current,t,this),o=this.match(r,e),i=o.redirectedFrom||o.fullPath;return{location:r,route:o,href:function(n,e,t){var r="hash"===t?"#"+e:e;return n?ti(n+"/"+r):r}(this.history.base,i,this.mode),normalizedTo:r,resolved:o}},_a.prototype.getRoutes=function(){return this.matcher.getRoutes()},_a.prototype.addRoute=function(n,e){this.matcher.addRoute(n,e),this.history.current!==Xo&&this.history.transitionTo(this.history.getCurrentLocation())},_a.prototype.addRoutes=function(n){this.matcher.addRoutes(n),this.history.current!==Xo&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(_a.prototype,wa),_a.install=function n(e){if(!n.installed||wi!==e){n.installed=!0,wi=e;var t=function(n){return void 0!==n},r=function(n,e){var r=n.$options._parentVnode;t(r)&&t(r=r.data)&&t(r=r.registerRouteInstance)&&r(n,e)};e.mixin({beforeCreate:function(){t(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),e.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,r(this,this)},destroyed:function(){r(this)}}),Object.defineProperty(e.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(e.prototype,"$route",{get:function(){return this._routerRoot._route}}),e.component("RouterView",Qo),e.component("RouterLink",ki);var o=e.config.optionMergeStrategies;o.beforeRouteEnter=o.beforeRouteLeave=o.beforeRouteUpdate=o.created}},_a.version="3.5.3",_a.isNavigationFailure=ra,_a.NavigationFailureType=Zi,_a.START_LOCATION=Xo,Ti&&window.Vue&&window.Vue.use(_a);var ka=_a;t(177),t(178),t(255),t(76),t(179),t(28),t(29),t(257);function Ca(n){n.locales&&Object.keys(n.locales).forEach((function(e){n.locales[e].path=e})),Object.freeze(n)}t(71),t(92),t(126);function Ta(n){return(Ta="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(n){return typeof n}:function(n){return n&&"function"==typeof Symbol&&n.constructor===Symbol&&n!==Symbol.prototype?"symbol":typeof n})(n)}var Sa=t(73),Aa=(t(189),t(18),t(46),t(231),t(232),t(40),t(30),{NotFound:function(){return Promise.all([t.e(0),t.e(4)]).then(t.bind(null,483))},Layout:function(){return Promise.all([t.e(0),t.e(2)]).then(t.bind(null,482))}}),Oa={"v-63408d9b":function(){return t.e(5).then(t.bind(null,484))},"v-59531294":function(){return t.e(6).then(t.bind(null,485))},"v-36f91442":function(){return t.e(7).then(t.bind(null,486))},"v-16a60614":function(){return t.e(8).then(t.bind(null,487))},"v-e7d501c2":function(){return t.e(9).then(t.bind(null,488))},"v-7eee78b8":function(){return t.e(10).then(t.bind(null,489))},"v-34f5415c":function(){return t.e(11).then(t.bind(null,490))},"v-eb7c4702":function(){return t.e(12).then(t.bind(null,491))},"v-561ee3be":function(){return t.e(13).then(t.bind(null,492))},"v-322966b8":function(){return t.e(14).then(t.bind(null,493))},"v-b7eba09e":function(){return t.e(15).then(t.bind(null,494))},"v-ad8a5978":function(){return t.e(16).then(t.bind(null,495))},"v-1c782489":function(){return t.e(17).then(t.bind(null,496))},"v-823cda28":function(){return t.e(18).then(t.bind(null,497))},"v-26ba5490":function(){return t.e(19).then(t.bind(null,498))},"v-1ea88dca":function(){return t.e(20).then(t.bind(null,499))},"v-60297416":function(){return t.e(21).then(t.bind(null,500))},"v-85fee93c":function(){return t.e(22).then(t.bind(null,501))},"v-745fbaa0":function(){return t.e(23).then(t.bind(null,502))},"v-586b2ff1":function(){return t.e(24).then(t.bind(null,503))},"v-ae61211c":function(){return t.e(25).then(t.bind(null,504))},"v-734f48ea":function(){return t.e(26).then(t.bind(null,505))},"v-96578d08":function(){return t.e(27).then(t.bind(null,506))},"v-506f5fdb":function(){return t.e(28).then(t.bind(null,507))},"v-1febd3ef":function(){return t.e(29).then(t.bind(null,508))},"v-1dc7bf9f":function(){return t.e(30).then(t.bind(null,509))},"v-a8add660":function(){return t.e(31).then(t.bind(null,510))},"v-5e8fbe84":function(){return t.e(32).then(t.bind(null,511))},"v-c8c0c076":function(){return t.e(33).then(t.bind(null,512))},"v-78ffd976":function(){return t.e(34).then(t.bind(null,513))},"v-53104ef6":function(){return t.e(35).then(t.bind(null,514))},"v-1a9d53e5":function(){return t.e(36).then(t.bind(null,515))},"v-150b83f6":function(){return t.e(37).then(t.bind(null,516))},"v-95c08fd2":function(){return t.e(38).then(t.bind(null,517))},"v-77761d97":function(){return t.e(39).then(t.bind(null,518))},"v-a113e2c4":function(){return t.e(40).then(t.bind(null,519))}};function ja(n){var e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}var Ia=/-(\w)/g,Pa=ja((function(n){return n.replace(Ia,(function(n,e){return e?e.toUpperCase():""}))})),za=/\B([A-Z])/g,Da=ja((function(n){return n.replace(za,"-$1").toLowerCase()})),La=ja((function(n){return n.charAt(0).toUpperCase()+n.slice(1)}));function Na(n,e){if(e)return n(e)?n(e):e.includes("-")?n(La(Pa(e))):n(La(e))||n(Da(e))}var Ba=Object.assign({},Aa,Oa),Ra=function(n){return Ba[n]},$a=function(n){return Oa[n]},Ma=function(n){return Aa[n]},Fa=function(n){return Do.component(n)};function Ga(n){return Na($a,n)}function Ua(n){return Na(Ma,n)}function Va(n){return Na(Ra,n)}function Ha(n){return Na(Fa,n)}function qa(){for(var n=arguments.length,e=new Array(n),t=0;t<n;t++)e[t]=arguments[t];return Promise.all(e.filter((function(n){return n})).map(function(){var n=Object(r.a)(regeneratorRuntime.mark((function n(e){var t;return regeneratorRuntime.wrap((function(n){for(;;)switch(n.prev=n.next){case 0:if(Ha(e)||!Va(e)){n.next=5;break}return n.next=3,Va(e)();case 3:t=n.sent,Do.component(e,t.default);case 5:case"end":return n.stop()}}),n)})));return function(e){return n.apply(this,arguments)}}()))}function Xa(n,e){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[n]=e)}var Ja=t(138),Ya=(t(190),t(110),t(54),t(219)),Wa=t.n(Ya),Za=t(220),Ka=t.n(Za),Qa={created:function(){if(this.siteMeta=this.$site.headTags.filter((function(n){return"meta"===Object(Ja.a)(n,1)[0]})).map((function(n){var e=Object(Ja.a)(n,2);e[0];return e[1]})),this.$ssrContext){var n=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(e=n)?e.map((function(n){var e="<meta";return Object.keys(n).forEach((function(t){e+=" ".concat(t,'="').concat(Ka()(n[t]),'"')})),e+">"})).join("\n    "):"",this.$ssrContext.canonicalLink=es(this.$canonicalUrl)}var e},mounted:function(){this.currentMetaTags=Object(Sa.a)(document.querySelectorAll("meta")),this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta:function(){document.title=this.$title,document.documentElement.lang=this.$lang;var n=this.getMergedMetaTags();this.currentMetaTags=ts(n,this.currentMetaTags)},getMergedMetaTags:function(){var n=this.$page.frontmatter.meta||[];return Wa()([{name:"description",content:this.$description}],n,this.siteMeta,rs)},updateCanonicalLink:function(){ns(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",es(this.$canonicalUrl))}},watch:{$page:function(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy:function(){ts(null,this.currentMetaTags),ns()}};function ns(){var n=document.querySelector("link[rel='canonical']");n&&n.remove()}function es(){var n=arguments.length>0&&void 0!==arguments[0]?arguments[0]:"";return n?'<link href="'.concat(n,'" rel="canonical" />'):""}function ts(n,e){if(e&&Object(Sa.a)(e).filter((function(n){return n.parentNode===document.head})).forEach((function(n){return document.head.removeChild(n)})),n)return n.map((function(n){var e=document.createElement("meta");return Object.keys(n).forEach((function(t){e.setAttribute(t,n[t])})),document.head.appendChild(e),e}))}function rs(n){for(var e=0,t=["name","property","itemprop"];e<t.length;e++){var r=t[e];if(n.hasOwnProperty(r))return n[r]+r}return JSON.stringify(n)}t(139);var os=t(152),is={mounted:function(){window.addEventListener("scroll",this.onScroll)},methods:{onScroll:t.n(os)()((function(){this.setActiveHash()}),300),setActiveHash:function(){for(var n=this,e=[].slice.call(document.querySelectorAll(".sidebar-link")),t=[].slice.call(document.querySelectorAll(".header-anchor")).filter((function(n){return e.some((function(e){return e.hash===n.hash}))})),r=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),o=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),i=window.innerHeight+r,a=0;a<t.length;a++){var s=t[a],c=t[a+1],l=0===a&&0===r||r>=s.parentElement.offsetTop+10&&(!c||r<c.parentElement.offsetTop-10),u=decodeURIComponent(this.$route.hash);if(l&&u!==decodeURIComponent(s.hash)){var p=s;if(i===o)for(var d=a+1;d<t.length;d++)if(u===decodeURIComponent(t[d].hash))return;return this.$vuepress.$set("disableScrollBehavior",!0),void this.$router.replace(decodeURIComponent(p.hash),(function(){n.$nextTick((function(){n.$vuepress.$set("disableScrollBehavior",!1)}))}))}}}},beforeDestroy:function(){window.removeEventListener("scroll",this.onScroll)}},as=(t(61),t(101)),ss=t.n(as),cs={mounted:function(){var n=this;ss.a.configure({showSpinner:!1}),this.$router.beforeEach((function(n,e,t){n.path===e.path||Do.component(n.name)||ss.a.start(),t()})),this.$router.afterEach((function(){ss.a.done(),n.isSidebarOpen=!1}))}};t(75),t(43),t(78),t(364);function ls(n,e){if(!(n instanceof e))throw new TypeError("Cannot call a class as a function")}t(99);function us(n,e){for(var t=0;t<e.length;t++){var r=e[t];r.enumerable=r.enumerable||!1,r.configurable=!0,"value"in r&&(r.writable=!0),Object.defineProperty(n,r.key,r)}}function ps(n,e,t){return e&&us(n.prototype,e),t&&us(n,t),Object.defineProperty(n,"prototype",{writable:!1}),n}t(365);var ds=function(){function n(){ls(this,n);this.containerEl=document.getElementById("message-container"),this.containerEl||(this.containerEl=document.createElement("div"),this.containerEl.id="message-container",document.body.appendChild(this.containerEl))}return ps(n,[{key:"show",value:function(n){var e=this,t=n.text,r=void 0===t?"":t,o=n.duration,i=void 0===o?3e3:o,a=document.createElement("div");a.className="message move-in",a.innerHTML='\n      <i style="fill: #06a35a;font-size: 14px;display:inline-flex;align-items: center;">\n        <svg style="fill: #06a35a;font-size: 14px;" t="1572421810237" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2323" width="16" height="16"><path d="M822.811993 824.617989c-83.075838 81.99224-188.546032 124.613757-316.049383 127.86455-122.085362-3.250794-223.943563-45.87231-305.935802-127.86455s-124.613757-184.21164-127.86455-305.935802c3.250794-127.503351 45.87231-232.973545 127.86455-316.049383 81.99224-83.075838 184.21164-126.058554 305.935802-129.309347 127.503351 3.250794 232.973545 46.23351 316.049383 129.309347 83.075838 83.075838 126.058554 188.546032 129.309347 316.049383C949.231746 640.406349 905.887831 742.62575 822.811993 824.617989zM432.716755 684.111464c3.973192 3.973192 8.307584 5.779189 13.364374 6.140388 5.05679 0.361199 9.752381-1.444797 13.364374-5.417989l292.571429-287.514638c3.973192-3.973192 5.779189-8.307584 5.779189-13.364374 0-5.05679-1.805996-9.752381-5.779189-13.364374l1.805996 1.805996c-3.973192-3.973192-8.668783-5.779189-14.086772-6.140388-5.417989-0.361199-10.47478 1.444797-14.809171 5.417989l-264.397884 220.33157c-3.973192 3.250794-8.668783 4.695591-14.447972 4.695591-5.779189 0-10.835979-1.444797-15.53157-3.973192l-94.273016-72.962257c-4.334392-3.250794-9.391182-4.334392-14.447972-3.973192s-9.391182 3.250794-12.641975 7.585185l-2.889594 3.973192c-3.250794 4.334392-4.334392 9.391182-3.973192 14.809171 0.722399 5.417989 2.528395 10.11358 5.779189 14.086772L432.716755 684.111464z" p-id="2324"></path></svg>\n      </i>\n      <div class="text">'.concat(r,"</div>\n    "),this.containerEl.appendChild(a),i>0&&setTimeout((function(){e.close(a)}),i)}},{key:"close",value:function(n){n.className=n.className.replace("move-in",""),n.className+="move-out",n.addEventListener("animationend",(function(){n.remove()}))}}]),n}(),fs={mounted:function(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},updated:function(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},methods:{updateCopy:function(){var n=this;setTimeout((function(){(['div[class*="language-"] pre','div[class*="aside-code"] aside']instanceof Array||Array.isArray(['div[class*="language-"] pre','div[class*="aside-code"] aside']))&&['div[class*="language-"] pre','div[class*="aside-code"] aside'].forEach((function(e){document.querySelectorAll(e).forEach(n.generateCopyButton)}))}),1e3)},generateCopyButton:function(n){var e=this;if(!n.classList.contains("codecopy-enabled")){var t=document.createElement("i");t.className="code-copy",t.innerHTML='<svg  style="color:#aaa;font-size:14px" t="1572422231464" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3201" width="14" height="14"><path d="M866.461538 39.384615H354.461538c-43.323077 0-78.769231 35.446154-78.76923 78.769231v39.384616h472.615384c43.323077 0 78.769231 35.446154 78.769231 78.76923v551.384616h39.384615c43.323077 0 78.769231-35.446154 78.769231-78.769231V118.153846c0-43.323077-35.446154-78.769231-78.769231-78.769231z m-118.153846 275.692308c0-43.323077-35.446154-78.769231-78.76923-78.769231H157.538462c-43.323077 0-78.769231 35.446154-78.769231 78.769231v590.769231c0 43.323077 35.446154 78.769231 78.769231 78.769231h512c43.323077 0 78.769231-35.446154 78.76923-78.769231V315.076923z m-354.461538 137.846154c0 11.815385-7.876923 19.692308-19.692308 19.692308h-157.538461c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h157.538461c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z m157.538461 315.076923c0 11.815385-7.876923 19.692308-19.692307 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h315.076923c11.815385 0 19.692308 7.876923 19.692307 19.692308v39.384615z m78.769231-157.538462c0 11.815385-7.876923 19.692308-19.692308 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h393.846153c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z" p-id="3202"></path></svg>',t.title="Copy to clipboard",t.addEventListener("click",(function(){e.copyToClipboard(n.innerText)})),n.appendChild(t),n.classList.add("codecopy-enabled")}},copyToClipboard:function(n){var e=document.createElement("textarea");e.value=n,e.setAttribute("readonly",""),e.style.position="absolute",e.style.left="-9999px",document.body.appendChild(e);var t=document.getSelection().rangeCount>0&&document.getSelection().getRangeAt(0);e.select(),document.execCommand("copy"),(new ds).show({text:"复制成功",duration:1e3}),document.body.removeChild(e),t&&(document.getSelection().removeAllRanges(),document.getSelection().addRange(t))}}};t(234),t(104),t(103),t(140),t(367);!function(n,e){void 0===e&&(e={});var t=e.insertAt;if(n&&"undefined"!=typeof document){var r=document.head||document.getElementsByTagName("head")[0],o=document.createElement("style");o.type="text/css","top"===t&&r.firstChild?r.insertBefore(o,r.firstChild):r.appendChild(o),o.styleSheet?o.styleSheet.cssText=n:o.appendChild(document.createTextNode(n))}}("@media (max-width: 1000px) {\n  .vuepress-plugin-demo-block__h_code {\n    display: none;\n  }\n  .vuepress-plugin-demo-block__app {\n    margin-left: auto !important;\n    margin-right: auto !important;\n  }\n}\n.vuepress-plugin-demo-block__wrapper {\n  margin-top: 10px;\n  border: 1px solid #ebebeb;\n  border-radius: 4px;\n  transition: all 0.2s;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display {\n  height: 400px;\n  display: flex;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__app {\n  width: 300px;\n  border: 1px solid #ebebeb;\n  box-shadow: 1px 1px 3px #ebebeb;\n  margin-right: 5px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code {\n  flex: 1;\n  overflow: auto;\n  height: 100%;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code > pre {\n  overflow: visible;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  max-height: 400px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper div {\n  box-sizing: border-box;\n}\n.vuepress-plugin-demo-block__wrapper:hover {\n  box-shadow: 0 0 11px rgba(33, 33, 33, 0.2);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code {\n  overflow: hidden;\n  height: 0;\n  padding: 0 !important;\n  background-color: #282c34;\n  border-radius: 0 !important;\n  transition: height 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code pre {\n  margin: 0 !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  padding: 20px;\n  border-bottom: 1px solid #ebebeb;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer {\n  position: relative;\n  text-align: center;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__codepen {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__expand::before {\n  border-top: none;\n  border-right: 6px solid transparent;\n  border-bottom: 6px solid #ccc;\n  border-left: 6px solid transparent;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__codepen,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand span,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand::before {\n  border-top-color: #3eaf7c !important;\n  border-bottom-color: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover svg {\n  fill: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand-text {\n  transition: all 0.5s;\n  opacity: 0;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:nth-last-child(2) {\n  right: 50px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:last-child {\n  right: 10px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button {\n  border-color: transparent;\n  background-color: transparent;\n  font-size: 14px;\n  color: #3eaf7c;\n  cursor: pointer;\n  outline: none;\n  margin: 0;\n  width: 46px;\n  position: relative;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::before {\n  content: attr(data-tip);\n  white-space: nowrap;\n  position: absolute;\n  top: -30px;\n  left: 50%;\n  color: #eee;\n  line-height: 1;\n  z-index: 1000;\n  border-radius: 4px;\n  padding: 6px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  background-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::after {\n  content: '' !important;\n  display: block;\n  position: absolute;\n  left: 50%;\n  top: -5px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  border: 5px solid transparent;\n  border-top-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button svg {\n  width: 34px;\n  height: 20px;\n  fill: #ccc;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__codepen {\n  position: absolute;\n  top: 10px;\n  transition: all 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand {\n  position: relative;\n  width: 100px;\n  height: 40px;\n  margin: 0;\n  color: #3eaf7c;\n  font-size: 14px;\n  background-color: transparent;\n  border-color: transparent;\n  outline: none;\n  transition: all 0.5s;\n  cursor: pointer;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand::before {\n  content: \"\";\n  position: absolute;\n  top: 50%;\n  left: 50%;\n  width: 0;\n  height: 0;\n  border-top: 6px solid #ccc;\n  border-right: 6px solid transparent;\n  border-left: 6px solid transparent;\n  -webkit-transform: translate(-50%, -50%);\n          transform: translate(-50%, -50%);\n}\n");var hs={jsLib:[],cssLib:[],jsfiddle:!0,codepen:!0,codepenLayout:"left",codepenJsProcessor:"babel",codepenEditors:"101",horizontal:!1,vue:"https://cdn.jsdelivr.net/npm/vue/dist/vue.min.js",react:"https://cdn.jsdelivr.net/npm/react/umd/react.production.min.js",reactDOM:"https://cdn.jsdelivr.net/npm/react-dom/umd/react-dom.production.min.js"},ms={},vs=function(n){return'<div id="app">\n'.concat(n,"\n</div>")},gs=function(n){return window.$VUEPRESS_DEMO_BLOCK&&void 0!==window.$VUEPRESS_DEMO_BLOCK[n]?window.$VUEPRESS_DEMO_BLOCK[n]:hs[n]},ys=function n(e,t,r){var o=document.createElement(e);return t&&Object.keys(t).forEach((function(n){if(n.indexOf("data"))o[n]=t[n];else{var e=n.replace("data","");o.dataset[e]=t[n]}})),r&&r.forEach((function(e){var t=e.tag,r=e.attrs,i=e.children;o.appendChild(n(t,r,i))})),o},bs=function(n,e,t){var r,o=(r=n.querySelectorAll(".".concat(e)),Array.prototype.slice.call(r));return 1!==o.length||t?o:o[0]},xs=function(n,e){var t,r,o=n.match(/<style>([\s\S]+)<\/style>/),i=n.match(/<template>([\s\S]+)<\/template>/),a=n.match(/<script>([\s\S]+)<\/script>/),s={css:o&&o[1].replace(/^\n|\n$/g,""),html:i&&i[1].replace(/^\n|\n$/g,""),js:a&&a[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};s.htmlTpl=vs(s.html),s.jsTpl=(t=s.js,r=t.replace(/export\s+default\s*?\{\n*/,"").replace(/\n*\}\s*$/,"").trim(),"new Vue({\n  el: '#app',\n  ".concat(r,"\n})")),s.script=function(n,e){var t=n.split(/export\s+default/),r="(function() {".concat(t[0]," ; return ").concat(t[1],"})()"),o=window.Babel?window.Babel.transform(r,{presets:["es2015"]}).code:r,i=[eval][0](o);return i.template=e,i}(s.js,s.html);var c=gs("vue");return s.jsLib.unshift(c),s},_s=function(n,e){var t,r=n.match(/<style>([\s\S]+)<\/style>/),o=n.match(/<html>([\s\S]+)<\/html>/),i=n.match(/<script>([\s\S]+)<\/script>/),a={css:r&&r[1].replace(/^\n|\n$/g,""),html:o&&o[1].replace(/^\n|\n$/g,""),js:i&&i[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};return a.htmlTpl=a.html,a.jsTpl=a.js,a.script=(t=a.js,window.Babel?window.Babel.transform(t,{presets:["es2015"]}).code:t),a},ws=function(n){return n=n.replace("export default ","").replace(/App\.__style__(\s*)=(\s*)`([\s\S]*)?`/,""),n+='ReactDOM.render(React.createElement(App), document.getElementById("app"))'};function Es(){var n=bs(document,"vuepress-plugin-demo-block__wrapper",!0);n.length?n.forEach((function(n){if("true"!==n.dataset.created){n.style.display="block";var e=bs(n,"vuepress-plugin-demo-block__code"),t=bs(n,"vuepress-plugin-demo-block__display"),r=bs(n,"vuepress-plugin-demo-block__footer"),o=bs(t,"vuepress-plugin-demo-block__app"),i=decodeURIComponent(n.dataset.code),a=decodeURIComponent(n.dataset.config),s=decodeURIComponent(n.dataset.type);a=a?JSON.parse(a):{};var c=e.querySelector("div").clientHeight,l="react"===s?function(n,e){var t=(0,window.Babel.transform)(n,{presets:["es2015","react"]}).code,r="(function(exports){var module={};module.exports=exports;".concat(t,";return module.exports.__esModule?module.exports.default:module.exports;})({})"),o=new Function("return ".concat(r))(),i={js:o,css:o.__style__||"",jsLib:e.jsLib||[],cssLib:e.cssLib||[],jsTpl:ws(n),htmlTpl:vs("")},a=gs("react"),s=gs("reactDOM");return i.jsLib.unshift(a,s),i}(i,a):"vanilla"===s?_s(i,a):xs(i,a),u=ys("button",{className:"".concat("vuepress-plugin-demo-block__expand")});if(r.appendChild(u),u.addEventListener("click",ks.bind(null,u,c,e,r)),gs("jsfiddle")&&r.appendChild(function(n){var e=n.css,t=n.htmlTpl,r=n.jsTpl,o=n.jsLib,i=n.cssLib,a=o.concat(i).concat(gs("cssLib")).concat(gs("jsLib")).join(",");return ys("form",{className:"vuepress-plugin-demo-block__jsfiddle",target:"_blank",action:"https://jsfiddle.net/api/post/library/pure/",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"css",value:e}},{tag:"input",attrs:{type:"hidden",name:"html",value:t}},{tag:"input",attrs:{type:"hidden",name:"js",value:r}},{tag:"input",attrs:{type:"hidden",name:"panel_js",value:3}},{tag:"input",attrs:{type:"hidden",name:"wrap",value:1}},{tag:"input",attrs:{type:"hidden",name:"resources",value:a}},{tag:"button",attrs:{type:"submit",className:"vuepress-plugin-demo-block__button",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088289967" class="icon" style="" viewBox="0 0 1170 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1952" xmlns:xlink="http://www.w3.org/1999/xlink" width="228.515625" height="200"><defs><style type="text/css"></style></defs><path d="M1028.571429 441.142857q63.428571 26.285714 102.571428 83.142857T1170.285714 650.857143q0 93.714286-67.428571 160.285714T940 877.714286q-2.285714 0-6.571429-0.285715t-6-0.285714H232q-97.142857-5.714286-164.571429-71.714286T0 645.142857q0-62.857143 31.428571-116t84-84q-6.857143-22.285714-6.857142-46.857143 0-65.714286 46.857142-112t113.714286-46.285714q54.285714 0 98.285714 33.142857 42.857143-88 127.142858-141.714286t186.571428-53.714285q94.857143 0 174.857143 46T982.571429 248.571429t46.571428 172q0 3.428571-0.285714 10.285714t-0.285714 10.285714zM267.428571 593.142857q0 69.714286 48 110.285714t118.857143 40.571429q78.285714 0 137.142857-56.571429-9.142857-11.428571-27.142857-32.285714T519.428571 626.285714q-38.285714 37.142857-82.285714 37.142857-31.428571 0-53.428571-19.142857T361.714286 594.285714q0-30.285714 22-49.714285t52.285714-19.428572q25.142857 0 48.285714 12t41.714286 31.428572 37.142857 42.857142 39.428572 46.857143 44 42.857143 55.428571 31.428572 69.428571 12q69.142857 0 116.857143-40.857143T936 594.857143q0-69.142857-48-109.714286t-118.285714-40.571428q-81.714286 0-137.714286 55.428571l53.142857 61.714286q37.714286-36.571429 81.142857-36.571429 29.714286 0 52.571429 18.857143t22.857143 48q0 32.571429-21.142857 52.285714t-53.714286 19.714286q-24.571429 0-47.142857-12t-41.142857-31.428571-37.428572-42.857143-39.714286-46.857143-44.285714-42.857143-55.142857-31.428571T434.285714 444.571429q-69.714286 0-118.285714 40.285714T267.428571 593.142857z" p-id="1953"></path></svg>',datatip:"JSFiddle"}}])}(l)),gs("codepen")&&r.appendChild(function(n){var e=n.css,t=n.htmlTpl,r=n.jsTpl,o=n.jsLib,i=n.cssLib,a=JSON.stringify({css:e,html:t,js:r,js_external:o.concat(gs("jsLib")).join(";"),css_external:i.concat(gs("cssLib")).join(";"),layout:gs("codepenLayout"),js_pre_processor:gs("codepenJsProcessor"),editors:gs("codepenEditors")});return ys("form",{className:"vuepress-plugin-demo-block__codepen",target:"_blank",action:"https://codepen.io/pen/define",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"data",value:a}},{tag:"button",attrs:{type:"submit",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088271207" class="icon" style="" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1737" xmlns:xlink="http://www.w3.org/1999/xlink" width="200" height="200"><defs><style type="text/css"></style></defs><path d="M123.428571 668l344.571429 229.714286v-205.142857L277.142857 565.142857z m-35.428571-82.285714l110.285714-73.714286-110.285714-73.714286v147.428572z m468 312l344.571429-229.714286-153.714286-102.857143-190.857143 127.428572v205.142857z m-44-281.714286l155.428571-104-155.428571-104-155.428571 104zM277.142857 458.857143l190.857143-127.428572V126.285714L123.428571 356z m548.571429 53.142857l110.285714 73.714286V438.285714z m-78.857143-53.142857l153.714286-102.857143-344.571429-229.714286v205.142857z m277.142857-102.857143v312q0 23.428571-19.428571 36.571429l-468 312q-12 7.428571-24.571429 7.428571t-24.571429-7.428571L19.428571 704.571429q-19.428571-13.142857-19.428571-36.571429V356q0-23.428571 19.428571-36.571429L487.428571 7.428571q12-7.428571 24.571429-7.428571t24.571429 7.428571l468 312q19.428571 13.142857 19.428571 36.571429z" p-id="1738"></path></svg>',className:"vuepress-plugin-demo-block__button",datatip:"Codepen"}}])}(l)),void 0!==a.horizontal?a.horizontal:gs("horizontal")){n.classList.add("vuepress-plugin-demo-block__horizontal");var p=e.firstChild.cloneNode(!0);p.classList.add("vuepress-plugin-demo-block__h_code"),t.appendChild(p)}if(l.css&&function(n){if(!ms[n]){var e=ys("style",{innerHTML:n});document.body.appendChild(e),ms[n]=!0}}(l.css),"react"===s)ReactDOM.render(React.createElement(l.js),o);else if("vue"===s){var d=(new(Vue.extend(l.script))).$mount();o.appendChild(d.$el)}else"vanilla"===s&&(o.innerHTML=l.html,new Function("return (function(){".concat(l.script,"})()"))());n.dataset.created="true"}})):setTimeout((function(n){Es()}),300)}function ks(n,e,t,r){var o="1"!==n.dataset.isExpand;t.style.height=o?"".concat(e,"px"):0,o?r.classList.add("vuepress-plugin-demo-block__show-link"):r.classList.remove("vuepress-plugin-demo-block__show-link"),n.dataset.isExpand=o?"1":"0"}var Cs={mounted:function(){window.$VUEPRESS_DEMO_BLOCK={jsfiddle:!1,codepen:!0,horizontal:!1},Es()},updated:function(){Es()}},Ts=(t(224),"auto"),Ss="zoom-in",As="zoom-out",Os="grab",js="move";function Is(n,e,t){var r=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],o={passive:!1};r?n.addEventListener(e,t,o):n.removeEventListener(e,t,o)}function Ps(n,e){if(n){var t=new Image;t.onload=function(){e&&e(t)},t.src=n}}function zs(n){return n.dataset.original?n.dataset.original:"A"===n.parentNode.tagName?n.parentNode.getAttribute("href"):null}function Ds(n,e,t){!function(n){var e=Ls,t=Ns;if(n.transition){var r=n.transition;delete n.transition,n[e]=r}if(n.transform){var o=n.transform;delete n.transform,n[t]=o}}(e);var r=n.style,o={};for(var i in e)t&&(o[i]=r[i]||""),r[i]=e[i];return o}var Ls="transition",Ns="transform",Bs="transform",Rs="transitionend";var $s=function(){},Ms={enableGrab:!0,preloadImage:!1,closeOnWindowResize:!0,transitionDuration:.4,transitionTimingFunction:"cubic-bezier(0.4, 0, 0, 1)",bgColor:"rgb(255, 255, 255)",bgOpacity:1,scaleBase:1,scaleExtra:.5,scrollThreshold:40,zIndex:998,customSize:null,onOpen:$s,onClose:$s,onGrab:$s,onMove:$s,onRelease:$s,onBeforeOpen:$s,onBeforeClose:$s,onBeforeGrab:$s,onBeforeRelease:$s,onImageLoading:$s,onImageLoaded:$s},Fs={init:function(n){var e,t;e=this,t=n,Object.getOwnPropertyNames(Object.getPrototypeOf(e)).forEach((function(n){e[n]=e[n].bind(t)}))},click:function(n){if(n.preventDefault(),Us(n))return window.open(this.target.srcOriginal||n.currentTarget.src,"_blank");this.shown?this.released?this.close():this.release():this.open(n.currentTarget)},scroll:function(){var n=document.documentElement||document.body.parentNode||document.body,e=window.pageXOffset||n.scrollLeft,t=window.pageYOffset||n.scrollTop;null===this.lastScrollPosition&&(this.lastScrollPosition={x:e,y:t});var r=this.lastScrollPosition.x-e,o=this.lastScrollPosition.y-t,i=this.options.scrollThreshold;(Math.abs(o)>=i||Math.abs(r)>=i)&&(this.lastScrollPosition=null,this.close())},keydown:function(n){(function(n){return"Escape"===(n.key||n.code)||27===n.keyCode})(n)&&(this.released?this.close():this.release(this.close))},mousedown:function(n){if(Gs(n)&&!Us(n)){n.preventDefault();var e=n.clientX,t=n.clientY;this.pressTimer=setTimeout(function(){this.grab(e,t)}.bind(this),200)}},mousemove:function(n){this.released||this.move(n.clientX,n.clientY)},mouseup:function(n){Gs(n)&&!Us(n)&&(clearTimeout(this.pressTimer),this.released?this.close():this.release())},touchstart:function(n){n.preventDefault();var e=n.touches[0],t=e.clientX,r=e.clientY;this.pressTimer=setTimeout(function(){this.grab(t,r)}.bind(this),200)},touchmove:function(n){if(!this.released){var e=n.touches[0],t=e.clientX,r=e.clientY;this.move(t,r)}},touchend:function(n){(function(n){n.targetTouches.length})(n)||(clearTimeout(this.pressTimer),this.released?this.close():this.release())},clickOverlay:function(){this.close()},resizeWindow:function(){this.close()}};function Gs(n){return 0===n.button}function Us(n){return n.metaKey||n.ctrlKey}var Vs={init:function(n){this.el=document.createElement("div"),this.instance=n,this.parent=document.body,Ds(this.el,{position:"fixed",top:0,left:0,right:0,bottom:0,opacity:0}),this.updateStyle(n.options),Is(this.el,"click",n.handler.clickOverlay.bind(n))},updateStyle:function(n){Ds(this.el,{zIndex:n.zIndex,backgroundColor:n.bgColor,transition:"opacity\n        "+n.transitionDuration+"s\n        "+n.transitionTimingFunction})},insert:function(){this.parent.appendChild(this.el)},remove:function(){this.parent.removeChild(this.el)},fadeIn:function(){this.el.offsetWidth,this.el.style.opacity=this.instance.options.bgOpacity},fadeOut:function(){this.el.style.opacity=0}},Hs="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(n){return typeof n}:function(n){return n&&"function"==typeof Symbol&&n.constructor===Symbol&&n!==Symbol.prototype?"symbol":typeof n},qs=function(){function n(n,e){for(var t=0;t<e.length;t++){var r=e[t];r.enumerable=r.enumerable||!1,r.configurable=!0,"value"in r&&(r.writable=!0),Object.defineProperty(n,r.key,r)}}return function(e,t,r){return t&&n(e.prototype,t),r&&n(e,r),e}}(),Xs=Object.assign||function(n){for(var e=1;e<arguments.length;e++){var t=arguments[e];for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(n[r]=t[r])}return n},Js={init:function(n,e){this.el=n,this.instance=e,this.srcThumbnail=this.el.getAttribute("src"),this.srcset=this.el.getAttribute("srcset"),this.srcOriginal=zs(this.el),this.rect=this.el.getBoundingClientRect(),this.translate=null,this.scale=null,this.styleOpen=null,this.styleClose=null},zoomIn:function(){var n=this.instance.options,e=n.zIndex,t=n.enableGrab,r=n.transitionDuration,o=n.transitionTimingFunction;this.translate=this.calculateTranslate(),this.scale=this.calculateScale(),this.styleOpen={position:"relative",zIndex:e+1,cursor:t?Os:As,transition:Bs+"\n        "+r+"s\n        "+o,transform:"translate3d("+this.translate.x+"px, "+this.translate.y+"px, 0px)\n        scale("+this.scale.x+","+this.scale.y+")",height:this.rect.height+"px",width:this.rect.width+"px"},this.el.offsetWidth,this.styleClose=Ds(this.el,this.styleOpen,!0)},zoomOut:function(){this.el.offsetWidth,Ds(this.el,{transform:"none"})},grab:function(n,e,t){var r=Ys(),o=r.x-n,i=r.y-e;Ds(this.el,{cursor:js,transform:"translate3d(\n        "+(this.translate.x+o)+"px, "+(this.translate.y+i)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},move:function(n,e,t){var r=Ys(),o=r.x-n,i=r.y-e;Ds(this.el,{transition:Bs,transform:"translate3d(\n        "+(this.translate.x+o)+"px, "+(this.translate.y+i)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},restoreCloseStyle:function(){Ds(this.el,this.styleClose)},restoreOpenStyle:function(){Ds(this.el,this.styleOpen)},upgradeSource:function(){if(this.srcOriginal){var n=this.el.parentNode;this.srcset&&this.el.removeAttribute("srcset");var e=this.el.cloneNode(!1);e.setAttribute("src",this.srcOriginal),e.style.position="fixed",e.style.visibility="hidden",n.appendChild(e),setTimeout(function(){this.el.setAttribute("src",this.srcOriginal),n.removeChild(e)}.bind(this),50)}},downgradeSource:function(){this.srcOriginal&&(this.srcset&&this.el.setAttribute("srcset",this.srcset),this.el.setAttribute("src",this.srcThumbnail))},calculateTranslate:function(){var n=Ys(),e=this.rect.left+this.rect.width/2,t=this.rect.top+this.rect.height/2;return{x:n.x-e,y:n.y-t}},calculateScale:function(){var n=this.el.dataset,e=n.zoomingHeight,t=n.zoomingWidth,r=this.instance.options,o=r.customSize,i=r.scaleBase;if(!o&&e&&t)return{x:t/this.rect.width,y:e/this.rect.height};if(o&&"object"===(void 0===o?"undefined":Hs(o)))return{x:o.width/this.rect.width,y:o.height/this.rect.height};var a=this.rect.width/2,s=this.rect.height/2,c=Ys(),l={x:c.x-a,y:c.y-s},u=l.x/a,p=l.y/s,d=i+Math.min(u,p);if(o&&"string"==typeof o){var f=t||this.el.naturalWidth,h=e||this.el.naturalHeight,m=parseFloat(o)*f/(100*this.rect.width),v=parseFloat(o)*h/(100*this.rect.height);if(d>m||d>v)return{x:m,y:v}}return{x:d,y:d}}};function Ys(){var n=document.documentElement;return{x:Math.min(n.clientWidth,window.innerWidth)/2,y:Math.min(n.clientHeight,window.innerHeight)/2}}function Ws(n,e,t){["mousedown","mousemove","mouseup","touchstart","touchmove","touchend"].forEach((function(r){Is(n,r,e[r],t)}))}var Zs=function(){function n(e){!function(n,e){if(!(n instanceof e))throw new TypeError("Cannot call a class as a function")}(this,n),this.target=Object.create(Js),this.overlay=Object.create(Vs),this.handler=Object.create(Fs),this.body=document.body,this.shown=!1,this.lock=!1,this.released=!0,this.lastScrollPosition=null,this.pressTimer=null,this.options=Xs({},Ms,e),this.overlay.init(this),this.handler.init(this)}return qs(n,[{key:"listen",value:function(n){if("string"==typeof n)for(var e=document.querySelectorAll(n),t=e.length;t--;)this.listen(e[t]);else"IMG"===n.tagName&&(n.style.cursor=Ss,Is(n,"click",this.handler.click),this.options.preloadImage&&Ps(zs(n)));return this}},{key:"config",value:function(n){return n?(Xs(this.options,n),this.overlay.updateStyle(this.options),this):this.options}},{key:"open",value:function(n){var e=this,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.options.onOpen;if(!this.shown&&!this.lock){var r="string"==typeof n?document.querySelector(n):n;if("IMG"===r.tagName){if(this.options.onBeforeOpen(r),this.target.init(r,this),!this.options.preloadImage){var o=this.target.srcOriginal;null!=o&&(this.options.onImageLoading(r),Ps(o,this.options.onImageLoaded))}this.shown=!0,this.lock=!0,this.target.zoomIn(),this.overlay.insert(),this.overlay.fadeIn(),Is(document,"scroll",this.handler.scroll),Is(document,"keydown",this.handler.keydown),this.options.closeOnWindowResize&&Is(window,"resize",this.handler.resizeWindow);var i=function n(){Is(r,Rs,n,!1),e.lock=!1,e.target.upgradeSource(),e.options.enableGrab&&Ws(document,e.handler,!0),t(r)};return Is(r,Rs,i),this}}}},{key:"close",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onClose;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeClose(t),this.lock=!0,this.body.style.cursor=Ts,this.overlay.fadeOut(),this.target.zoomOut(),Is(document,"scroll",this.handler.scroll,!1),Is(document,"keydown",this.handler.keydown,!1),this.options.closeOnWindowResize&&Is(window,"resize",this.handler.resizeWindow,!1);var r=function r(){Is(t,Rs,r,!1),n.shown=!1,n.lock=!1,n.target.downgradeSource(),n.options.enableGrab&&Ws(document,n.handler,!1),n.target.restoreCloseStyle(),n.overlay.remove(),e(t)};return Is(t,Rs,r),this}}},{key:"grab",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onGrab;if(this.shown&&!this.lock){var o=this.target.el;this.options.onBeforeGrab(o),this.released=!1,this.target.grab(n,e,t);var i=function n(){Is(o,Rs,n,!1),r(o)};return Is(o,Rs,i),this}}},{key:"move",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onMove;if(this.shown&&!this.lock){this.released=!1,this.body.style.cursor=js,this.target.move(n,e,t);var o=this.target.el,i=function n(){Is(o,Rs,n,!1),r(o)};return Is(o,Rs,i),this}}},{key:"release",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onRelease;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeRelease(t),this.lock=!0,this.body.style.cursor=Ts,this.target.restoreOpenStyle();var r=function r(){Is(t,Rs,r,!1),n.lock=!1,n.released=!0,e(t)};return Is(t,Rs,r),this}}}]),n}(),Ks=".theme-vdoing-content img:not(.no-zoom)",Qs=JSON.parse('{"bgColor":"rgba(0,0,0,0.6)"}'),nc=Number("500"),ec=function(){function n(){ls(this,n),this.instance=new Zs(Qs)}return ps(n,[{key:"update",value:function(){var n=arguments.length>0&&void 0!==arguments[0]?arguments[0]:Ks;"undefined"!=typeof window&&this.instance.listen(n)}},{key:"updateDelay",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:Ks,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:nc;setTimeout((function(){return n.update(e)}),t)}}]),n}(),tc=[Qa,is,cs,fs,Cs,{watch:{"$page.path":function(){void 0!==this.$vuepress.zooming&&this.$vuepress.zooming.updateDelay()}},mounted:function(){this.$vuepress.zooming=new ec,this.$vuepress.zooming.updateDelay()}}],rc={name:"GlobalLayout",computed:{layout:function(){var n=this.getLayout();return Xa("layout",n),Do.component(n)}},methods:{getLayout:function(){if(this.$page.path){var n=this.$page.frontmatter.layout;return n&&(this.$vuepress.getLayoutAsyncComponent(n)||this.$vuepress.getVueComponent(n))?n:"Layout"}return"NotFound"}}},oc=t(15),ic=Object(oc.a)(rc,(function(){var n=this.$createElement;return(this._self._c||n)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(n,e,t){var r;switch(e){case"components":n[e]||(n[e]={}),Object.assign(n[e],t);break;case"mixins":n[e]||(n[e]=[]),(r=n[e]).push.apply(r,Object(Sa.a)(t));break;default:throw new Error("Unknown option name.")}}(ic,"mixins",tc);var ac=[{name:"v-63408d9b",path:"/theory/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-63408d9b").then(t)}},{path:"/theory/index.html",redirect:"/theory/"},{path:"/00.目录页/01.理论.html",redirect:"/theory/"},{name:"v-59531294",path:"/practice/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-59531294").then(t)}},{path:"/practice/index.html",redirect:"/practice/"},{path:"/00.目录页/02.实践.html",redirect:"/practice/"},{name:"v-36f91442",path:"/hardware/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-36f91442").then(t)}},{path:"/hardware/index.html",redirect:"/hardware/"},{path:"/00.目录页/03.硬件.html",redirect:"/hardware/"},{name:"v-16a60614",path:"/software/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-16a60614").then(t)}},{path:"/software/index.html",redirect:"/software/"},{path:"/00.目录页/04.软件.html",redirect:"/software/"},{name:"v-e7d501c2",path:"/other/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-e7d501c2").then(t)}},{path:"/other/index.html",redirect:"/other/"},{path:"/00.目录页/05.其它.html",redirect:"/other/"},{name:"v-7eee78b8",path:"/write/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-7eee78b8").then(t)}},{path:"/write/index.html",redirect:"/write/"},{path:"/00.目录页/06.随笔.html",redirect:"/write/"},{name:"v-34f5415c",path:"/about/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-34f5415c").then(t)}},{path:"/about/index.html",redirect:"/about/"},{path:"/00.目录页/07.关于.html",redirect:"/about/"},{name:"v-eb7c4702",path:"/pages/baed3f/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-eb7c4702").then(t)}},{path:"/pages/baed3f/index.html",redirect:"/pages/baed3f/"},{path:"/00.目录页/09.实践/01.动手学深度学习.html",redirect:"/pages/baed3f/"},{name:"v-561ee3be",path:"/pages/4b2e49/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-561ee3be").then(t)}},{path:"/pages/4b2e49/index.html",redirect:"/pages/4b2e49/"},{path:"/00.目录页/09.实践/10.github.html",redirect:"/pages/4b2e49/"},{name:"v-322966b8",path:"/pages/9c32e1/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-322966b8").then(t)}},{path:"/pages/9c32e1/index.html",redirect:"/pages/9c32e1/"},{path:"/00.目录页/09.实践/20.Linux.html",redirect:"/pages/9c32e1/"},{name:"v-b7eba09e",path:"/pages/e22df7/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-b7eba09e").then(t)}},{path:"/pages/e22df7/index.html",redirect:"/pages/e22df7/"},{path:"/00.目录页/12.其他/01.论文.html",redirect:"/pages/e22df7/"},{name:"v-ad8a5978",path:"/pages/ffedf7/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-ad8a5978").then(t)}},{path:"/pages/ffedf7/index.html",redirect:"/pages/ffedf7/"},{path:"/00.目录页/12.其他/10.碎片.html",redirect:"/pages/ffedf7/"},{name:"v-1c782489",path:"/pages/bcceec/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-1c782489").then(t)}},{path:"/pages/bcceec/index.html",redirect:"/pages/bcceec/"},{path:"/01.理论/02.深度学习/01.动手学深度学习/01.Dive into Deep Learning.html",redirect:"/pages/bcceec/"},{name:"v-823cda28",path:"/pages/6ca4c7/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-823cda28").then(t)}},{path:"/pages/6ca4c7/index.html",redirect:"/pages/6ca4c7/"},{path:"/01.理论/02.深度学习/01.动手学深度学习/02.222.html",redirect:"/pages/6ca4c7/"},{name:"v-26ba5490",path:"/pages/aef4fc1/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-26ba5490").then(t)}},{path:"/pages/aef4fc1/index.html",redirect:"/pages/aef4fc1/"},{path:"/01.理论/10.index.html",redirect:"/pages/aef4fc1/"},{name:"v-1ea88dca",path:"/pages/3c32a32/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-1ea88dca").then(t)}},{path:"/pages/3c32a32/index.html",redirect:"/pages/3c32a32/"},{path:"/01.理论/20.第2级/01.第3级/02.4.html",redirect:"/pages/3c32a32/"},{name:"v-60297416",path:"/pages/3c32a31/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-60297416").then(t)}},{path:"/pages/3c32a31/index.html",redirect:"/pages/3c32a31/"},{path:"/01.理论/20.第2级/02.3.html",redirect:"/pages/3c32a31/"},{name:"v-85fee93c",path:"/pages/def99f/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-85fee93c").then(t)}},{path:"/pages/def99f/index.html",redirect:"/pages/def99f/"},{path:"/02.实践/01.动手学深度学习/01.课程安排.html",redirect:"/pages/def99f/"},{name:"v-745fbaa0",path:"/pages/3245f5/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-745fbaa0").then(t)}},{path:"/pages/3245f5/index.html",redirect:"/pages/3245f5/"},{path:"/02.实践/01.动手学深度学习/02.基础.html",redirect:"/pages/3245f5/"},{name:"v-586b2ff1",path:"/pages/4fa3d9/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-586b2ff1").then(t)}},{path:"/pages/4fa3d9/index.html",redirect:"/pages/4fa3d9/"},{path:"/02.实践/01.动手学深度学习/03.线性代数.html",redirect:"/pages/4fa3d9/"},{name:"v-ae61211c",path:"/pages/b0b256/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-ae61211c").then(t)}},{path:"/pages/b0b256/index.html",redirect:"/pages/b0b256/"},{path:"/02.实践/01.动手学深度学习/100.blog_test.html",redirect:"/pages/b0b256/"},{name:"v-734f48ea",path:"/pages/7c03e3/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-734f48ea").then(t)}},{path:"/pages/7c03e3/index.html",redirect:"/pages/7c03e3/"},{path:"/02.实践/10.Github/01.快速入门/01.Hello World.html",redirect:"/pages/7c03e3/"},{name:"v-96578d08",path:"/pages/018bc3/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-96578d08").then(t)}},{path:"/pages/018bc3/index.html",redirect:"/pages/018bc3/"},{path:"/02.实践/10.Github/01.快速入门/02.设置Git.html",redirect:"/pages/018bc3/"},{name:"v-506f5fdb",path:"/pages/35e538/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-506f5fdb").then(t)}},{path:"/pages/35e538/index.html",redirect:"/pages/35e538/"},{path:"/02.实践/20.Linux/01.简介和安装.html",redirect:"/pages/35e538/"},{name:"v-1febd3ef",path:"/pages/2d796d/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-1febd3ef").then(t)}},{path:"/pages/2d796d/index.html",redirect:"/pages/2d796d/"},{path:"/04.软件/01.Mobaxterm.html",redirect:"/pages/2d796d/"},{name:"v-1dc7bf9f",path:"/pages/aa7af1/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-1dc7bf9f").then(t)}},{path:"/pages/aa7af1/index.html",redirect:"/pages/aa7af1/"},{path:"/04.软件/10.Everything.html",redirect:"/pages/aa7af1/"},{name:"v-a8add660",path:"/pages/24a19d/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-a8add660").then(t)}},{path:"/pages/24a19d/index.html",redirect:"/pages/24a19d/"},{path:"/05.其它/01.论文/01.综述/01.用于显著和特定类别的目标检测的先进的深度学习技术.html",redirect:"/pages/24a19d/"},{name:"v-5e8fbe84",path:"/pages/fd6171/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-5e8fbe84").then(t)}},{path:"/pages/fd6171/index.html",redirect:"/pages/fd6171/"},{path:"/05.其它/01.论文/01.综述/10.test.html",redirect:"/pages/fd6171/"},{name:"v-c8c0c076",path:"/pages/c03dcc/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-c8c0c076").then(t)}},{path:"/pages/c03dcc/index.html",redirect:"/pages/c03dcc/"},{path:"/05.其它/01.论文/10.CV论文期刊介绍.html",redirect:"/pages/c03dcc/"},{name:"v-78ffd976",path:"/pages/cd64f7/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-78ffd976").then(t)}},{path:"/pages/cd64f7/index.html",redirect:"/pages/cd64f7/"},{path:"/05.其它/10.碎片/01.什么是自底向上自上而下的显著性目标检测.html",redirect:"/pages/cd64f7/"},{name:"v-53104ef6",path:"/archives/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-53104ef6").then(t)}},{path:"/archives/index.html",redirect:"/archives/"},{path:"/@pages/archivesPage.html",redirect:"/archives/"},{name:"v-1a9d53e5",path:"/categories/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-1a9d53e5").then(t)}},{path:"/categories/index.html",redirect:"/categories/"},{path:"/@pages/categoriesPage.html",redirect:"/categories/"},{name:"v-150b83f6",path:"/tags/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-150b83f6").then(t)}},{path:"/tags/index.html",redirect:"/tags/"},{path:"/@pages/tagsPage.html",redirect:"/tags/"},{name:"v-95c08fd2",path:"/pages/f2e63f/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-95c08fd2").then(t)}},{path:"/pages/f2e63f/index.html",redirect:"/pages/f2e63f/"},{path:"/_posts/随笔/你知道的越多，不知道的也就越多.html",redirect:"/pages/f2e63f/"},{name:"v-77761d97",path:"/pages/cd8bde/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-77761d97").then(t)}},{path:"/pages/cd8bde/index.html",redirect:"/pages/cd8bde/"},{path:"/_posts/随笔/拥抱生活，拥抱快乐.html",redirect:"/pages/cd8bde/"},{name:"v-a113e2c4",path:"/",component:ic,beforeEnter:function(n,e,t){qa("Layout","v-a113e2c4").then(t)}},{path:"/index.html",redirect:"/"},{path:"*",component:ic}],sc={title:"",description:"",base:"/",headTags:[["link",{rel:"icon",href:"/img/logo.ico"}],["meta",{name:"keywords",content:"随便写写"}],["meta",{name:"baidu-site-verification",content:"7F55weZDDc"}],["meta",{name:"theme-color",content:"#11a8cd"}]],pages:[{title:"理论",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"01.理论",imgUrl:"/img/theory.png",description:"基础知识"}},title:"理论",date:"2022-01-23T21:50:53.000Z",sidebar:!1,article:!1,comment:!1,editLink:!1,permalink:"/theory"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/01.%E7%90%86%E8%AE%BA.html",relativePath:"00.目录页/01.理论.md",key:"v-63408d9b",path:"/theory/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/01/23, 15:18:17",lastUpdatedTimestamp:1642922297e3},{title:"实践",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"02.实践",imgUrl:"/img/practice.png",description:"用代码来验证"}},title:"实践",date:"2022-01-23T21:50:54.000Z",sidebar:!1,article:!1,comment:!1,editLink:!1,permalink:"/practice"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/02.%E5%AE%9E%E8%B7%B5.html",relativePath:"00.目录页/02.实践.md",key:"v-59531294",path:"/practice/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/01/25, 00:33:13",lastUpdatedTimestamp:1643041993e3},{title:"硬件",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"03.硬件",imgUrl:"/img/hardware.png",description:"软件的基础是硬件"}},title:"硬件",date:"2022-01-23T21:50:56.000Z",sidebar:!1,article:!1,comment:!1,editLink:!1,permalink:"/hardware"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/03.%E7%A1%AC%E4%BB%B6.html",relativePath:"00.目录页/03.硬件.md",key:"v-36f91442",path:"/hardware/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/02/25, 10:57:13",lastUpdatedTimestamp:1645757833e3},{title:"软件",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"04.软件",imgUrl:"/img/software.png",description:"硬件的灵魂是软件"}},title:"软件",date:"2022-01-23T21:50:56.000Z",sidebar:!1,article:!1,comment:!1,editLink:!1,permalink:"/software"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/04.%E8%BD%AF%E4%BB%B6.html",relativePath:"00.目录页/04.软件.md",key:"v-16a60614",path:"/software/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/02/25, 10:57:13",lastUpdatedTimestamp:1645757833e3},{title:"其它",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"05.其它",imgUrl:"/img/other.png",description:"杂七杂八的东西"}},title:"其它",date:"2022-01-23T21:50:56.000Z",sidebar:!1,article:!1,comment:!1,editLink:!1,permalink:"/other"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/05.%E5%85%B6%E5%AE%83.html",relativePath:"00.目录页/05.其它.md",key:"v-e7d501c2",path:"/other/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/02/25, 10:57:13",lastUpdatedTimestamp:1645757833e3},{title:"随笔",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"06.随笔",imgUrl:"/img/write.png",description:"想写什么就写什么"}},title:"随笔",date:"2020-03-11T21:50:55.000Z",sidebar:!1,article:!1,comment:!1,editLink:!1,permalink:"/write"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/06.%E9%9A%8F%E7%AC%94.html",relativePath:"00.目录页/06.随笔.md",key:"v-7eee78b8",path:"/write/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/02/25, 10:57:13",lastUpdatedTimestamp:1645757833e3},{title:"关于",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"07.关于",imgUrl:"/img/about.png",description:"简单的介绍"}},title:"关于",date:"2022-01-23T21:50:56.000Z",sidebar:!1,article:!1,comment:!1,editLink:!1,permalink:"/about"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/07.%E5%85%B3%E4%BA%8E.html",relativePath:"00.目录页/07.关于.md",key:"v-34f5415c",path:"/about/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/02/25, 10:57:13",lastUpdatedTimestamp:1645757833e3},{title:"动手学深度学习",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"02.实践/01.动手学深度学习",imgUrl:"/img/practice.png",description:"Dive into Deep Learning"}},title:"动手学深度学习",date:"2022-02-03T21:50:53.000Z",sidebar:!1,article:!1,comment:!1,editLink:!1,permalink:"/pages/baed3f/"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/09.%E5%AE%9E%E8%B7%B5/01.%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0.html",relativePath:"00.目录页/09.实践/01.动手学深度学习.md",key:"v-eb7c4702",path:"/pages/baed3f/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/02/25, 11:28:41",lastUpdatedTimestamp:1645759721e3},{title:"Github",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"02.实践/10.Github",imgUrl:"/img/practice.png",description:"“学习”项目的好工具"}},title:"Github",date:"2022-02-07T15:25:53.000Z",sidebar:!1,article:!1,comment:!1,editLink:!1,permalink:"/pages/4b2e49/"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/09.%E5%AE%9E%E8%B7%B5/10.github.html",relativePath:"00.目录页/09.实践/10.github.md",key:"v-561ee3be",path:"/pages/4b2e49/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/02/25, 11:28:41",lastUpdatedTimestamp:1645759721e3},{title:"Github",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"02.实践/20.Linux",imgUrl:"/img/practice.png",description:"“学习”项目的好工具"}},title:"Github",date:"2022-02-07T15:25:53.000Z",sidebar:!1,article:!1,comment:!1,editLink:!1,permalink:"/pages/9c32e1/"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/09.%E5%AE%9E%E8%B7%B5/20.Linux.html",relativePath:"00.目录页/09.实践/20.Linux.md",key:"v-322966b8",path:"/pages/9c32e1/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/02/25, 11:28:41",lastUpdatedTimestamp:1645759721e3},{title:"论文",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"05.其它/01.论文",imgUrl:"/img/other.png",description:"论文分析"}},title:"论文",date:"2022-01-23T21:50:53.000Z",sidebar:!1,article:!1,comment:!1,editLink:!1,permalink:"/pages/e22df7/"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/12.%E5%85%B6%E4%BB%96/01.%E8%AE%BA%E6%96%87.html",relativePath:"00.目录页/12.其他/01.论文.md",key:"v-b7eba09e",path:"/pages/e22df7/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/02/25, 11:28:41",lastUpdatedTimestamp:1645759721e3},{title:"碎片",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"05.其它/10.碎片",imgUrl:"/img/other.png",description:"散乱的知识点"}},title:"碎片",date:"2022-01-23T21:50:53.000Z",sidebar:!1,article:!1,comment:!1,editLink:!1,permalink:"/pages/ffedf7/"},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/12.%E5%85%B6%E4%BB%96/10.%E7%A2%8E%E7%89%87.html",relativePath:"00.目录页/12.其他/10.碎片.md",key:"v-ad8a5978",path:"/pages/ffedf7/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/02/25, 11:28:41",lastUpdatedTimestamp:1645759721e3},{title:"Dive into Deep Learning",frontmatter:{title:"Dive into Deep Learning",date:"2022-01-23T14:42:15.000Z",permalink:"/pages/bcceec/",categories:["理论","人工智能","深度学习"],tags:[null]},regularPath:"/01.%E7%90%86%E8%AE%BA/02.%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/01.%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/01.Dive%20into%20Deep%20Learning.html",relativePath:"01.理论/02.深度学习/01.动手学深度学习/01.Dive into Deep Learning.md",key:"v-1c782489",path:"/pages/bcceec/",headers:[{level:3,title:"目标",slug:"目标",normalizedTitle:"目标",charIndex:13},{level:3,title:"内容",slug:"内容",normalizedTitle:"内容",charIndex:149},{level:2,title:"资源",slug:"资源",normalizedTitle:"资源",charIndex:411},{level:2,title:"数据操作",slug:"数据操作",normalizedTitle:"数据操作",charIndex:592},{level:3,title:"N维数组",slug:"n维数组",normalizedTitle:"n维数组",charIndex:614},{level:3,title:"创建数组",slug:"创建数组",normalizedTitle:"创建数组",charIndex:648},{level:3,title:"访问元素",slug:"访问元素",normalizedTitle:"访问元素",charIndex:752},{level:3,title:"张量",slug:"张量",normalizedTitle:"张量",charIndex:761},{level:3,title:"运算符",slug:"运算符",normalizedTitle:"运算符",charIndex:2777},{level:3,title:"广播机制",slug:"广播机制",normalizedTitle:"广播机制",charIndex:4734},{level:3,title:"索引和切片",slug:"索引和切片",normalizedTitle:"索引和切片",charIndex:5266},{level:3,title:"节省内存",slug:"节省内存",normalizedTitle:"节省内存",charIndex:5899},{level:3,title:"转换为其他Python对象",slug:"转换为其他python对象",normalizedTitle:"转换为其他python对象",charIndex:6947},{level:2,title:"预处理",slug:"预处理",normalizedTitle:"预处理",charIndex:597},{level:3,title:"读取数据集",slug:"读取数据集",normalizedTitle:"读取数据集",charIndex:7410},{level:3,title:"处理缺失值",slug:"处理缺失值",normalizedTitle:"处理缺失值",charIndex:8366},{level:3,title:"转换为张量格式",slug:"转换为张量格式",normalizedTitle:"转换为张量格式",charIndex:9131},{level:2,title:"向量",slug:"向量",normalizedTitle:"向量",charIndex:807},{level:2,title:"矩阵",slug:"矩阵",normalizedTitle:"矩阵",charIndex:674},{level:3,title:"范数",slug:"范数",normalizedTitle:"范数",charIndex:9348},{level:2,title:"特殊矩阵",slug:"特殊矩阵",normalizedTitle:"特殊矩阵",charIndex:9707},{level:2,title:"特征向量和特征值",slug:"特征向量和特征值",normalizedTitle:"特征向量和特征值",charIndex:9956},{level:2,title:"linear-algebra代码",slug:"linear-algebra代码",normalizedTitle:"linear-algebra代码",charIndex:10045},{level:3,title:"标量",slug:"标量",normalizedTitle:"标量",charIndex:1143},{level:3,title:"向量",slug:"向量-2",normalizedTitle:"向量",charIndex:807},{level:3,title:"长度、维度和形状",slug:"长度、维度和形状",normalizedTitle:"长度、维度和形状",charIndex:10404},{level:3,title:"矩阵",slug:"矩阵-2",normalizedTitle:"矩阵",charIndex:674},{level:3,title:"张量",slug:"张量-2",normalizedTitle:"张量",charIndex:761},{level:3,title:"降维",slug:"降维",normalizedTitle:"降维",charIndex:11662},{level:3,title:"非降维求和",slug:"非降维求和",normalizedTitle:"非降维求和",charIndex:12700},{level:3,title:"点积（Dot Product）",slug:"点积-dot-product",normalizedTitle:"点积（dot product）",charIndex:13085},{level:3,title:"矩阵-向量积",slug:"矩阵-向量积",normalizedTitle:"矩阵-向量积",charIndex:13624},{level:3,title:"矩阵-矩阵乘法",slug:"矩阵-矩阵乘法",normalizedTitle:"矩阵-矩阵乘法",charIndex:14196},{level:3,title:"范数",slug:"范数-2",normalizedTitle:"范数",charIndex:9348},{level:3,title:"More",slug:"more",normalizedTitle:"more",charIndex:15893},{level:2,title:"矩阵计算",slug:"矩阵计算",normalizedTitle:"矩阵计算",charIndex:16037},{level:3,title:"标量导数",slug:"标量导数",normalizedTitle:"标量导数",charIndex:16046},{level:3,title:"亚导数",slug:"亚导数",normalizedTitle:"亚导数",charIndex:16082},{level:3,title:"梯度",slug:"梯度",normalizedTitle:"梯度",charIndex:16115},{level:3,title:"标量对向量求导",slug:"标量对向量求导",normalizedTitle:"标量对向量求导",charIndex:16182},{level:3,title:"分子布局与分母布局",slug:"分子布局与分母布局",normalizedTitle:"分子布局与分母布局",charIndex:16471},{level:2,title:"自动求导",slug:"自动求导",normalizedTitle:"自动求导",charIndex:16709},{level:3,title:"链式法则",slug:"链式法则",normalizedTitle:"链式法则",charIndex:16803},{level:3,title:"自动求导",slug:"自动求导-2",normalizedTitle:"自动求导",charIndex:16709},{level:3,title:"计算图",slug:"计算图",normalizedTitle:"计算图",charIndex:16938},{level:3,title:"autograd代码",slug:"autograd代码",normalizedTitle:"autograd代码",charIndex:17577},{level:2,title:"房价预测模型",slug:"房价预测模型",normalizedTitle:"房价预测模型",charIndex:20412},{level:2,title:"线性模型",slug:"线性模型",normalizedTitle:"线性模型",charIndex:20425},{level:2,title:"衡量预估质量",slug:"衡量预估质量",normalizedTitle:"衡量预估质量",charIndex:20469},{level:2,title:"训练数据",slug:"训练数据",normalizedTitle:"训练数据",charIndex:20480},{level:2,title:"参数学习",slug:"参数学习",normalizedTitle:"参数学习",charIndex:20514},{level:2,title:"显示解",slug:"显示解",normalizedTitle:"显示解",charIndex:20523},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:20531},{level:2,title:"生成数据集",slug:"生成数据集",normalizedTitle:"生成数据集",charIndex:20899},{level:2,title:"读取数据集",slug:"读取数据集-2",normalizedTitle:"读取数据集",charIndex:7410},{level:2,title:"初始化模型参数",slug:"初始化模型参数",normalizedTitle:"初始化模型参数",charIndex:23308},{level:2,title:"定义模型",slug:"定义模型",normalizedTitle:"定义模型",charIndex:20756},{level:2,title:"定义损失函数",slug:"定义损失函数",normalizedTitle:"定义损失函数",charIndex:20767},{level:2,title:"定义优化算法",slug:"定义优化算法",normalizedTitle:"定义优化算法",charIndex:24167},{level:2,title:"训练",slug:"训练",normalizedTitle:"训练",charIndex:18880},{level:2,title:"生成数据集",slug:"生成数据集-2",normalizedTitle:"生成数据集",charIndex:20899},{level:2,title:"读取数据集",slug:"读取数据集-3",normalizedTitle:"读取数据集",charIndex:7410},{level:2,title:"定义模型",slug:"定义模型-2",normalizedTitle:"定义模型",charIndex:20756},{level:2,title:"初始化模型参数",slug:"初始化模型参数-2",normalizedTitle:"初始化模型参数",charIndex:23308},{level:2,title:"定义损失函数",slug:"定义损失函数-2",normalizedTitle:"定义损失函数",charIndex:20767},{level:2,title:"定义优化算法",slug:"定义优化算法-2",normalizedTitle:"定义优化算法",charIndex:24167},{level:2,title:"训练",slug:"训练-2",normalizedTitle:"训练",charIndex:18880},{level:2,title:"小结",slug:"小结",normalizedTitle:"小结",charIndex:29147},{level:2,title:"梯度下降",slug:"梯度下降",normalizedTitle:"梯度下降",charIndex:20663},{level:2,title:"选择学习率",slug:"选择学习率",normalizedTitle:"选择学习率",charIndex:29290},{level:2,title:"小批量随机梯度下降",slug:"小批量随机梯度下降",normalizedTitle:"小批量随机梯度下降",charIndex:20658},{level:2,title:"选择批量大小",slug:"选择批量大小",normalizedTitle:"选择批量大小",charIndex:29314},{level:2,title:"总结",slug:"总结-2",normalizedTitle:"总结",charIndex:20531},{level:2,title:"L2损失 均方损失",slug:"l2损失-均方损失",normalizedTitle:"l2损失 均方损失",charIndex:29413},{level:2,title:"L1 Loss 绝对值损失函数",slug:"l1-loss-绝对值损失函数",normalizedTitle:"l1 loss 绝对值损失函数",charIndex:29431},{level:2,title:"Huber' s Robust Loss",slug:"huber-s-robust-loss",normalizedTitle:"huber' s robust loss",charIndex:29556},{level:2,title:"回归vs分类",slug:"回归vs分类",normalizedTitle:"回归vs分类",charIndex:29631},{level:2,title:"从回归到多类分类",slug:"从回归到多类分类",normalizedTitle:"从回归到多类分类",charIndex:29676},{level:2,title:"步骤",slug:"步骤",normalizedTitle:"步骤",charIndex:17199},{level:2,title:"无校验比例",slug:"无校验比例",normalizedTitle:"无校验比例",charIndex:29700},{level:2,title:"校验比例 softmax",slug:"校验比例-softmax",normalizedTitle:"校验比例 softmax",charIndex:29712},{level:2,title:"交叉熵损失",slug:"交叉熵损失",normalizedTitle:"交叉熵损失",charIndex:29731},{level:2,title:"总结",slug:"总结-3",normalizedTitle:"总结",charIndex:20531},{level:2,title:"读取数据集",slug:"读取数据集-4",normalizedTitle:"读取数据集",charIndex:7410},{level:2,title:"读取小批量",slug:"读取小批量",normalizedTitle:"读取小批量",charIndex:32051},{level:2,title:"整合所有组件",slug:"整合所有组件",normalizedTitle:"整合所有组件",charIndex:32549},{level:2,title:"小结",slug:"小结-2",normalizedTitle:"小结",charIndex:29147}],headersStr:"目标 内容 资源 数据操作 N维数组 创建数组 访问元素 张量 运算符 广播机制 索引和切片 节省内存 转换为其他Python对象 预处理 读取数据集 处理缺失值 转换为张量格式 向量 矩阵 范数 特殊矩阵 特征向量和特征值 linear-algebra代码 标量 向量 长度、维度和形状 矩阵 张量 降维 非降维求和 点积（Dot Product） 矩阵-向量积 矩阵-矩阵乘法 范数 More 矩阵计算 标量导数 亚导数 梯度 标量对向量求导 分子布局与分母布局 自动求导 链式法则 自动求导 计算图 autograd代码 房价预测模型 线性模型 衡量预估质量 训练数据 参数学习 显示解 总结 生成数据集 读取数据集 初始化模型参数 定义模型 定义损失函数 定义优化算法 训练 生成数据集 读取数据集 定义模型 初始化模型参数 定义损失函数 定义优化算法 训练 小结 梯度下降 选择学习率 小批量随机梯度下降 选择批量大小 总结 L2损失 均方损失 L1 Loss 绝对值损失函数 Huber' s Robust Loss 回归vs分类 从回归到多类分类 步骤 无校验比例 校验比例 softmax 交叉熵损失 总结 读取数据集 读取小批量 整合所有组件 小结",content:"# 1.课程安排\n\n\n# 目标\n\n * 介绍深度学习经典和最新模型\n   * LeNet，ResNet，LSTM，BERT，...\n * 机器学习基础\n   * 损失函数、目标函数、过拟合、优化\n * 实践\n   * 使用Pytorch实现介绍的知识点\n   * 在真实数据上体验算法效果\n\n\n# 内容\n\n * 深度学习基础\n   * 线性神经网络，多层感知机\n * 卷积神经网络\n   * LeNet，AlexNet，VGG，Inception，ResNet\n * 循环神经网络\n   * RNN，GRU，LSTM，seq2seq\n * 注意力机制\n   * Attention，Transformer\n * 优化算法\n   * SGD，Momentum，Adam\n * 高性能计算\n   * 并行，多GPU，分布式\n * 计算机视觉\n   * 目标检测，语义分割\n * 自然言处理\n   * 词嵌入，BERT\n\n\n# 资源\n\n * 课程主页：https://courses.d2l.ai/zh-v2/\n * 教材：https://zh-v2.d2l.ai/\n * 课程论坛讨论：https://discuss.d2l.ai/c/chinese-version/16\n * Pytorch论坛：https://discuss.pytorch.org/\n\n\n# 深度学习介绍\n\n\n# 数据操作和预处理\n\n\n# 数据操作\n\n\n# N维数组\n\nN维数组是机器学习和神经网络的主要数据结构\n\n\n\n\n# 创建数组\n\n创建数组需要：\n\n * 形状：例如3x4矩阵\n * 每个元素的数据类型：例如32位浮点数（Tensor中默认是64位，而深度学习中常用32位）\n * 每个元素的值，例如全是0，或者随机数\n\n\n# 访问元素\n\n\n# 张量\n\n张量表示由一个数值组成的数组，这个数组可能有多个维度。 具有一个轴的张量对应数学上的向量（vector）； 具有两个轴的张量对应数学上的矩阵（matrix）； 具有两个轴以上的张量没有特殊的数学名称。\n\n> 首先，可以使用arange创建一个行向量x。 这个行向量包含从0开始的前12个整数，它们被默认创建为浮点数。 张量中的每个值都称为张量的元素（element）。 例如，张量x中有12个元素。 除非额外指定，新的张量默认将存储在内存中，并采用基于CPU的计算。\n\n * x = torch.arange(12)\n   * tensor([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n\n> 访问张量（沿每个轴的长度）的形状\n\n * x.shape\n   * torch.Size([12])\n\n> 张量中元素的总数(标量)\n\n * x.numel()\n   * 12\n\n> 要想改变一个张量的形状而不改变元素数量和元素值，可以调用reshape函数,通过改变张量的形状，张量的大小不会改变。\n\n * X = x.reshape(3, 4)\n   \n   * tensor([[ 0,  1,  2,  3],\n             [ 4,  5,  6,  7],\n             [ 8,  9, 10, 11]])\n     \n     \n     1\n     2\n     3\n     \n   \n   * 可以通过-1来调用此自动计算出维度的功能。 即可以用x.reshape(-1,4)或x.reshape(3,-1)来取代x.reshape(3,4)\n\n> 使用全0、全1、其他常量，或者从特定分布中随机采样的数字来初始化矩阵\n\n * torch.zeros((2, 3, 4))\n   \n   * tensor([[[0., 0., 0., 0.],\n              [0., 0., 0., 0.],\n              [0., 0., 0., 0.]],\n     \n             [[0., 0., 0., 0.],\n              [0., 0., 0., 0.],\n              [0., 0., 0., 0.]]])\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     \n\n * torch.ones((2, 3, 4))\n   \n   * tensor([[[1., 1., 1., 1.],\n              [1., 1., 1., 1.],\n              [1., 1., 1., 1.]],\n     \n             [[1., 1., 1., 1.],\n              [1., 1., 1., 1.],\n              [1., 1., 1., 1.]]])\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     \n\n * 通过从某个特定的概率分布中随机采样来得到张量中每个元素的值。\n   \n   * 例如，当构造数组来作为神经网络中的参数时，通常会随机初始化参数的值。\n   \n   * 以下代码创建一个形状为（3,4）的张量。 其中的每个元素都从均值为0、标准差为1的标准高斯分布（正态分布）中随机采样。\n   \n   * torch.randn(3, 4)\n     \n     * tensor([[ 0.1364,  0.3546, -0.9091, -1.8926],\n               [ 0.5786, -0.9019, -0.1305, -0.1899],\n               [ 0.5696,  1.1626, -0.5987,  0.4085]])\n       \n       \n       1\n       2\n       3\n       \n\n> 通过提供包含数值的Python列表（或嵌套列表），来为所需张量中的每个元素赋予确定值\n\n * torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n   \n   * tensor([[2, 1, 4, 3],\n             [1, 2, 3, 4],\n             [4, 3, 2, 1]])\n     \n     \n     1\n     2\n     3\n     \n     \n     ==最外层的列表对应于轴0，内层的列表对应于轴1==\n\n\n# 运算符\n\n按元素（elementwise）运算。将标准标量运算符应用于数组的每个元素\n\n对于任意具有相同形状的张量， 常见的标准算术运算符（+、-、\\*、/和**）都可以被升级为按元素运算\n\n * x = torch.tensor([1.0, 2, 4, 8])\n   y = torch.tensor([2, 2, 2, 2])\n   x + y, x - y, x * y, x / y, x ** y  # **运算符是求幂运算\n   \n   \n   1\n   2\n   3\n   \n   \n   * (tensor([ 3.,  4.,  6., 10.]),\n      tensor([-1.,  0.,  2.,  6.]),\n      tensor([ 2.,  4.,  8., 16.]),\n      tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n      tensor([ 1.,  4., 16., 64.]))\n     \n     \n     1\n     2\n     3\n     4\n     5\n     \n\n * torch.exp(x)\n   \n   * tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])\n     \n     \n     1\n     \n   \n   ----------------------------------------\n\n> 把多个张量*连结*（concatenate）在一起， 把它们端对端地叠起来形成一个更大的张量。\n\n只需要提供张量列表，并给出沿哪个轴连结\n\n * 沿行（轴-0，形状的第一个元素） 和按列（轴-1，形状的第二个元素）连结两个矩阵\n   \n   * X = torch.arange(12, dtype=torch.float32).reshape(3,4)\n     Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n     torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)\n     \n     \n     1\n     2\n     3\n     \n     \n     * (tensor([[ 0.,  1.,  2.,  3.],\n                [ 4.,  5.,  6.,  7.],\n                [ 8.,  9., 10., 11.],\n                [ 2.,  1.,  4.,  3.],\n                [ 1.,  2.,  3.,  4.],\n                [ 4.,  3.,  2.,  1.]]),\n        tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n                [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n                [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))\n       \n       \n       1\n       2\n       3\n       4\n       5\n       6\n       7\n       8\n       9\n       \n\n----------------------------------------\n\n> 通过逻辑运算符构建二元张量\n\n * 如果X和Y在该位置相等，则新张量中相应项的值为1\n\n * X == Y\n   \n   * tensor([[False,  True, False,  True],\n             [False, False, False, False],\n             [False, False, False, False]])\n     \n     \n     1\n     2\n     3\n     \n\n----------------------------------------\n\n> 对张量中的所有元素进行求和，会产生一个单元素张量\n\n * X.sum()\n   \n   * tensor(66.)\n     \n     \n     1\n     \n\n----------------------------------------\n\n\n# 广播机制\n\n形状不同，仍然可以通过调用 广播机制（broadcasting mechanism）来执行按元素操作\n\n * 首先，通过适当复制元素来扩展一个或两个数组， 以便在转换之后，两个张量具有相同的形状。\n   \n   * 其次，对生成的数组执行按元素操作。\n\n * a = torch.arange(3).reshape(3, 1)\n   b = torch.arange(2).reshape(1, 2)\n   a, b\n   \n   \n   1\n   2\n   3\n   \n   \n   (tensor([[0],\n            [1],\n            [2]]),\n    tensor([[0, 1]]))\n   \n   \n   1\n   2\n   3\n   4\n   \n\n矩阵a复制列， 矩阵b复制行\n\n * a + b\n   \n   * tensor([[0, 1],\n             [1, 2],\n             [2, 3]])\n     \n     \n     1\n     2\n     3\n     \n\n----------------------------------------\n\n\n# 索引和切片\n\n> 用[-1]选择最后一个元素，用[1:3]选择第二个和第三个元素\n> \n> 在二维中就是行元素\n\n * X[-1], X[1:3]\n   \n   * (tensor([ 8.,  9., 10., 11.]),\n      tensor([[ 4.,  5.,  6.,  7.],\n              [ 8.,  9., 10., 11.]]))\n     \n     \n     1\n     2\n     3\n     \n\n> 通过指定索引来将元素写入矩阵\n\n * X[1, 2] = 9\n   X\n   \n   \n   1\n   2\n   \n   \n   * tensor([[ 0.,  1.,  2.,  3.],\n             [ 4.,  5.,  9.,  7.],\n             [ 8.,  9., 10., 11.]])\n     \n     \n     1\n     2\n     3\n     \n\n> 为多个元素赋值相同的值\n\n * X[0:2, :] = 12\n   X\n   \n   \n   1\n   2\n   \n   \n   tensor([[12., 12., 12., 12.],\n           [12., 12., 12., 12.],\n           [ 8.,  9., 10., 11.]])\n   \n   \n   1\n   2\n   3\n   \n\n\n# 节省内存\n\n运行一些操作可能会导致为新结果分配内存。 例如，如果用Y = X + Y，将取消引用Y指向的张量，而是指向新分配的内存处的张量。\n\n在下面的例子中，使用Python的id()函数演示， id()函数提供了内存中引用对象的确切地址。\n\n运行Y = Y + X后，发现id(Y)指向另一个位置。 这是因为Python首先计算Y + X，为结果分配新的内存，然后使Y指向内存中的这个新位置。\n\n * before = id(Y)\n   Y = Y + X\n   id(Y) == before\n   \n   \n   1\n   2\n   3\n   \n   \n   False\n   \n   \n   1\n   \n\n这可能是不可取的，原因有两个：\n\n * 首先，不想总是不必要地分配内存。 在机器学习中，我们可能有数百兆的参数，并且在一秒内多次更新所有参数。 通常情况下，希望原地执行这些更新。\n * 其次，如果不原地更新，其他引用仍然会指向旧的内存位置， 这样某些代码可能会无意中引用旧的参数。\n\n> 所以需要执行原地操作。\n\n可以使用切片表示法将操作的结果分配给先前分配的数组，例如Y[:] = <expression>。\n\n * 创建一个新的矩阵Z，其形状与另一个Y相同， 使用zeros_like来分配一个全00的块。\n   \n   * Z = torch.zeros_like(Y)\n     print('id(Z):', id(Z))\n     Z[:] = X + Y\n     print('id(Z):', id(Z))\n     \n     \n     1\n     2\n     3\n     4\n     \n     \n     id(Z): 2016710171280\n     id(Z): 2016710171280\n     \n     \n     1\n     2\n     \n\n * 如果在后续计算中没有重复使用X， 我们也可以使用X[:] = X + Y或X += Y来减少操作的内存开销\n   \n   * before = id(X)\n     X += Y\n     id(X) == before\n     \n     \n     1\n     2\n     3\n     \n     \n     True\n     \n     \n     1\n     \n\n----------------------------------------\n\n\n# 转换为其他Python对象\n\n将深度学习框架定义的张量转换为NumPy张量（ndarray）很容易，反之也同样容易。 torch张量和numpy数组将共享它们的底层内存，就地操作更改一个张量也会同时更改另一个张量。\n\n * A = X.numpy()\n   B = torch.tensor(A)\n   type(A), type(B)\n   \n   \n   1\n   2\n   3\n   \n   \n   * (numpy.ndarray, torch.Tensor)\n     \n     \n     1\n     \n\n----------------------------------------\n\n> 要(将大小为1的张量转换为Python标量)，可以调用item函数或Python的内置函数\n\na = torch.tensor([3.5])\na, a.item(), float(a), int(a)\n\n\n1\n2\n\n\n(tensor([3.5000]), 3.5, 3.5, 3)\n\n\n1\n\n\n\n# 预处理\n\n\n# 读取数据集\n\n> 创建一个人工数据集，并存储在CSV（逗号分隔值）文件\n\nimport os\n\nos.makedirs(os.path.join('.', 'data'), exist_ok=True)\ndata_file = os.path.join('.', 'data', 'house_tiny.csv')\nwith open(data_file, 'w') as f:\n    f.write('NumRooms,Alley,Price\\n')  # 列名\n    f.write('NA,Pave,127500\\n')  # 每行表示一个数据样本\n    f.write('2,NA,106000\\n')\n    f.write('4,NA,178100\\n')\n    f.write('NA,NA,140000\\n')\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n * print(data_file)\n\n'.\\\\data\\\\house_tiny.csv'\n\n\n1\n\n * os.path.join()函数：连接两个或更多的路径名组件\n   * 1.如果各组件名首字母不包含’/’，则函数会自动加上\n   * 2.如果有一个组件是一个绝对路径，则在它之前的所有组件均会被舍弃\n   * 3.如果最后一个组件为空，则生成的路径以一个’/’分隔符结尾\n * os.makedirs(name, mode=0o777, exist_ok=False):用来创建多层目录（单层请用os.mkdir)\n   * ame：想创建的目录名\n   * mode：要为目录设置的权限数字模式，默认的模式为 0o777 (八进制)。\n   * exist_ok：是否在目录存在时触发异常。如果exist_ok为False（默认值），则在目标目录已存在的情况下触发FileExistsError异常；如果exist_ok为True，则在目标目录已存在的情况下不会触发FileExistsError异常。\n\n> 从创建的CSV文件中加载原始数据集\n\nimport pandas as pd\n\ndata = pd.read_csv(data_file)\nprint(data)\n\n\n1\n2\n3\n4\n\n\n\n\n\n# 处理缺失值\n\n“NaN”项代表缺失值。 [为了处理缺失的数据，典型的方法包括*插值法*和*删除法*，] 其中插值法用一个替代值弥补缺失值，而删除法则直接忽略缺失值.\n\n * 通过位置索引iloc，将data分成inputs和outputs， 其中前者为data的前两列，而后者为data的最后一列。 对于inputs中缺少的数值，用同一列的均值替换“NaN”项。\n   \n   * inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n     inputs = inputs.fillna(inputs.mean())\n     print(inputs)\n     \n     \n     1\n     2\n     3\n     \n     * \n     * 数值中的NA用均值替换，字符串中的不行\n\n * [对于inputs中的类别值或离散值，我们将“NaN”视为一个类别。] 由于“巷子类型”（“Alley”）列只接受两种类型的类别值“Pave”和“NaN”， pandas可以自动将此列转换为两列“Alley_Pave”和“Alley_nan”。 巷子类型为“Pave”的行会将“Alley_Pave”的值设置为1，“Alley_nan”的值设置为0。 缺少巷子类型的行会将“Alley_Pave”和“Alley_nan”分别设置为0和1。\n   \n   * inputs = pd.get_dummies(inputs, dummy_na=True)\n     print(inputs)\n     \n     \n     1\n     2\n     \n     * \n\n----------------------------------------\n\n\n# 转换为张量格式\n\n现在inputs和outputs中的所有条目都是数值类型，它们可以转换为张量格式\n\nimport torch\n\nX, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\nX, y\n\n\n1\n2\n3\n4\n\n\n\n\n----------------------------------------\n\n\n# 线性代数\n\n\n# 向量\n\n\n# 矩阵\n\n\n# 范数\n\n# -范数的定义\n\n在很多机器学习相关的著作和教材中，经常看到各式各样的距离及范数，如\n\n\n\n其中， 分别表示向量和矩阵。\n\n当然，也会看到欧式距离、均方误差等。例如，向量 的欧式范数 (Euclidean norm) 为\n\n\n\n用于表示向量的大小，这个范数也被叫做 -范数。\n\n * 为方便统一，一般将任意向量 的 -范数定义为:\n\n\n\n# 矩阵的范数\n\n上面是向量的范数，而矩阵的范数更加麻烦\n\n\n\n * 范数\n   * \n   * 取决于如何衡量b和c的长度\n * 常见范数\n   * 矩阵范数：最小的满足的上面公式的值\n   * Frobenius 范数\n     * 矩阵范数计算比较麻烦，所以常用的是Frobenius 范数\n     * 矩阵所有元素的平方和的算术平方根\n     * \n\n\n# 特殊矩阵\n\n# 对称和反对称\n\n\n\n# 正定\n\n\n\n正定矩阵乘以任意的列向量和行向量都大于等于0\n\n# 正交矩阵\n\n * 所以行都相互正交\n * 所有行都有单位长度\n   * \n * 可以写成(对角线都为1的单位矩阵)\n\n# 置换矩阵\n\n * 置换矩阵是一个方形二进制矩阵，它在每行和每列中只有一个1，而在其他地方则为0。\n\n * 置换矩阵： 当且仅当 $j=\\pi(i) $\n\n * 置换矩阵是正交矩阵\n\n----------------------------------------\n\n\n# 特征向量和特征值\n\n特征向量:不被矩阵改变方向的向量\n\n对称矩阵总是可以找到特征向量\n\n----------------------------------------\n\n\n# linear-algebra代码\n\n\n# 标量\n\n> 标量由只有一个元素的张量表示\n\nimport torch\n\nx = torch.tensor(3.0)\ny = torch.tensor(2.0)\n\nx + y, x * y, x / y, x**y\n\n\n1\n2\n3\n4\n5\n6\n\n\n(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))\n\n\n1\n\n\n\n# 向量\n\n> 向量可以视为标量值组成的列表。 将这些标量值称为向量的元素（element）或分量（component）。\n\nx = torch.arange(4)\nx\n\n\n1\n2\n\n\ntensor([0, 1, 2, 3])\n\n\n1\n\n\n==大量文献认为列向量是向量的默认方向==\n\n向量可以写为：\n\n\n# 长度、维度和形状\n\n * 向量只是一个数字数组，就像每个数组都有一个长度一样，每个向量也是如此。\n   \n   * 如果一个向量由个实值标量组成，可以将其表示为。 向量的长度通常称为向量的维度（dimension）。\n\n * 与普通的Python数组一样，可以通过调用Python的内置len()函数来访问张量的长度。\n   \n   * len(x)\n\n> 当用张量表示一个向量（只有一个轴）时，可以通过.shape属性访问向量的长度。\n> \n> 形状（shape）是一个元素组，列出了张量沿每个轴的长度（维数）。 对于(只有一个轴的张量，形状只有一个元素。)\n\nx.shape\n\ntorch.Size([4])\n\n\n1\n\n\n==请注意==，维度（dimension）这个词在不同上下文时往往会有不同的含义：\n\n向量或轴的维度被用来表示向量或轴的长度，即向量或轴的元素数量。\n\n然而，张量的维度用来表示张量具有的轴数。\n\n在这个意义上，张量的某个轴的维数就是这个轴的长度。\n\n\n# 矩阵\n\n在数学表示法中，使用来表示矩阵，其由行和列的实值标量组成。\n\n> 当调用函数来实例化张量时， 可以通过指定两个分量𝑚和𝑛来创建一个形状为𝑚×𝑛的矩阵。\n\nA = torch.arange(20).reshape(5, 4)\nA\n\n\n1\n2\n\n\n\n\n> 转置（transpose）\n\nA.T\n\n\n\n> 作为方阵的一种特殊类型，对称矩阵\\（symmetric matrix）𝐀等于其转置：𝐀=𝐀^⊤^\n\nB = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\nB\n\n\n1\n2\n\n\n\n\nB == B.T\n\n\n\n\n# 张量\n\n就像向量是标量的推广，矩阵是向量的推广一样，可以构建具有更多轴的数据结构。\n\n张量提供了描述具有任意数量轴的n维数组的通用方法。\n\n例如，向量是一阶张量，矩阵是二阶张量。\n\n张量用特殊字体的大写字母表示（例如，X、Y和Z），索引机制与矩阵类似。\n\n# 张量算法的基本性质\n\n给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量\n\nA = torch.arange(20, dtype=torch.float32).reshape(5, 4)\nB = A.clone()  # 通过分配新内存，将A的一个副本分配给B\nA, A + B\n\n\n1\n2\n3\n\n\n\n\n> 两个矩阵的按元素乘法称为Hadamard积（Hadamard product，哈达玛积）（数学符号⊙）\n\nA * B\n\n\n\n> 将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘。\n\na = 2\nX = torch.arange(24).reshape(2, 3, 4)\na + X, (a * X).shape\n\n\n1\n2\n3\n\n\n\n\n----------------------------------------\n\n\n# 降维\n\n默认情况下，调用求和函数会沿所有的轴降低张量的维度，使它变为一个标量\n\nx = torch.arange(4, dtype=torch.float32)\nx, x.sum()\n\n\n1\n2\n\n\n(tensor([0., 1., 2., 3.]), tensor(6.))\n\n\n1\n\n\nA.shape, A.sum()\n\n(torch.Size([5, 4]), tensor(190.))\n\n\n1\n\n\n> 还可以指定张量沿哪一个轴来通过求和降低维度\n\n==指定哪个轴，哪个轴就消失==\n\n * A_sum_axis0 = A.sum(axis=0)\n   A_sum_axis0, A_sum_axis0.shape\n   \n   \n   1\n   2\n   \n   \n   (tensor([40., 45., 50., 55.]), torch.Size([4]))\n   \n   \n   1\n   \n\n * A_sum_axis1 = A.sum(axis=1)\n   A_sum_axis1, A_sum_axis1.shape\n   \n   \n   1\n   2\n   \n   \n   (tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))\n   \n   \n   1\n   \n\n> 可以同时指定多个轴\n\n * A.sum(axis=[0, 1])  # SameasA.sum()\n   \n   \n   1\n   \n   \n   tensor(190.)\n   \n   \n   1\n   \n\n----------------------------------------\n\n> 一个与求和相关的量是平均值（mean或average）\n\n * A.mean(), A.sum() / A.numel()\n   \n   \n   1\n   \n   \n   (tensor(9.5000), tensor(9.5000))\n   \n   \n   1\n   \n\n> 计算平均值的函数也可以沿指定轴降低张量的维度\n\n * A.mean(axis=0), A.sum(axis=0) / A.shape[0]\n   \n   \n   1\n   \n   \n   (tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))\n   \n   \n   1\n   \n\n\n# 非降维求和\n\n有时在调用函数来计算总和或均值时保持轴数不变会很有用,比如广播时需要保证轴数相等\n\n * 使用参数keepdims=True\n   \n   * sum_A = A.sum(axis=1, keepdims=True)\n     sum_A\n     \n     \n     1\n     2\n     \n     \n     \n\n==注意==：\n\n> 由于sum_A在对每行进行求和后仍保持两个轴，可以(通过广播将A除以sum_A)\n\n * A / sum_A\n   \n   \n\n> 如果想沿[某个轴计算A元素的累积总和]， 比如axis=0（按行计算），可以调用cumsum函数。 此函数不会沿任何轴降低输入张量的维度。\n\nA.cumsum(axis=0)\n\n\n\n----------------------------------------\n\n\n# 点积（Dot Product）\n\n给定两个向量， 它们的点积（dot product）（或） 是相同位置的按元素乘积的和：\n\n * y = torch.ones(4, dtype = torch.float32)\n   x, y, torch.dot(x, y)\n   \n   \n   1\n   2\n   \n   \n   (tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))\n   \n   \n   1\n   \n   \n   > 也可以通过执行按元素乘法，然后进行求和来表示两个向量的点积\n   \n   * torch.sum(x * y)\n     \n     ensor(6.)\n     \n     \n     1\n     \n\n# 点积的应用\n\n例如\n\n * 给定一组由向量表示的值，和一组由表示的权重。中的值根据权重的加权和，可以表示为点积。\n * 当权重为非负数且和为1（即）时，点积表示加权平均（weighted average）。\n * 将两个向量规范化得到单位长度后，点积表示它们夹角的余弦。\n\n----------------------------------------\n\n\n# 矩阵-向量积\n\n矩阵-向量积（matrix-vector product）。\n\n * 定义矩阵和向量。\n   * 将矩阵用它的行向量表示：\n\n其中每个都是行向量，表示矩阵的第行。 矩阵向量积是一个长度为的列向量，其第个元素是点积：\n\n> 用与点积相同的mv函数表示矩阵-向量积。\n\n当为矩阵A和向量x调用torch.mv(A, x)时，会执行矩阵-向量积。\n\n注意，A的列维数（沿轴1的长度）必须与x的维数（其长度）相同。\n\nA.shape, x.shape, torch.mv(A, x)#MV：matrix vector multiplication\n\n\n1\n\n\n(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))\n\n\n1\n\n\n----------------------------------------\n\n可以把一个矩阵乘法看作是一个从到向量的转换。\n\n> 这些转换是非常有用的。\n> \n> 例如\n> \n>  * 可以用方阵的乘法来表示旋转。\n>  * 也可以使用矩阵-向量积来描述在给定前一层的值时，求解神经网络每一层所需的复杂计算。\n\n----------------------------------------\n\n\n# 矩阵-矩阵乘法\n\n矩阵-矩阵乘法（matrix-matrix multiplication）\n\n * 假设我们有两个矩阵和：\n\n * 用行向量表示矩阵的第行，并让列向量作为矩阵的第列。要生成矩阵积，最简单的方法是==考虑的行向量和的列向量==:\n\n * 简单地将==每个元素计算为点积==：\n\n==可以将矩阵-矩阵乘法看作是简单地执行次矩阵-向量积，并将结果拼接在一起，形成一个矩阵==。\n\n * torch.mm(A, B)#mm:matrix multiplication\n   \n   \n   1\n   \n   \n   \n\n==注意==：矩阵-矩阵乘法可以简单地称为矩阵乘法，不应与\"Hadamard积\"混淆。\n\n----------------------------------------\n\n矩阵-矩阵乘法可以简单地称为矩阵乘法，不应与\"Hadamard积\"混淆。\n\n\n# 范数\n\n * 线性代数中最有用的一些运算符是范数（norm）。\n   \n   * 非正式地说，一个向量的范数告诉我们一个向量有多大。\n   * 这里考虑的大小（size）概念不涉及维度，而是分量的大小。\n\n * 在线性代数中，向量范数是将向量映射到标量的函数。\n\n * 给定任意向量，向量范数要满足一些属性。\n   \n   * 第一个性质是：如果按常数因子缩放向量的所有元素，其范数也会按相同常数因子的绝对值缩放：\n     \n     * \n   \n   * 第二个性质是我们熟悉的三角不等式:\n     \n     * \n   \n   * 第三个性质简单地说范数必须是非负的:\n     \n     * \n     \n     * 因为在大多数情况下，任何东西的最小的大小是0。\n     \n     * 要求范数最小为0，当且仅当向量全由0组成。\n       \n       * \n\n> 范数听起来很像距离的度量。 如果你还记得欧几里得距离和毕达哥拉斯定理(勾股定理)，那么非负性的概念和三角不等式可能会给你一些启发。 事实上，==欧几里得距离是一个范数==：\n\n假设维向量中的元素是，其**范数是向量元素平方和的平方根：**\n\n($$|\\mathbf{x}|2 = \\sqrt{\\sum{i=1}^n x_i^2},$$)\n\n其中，在范数中常常省略下标，也就是说==等同于==。\n\n> 计算向量的范数\n\nu = torch.tensor([3.0, -4.0])\ntorch.norm(u)\n\n\n1\n2\n\n\ntensor(5.)\n\n\n1\n\n\n在深度学习中，我们更经常地使用范数的平方。 你还会经常遇到[范数，它表示为向量元素的绝对值之和：]\n\n($$|\\mathbf{x}|1 = \\sum{i=1}^n \\left|x_i \\right|.$$)\n\n与范数相比，范数受异常值的影响较小。\n\n> 为了计算范数，我们将绝对值函数和按元素求和组合起来。\n\ntorch.abs(u).sum()\n\n\n1\n\n\ntensor(7.)\n\n\n1\n\n * 范数和范数都是更一般的范数的特例：\n\n类似于向量的范数，==矩阵==**(**的Frobenius范数（Frobenius norm）是==矩阵元素平方和的平方根==：)\n\n($$|\\mathbf{X}|F = \\sqrt{\\sum{i=1}^m \\sum_{j=1}^n x_{ij}^2}.$$)\n\nFrobenius范数满足向量范数的所有性质，它就像是矩阵形向量的范数。\n\n> 计算矩阵的Frobenius范数。\n\ntorch.norm(torch.ones((4, 9)))\n\n\n1\n\n\ntensor(6.)\n\n\n1\n\n\n# 范数和目标\n\n在深度学习中，经常试图解决优化问题：\n\n * 最大化分配给观测数据的概率;\n * 最小化预测和真实观测之间的距离。\n * 用向量表示物品（如单词、产品或新闻文章），以便最小化相似项目之间的距离，最大化不同项目之间的距离。\n * 目标，或许是深度学习算法最重要的组成部分（除了数据），通常被表达为范数。\n\n\n# More\n\n线性代数还有很多，其中很多数学对于机器学习非常有用。\n\n * 例如，矩阵可以分解为因子，这些分解可以显示真实世界数据集中的低维结构。\n\n * 机器学习的整个子领域都侧重于使用矩阵分解及其向高阶张量的泛化，来发现数据集中的结构并解决预测问题。\n\n线性代数运算的在线附录\n\n\n# 矩阵计算\n\n\n# 标量导数\n\n * 导数是切线的斜率\n   * \n * \n * \n\n\n# 亚导数\n\n将导数拓展到不可微的函数\n\n * * \n * \n\n\n# 梯度\n\n将导数拓展到向量\n\n * \n\n * ----------------------------------------\n\n\n# 标量对向量求导\n\n * * ==是列向量，导数是行向量==\n   * 比如,y=\n     * \n     * \n     * 梯度指向的是值变化最大的方向\n   * 比如\n   * ==内积求导==：L2-范数求导可以转化为内积求导\n\n * ----------------------------------------\n   \n   * \n\n * ----------------------------------------\n   \n   * \n   * \n\n# 拓展到矩阵\n\n----------------------------------------\n\n\n# 分子布局与分母布局\n\n# 前提\n\n 1. 分子分母都是向量，且一个是行向量，另一个是列向量\n 2. 分子分母一个是标量，另一个是行向量或列向量\n\n当满足1或2时，讨论分母布局/分子布局才有意义。\n\n# 结论\n\n 1. 谁是列向量就是什么布局。分母是列向量，就是分母布局；分子是列向量，就是分子布局。\n\n\n\n * \n * \n * \n\n> 中分母是列向量，所以是分母布局， 中分子是列向量，所以是分子布局\n> \n> 但要求统一是分子布局，所以把 的分母布局转置为分子布局\n\n\n# 自动求导\n\n * 深度学习框架可以自动计算导数：\n   * 首先将梯度附加到想要对其计算偏导数的变量上。然后\n   * 记录目标值的计算，执行它的反向传播函数，并访问得到的梯度。\n\n\n# 链式法则\n\n# 标量链式法则\n\n# 向量链式法则\n\n拓展到向量\n\n# 例1\n\n# 例2\n\n\n\n\n# 自动求导\n\n * 计算一个函数在指定值上的导数\n\n * 区别于符号求导和数值求导\n   \n   * 符号求导\n     * \n   * 数值求导\n     * \n\n\n# 计算图\n\n * 将代码分解成操作子\n * 将计算表示成一个无环图\n   * \n\n# 计算图的2中构造方式\n\n * 显示构造\n   * \n   * Tensorflow/Theano/MXNet\n * 隐式构造\n   * \n   * PyTorch/MXNet\n   * 构造出Tensor后，系统会记住所有的计算操作\n\n# 自动求导的2种模式\n\n正向累积和反向累积\n\n链式法则：\n\n * 正向累积\n   * \n * ==反向累积、又称反向传递（BP，Backpropagation）==\n   * \n\n# 反向累积\n\n==步骤==\n\n1.构造计算图\n\n2.前向（forward）：执行图，存储中间结果\n\n3.反向（backward）：从相反方向执行图，然后去除不需要的枝\n\n * \n\n----------------------------------------\n\n * \n * \n * \n\n----------------------------------------\n\n==复杂度== 计算复杂度：O（n），n是操作子个数，通常正向和反向的代价类似 内存复杂度：O（n），因为需要存储正向的所有中间结果\n\n> 而正向累积： 计算复杂度:O（n），用来计算一个变量的梯度\n> \n> 内存复杂度:O（1），不保存中间值\n> \n> 神经网络中不用正向累积，因为需要对每一层都计算梯度\n\n----------------------------------------\n\n\n# autograd代码\n\n深度学习框架通过自动计算导数，即自动微分（automatic differentiation）来加快求导。\n\n实际中，根据我们设计的模型，系统会构建一个计算图（computational graph）， 来跟踪计算是哪些数据通过哪些操作组合起来产生输出。\n\n自动微分使系统能够随后反向传播梯度。 这里，反向传播（backpropagate）意味着跟踪整个计算图，==填充关于每个参数的偏导数==。\n\n# 例子\n\n对函数关于列向量求导\n\n> 首先，创建变量x并为其分配一个初始值。\n\n * import torch\n   \n   x = torch.arange(4.0)\n   x\n   \n   \n   1\n   2\n   3\n   4\n   \n   \n   tensor([0., 1., 2., 3.])\n   \n   \n   1\n   \n\n> 在计算𝑦关于𝐱的梯度之前，需要一个地方来存储梯度\n\n不会在每次对一个参数求导时都分配新的内存。\n\n因为经常会成千上万次地更新相同的参数，每次都分配新的内存可能很快就会将内存耗尽。\n\n注意，一个标量函数关于向量𝐱的梯度是向量，并且与𝐱具有相同的形状。\n\n * x.requires_grad_(True)  # 等价于x=torch.arange(4.0,requires_grad=True)\n   x.grad  # 默认值是None\n   \n   \n   1\n   2\n   \n   \n   tensor([1., 1., 1., 1.])\n   \n   \n   1\n   \n\n> 计算𝑦\n\n * y = 2 * torch.dot(x, x) # 内积\n   y\n   \n   \n   1\n   2\n   \n   \n   tensor(28., grad_fn=<MulBackward0>)\n   \n   \n   1\n   \n\n> 通过调用反向传播函数来自动计算y关于x每个分量的梯度\n\ny.backward()\nx.grad\n\n\n1\n2\n\n\ntensor([ 0.,  4.,  8., 12.])\n\n\n1\n\n\n> 函数关于的梯度应为。 快速验证这个梯度是否计算正确。\n\nx.grad == 4 * x\n\n\n1\n\n\ntensor([True, True, True, True])\n\n\n1\n\n\n> 计算x的另一个函数\n\n# 在默认情况下，PyTorch会累积梯度，所以需要清除之前的值\nx.grad.zero_()#需要先清0，不然会累加上一个x.grad\ny = x.sum()#向量求和的导数全是1\ny.backward()\nx.grad\n\n\n1\n2\n3\n4\n5\n\n\ntensor([1., 1., 1., 1.])\n\n\n1\n\n\n# 非标量变量的反向传播\n\n当y不是标量时，向量y关于向量x的导数的最自然解释是一个矩阵。 对于高阶和高维的y和x，求导的结果可以是一个高阶张量。\n\n然而，虽然这些更奇特的对象确实出现在高级机器学习中（包括[深度学习中]）， 但当我们调用向量的反向计算时，我们通常会试图计算一批训练样本中每个组成部分的损失函数的导数。 ???这里，我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和。\n\n# 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。\n# 在我们的例子中，我们只想求偏导数的和，所以传递一个1的梯度是合适的\nx.grad.zero_()\ny = x * x#x*x表示各元素相乘，y是向量\n# 等价于y.backward(torch.ones(len(x)))？？？\ny.sum().backward()#y向量直接求导的结果是矩阵，所以把y向量通过sum转为标量\nx.grad\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\ntensor([0., 2., 4., 6.])\n\n\n1\n\n\n----------------------------------------\n\n# 分离计算\n\n有时，我们希望[将某些计算移动到记录的计算图之外]。 例如，假设y是作为x的函数计算的，而z则是作为y和x的函数计算的。 想象一下，我们想计算z关于x的梯度，但由于某种原因，我们希望将y视为一个常数，并且只考虑到x在y被计算后发挥的作用。\n\n在这里，我们可以分离y来返回一个新变量u，该变量与y具有相同的值，但丢弃计算图中如何计算y的任何信息。 换句话说，梯度不会向后流经u到x。 因此，下面的反向传播函数计算z=u*x关于x的偏导数，同时将u作为常数处理，而不是z=x*x*x关于x的偏导数。\n\nx.grad.zero_()\ny = x * x\nu = y.detach()\nz = u * x\n\nz.sum().backward()\nx.grad == u\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\ntensor([True, True, True, True])\n\n\n1\n\n\n由于记录了y的计算结果，我们可以随后在y上调用反向传播，得到y=x*x关于的x的导数，即2*x。\n\nx.grad.zero_()\ny.sum().backward()\nx.grad == 2 * x\n\n\n1\n2\n3\n\n\ntensor([True, True, True, True])\n\n\n1\n\n\n----------------------------------------\n\n# Python控制流的梯度计算\n\n使用自动微分的一个好处是： [即使构建函数的计算图需要通过Python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度]。 在下面的代码中，while循环的迭代次数和if语句的结果都取决于输入a的值。\n\ndef f(a):\n    b = a * 2\n    while b.norm() < 1000:\n        b = b * 2\n    if b.sum() > 0:\n        c = b\n    else:\n        c = 100 * b\n    return c\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n计算梯度\n\na = torch.randn(size=(), requires_grad=True)\nd = f(a)\nd.backward()\n\n\n1\n2\n3\n\n\n分析上面定义的f函数: 它在其输入a中是分段线性的。 对于任何a，存在某个常量标量k，使得f(a)=k*a，其中k的值取决于输入a。 因此，可以用d/a验证梯度是否正确。\n\na.grad == d / a\n\n\n1\n\n\ntensor(True)\n\n\n1\n\n\n----------------------------------------\n\n\n# 线性回归\n\n\n# 房价预测模型\n\n\n\n\n# 线性模型\n\n\n\n> 线性模型可以看做是单层神经网络\n\n> 神经网络源于神经科学\n\n\n# 衡量预估质量\n\n\n# 训练数据\n\n定义好模型和偏差后，开始学习参数（权重和偏差）\n\n\n# 参数学习\n\n\n# 显示解\n\n\n# 总结\n\n * 线性回归是对n维输入的加权，外加偏差\n * 使用平方损失来衡量预测值和真实值的差异\n * 线性回归有显示解\n * 线性回归可以看做是单层神经网络\n\n\n# 线性回归的从零开始实现\n\n * 从零开始实现整个方法，包括数据流水线、模型、损失函数和小批量随机梯度下降优化器\n   \n   * 虽然现代的深度学习框架几乎可以自动化地进行所有这些工作，但从零开始实现可以确保你真正知道自己在做什么。\n   * 同时，了解更细致的工作原理将方便我们自定义模型、自定义层或自定义损失函数。\n   * 将只使用张量和自动求导。\n\n * import random\n   import torch\n   from d2l import torch as d2l\n   \n   \n   1\n   2\n   3\n   \n   \n   \n   # 生成数据集\n   \n   为了简单起见，将根据带有噪声的线性模型构造一个人造数据集。 任务是使用这个有限样本的数据集来恢复这个模型的参数。 将使用低维数据，这样可以很容易地将其可视化。\n\n * 在下面的代码中，生成一个包含1000个样本的数据集，每个样本包含从标准正态分布中采样的2个特征。\n   \n   * 合成数据集是一个矩阵。\n   \n   * 使用线性模型参数、和噪声项生成数据集及其标签：\n   \n   * 可以将视为模型预测和标签时的潜在观测误差。\n   * 在这里认为标准假设成立，即服从均值为0的正态分布。\n   * 为了简化问题，将标准差设为0.01。\n\n> 生成合成数据集\n\n * def synthetic_data(w, b, num_examples):  #@save\n       \"\"\"生成y=Xw+b+噪声\"\"\"\n       X = torch.normal(0, 1, (num_examples, len(w))) # 生成一个均值为0，方差为1的正态分布的矩阵\n       y = torch.matmul(X, w) + b\n       y += torch.normal(0, 0.01, y.shape) # 加入随机噪音\n       return X, y.reshape((-1, 1))  #保证最后的格式正确，而过程比如matmul中的格式可以随意\n   \n   true_w = torch.tensor([2, -3.4])\n   true_b = 4.2\n   features, labels = synthetic_data(true_w, true_b, 1000)\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   \n   * torch.mul | torch.mm | torch.bmm | torch.matmul的区别和使用\n\n> features中的每一行都包含一个二维数据样本，labels中的每一行都包含一维标签值（一个标量）。\n\n * print('features:', features[0],'\\nlabel:', labels[0])\n   \n   \n   1\n   \n   \n   \n\n> 生成第二个特征features[:, 1]和labels的散点图，可以直观观察到两者之间的线性关系\n\n * d2l.set_figsize()\n   d2l.plt.scatter(features[:, (1)].detach().numpy(), labels.detach().numpy(), 1);\n   \n   \n   1\n   2\n   \n   \n   \n\n\n# 读取数据集\n\n训练模型时要对数据集进行遍历，每次抽取一小批量样本，并使用它们来更新我们的模型。 由于这个过程是训练机器学习算法的基础，所以有必要定义一个函数，该函数能打乱数据集中的样本并以小批量方式获取数据。\n\n> 定义一个data_iter函数，该函数接收批量大小、特征矩阵和标签向量作为输入，生成大小为batch_size的小批量。\n> \n> 每个小批量包含一组特征和标签。\n\n * def data_iter(batch_size, features, labels):\n       num_examples = len(features)\n       indices = list(range(num_examples))\n       # 这些样本是随机读取的，没有特定的顺序\n       random.shuffle(indices)\n       for i in range(0, num_examples, batch_size):\n           batch_indices = torch.tensor(\n               indices[i: min(i + batch_size, num_examples)])\n           yield features[batch_indices], labels[batch_indices] #迭代器配合下面的for循环进行return，减少内存的占用\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   \n   * 利用GPU并行运算的优势，处理合理大小的“小批量”。\n   * 每个样本都可以并行地进行模型计算，且每个样本损失函数的梯度也可以被并行计算。\n   * GPU可以在处理几百个样本时，所花费的时间不比处理一个样本时多太多。\n   \n   > 直观感受一下小批量运算：读取第一个小批量数据样本并打印。\n   > \n   > 每个批量的特征维度显示批量大小和输入特征数。\n   > \n   > 同样的，批量的标签形状与batch_size相等。\n\n * batch_size = 10\n   \n   for X, y in data_iter(batch_size, features, labels):\n       print(X, '\\n', y)\n       break\n   \n   \n   1\n   2\n   3\n   4\n   5\n   \n   * 当运行迭代时，会连续地获得不同的小批量，直至遍历完整个数据集。\n   * 上面实现的迭代执行效率很低，可能会在实际问题上陷入麻烦。\n     * 例如，它要求我们将所有数据加载到内存中，并执行大量的随机内存访问。\n     * 在深度学习框架中实现的内置迭代器效率要高得多， 它可以处理存储在文件中的数据和数据流提供的数据。\n\n\n# 初始化模型参数\n\n在开始用小批量随机梯度下降优化模型参数之前， 需要先有一些参数。\n\n> 通过从均值为0、标准差为0.01的正态分布中采样随机数来初始化权重， 并将偏置初始化为0。\n\n * w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)\n   b = torch.zeros(1, requires_grad=True)\n   \n   \n   1\n   2\n   \n   \n   * 在初始化参数之后，任务是更新这些参数，直到这些参数足够拟合数据。\n   \n   * 每次更新都需要计算损失函数关于模型参数的梯度。\n   \n   * 有了这个梯度，就可以向减小损失的方向更新每个参数。\n   \n   * 因为手动计算梯度很枯燥而且容易出错，所以没有人会手动计算梯度。 所以使用引入的自动微分来计算梯度。\n\n\n# 定义模型\n\n接下来，必须[定义模型，将模型的输入和参数同模型的输出关联起来。\n\n要计算线性模型的输出，只需计算输入特征和模型权重的矩阵-向量乘法后加上偏置。\n\n * 注意，上面的是一个向量，而是一个标量。\n   \n   * 这里是广播机制：当用一个向量加一个标量时，标量会被加到向量的每个分量上。\n\n * def linreg(X, w, b):  #@save\n       \"\"\"线性回归模型\"\"\"\n       return torch.matmul(X, w) + b\n   \n   \n   1\n   2\n   3\n   \n\n\n# 定义损失函数\n\n因为需要计算损失函数的梯度，所以应该先定义损失函数。\n\n使用平方损失函数。\n\n在实现中，需要将真实值y的形状转换为和预测值y_hat的形状相同。\n\ndef squared_loss(y_hat, y):  #@save\n    \"\"\"均方损失\"\"\"\n    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2\n\n\n1\n2\n3\n\n\n\n# 定义优化算法\n\n线性回归有解析解\n\n但其他模型却没有。所以使用小批量随机梯度下降。\n\n在每一步中，使用从数据集中随机抽取的一个小批量，然后根据参数计算损失的梯度。 接下来，朝着减少损失的方向更新参数。\n\n> 下面的函数实现小批量随机梯度下降更新。 该函数接受模型参数集合、学习速率和批量大小作为输入。\n> \n> 每一步更新的大小由学习速率lr决定。\n> \n> 因为计算的损失是一个批量样本的总和，所以用批量大小（batch_size） 来规范化步长，这样步长大小就不会取决于对批量大小的选择。\n\n * def sgd(params, lr, batch_size):  #@save\n       \"\"\"小批量随机梯度下降\"\"\" \n       with torch.no_grad(): # 更新时不需要梯度运算\n           for param in params:\n               param -= lr * param.grad / batch_size # 取了均值，与在上面损失函数取均值效果一样\n               param.grad.zero_() # 手动设置梯度为0\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   \n\n\n# 训练\n\n现在已经准备好了模型训练所有需要的要素，可以实现主要的训练过程部分了。\n\n * 在每次迭代中，读取一小批量训练样本，并通过模型来获得一组预测。\n * 计算完损失后，开始反向传播，存储每个参数的梯度。\n * 最后，我们调用优化算法sgd来更新模型参数。\n\n> 概括一下，将执行以下循环：\n\n * 初始化参数\n * 重复以下训练，直到完成\n   * 计算梯度\n   * 更新参数\n\n在每个迭代周期（epoch）中，使用data_iter函数遍历整个数据集，并将训练数据集中所有样本都使用一次（假设样本数能够被批量大小整除）。 这里的迭代周期个数num_epochs和学习率lr都是超参数，分别设为3和0.03。 设置超参数很棘手，需要通过反复试验进行调整。\n\nlr = 0.03\nnum_epochs = 3\nnet = linreg\nloss = squared_loss\n\nfor epoch in range(num_epochs):\n    for X, y in data_iter(batch_size, features, labels):\n        l = loss(net(X, w, b), y)  # X和y的小批量损失\n        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，\n        # 并以此计算关于[w,b]的梯度\n        l.sum().backward()\n        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数\n    with torch.no_grad():\n        train_l = loss(net(features, w, b), labels)\n        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\n> 因为使用的是自己合成的数据集，所以知道真正的参数是什么。\n> \n> 因此，我们可以通过比较真实参数和通过训练学到的参数来评估训练的成功程度。\n> \n> 事实上，真实参数和通过训练学到的参数确实非常接近。\n\n * print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')\n   print(f'b的估计误差: {true_b - b}')\n   \n   \n   1\n   2\n   \n   \n   \n\n * 注意，不应该想当然地认为能够完美地求解参数。\n   \n   * 在机器学习中，通常不太关心恢复真正的参数，而更关心如何高度准确预测参数。\n   * 幸运的是，即使是在复杂的优化问题上，随机梯度下降通常也能找到非常好的解。\n   * 其中一个原因是，在深度网络中存在许多参数组合能够实现高度精确的预测。\n\n\n# 线性回归的简洁实现\n\n\n# 生成数据集\n\n> 首先生成数据集。\n\n * import numpy as np\n   import torch\n   from torch.utils import data\n   from d2l import torch as d2l\n   \n   true_w = torch.tensor([2, -3.4])\n   true_b = 4.2\n   features, labels = d2l.synthetic_data(true_w, true_b, 1000)\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   \n\n\n# 读取数据集\n\n可以调用框架中现有的API来读取数据。\n\n将features和labels作为API的参数传递，并通过数据迭代器指定batch_size。\n\n此外，布尔值is_train表示是否希望数据迭代器对象在每个迭代周期内打乱数据。\n\n * def load_array(data_arrays, batch_size, is_train=True):  #@save\n       \"\"\"构造一个PyTorch数据迭代器\"\"\"\n       dataset = data.TensorDataset(*data_arrays) # data.TensorDataset对数据进行打包\n       return data.DataLoader(dataset, batch_size, shuffle=is_train)\n   \n   batch_size = 10\n   data_iter = load_array((features, labels), batch_size)\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   \n\n> 为了验证是否正常工作，读取并打印第一个小批量样本。\n> \n> 这里使用iter构造Python迭代器，并使用next从迭代器中获取第一项。\n\n * next(iter(data_iter))\n   \n   \n   1\n   \n\n\n# 定义模型\n\n对于标准深度学习模型，可以使用框架的预定义好的层。\n\n这使我们只需关注使用哪些层来构造模型，而不必关注层的实现细节。\n\n * 首先定义一个模型变量net，它是一个Sequential类的实例。\n   * Sequential类将多个层串联在一起。\n   * 当给定输入数据时，Sequential实例将数据传入到第一层， 然后将第一层的输出作为第二层的输入，以此类推。\n   * 在下面的例子中，我们的模型只包含一个层，因此实际上不需要Sequential。\n   * 但是由于以后几乎所有的模型都是多层的，在这里使用Sequential会让你熟悉“标准的流水线”。\n\n回顾 :单层网络架构: 这一单层被称为全连接层（fully-connected layer）， 因为它的每一个输入都通过矩阵-向量乘法得到它的每个输出。\n\n在PyTorch中，全连接层在Linear类中定义。 值得注意的是，我们将两个参数传递到nn.Linear中。 第一个指定输入特征形状，即2，第二个指定输出特征形状，输出特征形状为单个标量，因此为1。\n\n * # nn是神经网络的缩写\n   from torch import nn\n   \n   net = nn.Sequential(nn.Linear(2, 1)) # Sequential函数将各层按顺序放在一起，然后可以通过索引访问\n   \n   \n   1\n   2\n   3\n   4\n   \n\n\n# 初始化模型参数\n\n在使用net之前，我们需要初始化模型参数。 如在线性回归模型中的权重和偏置。\n\n深度学习框架通常有预定义的方法来初始化参数。 在这里，我们指定每个权重参数应该从均值为0、标准差为0.01的正态分布中随机采样， 偏置参数将初始化为零。\n\n正如我们在构造nn.Linear时指定输入和输出尺寸一样， 现在我们能直接访问参数以设定它们的初始值。\n\n我们通过net[0]选择网络中的第一个图层， 然后使用weight.data和bias.data方法访问参数。\n\n我们还可以使用替换方法normal_和fill_来重写参数值。\n\n * net[0].weight.data.normal_(0, 0.01) # normal_表示替换\n   net[0].bias.data.fill_(0)\n   \n   \n   1\n   2\n   \n\n\n# 定义损失函数\n\n[计算均方误差使用的是MSELoss类，也称为平方范数]。默认情况下，它返回所有样本损失的平均值。\n\nloss = nn.MSELoss()\n\n\n1\n\n\n\n# 定义优化算法\n\n小批量随机梯度下降算法是一种优化神经网络的标准工具， PyTorch在optim模块中实现了该算法的许多变种。 当我们(实例化一个SGD实例)时，我们要指定优化的参数 （可通过net.parameters()从我们的模型中获得）以及优化算法所需的超参数字典。 小批量随机梯度下降只需要设置lr值，这里设置为0.03。\n\ntrainer = torch.optim.SGD(net.parameters(), lr=0.03)\n\n\n1\n\n\n\n# 训练\n\n通过深度学习框架的高级API来实现我们的模型只需要相对较少的代码。 我们不必单独分配参数、不必定义我们的损失函数，也不必手动实现小批量随机梯度下降。 当我们需要更复杂的模型时，高级API的优势将大大增加。 当我们有了所有的基本组件，[训练过程代码与我们从零开始实现时所做的非常相似]。\n\n回顾一下：在每个迭代周期里，我们将完整遍历一次数据集（train_data）， 不停地从中获取一个小批量的输入和相应的标签。 对于每一个小批量，我们会进行以下步骤:\n\n * 通过调用net(X)生成预测并计算损失l（前向传播）。\n * 通过进行反向传播来计算梯度。\n * 通过调用优化器来更新模型参数。\n\n为了更好的衡量训练效果，我们计算每个迭代周期后的损失，并打印它来监控训练过程。\n\nnum_epochs = 3\nfor epoch in range(num_epochs):\n    for X, y in data_iter:\n        l = loss(net(X) ,y)\n        trainer.zero_grad()\n        l.backward()\n        trainer.step() # 进行模型的更新\n    l = loss(net(features), labels)\n    print(f'epoch {epoch + 1}, loss {l:f}')\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n\n> 下面我们[比较生成数据集的真实参数和通过有限数据训练获得的模型参数]。 要访问参数，我们首先从net访问所需的层，然后读取该层的权重和偏置。 正如在从零开始实现中一样，我们估计得到的参数与生成数据的真实参数非常接近。\n\n * w = net[0].weight.data\n   print('w的估计误差：', true_w - w.reshape(true_w.shape))\n   b = net[0].bias.data\n   print('b的估计误差：', true_b - b)\n   \n   \n   1\n   2\n   3\n   4\n   \n   \n   \n\n\n# 小结\n\n * 我们可以使用PyTorch的高级API更简洁地实现模型。\n * 在PyTorch中，data模块提供了数据处理工具，nn模块定义了大量的神经网络层和常见损失函数。\n * 我们可以通过_结尾的方法将参数替换，从而初始化参数。\n\n\n# 基础优化算法\n\n\n# 梯度下降\n\n\n# 选择学习率\n\n\n# 小批量随机梯度下降\n\n\n# 选择批量大小\n\n\n# 总结\n\n * 梯度下降通过不断沿着反梯度方向更新参数求解\n * 小批量随机梯度下降是深度学习默认的求解算法\n * 两个重要的超参数是批量大小和学习率\n\n\n# 损失函数\n\n\n# L2损失 均方损失\n\n\n\n\n\n\n# L1 Loss 绝对值损失函数\n\n有时候对于相隔较远的点，不希望大梯度更新参数。此时考虑绝对值损失函数\n\n\n\n\n\n真实值和预测值不管相隔多远，梯度都是常数，参数更新不会特别大，更稳定\n\n缺点是0点处不可导，且有剧烈的变化，导致优化末期不稳定\n\n\n# Huber' s Robust Loss\n\n结合上面两者的优点 当相差大于1用绝对值误差，其他情况用均方误差\n\n\n\n\n# Softmax回归\n\n\n# 回归vs分类\n\n * 回归估计一个连续值\n * 分类预测一个离散类别\n   * \n\n\n# 从回归到多类分类\n\n\n\n\n# 步骤\n\n\n\n\n# 无校验比例\n\n\n\n\n# 校验比例 softmax\n\n\n\n\n# 交叉熵损失\n\n\n\n\n# 总结\n\n * Softmax回归是一个多类分类模型\n * 使用Softmax操作子得到每个类的预测置信度\n * 使用交叉熵来来衡量预测和标号的区别\n\n\n# 图像分类数据集\n\nMNIST数据集是图像分类中广泛使用的数据集之一，但作为基准数据集过于简单。 我们将使用类似但更复杂的Fashion-MNIST数据集。\n\nimport torch\nimport torchvision\nfrom torch.utils import data\nfrom torchvision import transforms\nfrom d2l import torch as d2l\n\nd2l.use_svg_display()\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 读取数据集\n\n通过框架中的内置函数将Fashion-MNIST数据集下载并读取到内存中。\n\n# 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，\n# 并除以255使得所有像素的数值均在0到1之间\ntrans = transforms.ToTensor()\nmnist_train = torchvision.datasets.FashionMNIST(\n    root=\"../data\", train=True, transform=trans, download=True)\nmnist_test = torchvision.datasets.FashionMNIST(\n    root=\"../data\", train=False, transform=trans, download=True)\n\n\n1\n2\n3\n4\n5\n6\n7\n\n * Fashion-MNIST由10个类别的图像组成， 每个类别由训练数据集（train dataset）中的6000张图像 和测试数据集（test dataset）中的1000张图像组成。 因此，训练集和测试集分别包含60000和10000张图像。 测试数据集不会用于训练，只用于评估模型性能。\n\nlen(mnist_train), len(mnist_test)\n\n\n1\n\n\n\n\n * 每个输入图像的高度和宽度均为28像素。数据集由灰度图像组成，其通道数为1。为了简洁起见，本书将高度像素、宽度像素图像的形状记为或（,）。\n\nmnist_train[0][0].shape\n\n\n1\n\n\n\n\n * Fashion-MNIST中包含的10个类别，分别为t-shirt（T恤）、trouser（裤子）、pullover（套衫）、dress（连衣裙）、coat（外套）、sandal（凉鞋）、shirt（衬衫）、sneaker（运动鞋）、bag（包）和ankle boot（短靴）。 以下函数用于在数字标签索引及其文本名称之间进行转换。\n\ndef get_fashion_mnist_labels(labels):  #@save\n    \"\"\"返回Fashion-MNIST数据集的文本标签\"\"\"\n    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n    return [text_labels[int(i)] for i in labels]\n\n\n1\n2\n3\n4\n5\n\n * 创建一个函数来可视化这些样本\n\ndef show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):  #@save\n    \"\"\"绘制图像列表\"\"\"\n    figsize = (num_cols * scale, num_rows * scale)\n    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)\n    axes = axes.flatten()\n    for i, (ax, img) in enumerate(zip(axes, imgs)):\n        if torch.is_tensor(img):\n            # 图片张量\n            ax.imshow(img.numpy())\n        else:\n            # PIL图片\n            ax.imshow(img)\n        ax.axes.get_xaxis().set_visible(False)\n        ax.axes.get_yaxis().set_visible(False)\n        if titles:\n            ax.set_title(titles[i])\n    return axes\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n * 以下是训练数据集中前几个样本的图像及其相应的标签\n\nX, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))\nshow_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y));\n\n\n1\n2\n\n\n\n\n\n# 读取小批量\n\n为了使我们在读取训练集和测试集时更容易，我们使用内置的数据迭代器，而不是从零开始创建。 回顾一下，在每次迭代中，数据加载器每次都会[读取一小批量数据，大小为batch_size]。 通过内置数据迭代器，我们可以随机打乱了所有样本，从而无偏见地读取小批量。\n\nbatch_size = 256\n\ndef get_dataloader_workers():  #@save\n    \"\"\"使用4个进程来读取数据\"\"\"\n    return 4\n\ntrain_iter = data.DataLoader(mnist_train, batch_size, shuffle=True,\n                             num_workers=get_dataloader_workers())\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * 读取训练数据所需的时间\n\ntimer = d2l.Timer()\nfor X, y in train_iter:\n    continue\nf'{timer.stop():.2f} sec'\n\n\n1\n2\n3\n4\n\n\n\n\n\n# 整合所有组件\n\n现在我们[定义load_data_fashion_mnist函数]，用于获取和读取Fashion-MNIST数据集。 这个函数返回训练集和验证集的数据迭代器。 此外，这个函数还接受一个可选参数resize，用来将图像大小调整为另一种形状。\n\ndef load_data_fashion_mnist(batch_size, resize=None):  #@save\n    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\"\"\"\n    trans = [transforms.ToTensor()]\n    if resize:\n        trans.insert(0, transforms.Resize(resize))\n    trans = transforms.Compose(trans)\n    mnist_train = torchvision.datasets.FashionMNIST(\n        root=\"../data\", train=True, transform=trans, download=True)\n    mnist_test = torchvision.datasets.FashionMNIST(\n        root=\"../data\", train=False, transform=trans, download=True)\n    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n                            num_workers=get_dataloader_workers()),\n            data.DataLoader(mnist_test, batch_size, shuffle=False,\n                            num_workers=get_dataloader_workers()))\t\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n * 下面，我们通过指定resize参数来测试load_data_fashion_mnist函数的图像大小调整功能。\n\ntrain_iter, test_iter = load_data_fashion_mnist(32, resize=64)\nfor X, y in train_iter:\n    print(X.shape, X.dtype, y.shape, y.dtype)\n    break\n\n\n1\n2\n3\n4\n\n\n\n\n\n# 小结\n\n * Fashion-MNIST是一个服装分类数据集，由10个类别的图像组成。我们将在后续章节中使用此数据集来评估各种分类算法。\n * 我们将高度像素，宽度像素图像的形状记为或（,）。\n * 数据迭代器是获得更高性能的关键组件。依靠实现良好的数据迭代器，利用高性能计算来避免减慢训练过程。",normalizedContent:"# 1.课程安排\n\n\n# 目标\n\n * 介绍深度学习经典和最新模型\n   * lenet，resnet，lstm，bert，...\n * 机器学习基础\n   * 损失函数、目标函数、过拟合、优化\n * 实践\n   * 使用pytorch实现介绍的知识点\n   * 在真实数据上体验算法效果\n\n\n# 内容\n\n * 深度学习基础\n   * 线性神经网络，多层感知机\n * 卷积神经网络\n   * lenet，alexnet，vgg，inception，resnet\n * 循环神经网络\n   * rnn，gru，lstm，seq2seq\n * 注意力机制\n   * attention，transformer\n * 优化算法\n   * sgd，momentum，adam\n * 高性能计算\n   * 并行，多gpu，分布式\n * 计算机视觉\n   * 目标检测，语义分割\n * 自然言处理\n   * 词嵌入，bert\n\n\n# 资源\n\n * 课程主页：https://courses.d2l.ai/zh-v2/\n * 教材：https://zh-v2.d2l.ai/\n * 课程论坛讨论：https://discuss.d2l.ai/c/chinese-version/16\n * pytorch论坛：https://discuss.pytorch.org/\n\n\n# 深度学习介绍\n\n\n# 数据操作和预处理\n\n\n# 数据操作\n\n\n# n维数组\n\nn维数组是机器学习和神经网络的主要数据结构\n\n\n\n\n# 创建数组\n\n创建数组需要：\n\n * 形状：例如3x4矩阵\n * 每个元素的数据类型：例如32位浮点数（tensor中默认是64位，而深度学习中常用32位）\n * 每个元素的值，例如全是0，或者随机数\n\n\n# 访问元素\n\n\n# 张量\n\n张量表示由一个数值组成的数组，这个数组可能有多个维度。 具有一个轴的张量对应数学上的向量（vector）； 具有两个轴的张量对应数学上的矩阵（matrix）； 具有两个轴以上的张量没有特殊的数学名称。\n\n> 首先，可以使用arange创建一个行向量x。 这个行向量包含从0开始的前12个整数，它们被默认创建为浮点数。 张量中的每个值都称为张量的元素（element）。 例如，张量x中有12个元素。 除非额外指定，新的张量默认将存储在内存中，并采用基于cpu的计算。\n\n * x = torch.arange(12)\n   * tensor([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n\n> 访问张量（沿每个轴的长度）的形状\n\n * x.shape\n   * torch.size([12])\n\n> 张量中元素的总数(标量)\n\n * x.numel()\n   * 12\n\n> 要想改变一个张量的形状而不改变元素数量和元素值，可以调用reshape函数,通过改变张量的形状，张量的大小不会改变。\n\n * x = x.reshape(3, 4)\n   \n   * tensor([[ 0,  1,  2,  3],\n             [ 4,  5,  6,  7],\n             [ 8,  9, 10, 11]])\n     \n     \n     1\n     2\n     3\n     \n   \n   * 可以通过-1来调用此自动计算出维度的功能。 即可以用x.reshape(-1,4)或x.reshape(3,-1)来取代x.reshape(3,4)\n\n> 使用全0、全1、其他常量，或者从特定分布中随机采样的数字来初始化矩阵\n\n * torch.zeros((2, 3, 4))\n   \n   * tensor([[[0., 0., 0., 0.],\n              [0., 0., 0., 0.],\n              [0., 0., 0., 0.]],\n     \n             [[0., 0., 0., 0.],\n              [0., 0., 0., 0.],\n              [0., 0., 0., 0.]]])\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     \n\n * torch.ones((2, 3, 4))\n   \n   * tensor([[[1., 1., 1., 1.],\n              [1., 1., 1., 1.],\n              [1., 1., 1., 1.]],\n     \n             [[1., 1., 1., 1.],\n              [1., 1., 1., 1.],\n              [1., 1., 1., 1.]]])\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     \n\n * 通过从某个特定的概率分布中随机采样来得到张量中每个元素的值。\n   \n   * 例如，当构造数组来作为神经网络中的参数时，通常会随机初始化参数的值。\n   \n   * 以下代码创建一个形状为（3,4）的张量。 其中的每个元素都从均值为0、标准差为1的标准高斯分布（正态分布）中随机采样。\n   \n   * torch.randn(3, 4)\n     \n     * tensor([[ 0.1364,  0.3546, -0.9091, -1.8926],\n               [ 0.5786, -0.9019, -0.1305, -0.1899],\n               [ 0.5696,  1.1626, -0.5987,  0.4085]])\n       \n       \n       1\n       2\n       3\n       \n\n> 通过提供包含数值的python列表（或嵌套列表），来为所需张量中的每个元素赋予确定值\n\n * torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n   \n   * tensor([[2, 1, 4, 3],\n             [1, 2, 3, 4],\n             [4, 3, 2, 1]])\n     \n     \n     1\n     2\n     3\n     \n     \n     ==最外层的列表对应于轴0，内层的列表对应于轴1==\n\n\n# 运算符\n\n按元素（elementwise）运算。将标准标量运算符应用于数组的每个元素\n\n对于任意具有相同形状的张量， 常见的标准算术运算符（+、-、\\*、/和**）都可以被升级为按元素运算\n\n * x = torch.tensor([1.0, 2, 4, 8])\n   y = torch.tensor([2, 2, 2, 2])\n   x + y, x - y, x * y, x / y, x ** y  # **运算符是求幂运算\n   \n   \n   1\n   2\n   3\n   \n   \n   * (tensor([ 3.,  4.,  6., 10.]),\n      tensor([-1.,  0.,  2.,  6.]),\n      tensor([ 2.,  4.,  8., 16.]),\n      tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n      tensor([ 1.,  4., 16., 64.]))\n     \n     \n     1\n     2\n     3\n     4\n     5\n     \n\n * torch.exp(x)\n   \n   * tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])\n     \n     \n     1\n     \n   \n   ----------------------------------------\n\n> 把多个张量*连结*（concatenate）在一起， 把它们端对端地叠起来形成一个更大的张量。\n\n只需要提供张量列表，并给出沿哪个轴连结\n\n * 沿行（轴-0，形状的第一个元素） 和按列（轴-1，形状的第二个元素）连结两个矩阵\n   \n   * x = torch.arange(12, dtype=torch.float32).reshape(3,4)\n     y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n     torch.cat((x, y), dim=0), torch.cat((x, y), dim=1)\n     \n     \n     1\n     2\n     3\n     \n     \n     * (tensor([[ 0.,  1.,  2.,  3.],\n                [ 4.,  5.,  6.,  7.],\n                [ 8.,  9., 10., 11.],\n                [ 2.,  1.,  4.,  3.],\n                [ 1.,  2.,  3.,  4.],\n                [ 4.,  3.,  2.,  1.]]),\n        tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n                [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n                [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))\n       \n       \n       1\n       2\n       3\n       4\n       5\n       6\n       7\n       8\n       9\n       \n\n----------------------------------------\n\n> 通过逻辑运算符构建二元张量\n\n * 如果x和y在该位置相等，则新张量中相应项的值为1\n\n * x == y\n   \n   * tensor([[false,  true, false,  true],\n             [false, false, false, false],\n             [false, false, false, false]])\n     \n     \n     1\n     2\n     3\n     \n\n----------------------------------------\n\n> 对张量中的所有元素进行求和，会产生一个单元素张量\n\n * x.sum()\n   \n   * tensor(66.)\n     \n     \n     1\n     \n\n----------------------------------------\n\n\n# 广播机制\n\n形状不同，仍然可以通过调用 广播机制（broadcasting mechanism）来执行按元素操作\n\n * 首先，通过适当复制元素来扩展一个或两个数组， 以便在转换之后，两个张量具有相同的形状。\n   \n   * 其次，对生成的数组执行按元素操作。\n\n * a = torch.arange(3).reshape(3, 1)\n   b = torch.arange(2).reshape(1, 2)\n   a, b\n   \n   \n   1\n   2\n   3\n   \n   \n   (tensor([[0],\n            [1],\n            [2]]),\n    tensor([[0, 1]]))\n   \n   \n   1\n   2\n   3\n   4\n   \n\n矩阵a复制列， 矩阵b复制行\n\n * a + b\n   \n   * tensor([[0, 1],\n             [1, 2],\n             [2, 3]])\n     \n     \n     1\n     2\n     3\n     \n\n----------------------------------------\n\n\n# 索引和切片\n\n> 用[-1]选择最后一个元素，用[1:3]选择第二个和第三个元素\n> \n> 在二维中就是行元素\n\n * x[-1], x[1:3]\n   \n   * (tensor([ 8.,  9., 10., 11.]),\n      tensor([[ 4.,  5.,  6.,  7.],\n              [ 8.,  9., 10., 11.]]))\n     \n     \n     1\n     2\n     3\n     \n\n> 通过指定索引来将元素写入矩阵\n\n * x[1, 2] = 9\n   x\n   \n   \n   1\n   2\n   \n   \n   * tensor([[ 0.,  1.,  2.,  3.],\n             [ 4.,  5.,  9.,  7.],\n             [ 8.,  9., 10., 11.]])\n     \n     \n     1\n     2\n     3\n     \n\n> 为多个元素赋值相同的值\n\n * x[0:2, :] = 12\n   x\n   \n   \n   1\n   2\n   \n   \n   tensor([[12., 12., 12., 12.],\n           [12., 12., 12., 12.],\n           [ 8.,  9., 10., 11.]])\n   \n   \n   1\n   2\n   3\n   \n\n\n# 节省内存\n\n运行一些操作可能会导致为新结果分配内存。 例如，如果用y = x + y，将取消引用y指向的张量，而是指向新分配的内存处的张量。\n\n在下面的例子中，使用python的id()函数演示， id()函数提供了内存中引用对象的确切地址。\n\n运行y = y + x后，发现id(y)指向另一个位置。 这是因为python首先计算y + x，为结果分配新的内存，然后使y指向内存中的这个新位置。\n\n * before = id(y)\n   y = y + x\n   id(y) == before\n   \n   \n   1\n   2\n   3\n   \n   \n   false\n   \n   \n   1\n   \n\n这可能是不可取的，原因有两个：\n\n * 首先，不想总是不必要地分配内存。 在机器学习中，我们可能有数百兆的参数，并且在一秒内多次更新所有参数。 通常情况下，希望原地执行这些更新。\n * 其次，如果不原地更新，其他引用仍然会指向旧的内存位置， 这样某些代码可能会无意中引用旧的参数。\n\n> 所以需要执行原地操作。\n\n可以使用切片表示法将操作的结果分配给先前分配的数组，例如y[:] = <expression>。\n\n * 创建一个新的矩阵z，其形状与另一个y相同， 使用zeros_like来分配一个全00的块。\n   \n   * z = torch.zeros_like(y)\n     print('id(z):', id(z))\n     z[:] = x + y\n     print('id(z):', id(z))\n     \n     \n     1\n     2\n     3\n     4\n     \n     \n     id(z): 2016710171280\n     id(z): 2016710171280\n     \n     \n     1\n     2\n     \n\n * 如果在后续计算中没有重复使用x， 我们也可以使用x[:] = x + y或x += y来减少操作的内存开销\n   \n   * before = id(x)\n     x += y\n     id(x) == before\n     \n     \n     1\n     2\n     3\n     \n     \n     true\n     \n     \n     1\n     \n\n----------------------------------------\n\n\n# 转换为其他python对象\n\n将深度学习框架定义的张量转换为numpy张量（ndarray）很容易，反之也同样容易。 torch张量和numpy数组将共享它们的底层内存，就地操作更改一个张量也会同时更改另一个张量。\n\n * a = x.numpy()\n   b = torch.tensor(a)\n   type(a), type(b)\n   \n   \n   1\n   2\n   3\n   \n   \n   * (numpy.ndarray, torch.tensor)\n     \n     \n     1\n     \n\n----------------------------------------\n\n> 要(将大小为1的张量转换为python标量)，可以调用item函数或python的内置函数\n\na = torch.tensor([3.5])\na, a.item(), float(a), int(a)\n\n\n1\n2\n\n\n(tensor([3.5000]), 3.5, 3.5, 3)\n\n\n1\n\n\n\n# 预处理\n\n\n# 读取数据集\n\n> 创建一个人工数据集，并存储在csv（逗号分隔值）文件\n\nimport os\n\nos.makedirs(os.path.join('.', 'data'), exist_ok=true)\ndata_file = os.path.join('.', 'data', 'house_tiny.csv')\nwith open(data_file, 'w') as f:\n    f.write('numrooms,alley,price\\n')  # 列名\n    f.write('na,pave,127500\\n')  # 每行表示一个数据样本\n    f.write('2,na,106000\\n')\n    f.write('4,na,178100\\n')\n    f.write('na,na,140000\\n')\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n * print(data_file)\n\n'.\\\\data\\\\house_tiny.csv'\n\n\n1\n\n * os.path.join()函数：连接两个或更多的路径名组件\n   * 1.如果各组件名首字母不包含’/’，则函数会自动加上\n   * 2.如果有一个组件是一个绝对路径，则在它之前的所有组件均会被舍弃\n   * 3.如果最后一个组件为空，则生成的路径以一个’/’分隔符结尾\n * os.makedirs(name, mode=0o777, exist_ok=false):用来创建多层目录（单层请用os.mkdir)\n   * ame：想创建的目录名\n   * mode：要为目录设置的权限数字模式，默认的模式为 0o777 (八进制)。\n   * exist_ok：是否在目录存在时触发异常。如果exist_ok为false（默认值），则在目标目录已存在的情况下触发fileexistserror异常；如果exist_ok为true，则在目标目录已存在的情况下不会触发fileexistserror异常。\n\n> 从创建的csv文件中加载原始数据集\n\nimport pandas as pd\n\ndata = pd.read_csv(data_file)\nprint(data)\n\n\n1\n2\n3\n4\n\n\n\n\n\n# 处理缺失值\n\n“nan”项代表缺失值。 [为了处理缺失的数据，典型的方法包括*插值法*和*删除法*，] 其中插值法用一个替代值弥补缺失值，而删除法则直接忽略缺失值.\n\n * 通过位置索引iloc，将data分成inputs和outputs， 其中前者为data的前两列，而后者为data的最后一列。 对于inputs中缺少的数值，用同一列的均值替换“nan”项。\n   \n   * inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n     inputs = inputs.fillna(inputs.mean())\n     print(inputs)\n     \n     \n     1\n     2\n     3\n     \n     * \n     * 数值中的na用均值替换，字符串中的不行\n\n * [对于inputs中的类别值或离散值，我们将“nan”视为一个类别。] 由于“巷子类型”（“alley”）列只接受两种类型的类别值“pave”和“nan”， pandas可以自动将此列转换为两列“alley_pave”和“alley_nan”。 巷子类型为“pave”的行会将“alley_pave”的值设置为1，“alley_nan”的值设置为0。 缺少巷子类型的行会将“alley_pave”和“alley_nan”分别设置为0和1。\n   \n   * inputs = pd.get_dummies(inputs, dummy_na=true)\n     print(inputs)\n     \n     \n     1\n     2\n     \n     * \n\n----------------------------------------\n\n\n# 转换为张量格式\n\n现在inputs和outputs中的所有条目都是数值类型，它们可以转换为张量格式\n\nimport torch\n\nx, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\nx, y\n\n\n1\n2\n3\n4\n\n\n\n\n----------------------------------------\n\n\n# 线性代数\n\n\n# 向量\n\n\n# 矩阵\n\n\n# 范数\n\n# -范数的定义\n\n在很多机器学习相关的著作和教材中，经常看到各式各样的距离及范数，如\n\n\n\n其中， 分别表示向量和矩阵。\n\n当然，也会看到欧式距离、均方误差等。例如，向量 的欧式范数 (euclidean norm) 为\n\n\n\n用于表示向量的大小，这个范数也被叫做 -范数。\n\n * 为方便统一，一般将任意向量 的 -范数定义为:\n\n\n\n# 矩阵的范数\n\n上面是向量的范数，而矩阵的范数更加麻烦\n\n\n\n * 范数\n   * \n   * 取决于如何衡量b和c的长度\n * 常见范数\n   * 矩阵范数：最小的满足的上面公式的值\n   * frobenius 范数\n     * 矩阵范数计算比较麻烦，所以常用的是frobenius 范数\n     * 矩阵所有元素的平方和的算术平方根\n     * \n\n\n# 特殊矩阵\n\n# 对称和反对称\n\n\n\n# 正定\n\n\n\n正定矩阵乘以任意的列向量和行向量都大于等于0\n\n# 正交矩阵\n\n * 所以行都相互正交\n * 所有行都有单位长度\n   * \n * 可以写成(对角线都为1的单位矩阵)\n\n# 置换矩阵\n\n * 置换矩阵是一个方形二进制矩阵，它在每行和每列中只有一个1，而在其他地方则为0。\n\n * 置换矩阵： 当且仅当 $j=\\pi(i) $\n\n * 置换矩阵是正交矩阵\n\n----------------------------------------\n\n\n# 特征向量和特征值\n\n特征向量:不被矩阵改变方向的向量\n\n对称矩阵总是可以找到特征向量\n\n----------------------------------------\n\n\n# linear-algebra代码\n\n\n# 标量\n\n> 标量由只有一个元素的张量表示\n\nimport torch\n\nx = torch.tensor(3.0)\ny = torch.tensor(2.0)\n\nx + y, x * y, x / y, x**y\n\n\n1\n2\n3\n4\n5\n6\n\n\n(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))\n\n\n1\n\n\n\n# 向量\n\n> 向量可以视为标量值组成的列表。 将这些标量值称为向量的元素（element）或分量（component）。\n\nx = torch.arange(4)\nx\n\n\n1\n2\n\n\ntensor([0, 1, 2, 3])\n\n\n1\n\n\n==大量文献认为列向量是向量的默认方向==\n\n向量可以写为：\n\n\n# 长度、维度和形状\n\n * 向量只是一个数字数组，就像每个数组都有一个长度一样，每个向量也是如此。\n   \n   * 如果一个向量由个实值标量组成，可以将其表示为。 向量的长度通常称为向量的维度（dimension）。\n\n * 与普通的python数组一样，可以通过调用python的内置len()函数来访问张量的长度。\n   \n   * len(x)\n\n> 当用张量表示一个向量（只有一个轴）时，可以通过.shape属性访问向量的长度。\n> \n> 形状（shape）是一个元素组，列出了张量沿每个轴的长度（维数）。 对于(只有一个轴的张量，形状只有一个元素。)\n\nx.shape\n\ntorch.size([4])\n\n\n1\n\n\n==请注意==，维度（dimension）这个词在不同上下文时往往会有不同的含义：\n\n向量或轴的维度被用来表示向量或轴的长度，即向量或轴的元素数量。\n\n然而，张量的维度用来表示张量具有的轴数。\n\n在这个意义上，张量的某个轴的维数就是这个轴的长度。\n\n\n# 矩阵\n\n在数学表示法中，使用来表示矩阵，其由行和列的实值标量组成。\n\n> 当调用函数来实例化张量时， 可以通过指定两个分量𝑚和𝑛来创建一个形状为𝑚×𝑛的矩阵。\n\na = torch.arange(20).reshape(5, 4)\na\n\n\n1\n2\n\n\n\n\n> 转置（transpose）\n\na.t\n\n\n\n> 作为方阵的一种特殊类型，对称矩阵\\（symmetric matrix）𝐀等于其转置：𝐀=𝐀^⊤^\n\nb = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\nb\n\n\n1\n2\n\n\n\n\nb == b.t\n\n\n\n\n# 张量\n\n就像向量是标量的推广，矩阵是向量的推广一样，可以构建具有更多轴的数据结构。\n\n张量提供了描述具有任意数量轴的n维数组的通用方法。\n\n例如，向量是一阶张量，矩阵是二阶张量。\n\n张量用特殊字体的大写字母表示（例如，x、y和z），索引机制与矩阵类似。\n\n# 张量算法的基本性质\n\n给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量\n\na = torch.arange(20, dtype=torch.float32).reshape(5, 4)\nb = a.clone()  # 通过分配新内存，将a的一个副本分配给b\na, a + b\n\n\n1\n2\n3\n\n\n\n\n> 两个矩阵的按元素乘法称为hadamard积（hadamard product，哈达玛积）（数学符号⊙）\n\na * b\n\n\n\n> 将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘。\n\na = 2\nx = torch.arange(24).reshape(2, 3, 4)\na + x, (a * x).shape\n\n\n1\n2\n3\n\n\n\n\n----------------------------------------\n\n\n# 降维\n\n默认情况下，调用求和函数会沿所有的轴降低张量的维度，使它变为一个标量\n\nx = torch.arange(4, dtype=torch.float32)\nx, x.sum()\n\n\n1\n2\n\n\n(tensor([0., 1., 2., 3.]), tensor(6.))\n\n\n1\n\n\na.shape, a.sum()\n\n(torch.size([5, 4]), tensor(190.))\n\n\n1\n\n\n> 还可以指定张量沿哪一个轴来通过求和降低维度\n\n==指定哪个轴，哪个轴就消失==\n\n * a_sum_axis0 = a.sum(axis=0)\n   a_sum_axis0, a_sum_axis0.shape\n   \n   \n   1\n   2\n   \n   \n   (tensor([40., 45., 50., 55.]), torch.size([4]))\n   \n   \n   1\n   \n\n * a_sum_axis1 = a.sum(axis=1)\n   a_sum_axis1, a_sum_axis1.shape\n   \n   \n   1\n   2\n   \n   \n   (tensor([ 6., 22., 38., 54., 70.]), torch.size([5]))\n   \n   \n   1\n   \n\n> 可以同时指定多个轴\n\n * a.sum(axis=[0, 1])  # sameasa.sum()\n   \n   \n   1\n   \n   \n   tensor(190.)\n   \n   \n   1\n   \n\n----------------------------------------\n\n> 一个与求和相关的量是平均值（mean或average）\n\n * a.mean(), a.sum() / a.numel()\n   \n   \n   1\n   \n   \n   (tensor(9.5000), tensor(9.5000))\n   \n   \n   1\n   \n\n> 计算平均值的函数也可以沿指定轴降低张量的维度\n\n * a.mean(axis=0), a.sum(axis=0) / a.shape[0]\n   \n   \n   1\n   \n   \n   (tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))\n   \n   \n   1\n   \n\n\n# 非降维求和\n\n有时在调用函数来计算总和或均值时保持轴数不变会很有用,比如广播时需要保证轴数相等\n\n * 使用参数keepdims=true\n   \n   * sum_a = a.sum(axis=1, keepdims=true)\n     sum_a\n     \n     \n     1\n     2\n     \n     \n     \n\n==注意==：\n\n> 由于sum_a在对每行进行求和后仍保持两个轴，可以(通过广播将a除以sum_a)\n\n * a / sum_a\n   \n   \n\n> 如果想沿[某个轴计算a元素的累积总和]， 比如axis=0（按行计算），可以调用cumsum函数。 此函数不会沿任何轴降低输入张量的维度。\n\na.cumsum(axis=0)\n\n\n\n----------------------------------------\n\n\n# 点积（dot product）\n\n给定两个向量， 它们的点积（dot product）（或） 是相同位置的按元素乘积的和：\n\n * y = torch.ones(4, dtype = torch.float32)\n   x, y, torch.dot(x, y)\n   \n   \n   1\n   2\n   \n   \n   (tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))\n   \n   \n   1\n   \n   \n   > 也可以通过执行按元素乘法，然后进行求和来表示两个向量的点积\n   \n   * torch.sum(x * y)\n     \n     ensor(6.)\n     \n     \n     1\n     \n\n# 点积的应用\n\n例如\n\n * 给定一组由向量表示的值，和一组由表示的权重。中的值根据权重的加权和，可以表示为点积。\n * 当权重为非负数且和为1（即）时，点积表示加权平均（weighted average）。\n * 将两个向量规范化得到单位长度后，点积表示它们夹角的余弦。\n\n----------------------------------------\n\n\n# 矩阵-向量积\n\n矩阵-向量积（matrix-vector product）。\n\n * 定义矩阵和向量。\n   * 将矩阵用它的行向量表示：\n\n其中每个都是行向量，表示矩阵的第行。 矩阵向量积是一个长度为的列向量，其第个元素是点积：\n\n> 用与点积相同的mv函数表示矩阵-向量积。\n\n当为矩阵a和向量x调用torch.mv(a, x)时，会执行矩阵-向量积。\n\n注意，a的列维数（沿轴1的长度）必须与x的维数（其长度）相同。\n\na.shape, x.shape, torch.mv(a, x)#mv：matrix vector multiplication\n\n\n1\n\n\n(torch.size([5, 4]), torch.size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))\n\n\n1\n\n\n----------------------------------------\n\n可以把一个矩阵乘法看作是一个从到向量的转换。\n\n> 这些转换是非常有用的。\n> \n> 例如\n> \n>  * 可以用方阵的乘法来表示旋转。\n>  * 也可以使用矩阵-向量积来描述在给定前一层的值时，求解神经网络每一层所需的复杂计算。\n\n----------------------------------------\n\n\n# 矩阵-矩阵乘法\n\n矩阵-矩阵乘法（matrix-matrix multiplication）\n\n * 假设我们有两个矩阵和：\n\n * 用行向量表示矩阵的第行，并让列向量作为矩阵的第列。要生成矩阵积，最简单的方法是==考虑的行向量和的列向量==:\n\n * 简单地将==每个元素计算为点积==：\n\n==可以将矩阵-矩阵乘法看作是简单地执行次矩阵-向量积，并将结果拼接在一起，形成一个矩阵==。\n\n * torch.mm(a, b)#mm:matrix multiplication\n   \n   \n   1\n   \n   \n   \n\n==注意==：矩阵-矩阵乘法可以简单地称为矩阵乘法，不应与\"hadamard积\"混淆。\n\n----------------------------------------\n\n矩阵-矩阵乘法可以简单地称为矩阵乘法，不应与\"hadamard积\"混淆。\n\n\n# 范数\n\n * 线性代数中最有用的一些运算符是范数（norm）。\n   \n   * 非正式地说，一个向量的范数告诉我们一个向量有多大。\n   * 这里考虑的大小（size）概念不涉及维度，而是分量的大小。\n\n * 在线性代数中，向量范数是将向量映射到标量的函数。\n\n * 给定任意向量，向量范数要满足一些属性。\n   \n   * 第一个性质是：如果按常数因子缩放向量的所有元素，其范数也会按相同常数因子的绝对值缩放：\n     \n     * \n   \n   * 第二个性质是我们熟悉的三角不等式:\n     \n     * \n   \n   * 第三个性质简单地说范数必须是非负的:\n     \n     * \n     \n     * 因为在大多数情况下，任何东西的最小的大小是0。\n     \n     * 要求范数最小为0，当且仅当向量全由0组成。\n       \n       * \n\n> 范数听起来很像距离的度量。 如果你还记得欧几里得距离和毕达哥拉斯定理(勾股定理)，那么非负性的概念和三角不等式可能会给你一些启发。 事实上，==欧几里得距离是一个范数==：\n\n假设维向量中的元素是，其**范数是向量元素平方和的平方根：**\n\n($$|\\mathbf{x}|2 = \\sqrt{\\sum{i=1}^n x_i^2},$$)\n\n其中，在范数中常常省略下标，也就是说==等同于==。\n\n> 计算向量的范数\n\nu = torch.tensor([3.0, -4.0])\ntorch.norm(u)\n\n\n1\n2\n\n\ntensor(5.)\n\n\n1\n\n\n在深度学习中，我们更经常地使用范数的平方。 你还会经常遇到[范数，它表示为向量元素的绝对值之和：]\n\n($$|\\mathbf{x}|1 = \\sum{i=1}^n \\left|x_i \\right|.$$)\n\n与范数相比，范数受异常值的影响较小。\n\n> 为了计算范数，我们将绝对值函数和按元素求和组合起来。\n\ntorch.abs(u).sum()\n\n\n1\n\n\ntensor(7.)\n\n\n1\n\n * 范数和范数都是更一般的范数的特例：\n\n类似于向量的范数，==矩阵==**(**的frobenius范数（frobenius norm）是==矩阵元素平方和的平方根==：)\n\n($$|\\mathbf{x}|f = \\sqrt{\\sum{i=1}^m \\sum_{j=1}^n x_{ij}^2}.$$)\n\nfrobenius范数满足向量范数的所有性质，它就像是矩阵形向量的范数。\n\n> 计算矩阵的frobenius范数。\n\ntorch.norm(torch.ones((4, 9)))\n\n\n1\n\n\ntensor(6.)\n\n\n1\n\n\n# 范数和目标\n\n在深度学习中，经常试图解决优化问题：\n\n * 最大化分配给观测数据的概率;\n * 最小化预测和真实观测之间的距离。\n * 用向量表示物品（如单词、产品或新闻文章），以便最小化相似项目之间的距离，最大化不同项目之间的距离。\n * 目标，或许是深度学习算法最重要的组成部分（除了数据），通常被表达为范数。\n\n\n# more\n\n线性代数还有很多，其中很多数学对于机器学习非常有用。\n\n * 例如，矩阵可以分解为因子，这些分解可以显示真实世界数据集中的低维结构。\n\n * 机器学习的整个子领域都侧重于使用矩阵分解及其向高阶张量的泛化，来发现数据集中的结构并解决预测问题。\n\n线性代数运算的在线附录\n\n\n# 矩阵计算\n\n\n# 标量导数\n\n * 导数是切线的斜率\n   * \n * \n * \n\n\n# 亚导数\n\n将导数拓展到不可微的函数\n\n * * \n * \n\n\n# 梯度\n\n将导数拓展到向量\n\n * \n\n * ----------------------------------------\n\n\n# 标量对向量求导\n\n * * ==是列向量，导数是行向量==\n   * 比如,y=\n     * \n     * \n     * 梯度指向的是值变化最大的方向\n   * 比如\n   * ==内积求导==：l2-范数求导可以转化为内积求导\n\n * ----------------------------------------\n   \n   * \n\n * ----------------------------------------\n   \n   * \n   * \n\n# 拓展到矩阵\n\n----------------------------------------\n\n\n# 分子布局与分母布局\n\n# 前提\n\n 1. 分子分母都是向量，且一个是行向量，另一个是列向量\n 2. 分子分母一个是标量，另一个是行向量或列向量\n\n当满足1或2时，讨论分母布局/分子布局才有意义。\n\n# 结论\n\n 1. 谁是列向量就是什么布局。分母是列向量，就是分母布局；分子是列向量，就是分子布局。\n\n\n\n * \n * \n * \n\n> 中分母是列向量，所以是分母布局， 中分子是列向量，所以是分子布局\n> \n> 但要求统一是分子布局，所以把 的分母布局转置为分子布局\n\n\n# 自动求导\n\n * 深度学习框架可以自动计算导数：\n   * 首先将梯度附加到想要对其计算偏导数的变量上。然后\n   * 记录目标值的计算，执行它的反向传播函数，并访问得到的梯度。\n\n\n# 链式法则\n\n# 标量链式法则\n\n# 向量链式法则\n\n拓展到向量\n\n# 例1\n\n# 例2\n\n\n\n\n# 自动求导\n\n * 计算一个函数在指定值上的导数\n\n * 区别于符号求导和数值求导\n   \n   * 符号求导\n     * \n   * 数值求导\n     * \n\n\n# 计算图\n\n * 将代码分解成操作子\n * 将计算表示成一个无环图\n   * \n\n# 计算图的2中构造方式\n\n * 显示构造\n   * \n   * tensorflow/theano/mxnet\n * 隐式构造\n   * \n   * pytorch/mxnet\n   * 构造出tensor后，系统会记住所有的计算操作\n\n# 自动求导的2种模式\n\n正向累积和反向累积\n\n链式法则：\n\n * 正向累积\n   * \n * ==反向累积、又称反向传递（bp，backpropagation）==\n   * \n\n# 反向累积\n\n==步骤==\n\n1.构造计算图\n\n2.前向（forward）：执行图，存储中间结果\n\n3.反向（backward）：从相反方向执行图，然后去除不需要的枝\n\n * \n\n----------------------------------------\n\n * \n * \n * \n\n----------------------------------------\n\n==复杂度== 计算复杂度：o（n），n是操作子个数，通常正向和反向的代价类似 内存复杂度：o（n），因为需要存储正向的所有中间结果\n\n> 而正向累积： 计算复杂度:o（n），用来计算一个变量的梯度\n> \n> 内存复杂度:o（1），不保存中间值\n> \n> 神经网络中不用正向累积，因为需要对每一层都计算梯度\n\n----------------------------------------\n\n\n# autograd代码\n\n深度学习框架通过自动计算导数，即自动微分（automatic differentiation）来加快求导。\n\n实际中，根据我们设计的模型，系统会构建一个计算图（computational graph）， 来跟踪计算是哪些数据通过哪些操作组合起来产生输出。\n\n自动微分使系统能够随后反向传播梯度。 这里，反向传播（backpropagate）意味着跟踪整个计算图，==填充关于每个参数的偏导数==。\n\n# 例子\n\n对函数关于列向量求导\n\n> 首先，创建变量x并为其分配一个初始值。\n\n * import torch\n   \n   x = torch.arange(4.0)\n   x\n   \n   \n   1\n   2\n   3\n   4\n   \n   \n   tensor([0., 1., 2., 3.])\n   \n   \n   1\n   \n\n> 在计算𝑦关于𝐱的梯度之前，需要一个地方来存储梯度\n\n不会在每次对一个参数求导时都分配新的内存。\n\n因为经常会成千上万次地更新相同的参数，每次都分配新的内存可能很快就会将内存耗尽。\n\n注意，一个标量函数关于向量𝐱的梯度是向量，并且与𝐱具有相同的形状。\n\n * x.requires_grad_(true)  # 等价于x=torch.arange(4.0,requires_grad=true)\n   x.grad  # 默认值是none\n   \n   \n   1\n   2\n   \n   \n   tensor([1., 1., 1., 1.])\n   \n   \n   1\n   \n\n> 计算𝑦\n\n * y = 2 * torch.dot(x, x) # 内积\n   y\n   \n   \n   1\n   2\n   \n   \n   tensor(28., grad_fn=<mulbackward0>)\n   \n   \n   1\n   \n\n> 通过调用反向传播函数来自动计算y关于x每个分量的梯度\n\ny.backward()\nx.grad\n\n\n1\n2\n\n\ntensor([ 0.,  4.,  8., 12.])\n\n\n1\n\n\n> 函数关于的梯度应为。 快速验证这个梯度是否计算正确。\n\nx.grad == 4 * x\n\n\n1\n\n\ntensor([true, true, true, true])\n\n\n1\n\n\n> 计算x的另一个函数\n\n# 在默认情况下，pytorch会累积梯度，所以需要清除之前的值\nx.grad.zero_()#需要先清0，不然会累加上一个x.grad\ny = x.sum()#向量求和的导数全是1\ny.backward()\nx.grad\n\n\n1\n2\n3\n4\n5\n\n\ntensor([1., 1., 1., 1.])\n\n\n1\n\n\n# 非标量变量的反向传播\n\n当y不是标量时，向量y关于向量x的导数的最自然解释是一个矩阵。 对于高阶和高维的y和x，求导的结果可以是一个高阶张量。\n\n然而，虽然这些更奇特的对象确实出现在高级机器学习中（包括[深度学习中]）， 但当我们调用向量的反向计算时，我们通常会试图计算一批训练样本中每个组成部分的损失函数的导数。 ???这里，我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和。\n\n# 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。\n# 在我们的例子中，我们只想求偏导数的和，所以传递一个1的梯度是合适的\nx.grad.zero_()\ny = x * x#x*x表示各元素相乘，y是向量\n# 等价于y.backward(torch.ones(len(x)))？？？\ny.sum().backward()#y向量直接求导的结果是矩阵，所以把y向量通过sum转为标量\nx.grad\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\ntensor([0., 2., 4., 6.])\n\n\n1\n\n\n----------------------------------------\n\n# 分离计算\n\n有时，我们希望[将某些计算移动到记录的计算图之外]。 例如，假设y是作为x的函数计算的，而z则是作为y和x的函数计算的。 想象一下，我们想计算z关于x的梯度，但由于某种原因，我们希望将y视为一个常数，并且只考虑到x在y被计算后发挥的作用。\n\n在这里，我们可以分离y来返回一个新变量u，该变量与y具有相同的值，但丢弃计算图中如何计算y的任何信息。 换句话说，梯度不会向后流经u到x。 因此，下面的反向传播函数计算z=u*x关于x的偏导数，同时将u作为常数处理，而不是z=x*x*x关于x的偏导数。\n\nx.grad.zero_()\ny = x * x\nu = y.detach()\nz = u * x\n\nz.sum().backward()\nx.grad == u\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\ntensor([true, true, true, true])\n\n\n1\n\n\n由于记录了y的计算结果，我们可以随后在y上调用反向传播，得到y=x*x关于的x的导数，即2*x。\n\nx.grad.zero_()\ny.sum().backward()\nx.grad == 2 * x\n\n\n1\n2\n3\n\n\ntensor([true, true, true, true])\n\n\n1\n\n\n----------------------------------------\n\n# python控制流的梯度计算\n\n使用自动微分的一个好处是： [即使构建函数的计算图需要通过python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度]。 在下面的代码中，while循环的迭代次数和if语句的结果都取决于输入a的值。\n\ndef f(a):\n    b = a * 2\n    while b.norm() < 1000:\n        b = b * 2\n    if b.sum() > 0:\n        c = b\n    else:\n        c = 100 * b\n    return c\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n计算梯度\n\na = torch.randn(size=(), requires_grad=true)\nd = f(a)\nd.backward()\n\n\n1\n2\n3\n\n\n分析上面定义的f函数: 它在其输入a中是分段线性的。 对于任何a，存在某个常量标量k，使得f(a)=k*a，其中k的值取决于输入a。 因此，可以用d/a验证梯度是否正确。\n\na.grad == d / a\n\n\n1\n\n\ntensor(true)\n\n\n1\n\n\n----------------------------------------\n\n\n# 线性回归\n\n\n# 房价预测模型\n\n\n\n\n# 线性模型\n\n\n\n> 线性模型可以看做是单层神经网络\n\n> 神经网络源于神经科学\n\n\n# 衡量预估质量\n\n\n# 训练数据\n\n定义好模型和偏差后，开始学习参数（权重和偏差）\n\n\n# 参数学习\n\n\n# 显示解\n\n\n# 总结\n\n * 线性回归是对n维输入的加权，外加偏差\n * 使用平方损失来衡量预测值和真实值的差异\n * 线性回归有显示解\n * 线性回归可以看做是单层神经网络\n\n\n# 线性回归的从零开始实现\n\n * 从零开始实现整个方法，包括数据流水线、模型、损失函数和小批量随机梯度下降优化器\n   \n   * 虽然现代的深度学习框架几乎可以自动化地进行所有这些工作，但从零开始实现可以确保你真正知道自己在做什么。\n   * 同时，了解更细致的工作原理将方便我们自定义模型、自定义层或自定义损失函数。\n   * 将只使用张量和自动求导。\n\n * import random\n   import torch\n   from d2l import torch as d2l\n   \n   \n   1\n   2\n   3\n   \n   \n   \n   # 生成数据集\n   \n   为了简单起见，将根据带有噪声的线性模型构造一个人造数据集。 任务是使用这个有限样本的数据集来恢复这个模型的参数。 将使用低维数据，这样可以很容易地将其可视化。\n\n * 在下面的代码中，生成一个包含1000个样本的数据集，每个样本包含从标准正态分布中采样的2个特征。\n   \n   * 合成数据集是一个矩阵。\n   \n   * 使用线性模型参数、和噪声项生成数据集及其标签：\n   \n   * 可以将视为模型预测和标签时的潜在观测误差。\n   * 在这里认为标准假设成立，即服从均值为0的正态分布。\n   * 为了简化问题，将标准差设为0.01。\n\n> 生成合成数据集\n\n * def synthetic_data(w, b, num_examples):  #@save\n       \"\"\"生成y=xw+b+噪声\"\"\"\n       x = torch.normal(0, 1, (num_examples, len(w))) # 生成一个均值为0，方差为1的正态分布的矩阵\n       y = torch.matmul(x, w) + b\n       y += torch.normal(0, 0.01, y.shape) # 加入随机噪音\n       return x, y.reshape((-1, 1))  #保证最后的格式正确，而过程比如matmul中的格式可以随意\n   \n   true_w = torch.tensor([2, -3.4])\n   true_b = 4.2\n   features, labels = synthetic_data(true_w, true_b, 1000)\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   \n   * torch.mul | torch.mm | torch.bmm | torch.matmul的区别和使用\n\n> features中的每一行都包含一个二维数据样本，labels中的每一行都包含一维标签值（一个标量）。\n\n * print('features:', features[0],'\\nlabel:', labels[0])\n   \n   \n   1\n   \n   \n   \n\n> 生成第二个特征features[:, 1]和labels的散点图，可以直观观察到两者之间的线性关系\n\n * d2l.set_figsize()\n   d2l.plt.scatter(features[:, (1)].detach().numpy(), labels.detach().numpy(), 1);\n   \n   \n   1\n   2\n   \n   \n   \n\n\n# 读取数据集\n\n训练模型时要对数据集进行遍历，每次抽取一小批量样本，并使用它们来更新我们的模型。 由于这个过程是训练机器学习算法的基础，所以有必要定义一个函数，该函数能打乱数据集中的样本并以小批量方式获取数据。\n\n> 定义一个data_iter函数，该函数接收批量大小、特征矩阵和标签向量作为输入，生成大小为batch_size的小批量。\n> \n> 每个小批量包含一组特征和标签。\n\n * def data_iter(batch_size, features, labels):\n       num_examples = len(features)\n       indices = list(range(num_examples))\n       # 这些样本是随机读取的，没有特定的顺序\n       random.shuffle(indices)\n       for i in range(0, num_examples, batch_size):\n           batch_indices = torch.tensor(\n               indices[i: min(i + batch_size, num_examples)])\n           yield features[batch_indices], labels[batch_indices] #迭代器配合下面的for循环进行return，减少内存的占用\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   \n   * 利用gpu并行运算的优势，处理合理大小的“小批量”。\n   * 每个样本都可以并行地进行模型计算，且每个样本损失函数的梯度也可以被并行计算。\n   * gpu可以在处理几百个样本时，所花费的时间不比处理一个样本时多太多。\n   \n   > 直观感受一下小批量运算：读取第一个小批量数据样本并打印。\n   > \n   > 每个批量的特征维度显示批量大小和输入特征数。\n   > \n   > 同样的，批量的标签形状与batch_size相等。\n\n * batch_size = 10\n   \n   for x, y in data_iter(batch_size, features, labels):\n       print(x, '\\n', y)\n       break\n   \n   \n   1\n   2\n   3\n   4\n   5\n   \n   * 当运行迭代时，会连续地获得不同的小批量，直至遍历完整个数据集。\n   * 上面实现的迭代执行效率很低，可能会在实际问题上陷入麻烦。\n     * 例如，它要求我们将所有数据加载到内存中，并执行大量的随机内存访问。\n     * 在深度学习框架中实现的内置迭代器效率要高得多， 它可以处理存储在文件中的数据和数据流提供的数据。\n\n\n# 初始化模型参数\n\n在开始用小批量随机梯度下降优化模型参数之前， 需要先有一些参数。\n\n> 通过从均值为0、标准差为0.01的正态分布中采样随机数来初始化权重， 并将偏置初始化为0。\n\n * w = torch.normal(0, 0.01, size=(2,1), requires_grad=true)\n   b = torch.zeros(1, requires_grad=true)\n   \n   \n   1\n   2\n   \n   \n   * 在初始化参数之后，任务是更新这些参数，直到这些参数足够拟合数据。\n   \n   * 每次更新都需要计算损失函数关于模型参数的梯度。\n   \n   * 有了这个梯度，就可以向减小损失的方向更新每个参数。\n   \n   * 因为手动计算梯度很枯燥而且容易出错，所以没有人会手动计算梯度。 所以使用引入的自动微分来计算梯度。\n\n\n# 定义模型\n\n接下来，必须[定义模型，将模型的输入和参数同模型的输出关联起来。\n\n要计算线性模型的输出，只需计算输入特征和模型权重的矩阵-向量乘法后加上偏置。\n\n * 注意，上面的是一个向量，而是一个标量。\n   \n   * 这里是广播机制：当用一个向量加一个标量时，标量会被加到向量的每个分量上。\n\n * def linreg(x, w, b):  #@save\n       \"\"\"线性回归模型\"\"\"\n       return torch.matmul(x, w) + b\n   \n   \n   1\n   2\n   3\n   \n\n\n# 定义损失函数\n\n因为需要计算损失函数的梯度，所以应该先定义损失函数。\n\n使用平方损失函数。\n\n在实现中，需要将真实值y的形状转换为和预测值y_hat的形状相同。\n\ndef squared_loss(y_hat, y):  #@save\n    \"\"\"均方损失\"\"\"\n    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2\n\n\n1\n2\n3\n\n\n\n# 定义优化算法\n\n线性回归有解析解\n\n但其他模型却没有。所以使用小批量随机梯度下降。\n\n在每一步中，使用从数据集中随机抽取的一个小批量，然后根据参数计算损失的梯度。 接下来，朝着减少损失的方向更新参数。\n\n> 下面的函数实现小批量随机梯度下降更新。 该函数接受模型参数集合、学习速率和批量大小作为输入。\n> \n> 每一步更新的大小由学习速率lr决定。\n> \n> 因为计算的损失是一个批量样本的总和，所以用批量大小（batch_size） 来规范化步长，这样步长大小就不会取决于对批量大小的选择。\n\n * def sgd(params, lr, batch_size):  #@save\n       \"\"\"小批量随机梯度下降\"\"\" \n       with torch.no_grad(): # 更新时不需要梯度运算\n           for param in params:\n               param -= lr * param.grad / batch_size # 取了均值，与在上面损失函数取均值效果一样\n               param.grad.zero_() # 手动设置梯度为0\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   \n\n\n# 训练\n\n现在已经准备好了模型训练所有需要的要素，可以实现主要的训练过程部分了。\n\n * 在每次迭代中，读取一小批量训练样本，并通过模型来获得一组预测。\n * 计算完损失后，开始反向传播，存储每个参数的梯度。\n * 最后，我们调用优化算法sgd来更新模型参数。\n\n> 概括一下，将执行以下循环：\n\n * 初始化参数\n * 重复以下训练，直到完成\n   * 计算梯度\n   * 更新参数\n\n在每个迭代周期（epoch）中，使用data_iter函数遍历整个数据集，并将训练数据集中所有样本都使用一次（假设样本数能够被批量大小整除）。 这里的迭代周期个数num_epochs和学习率lr都是超参数，分别设为3和0.03。 设置超参数很棘手，需要通过反复试验进行调整。\n\nlr = 0.03\nnum_epochs = 3\nnet = linreg\nloss = squared_loss\n\nfor epoch in range(num_epochs):\n    for x, y in data_iter(batch_size, features, labels):\n        l = loss(net(x, w, b), y)  # x和y的小批量损失\n        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，\n        # 并以此计算关于[w,b]的梯度\n        l.sum().backward()\n        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数\n    with torch.no_grad():\n        train_l = loss(net(features, w, b), labels)\n        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\n> 因为使用的是自己合成的数据集，所以知道真正的参数是什么。\n> \n> 因此，我们可以通过比较真实参数和通过训练学到的参数来评估训练的成功程度。\n> \n> 事实上，真实参数和通过训练学到的参数确实非常接近。\n\n * print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}')\n   print(f'b的估计误差: {true_b - b}')\n   \n   \n   1\n   2\n   \n   \n   \n\n * 注意，不应该想当然地认为能够完美地求解参数。\n   \n   * 在机器学习中，通常不太关心恢复真正的参数，而更关心如何高度准确预测参数。\n   * 幸运的是，即使是在复杂的优化问题上，随机梯度下降通常也能找到非常好的解。\n   * 其中一个原因是，在深度网络中存在许多参数组合能够实现高度精确的预测。\n\n\n# 线性回归的简洁实现\n\n\n# 生成数据集\n\n> 首先生成数据集。\n\n * import numpy as np\n   import torch\n   from torch.utils import data\n   from d2l import torch as d2l\n   \n   true_w = torch.tensor([2, -3.4])\n   true_b = 4.2\n   features, labels = d2l.synthetic_data(true_w, true_b, 1000)\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   \n\n\n# 读取数据集\n\n可以调用框架中现有的api来读取数据。\n\n将features和labels作为api的参数传递，并通过数据迭代器指定batch_size。\n\n此外，布尔值is_train表示是否希望数据迭代器对象在每个迭代周期内打乱数据。\n\n * def load_array(data_arrays, batch_size, is_train=true):  #@save\n       \"\"\"构造一个pytorch数据迭代器\"\"\"\n       dataset = data.tensordataset(*data_arrays) # data.tensordataset对数据进行打包\n       return data.dataloader(dataset, batch_size, shuffle=is_train)\n   \n   batch_size = 10\n   data_iter = load_array((features, labels), batch_size)\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   \n\n> 为了验证是否正常工作，读取并打印第一个小批量样本。\n> \n> 这里使用iter构造python迭代器，并使用next从迭代器中获取第一项。\n\n * next(iter(data_iter))\n   \n   \n   1\n   \n\n\n# 定义模型\n\n对于标准深度学习模型，可以使用框架的预定义好的层。\n\n这使我们只需关注使用哪些层来构造模型，而不必关注层的实现细节。\n\n * 首先定义一个模型变量net，它是一个sequential类的实例。\n   * sequential类将多个层串联在一起。\n   * 当给定输入数据时，sequential实例将数据传入到第一层， 然后将第一层的输出作为第二层的输入，以此类推。\n   * 在下面的例子中，我们的模型只包含一个层，因此实际上不需要sequential。\n   * 但是由于以后几乎所有的模型都是多层的，在这里使用sequential会让你熟悉“标准的流水线”。\n\n回顾 :单层网络架构: 这一单层被称为全连接层（fully-connected layer）， 因为它的每一个输入都通过矩阵-向量乘法得到它的每个输出。\n\n在pytorch中，全连接层在linear类中定义。 值得注意的是，我们将两个参数传递到nn.linear中。 第一个指定输入特征形状，即2，第二个指定输出特征形状，输出特征形状为单个标量，因此为1。\n\n * # nn是神经网络的缩写\n   from torch import nn\n   \n   net = nn.sequential(nn.linear(2, 1)) # sequential函数将各层按顺序放在一起，然后可以通过索引访问\n   \n   \n   1\n   2\n   3\n   4\n   \n\n\n# 初始化模型参数\n\n在使用net之前，我们需要初始化模型参数。 如在线性回归模型中的权重和偏置。\n\n深度学习框架通常有预定义的方法来初始化参数。 在这里，我们指定每个权重参数应该从均值为0、标准差为0.01的正态分布中随机采样， 偏置参数将初始化为零。\n\n正如我们在构造nn.linear时指定输入和输出尺寸一样， 现在我们能直接访问参数以设定它们的初始值。\n\n我们通过net[0]选择网络中的第一个图层， 然后使用weight.data和bias.data方法访问参数。\n\n我们还可以使用替换方法normal_和fill_来重写参数值。\n\n * net[0].weight.data.normal_(0, 0.01) # normal_表示替换\n   net[0].bias.data.fill_(0)\n   \n   \n   1\n   2\n   \n\n\n# 定义损失函数\n\n[计算均方误差使用的是mseloss类，也称为平方范数]。默认情况下，它返回所有样本损失的平均值。\n\nloss = nn.mseloss()\n\n\n1\n\n\n\n# 定义优化算法\n\n小批量随机梯度下降算法是一种优化神经网络的标准工具， pytorch在optim模块中实现了该算法的许多变种。 当我们(实例化一个sgd实例)时，我们要指定优化的参数 （可通过net.parameters()从我们的模型中获得）以及优化算法所需的超参数字典。 小批量随机梯度下降只需要设置lr值，这里设置为0.03。\n\ntrainer = torch.optim.sgd(net.parameters(), lr=0.03)\n\n\n1\n\n\n\n# 训练\n\n通过深度学习框架的高级api来实现我们的模型只需要相对较少的代码。 我们不必单独分配参数、不必定义我们的损失函数，也不必手动实现小批量随机梯度下降。 当我们需要更复杂的模型时，高级api的优势将大大增加。 当我们有了所有的基本组件，[训练过程代码与我们从零开始实现时所做的非常相似]。\n\n回顾一下：在每个迭代周期里，我们将完整遍历一次数据集（train_data）， 不停地从中获取一个小批量的输入和相应的标签。 对于每一个小批量，我们会进行以下步骤:\n\n * 通过调用net(x)生成预测并计算损失l（前向传播）。\n * 通过进行反向传播来计算梯度。\n * 通过调用优化器来更新模型参数。\n\n为了更好的衡量训练效果，我们计算每个迭代周期后的损失，并打印它来监控训练过程。\n\nnum_epochs = 3\nfor epoch in range(num_epochs):\n    for x, y in data_iter:\n        l = loss(net(x) ,y)\n        trainer.zero_grad()\n        l.backward()\n        trainer.step() # 进行模型的更新\n    l = loss(net(features), labels)\n    print(f'epoch {epoch + 1}, loss {l:f}')\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n\n> 下面我们[比较生成数据集的真实参数和通过有限数据训练获得的模型参数]。 要访问参数，我们首先从net访问所需的层，然后读取该层的权重和偏置。 正如在从零开始实现中一样，我们估计得到的参数与生成数据的真实参数非常接近。\n\n * w = net[0].weight.data\n   print('w的估计误差：', true_w - w.reshape(true_w.shape))\n   b = net[0].bias.data\n   print('b的估计误差：', true_b - b)\n   \n   \n   1\n   2\n   3\n   4\n   \n   \n   \n\n\n# 小结\n\n * 我们可以使用pytorch的高级api更简洁地实现模型。\n * 在pytorch中，data模块提供了数据处理工具，nn模块定义了大量的神经网络层和常见损失函数。\n * 我们可以通过_结尾的方法将参数替换，从而初始化参数。\n\n\n# 基础优化算法\n\n\n# 梯度下降\n\n\n# 选择学习率\n\n\n# 小批量随机梯度下降\n\n\n# 选择批量大小\n\n\n# 总结\n\n * 梯度下降通过不断沿着反梯度方向更新参数求解\n * 小批量随机梯度下降是深度学习默认的求解算法\n * 两个重要的超参数是批量大小和学习率\n\n\n# 损失函数\n\n\n# l2损失 均方损失\n\n\n\n\n\n\n# l1 loss 绝对值损失函数\n\n有时候对于相隔较远的点，不希望大梯度更新参数。此时考虑绝对值损失函数\n\n\n\n\n\n真实值和预测值不管相隔多远，梯度都是常数，参数更新不会特别大，更稳定\n\n缺点是0点处不可导，且有剧烈的变化，导致优化末期不稳定\n\n\n# huber' s robust loss\n\n结合上面两者的优点 当相差大于1用绝对值误差，其他情况用均方误差\n\n\n\n\n# softmax回归\n\n\n# 回归vs分类\n\n * 回归估计一个连续值\n * 分类预测一个离散类别\n   * \n\n\n# 从回归到多类分类\n\n\n\n\n# 步骤\n\n\n\n\n# 无校验比例\n\n\n\n\n# 校验比例 softmax\n\n\n\n\n# 交叉熵损失\n\n\n\n\n# 总结\n\n * softmax回归是一个多类分类模型\n * 使用softmax操作子得到每个类的预测置信度\n * 使用交叉熵来来衡量预测和标号的区别\n\n\n# 图像分类数据集\n\nmnist数据集是图像分类中广泛使用的数据集之一，但作为基准数据集过于简单。 我们将使用类似但更复杂的fashion-mnist数据集。\n\nimport torch\nimport torchvision\nfrom torch.utils import data\nfrom torchvision import transforms\nfrom d2l import torch as d2l\n\nd2l.use_svg_display()\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 读取数据集\n\n通过框架中的内置函数将fashion-mnist数据集下载并读取到内存中。\n\n# 通过totensor实例将图像数据从pil类型变换成32位浮点数格式，\n# 并除以255使得所有像素的数值均在0到1之间\ntrans = transforms.totensor()\nmnist_train = torchvision.datasets.fashionmnist(\n    root=\"../data\", train=true, transform=trans, download=true)\nmnist_test = torchvision.datasets.fashionmnist(\n    root=\"../data\", train=false, transform=trans, download=true)\n\n\n1\n2\n3\n4\n5\n6\n7\n\n * fashion-mnist由10个类别的图像组成， 每个类别由训练数据集（train dataset）中的6000张图像 和测试数据集（test dataset）中的1000张图像组成。 因此，训练集和测试集分别包含60000和10000张图像。 测试数据集不会用于训练，只用于评估模型性能。\n\nlen(mnist_train), len(mnist_test)\n\n\n1\n\n\n\n\n * 每个输入图像的高度和宽度均为28像素。数据集由灰度图像组成，其通道数为1。为了简洁起见，本书将高度像素、宽度像素图像的形状记为或（,）。\n\nmnist_train[0][0].shape\n\n\n1\n\n\n\n\n * fashion-mnist中包含的10个类别，分别为t-shirt（t恤）、trouser（裤子）、pullover（套衫）、dress（连衣裙）、coat（外套）、sandal（凉鞋）、shirt（衬衫）、sneaker（运动鞋）、bag（包）和ankle boot（短靴）。 以下函数用于在数字标签索引及其文本名称之间进行转换。\n\ndef get_fashion_mnist_labels(labels):  #@save\n    \"\"\"返回fashion-mnist数据集的文本标签\"\"\"\n    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n    return [text_labels[int(i)] for i in labels]\n\n\n1\n2\n3\n4\n5\n\n * 创建一个函数来可视化这些样本\n\ndef show_images(imgs, num_rows, num_cols, titles=none, scale=1.5):  #@save\n    \"\"\"绘制图像列表\"\"\"\n    figsize = (num_cols * scale, num_rows * scale)\n    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)\n    axes = axes.flatten()\n    for i, (ax, img) in enumerate(zip(axes, imgs)):\n        if torch.is_tensor(img):\n            # 图片张量\n            ax.imshow(img.numpy())\n        else:\n            # pil图片\n            ax.imshow(img)\n        ax.axes.get_xaxis().set_visible(false)\n        ax.axes.get_yaxis().set_visible(false)\n        if titles:\n            ax.set_title(titles[i])\n    return axes\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n * 以下是训练数据集中前几个样本的图像及其相应的标签\n\nx, y = next(iter(data.dataloader(mnist_train, batch_size=18)))\nshow_images(x.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y));\n\n\n1\n2\n\n\n\n\n\n# 读取小批量\n\n为了使我们在读取训练集和测试集时更容易，我们使用内置的数据迭代器，而不是从零开始创建。 回顾一下，在每次迭代中，数据加载器每次都会[读取一小批量数据，大小为batch_size]。 通过内置数据迭代器，我们可以随机打乱了所有样本，从而无偏见地读取小批量。\n\nbatch_size = 256\n\ndef get_dataloader_workers():  #@save\n    \"\"\"使用4个进程来读取数据\"\"\"\n    return 4\n\ntrain_iter = data.dataloader(mnist_train, batch_size, shuffle=true,\n                             num_workers=get_dataloader_workers())\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * 读取训练数据所需的时间\n\ntimer = d2l.timer()\nfor x, y in train_iter:\n    continue\nf'{timer.stop():.2f} sec'\n\n\n1\n2\n3\n4\n\n\n\n\n\n# 整合所有组件\n\n现在我们[定义load_data_fashion_mnist函数]，用于获取和读取fashion-mnist数据集。 这个函数返回训练集和验证集的数据迭代器。 此外，这个函数还接受一个可选参数resize，用来将图像大小调整为另一种形状。\n\ndef load_data_fashion_mnist(batch_size, resize=none):  #@save\n    \"\"\"下载fashion-mnist数据集，然后将其加载到内存中\"\"\"\n    trans = [transforms.totensor()]\n    if resize:\n        trans.insert(0, transforms.resize(resize))\n    trans = transforms.compose(trans)\n    mnist_train = torchvision.datasets.fashionmnist(\n        root=\"../data\", train=true, transform=trans, download=true)\n    mnist_test = torchvision.datasets.fashionmnist(\n        root=\"../data\", train=false, transform=trans, download=true)\n    return (data.dataloader(mnist_train, batch_size, shuffle=true,\n                            num_workers=get_dataloader_workers()),\n            data.dataloader(mnist_test, batch_size, shuffle=false,\n                            num_workers=get_dataloader_workers()))\t\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n * 下面，我们通过指定resize参数来测试load_data_fashion_mnist函数的图像大小调整功能。\n\ntrain_iter, test_iter = load_data_fashion_mnist(32, resize=64)\nfor x, y in train_iter:\n    print(x.shape, x.dtype, y.shape, y.dtype)\n    break\n\n\n1\n2\n3\n4\n\n\n\n\n\n# 小结\n\n * fashion-mnist是一个服装分类数据集，由10个类别的图像组成。我们将在后续章节中使用此数据集来评估各种分类算法。\n * 我们将高度像素，宽度像素图像的形状记为或（,）。\n * 数据迭代器是获得更高性能的关键组件。依靠实现良好的数据迭代器，利用高性能计算来避免减慢训练过程。",charsets:{cjk:!0},lastUpdated:"2022/02/28, 22:17:26",lastUpdatedTimestamp:1646057846e3},{title:"222",frontmatter:{title:222,date:"2022-02-28T21:09:56.000Z",permalink:"/pages/6ca4c7/",categories:["理论","深度学习","动手学深度学习"],tags:[null]},regularPath:"/01.%E7%90%86%E8%AE%BA/02.%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/01.%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02.222.html",relativePath:"01.理论/02.深度学习/01.动手学深度学习/02.222.md",key:"v-823cda28",path:"/pages/6ca4c7/",headersStr:null,content:"dsffdF\n\n测试",normalizedContent:"dsffdf\n\n测试",charsets:{cjk:!0},lastUpdated:"2022/02/28, 22:33:00",lastUpdatedTimestamp:164605878e4},{title:"拥抱生活，拥抱快乐",frontmatter:{title:"拥抱生活，拥抱快乐",date:"2020-06-26T20:40:38.000Z",categories:["随笔"],tags:["鸡汤"],author:{name:"xugaoyi",link:"https://github.com/xugaoyi1"},permalink:"/pages/aef4fc1/"},regularPath:"/01.%E7%90%86%E8%AE%BA/10.index.html",relativePath:"01.理论/10.index.md",key:"v-26ba5490",path:"/pages/aef4fc1/",headers:[{level:2,title:"2",slug:"_2",normalizedTitle:"2",charIndex:2},{level:3,title:"3",slug:"_3",normalizedTitle:"3",charIndex:8},{level:2,title:"2.2",slug:"_2-2",normalizedTitle:"2.2",charIndex:27},{level:3,title:"2.3",slug:"_2-3",normalizedTitle:"2.3",charIndex:35},{level:2,title:"3.2",slug:"_3-2",normalizedTitle:"3.2",charIndex:51}],headersStr:"2 3 2.2 2.3 3.2",content:"# 2\n\n\n# 3\n\n# 4\n\n\n# 2.1\n\n\n# 2.2\n\n\n# 2.3\n\n\n# 3.1\n\n\n# 3.2",normalizedContent:"# 2\n\n\n# 3\n\n# 4\n\n\n# 2.1\n\n\n# 2.2\n\n\n# 2.3\n\n\n# 3.1\n\n\n# 3.2",charsets:{},lastUpdated:"2022/01/23, 15:18:17",lastUpdatedTimestamp:1642922297e3},{title:"第4级",frontmatter:{title:"第4级",date:"2020-06-26T20:40:38.000Z",categories:["随笔"],tags:["鸡汤"],author:{name:"xugaoyi",link:"https://github.com/xugaoyi"},permalink:"/pages/3c32a32/"},regularPath:"/01.%E7%90%86%E8%AE%BA/20.%E7%AC%AC2%E7%BA%A7/01.%E7%AC%AC3%E7%BA%A7/02.4.html",relativePath:"01.理论/20.第2级/01.第3级/02.4.md",key:"v-1ea88dca",path:"/pages/3c32a32/",headers:[{level:2,title:"2级",slug:"_2级",normalizedTitle:"2级",charIndex:9},{level:3,title:"3级",slug:"_3级",normalizedTitle:"3级",charIndex:16},{level:2,title:"2.2级",slug:"_2-2级",normalizedTitle:"2.2级",charIndex:38},{level:3,title:"2.3级",slug:"_2-3级",normalizedTitle:"2.3级",charIndex:47},{level:2,title:"3.2级",slug:"_3-2级",normalizedTitle:"3.2级",charIndex:81},{level:3,title:"3.3级",slug:"_3-3级",normalizedTitle:"3.3级",charIndex:90}],headersStr:"2级 3级 2.2级 2.3级 3.2级 3.3级",content:"# 1级\n\n\n# 2级\n\n\n# 3级\n\n# 4级\n\n\n# 2.1级\n\n\n# 2.2级\n\n\n# 2.3级\n\n# 2.4级\n\n# 2.5级\n\n\n# 3.1级\n\n\n# 3.2级\n\n\n# 3.3级\n\n# 3.4级",normalizedContent:"# 1级\n\n\n# 2级\n\n\n# 3级\n\n# 4级\n\n\n# 2.1级\n\n\n# 2.2级\n\n\n# 2.3级\n\n# 2.4级\n\n# 2.5级\n\n\n# 3.1级\n\n\n# 3.2级\n\n\n# 3.3级\n\n# 3.4级",charsets:{cjk:!0},lastUpdated:"2022/01/23, 15:18:17",lastUpdatedTimestamp:1642922297e3},{title:"拥抱生活，拥抱快乐",frontmatter:{title:"拥抱生活，拥抱快乐",date:"2020-06-26T20:40:38.000Z",categories:["随笔"],tags:["鸡汤"],author:{name:"xugaoyi",link:"https://github.com/xugaoyi"},permalink:"/pages/3c32a31/"},regularPath:"/01.%E7%90%86%E8%AE%BA/20.%E7%AC%AC2%E7%BA%A7/02.3.html",relativePath:"01.理论/20.第2级/02.3.md",key:"v-60297416",path:"/pages/3c32a31/",headers:[{level:2,title:"2",slug:"_2",normalizedTitle:"2",charIndex:8},{level:3,title:"3",slug:"_3",normalizedTitle:"3",charIndex:14},{level:2,title:"2.2",slug:"_2-2",normalizedTitle:"2.2",charIndex:33},{level:3,title:"2.3",slug:"_2-3",normalizedTitle:"2.3",charIndex:41},{level:2,title:"3.2",slug:"_3-2",normalizedTitle:"3.2",charIndex:57}],headersStr:"2 3 2.2 2.3 3.2",content:"# 1\n\n\n# 2\n\n\n# 3\n\n# 4\n\n\n# 2.1\n\n\n# 2.2\n\n\n# 2.3\n\n\n# 3.1\n\n\n# 3.2",normalizedContent:"# 1\n\n\n# 2\n\n\n# 3\n\n# 4\n\n\n# 2.1\n\n\n# 2.2\n\n\n# 2.3\n\n\n# 3.1\n\n\n# 3.2",charsets:{},lastUpdated:"2022/01/23, 15:18:17",lastUpdatedTimestamp:1642922297e3},{title:"课程安排",frontmatter:{title:"课程安排",date:"2022-01-21T12:25:41.000Z",permalink:"/pages/def99f/",categories:["实践","动手学深度学习(Dive into Deep Learning)"],tags:[null]},regularPath:"/02.%E5%AE%9E%E8%B7%B5/01.%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/01.%E8%AF%BE%E7%A8%8B%E5%AE%89%E6%8E%92.html",relativePath:"02.实践/01.动手学深度学习/01.课程安排.md",key:"v-85fee93c",path:"/pages/def99f/",headers:[{level:2,title:"目标",slug:"目标",normalizedTitle:"目标",charIndex:2},{level:2,title:"内容",slug:"内容",normalizedTitle:"内容",charIndex:138},{level:2,title:"资源",slug:"资源",normalizedTitle:"资源",charIndex:400}],headersStr:"目标 内容 资源",content:"# 目标\n\n * 介绍深度学习经典和最新模型\n   * LeNet，ResNet，LSTM，BERT，...\n * 机器学习基础\n   * 损失函数、目标函数、过拟合、优化\n * 实践\n   * 使用Pytorch实现介绍的知识点\n   * 在真实数据上体验算法效果\n\n\n# 内容\n\n * 深度学习基础\n   * 线性神经网络，多层感知机\n * 卷积神经网络\n   * LeNet，AlexNet，VGG，Inception，ResNet\n * 循环神经网络\n   * RNN，GRU，LSTM，seq2seq\n * 注意力机制\n   * Attention，Transformer\n * 优化算法\n   * SGD，Momentum，Adam\n * 高性能计算\n   * 并行，多GPU，分布式\n * 计算机视觉\n   * 目标检测，语义分割\n * 自然言处理\n   * 词嵌入，BERT\n\n\n# 资源\n\n * 课程主页：https://courses.d2l.ai/zh-v2/\n * 教材：https://zh-v2.d2l.ai/\n * 课程论坛讨论：https://discuss.d2l.ai/c/chinese-version/16\n * Pytorch论坛：https://discuss.pytorch.org/",normalizedContent:"# 目标\n\n * 介绍深度学习经典和最新模型\n   * lenet，resnet，lstm，bert，...\n * 机器学习基础\n   * 损失函数、目标函数、过拟合、优化\n * 实践\n   * 使用pytorch实现介绍的知识点\n   * 在真实数据上体验算法效果\n\n\n# 内容\n\n * 深度学习基础\n   * 线性神经网络，多层感知机\n * 卷积神经网络\n   * lenet，alexnet，vgg，inception，resnet\n * 循环神经网络\n   * rnn，gru，lstm，seq2seq\n * 注意力机制\n   * attention，transformer\n * 优化算法\n   * sgd，momentum，adam\n * 高性能计算\n   * 并行，多gpu，分布式\n * 计算机视觉\n   * 目标检测，语义分割\n * 自然言处理\n   * 词嵌入，bert\n\n\n# 资源\n\n * 课程主页：https://courses.d2l.ai/zh-v2/\n * 教材：https://zh-v2.d2l.ai/\n * 课程论坛讨论：https://discuss.d2l.ai/c/chinese-version/16\n * pytorch论坛：https://discuss.pytorch.org/",charsets:{cjk:!0},lastUpdated:"2022/02/03, 11:55:13",lastUpdatedTimestamp:1643860513e3},{title:"基础",frontmatter:{title:"基础",date:"2022-01-21T12:25:41.000Z",permalink:"/pages/3245f5/",categories:["实践","动手学深度学习(Dive into Deep Learning)"],tags:[null]},regularPath:"/02.%E5%AE%9E%E8%B7%B5/01.%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02.%E5%9F%BA%E7%A1%80.html",relativePath:"02.实践/01.动手学深度学习/02.基础.md",key:"v-745fbaa0",path:"/pages/3245f5/",headers:[{level:2,title:"深度学习介绍",slug:"深度学习介绍",normalizedTitle:"深度学习介绍",charIndex:2},{level:2,title:"数据操作和预处理",slug:"数据操作和预处理",normalizedTitle:"数据操作和预处理",charIndex:13},{level:3,title:"数据操作",slug:"数据操作",normalizedTitle:"数据操作",charIndex:13},{level:3,title:"预处理",slug:"预处理",normalizedTitle:"预处理",charIndex:18}],headersStr:"深度学习介绍 数据操作和预处理 数据操作 预处理",content:"# 深度学习介绍\n\n\n# 数据操作和预处理\n\n\n# 数据操作\n\n# N维数组\n\nN维数组是机器学习和神经网络的主要数据结构\n\n\n\n# 创建数组\n\n创建数组需要：\n\n * 形状：例如3x4矩阵\n * 每个元素的数据类型：例如32位浮点数（Tensor中默认是64位，而深度学习中常用32位）\n * 每个元素的值，例如全是0，或者随机数\n\n# 访问元素\n\n# 张量\n\n张量表示由一个数值组成的数组，这个数组可能有多个维度。 具有一个轴的张量对应数学上的向量（vector）； 具有两个轴的张量对应数学上的矩阵（matrix）； 具有两个轴以上的张量没有特殊的数学名称。\n\n> 首先，可以使用arange创建一个行向量x。 这个行向量包含从0开始的前12个整数，它们被默认创建为浮点数。 张量中的每个值都称为张量的元素（element）。 例如，张量x中有12个元素。 除非额外指定，新的张量默认将存储在内存中，并采用基于CPU的计算。\n\n * x = torch.arange(12)\n   * tensor([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n\n> 访问张量（沿每个轴的长度）的形状\n\n * x.shape\n   * torch.size([12])\n\n> 张量中元素的总数(标量)\n\n * x.numel()\n   * 12\n\n> 要想改变一个张量的形状而不改变元素数量和元素值，可以调用reshape函数,通过改变张量的形状，张量的大小不会改变。\n\n * X = x.reshape(3, 4)\n   \n   * tensor([[ 0,  1,  2,  3],\n             [ 4,  5,  6,  7],\n             [ 8,  9, 10, 11]])\n     \n     \n     1\n     2\n     3\n     \n   \n   * 可以通过-1来调用此自动计算出维度的功能。 即可以用x.reshape(-1,4)或x.reshape(3,-1)来取代x.reshape(3,4)\n\n> 使用全0、全1、其他常量，或者从特定分布中随机采样的数字来初始化矩阵\n\n * torch.zeros((2, 3, 4))\n   \n   * tensor([[[0., 0., 0., 0.],\n              [0., 0., 0., 0.],\n              [0., 0., 0., 0.]],\n     \n             [[0., 0., 0., 0.],\n              [0., 0., 0., 0.],\n              [0., 0., 0., 0.]]])\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     \n\n * torch.ones((2, 3, 4))\n   \n   * tensor([[[1., 1., 1., 1.],\n              [1., 1., 1., 1.],\n              [1., 1., 1., 1.]],\n     \n             [[1., 1., 1., 1.],\n              [1., 1., 1., 1.],\n              [1., 1., 1., 1.]]])\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     \n\n * 通过从某个特定的概率分布中随机采样来得到张量中每个元素的值。\n   \n   * 例如，当构造数组来作为神经网络中的参数时，通常会随机初始化参数的值。\n   \n   * 以下代码创建一个形状为（3,4）的张量。 其中的每个元素都从均值为0、标准差为1的标准高斯分布（正态分布）中随机采样。\n   \n   * torch.randn(3, 4)\n     \n     * tensor([[ 0.1364,  0.3546, -0.9091, -1.8926],\n               [ 0.5786, -0.9019, -0.1305, -0.1899],\n               [ 0.5696,  1.1626, -0.5987,  0.4085]])\n       \n       \n       1\n       2\n       3\n       \n\n> 通过提供包含数值的Python列表（或嵌套列表），来为所需张量中的每个元素赋予确定值\n\n * torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n   \n   * tensor([[2, 1, 4, 3],\n             [1, 2, 3, 4],\n             [4, 3, 2, 1]])\n     \n     \n     1\n     2\n     3\n     \n     \n     最外层的列表对应于轴0，内层的列表对应于轴1\n\n# 运算符\n\n按元素（elementwise）运算。将标准标量运算符应用于数组的每个元素\n\n对于任意具有相同形状的张量， 常见的标准算术运算符（+、-、*、/和**）都可以被升级为按元素运算\n\n * x = torch.tensor([1.0, 2, 4, 8])\n   y = torch.tensor([2, 2, 2, 2])\n   x + y, x - y, x * y, x / y, x ** y  # **运算符是求幂运算\n   \n   \n   1\n   2\n   3\n   \n   \n   * (tensor([ 3.,  4.,  6., 10.]),\n      tensor([-1.,  0.,  2.,  6.]),\n      tensor([ 2.,  4.,  8., 16.]),\n      tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n      tensor([ 1.,  4., 16., 64.]))\n     \n     \n     1\n     2\n     3\n     4\n     5\n     \n\n * torch.exp(x)\n   \n   * tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])\n     \n     \n     1\n     \n   \n   ----------------------------------------\n\n> 把多个张量连结（concatenate）在一起， 把它们端对端地叠起来形成一个更大的张量。\n\n只需要提供张量列表，并给出沿哪个轴连结\n\n * 沿行（轴-0，形状的第一个元素） 和按列（轴-1，形状的第二个元素）连结两个矩阵\n   \n   * X = torch.arange(12, dtype=torch.float32).reshape(3,4)\n     Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n     torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)\n     \n     \n     1\n     2\n     3\n     \n     \n     * (tensor([[ 0.,  1.,  2.,  3.],\n                [ 4.,  5.,  6.,  7.],\n                [ 8.,  9., 10., 11.],\n                [ 2.,  1.,  4.,  3.],\n                [ 1.,  2.,  3.,  4.],\n                [ 4.,  3.,  2.,  1.]]),\n        tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n                [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n                [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))\n       \n       \n       1\n       2\n       3\n       4\n       5\n       6\n       7\n       8\n       9\n       \n\n----------------------------------------\n\n> 通过逻辑运算符构建二元张量\n\n * 如果X和Y在该位置相等，则新张量中相应项的值为1\n\n * X == Y\n   \n   * tensor([[False,  True, False,  True],\n             [False, False, False, False],\n             [False, False, False, False]])\n     \n     \n     1\n     2\n     3\n     \n\n----------------------------------------\n\n> 对张量中的所有元素进行求和，会产生一个单元素张量\n\n * X.sum()\n   \n   * tensor(66.)\n     \n     \n     1\n     \n\n----------------------------------------\n\n# 广播机制\n\n形状不同，仍然可以通过调用 广播机制（broadcasting mechanism）来执行按元素操作\n\n * 首先，通过适当复制元素来扩展一个或两个数组， 以便在转换之后，两个张量具有相同的形状。\n   \n   * 其次，对生成的数组执行按元素操作。\n\n * a = torch.arange(3).reshape(3, 1)\n   b = torch.arange(2).reshape(1, 2)\n   a, b\n   \n   \n   1\n   2\n   3\n   \n   \n   (tensor([[0],\n            [1],\n            [2]]),\n    tensor([[0, 1]]))\n   \n   \n   1\n   2\n   3\n   4\n   \n\n矩阵a复制列， 矩阵b复制行\n\n * a + b\n   \n   * tensor([[0, 1],\n             [1, 2],\n             [2, 3]])\n     \n     \n     1\n     2\n     3\n     \n\n----------------------------------------\n\n# 索引和切片\n\n> 用[-1]选择最后一个元素，用[1:3]选择第二个和第三个元素\n> \n> 在二维中就是行元素\n\n * X[-1], X[1:3]\n   \n   * (tensor([ 8.,  9., 10., 11.]),\n      tensor([[ 4.,  5.,  6.,  7.],\n              [ 8.,  9., 10., 11.]]))\n     \n     \n     1\n     2\n     3\n     \n\n> 通过指定索引来将元素写入矩阵\n\n * X[1, 2] = 9\n   X\n   \n   \n   1\n   2\n   \n   \n   * tensor([[ 0.,  1.,  2.,  3.],\n             [ 4.,  5.,  9.,  7.],\n             [ 8.,  9., 10., 11.]])\n     \n     \n     1\n     2\n     3\n     \n\n> 为多个元素赋值相同的值\n\n * X[0:2, :] = 12\n   X\n   \n   \n   1\n   2\n   \n   \n   tensor([[12., 12., 12., 12.],\n           [12., 12., 12., 12.],\n           [ 8.,  9., 10., 11.]])\n   \n   \n   1\n   2\n   3\n   \n\n# 节省内存\n\n运行一些操作可能会导致为新结果分配内存。 例如，如果用Y = X + Y，将取消引用Y指向的张量，而是指向新分配的内存处的张量。\n\n在下面的例子中，使用Python的id()函数演示， id()函数提供了内存中引用对象的确切地址。\n\n运行Y = Y + X后，发现id(Y)指向另一个位置。 这是因为Python首先计算Y + X，为结果分配新的内存，然后使Y指向内存中的这个新位置。\n\n * before = id(Y)\n   Y = Y + X\n   id(Y) == before\n   \n   \n   1\n   2\n   3\n   \n   \n   False\n   \n   \n   1\n   \n\n这可能是不可取的，原因有两个：\n\n * 首先，不想总是不必要地分配内存。 在机器学习中，我们可能有数百兆的参数，并且在一秒内多次更新所有参数。 通常情况下，希望原地执行这些更新。\n * 其次，如果不原地更新，其他引用仍然会指向旧的内存位置， 这样某些代码可能会无意中引用旧的参数。\n\n> 所以需要**执行原地操作**。\n\n可以使用切片表示法将操作的结果分配给先前分配的数组，例如Y[:] = <expression>。\n\n * 创建一个新的矩阵Z，其形状与另一个Y相同， 使用zeros_like来分配一个全00的块。\n   \n   * Z = torch.zeros_like(Y)\n     print('id(Z):', id(Z))\n     Z[:] = X + Y\n     print('id(Z):', id(Z))\n     \n     \n     1\n     2\n     3\n     4\n     \n     \n     id(Z): 2016710171280\n     id(Z): 2016710171280\n     \n     \n     1\n     2\n     \n\n * 如果在后续计算中没有重复使用X， 我们也可以使用X[:] = X + Y或X += Y来减少操作的内存开销\n   \n   * before = id(X)\n     X += Y\n     id(X) == before\n     \n     \n     1\n     2\n     3\n     \n     \n     True\n     \n     \n     1\n     \n\n----------------------------------------\n\n# 转换为其他Python对象\n\n将深度学习框架定义的张量转换为NumPy张量（ndarray）很容易，反之也同样容易。 torch张量和numpy数组将共享它们的底层内存，就地操作更改一个张量也会同时更改另一个张量。\n\n * A = X.numpy()\n   B = torch.tensor(A)\n   type(A), type(B)\n   \n   \n   1\n   2\n   3\n   \n   \n   * (numpy.ndarray, torch.Tensor)\n     \n     \n     1\n     \n\n----------------------------------------\n\n> 要(将大小为1的张量转换为Python标量)，可以调用item函数或Python的内置函数\n\na = torch.tensor([3.5])\na, a.item(), float(a), int(a)\n\n\n1\n2\n\n\n(tensor([3.5000]), 3.5, 3.5, 3)\n\n\n1\n\n\n\n# 预处理\n\n# 读取数据集\n\n> 创建一个人工数据集，并存储在CSV（逗号分隔值）文件\n\nimport os\n\nos.makedirs(os.path.join('.', 'data'), exist_ok=True)\ndata_file = os.path.join('.', 'data', 'house_tiny.csv')\nwith open(data_file, 'w') as f:\n    f.write('NumRooms,Alley,Price\\n')  # 列名\n    f.write('NA,Pave,127500\\n')  # 每行表示一个数据样本\n    f.write('2,NA,106000\\n')\n    f.write('4,NA,178100\\n')\n    f.write('NA,NA,140000\\n')\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n * print(data_file)\n\n'.\\\\data\\\\house_tiny.csv'\n\n\n1\n\n * os.makedirs(name, mode=0o777, exist_ok=False):用来创建多层目录（单层请用os.mkdir)\n   * name：想创建的目录名\n   * mode：要为目录设置的权限数字模式，默认的模式为 0o777 (八进制)。\n   * exist_ok：是否在目录存在时触发异常。如果exist_ok为False（默认值），则在目标目录已存在的情况下触发FileExistsError异常；如果exist_ok为True，则在目标目录已存在的情况下不会触发FileExistsError异常。\n * os.path.join()函数：连接两个或更多的路径名组件\n   * 1.如果各组件名首字母不包含’/’，则函数会自动加上\n   * 2.如果有一个组件是一个绝对路径，则在它之前的所有组件均会被舍弃\n   * 3.如果最后一个组件为空，则生成的路径以一个’/’分隔符结尾\n\n> 从创建的CSV文件中加载原始数据集\n\nimport pandas as pd\n\ndata = pd.read_csv(data_file)\nprint(data)\n\n\n1\n2\n3\n4\n\n\n\n\n----------------------------------------\n\n# 补充：python 标准库：os\n\npython 标准库：os - 知乎 (zhihu.com)\n\n> os 顾名思义，就是与操作系统相关的标准库。如：文件，目录，执行系统命令等。\n\n# 1.导入模块\n\nos 是 python 标准库模块，随 python 一起安装，无需单独安装，可直接导入。\n\nimport os\n\n\n1\n\n\n# 2.path 子模块\n\n涉及与磁盘文件操作，最常使用的当属 path 模块了。path 是 os 的子模块，可以通过 from os import path 使用，也可以直接通过 os.path 属性的方式使用。本文，为了保持一致性，统一采用后者的书写形式。\n\n2.1 exists(path)\n\n检测文件或目录是否存在。存在返回 True , 不存在返回 False 。\n\nos.path.exists(\"dog.jpeg\")\nTrue\n\n\n1\n2\n\n\n2.2 isfile(path)\n\n判断是否为文件。是返回 True， 不是返回 False。也可以用来判断文件是否存在。\n\nos.path.isfile(\"dogs/\")\nFalse\n\n\n1\n2\n\n\n2.3 isdir(path)\n\n判断是否为目录。是返回 True， 不是返回 False。也可以用来判断目录是否存在。\n\nos.path.isdir(\"dogs/\")\nTrue\n\n\n1\n2\n\n\n2.4 basename(path)\n\n返回path最后的文件名。如果path以／或\\结尾，那么就会返回空值（含扩展）。\n\nos.path.basename(\"dir1/dir2/file.ext\")\n'file.ext'\n\n\n1\n2\n\n\n2.5 dirname(path)\n\n返回文件所在目录。\n\nos.path.dirname(\"dir1/dir2/file.ext\")\n'dir1/dir2'\n\n\n1\n2\n\n\n2.6 split(path)\n\n返回一个元组。元组第一个元素为文件所在目录，第二个元素为文件名（含扩展）。等效于 (dirname(path), basename(path))。\n\nos.path.split(\"dir1/dir2/file.ext\")\n('dir1/dir2', 'file.ext')\n\n\n1\n2\n\n\n2.7 splitext(path)\n\n返回一个元组。元组第一个元素为文件所在目录和文件名（不含扩展），第二个元素为扩展名（包含 .）。常用来读取或更改文件扩展名。\n\nos.path.splitext(\"dir1/dir2/file.ext\")\n('dir1/dir2/file', '.ext')\n\n\n1\n2\n\n\n*2.8 join(path, paths)\n\n将路径不同部分拼接成一个完整的路径。等效于 os.sep.join([path, *paths]) 。\n\nos.path.join(\"dir1\", \"dir2\", \"file.ext\")\n'dir1/dir2/file.ext'\n\n\n1\n2\n\n\n2.9 getsize(path)\n\n返回文件大小。单位字节。\n\nos.path.getsize(\"dog.jpeg\")\n18335\n\n\n1\n2\n\n\n# 3.目录操作\n\n3.1 listdir(path='.')\n\n返回一个列表。列表为给定目录下所有文件和子目录，但不包含特殊目录 . 和 ..。默认为当前目录。\n\nos.listdir(\"dogs\")[:5]\n['122.Pointer',\n '069.French_bulldog',\n '124.Poodle',\n '112.Nova_scotia_duck_tolling_retriever',\n '043.Canaan_dog']\n\n\n1\n2\n3\n4\n5\n6\n\n\n3.2 mkdir(path, mode=0o777)\n\n创建名为 path 的目录。并以数字形式指定目录权限，默认权限为 777 。\n\nos.mkdir(\"newdir\")\n\n\n1\n\n\n3.3 makedirs(path, mode=0o777)\n\n递归方式创建路径为 path 的目录。并以数字形式指定目录权限，默认权限为 777 。可以看作功能更强大的 mkdir，它会自动创建叶子节点目录的所有上级目录，而 mkdir 必须在上级目录已经存在情况下，才能创建叶子节点的目录。\n\nos.makedirs(\"parent/child/newdir\")\n\n\n1\n\n\n3.4 rmdir(path)\n\n删除目录。目录必须存在，并且只能删除空目录。不存在或不为空，都会异常。要想递归删除整个目录树，请使用 shutil.rmtree()。\n\nos.rmdir(\"newdir\")\n\n\n1\n\n\n3.5 removedirs(path)\n\n递归删除目录。目录必须存在，并且只能删除空目录。不存在或不为空，都会异常。与 rmdir 不同的是，在删除了叶子节点目录后，会逐次删除上级目录，直到遇到不为空的目录。\n\nos.removedirs(\"parent/child/newdir\")\n\n\n1\n\n\n3.6 remove(path)\n\n删除文件。不能删除目录，给定路径必须为文件，否则会异常。\n\nWarm Suggestion: 以下复制文件的操作，推荐使用 shutil.copyfile。\n\n# 复制文件\nwith open(\"dog.jpeg\", \"rb\") as f:\n    content = f.read()\n    with open(\"dog.copy.jpeg\", \"wb\") as f2:\n        f2.write(content)\n\n# 删除文件\nos.remove(\"dog.copy.jpeg\")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n# 4. 其他 os 接口\n\n4.1 getenv(key, default=None)\n\n获取环境变量。\n\nos.getenv(\"PATH\")\n'/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin'\n\n\n1\n2\n\n\n4.2 get_exec_path(env=None)\n\n返回用于搜索可执行文件的目录列表。看以看作是 PATH 环境变量的列表形式。\n\nos.get_exec_path()\n['/usr/local/bin',\n '/usr/bin',\n '/bin',\n '/usr/sbin',\n '/sbin']\n\n\n1\n2\n3\n4\n5\n6\n\n\n4.3 system(command)\n\n在当前进程中，启动子进程，执行命令 command（字符串），主进程会阻塞，直到子进程执行完成。这是通过调用标准C函数 system() 来实现的，并且具有相同的限制。\n\nif os.name == \"nt\":\n    command = \"dir\"\nelse:\n    command = \"ls -l\"\n\nos.system(command)\n0\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n----------------------------------------\n\n# 补充：python 使用 with open（） as 读写文件\n\npython 使用 with open（） as 读写文件_xrinosvip的博客-CSDN博客_python withopen\n\n# 读文件\n\n要以读文件的模式打开一个文件对象，使用Python内置的open()函数，传入文件名和标示符：\n\n>>> f = open('E:\\python\\python\\test.txt', 'r')\n\n\n1\n\n\n标示符'r'表示读，这样，我们就成功地打开了一个文件。\n\n如果文件不存在，open()函数就会抛出一个IOError的错误，并且给出错误码和详细的信息告诉你文件不存在：\n\nf=open('E:\\python\\python\\notfound.txt', 'r')\n\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nFileNotFoundError: [Errno 2] No such file or directory: 'E:\\python\\python\\notfound.txt'\n\n\n1\n2\n3\n4\n5\n\n\n如果文件打开成功，接下来，调用read()方法可以一次读取文件的全部内容，Python把内容读到内存，用一个str对象表示：\n\n>>> f.read()\n\n'Hello, python!'\n\n\n1\n2\n3\n\n\n最后一步是调用close()方法关闭文件。文件使用完毕后必须关闭，因为文件对象会占用操作系统的资源，并且操作系统同一时间能打开的文件数量也是有限的：\n\n>>> f.close()\n\n\n1\n\n\n由于文件读写时都有可能产生IOError，一旦出错，后面的f.close()就不会调用。所以，为了保证无论是否出错都能正确地关闭文件，我们可以使用try ... finally来实现：\n\ntry:\n    f = open('/path/', 'r')\n    print(f.read())\nfinally:\n    if f:\n        f.close()\n\n\n1\n2\n3\n4\n5\n6\n\n\n每次都这么写实在太繁琐，所以，Python引入了with语句来自动帮我们调用close()方法：\n\nwith open('/path/to/file', 'r') as f:\n    print(f.read())\n\n\n1\n2\n\n\n这和前面的try ... finally是一样的，但是代码更佳简洁，并且不必调用f.close()方法。\n\n调用read()会一次性读取文件的全部内容，如果文件有20G，内存就爆了，所以，要保险起见，可以反复调用read(size)方法，每次最多读取size个字节的内容。另外，调用readline()可以每次读取一行内容，调用readlines()一次读取所有内容并按行返回list。因此，要根据需要决定怎么调用。\n\n * 如果文件很小，read()一次性读取最方便；\n * 如果不能确定文件大小，反复调用read(size)比较保险；\n * 如果是配置文件，调用readlines()最方便：\n\nfor line in f.readlines():\n    print(line.strip()) # 把末尾的'\\n'删掉\n\n\n1\n2\n\n\n----------------------------------------\n\n# 写文件\n\n写文件和读文件是一样的，唯一区别是调用open()函数时，传入标识符'w'或者'wb'表示写文本文件或写二进制文件：\n\n>>> f = open('E:\\python\\python\\test.txt', 'w')\n>>> f.write('Hello, python!')\n>>> f.close()\n\n\n1\n2\n3\n\n\n可以反复调用write()来写入文件，但是务必要调用f.close()来关闭文件。当我们写文件时，操作系统往往不会立刻把数据写入磁盘，而是放到内存缓存起来，空闲的时候再慢慢写入。只有调用close()方法时，操作系统才保证把没有写入的数据全部写入磁盘。忘记调用close()的后果是数据可能只写了一部分到磁盘，剩下的丢失了。所以，还是用with语句来得保险：\n\nwith open('E:\\python\\python\\test.txt', 'w') as f:\n    f.write('Hello, python!')\n\n\n1\n2\n\n\n要写入特定编码的文本文件，请给open()函数传入encoding参数，将字符串自动转换成指定编码\n\n# 字符编码\n\n要读取非UTF-8编码的文本文件，需要给open()函数传入encoding参数，例如，读取GBK编码的文件：\n\n>>> f = open('E:\\python\\python\\gbk.txt', 'r', encoding='gbk')\n>>> f.read()\n'测试'\n\n\n1\n2\n3\n\n\n遇到有些编码不规范的文件，你可能会遇到UnicodeDecodeError，因为在文本文件中可能夹杂了一些非法编码的字符。遇到这种情况，open()函数还接收一个errors参数，表示如果遇到编码错误后如何处理。最简单的方式是直接忽略：\n\n>>> f = open('E:\\python\\python\\gbk.txt', 'r', encoding='gbk', errors='ignore')\n\n\n1\n\n\n# 二进制文件\n\n前面讲的默认都是读取文本文件，并且是UTF-8编码的文本文件。要读取二进制文件，比如图片、视频等等，用'rb'模式打开文件即可：\n\n>>> f = open('E:\\python\\python\\test.jpg', 'rb')\n>>> f.read()\nb'\\xff\\xd8\\xff\\xe1\\x00\\x18Exif\\x00\\x00...' # 十六进制表示的字节\n\n\n1\n2\n3\n\n\n总结：以后读写文件尽量使用with open语句，少使用f = open()语句\n\n对于多个文件的读写，可以写成以下两种方式：\n\n1、\n\nwith open('C:\\Desktop\\text.txt','r') as f:\n    with open('C:\\Desktop\\text1.txt','r') as f1:\n        with open('C:\\Desktop\\text2.txt','r') as f2　　　　　　\n        ........　　　　　　　\n        ........　　　　　　　\n        ........\n\n\n1\n2\n3\n4\n5\n6\n\n\n2、\n\nwith open(''C:\\Desktop\\text.txt','r') as f:\n........\nwith open(''C:\\Desktop\\text1.txt','r') as f1:\n........\nwith open('C:\\Desktop\\text2.txt','r') as f2:\n........\n\n\n1\n2\n3\n4\n5\n6\n\n\n# 文件的读写方式列表\n\n# File 对象属性\n\n\n\n----------------------------------------\n\n# 处理缺失值\n\n“NaN”项代表缺失值。为了处理缺失的数据，典型的方法包括插值法和删除法， 其中插值法用一个替代值弥补缺失值，而删除法则直接忽略缺失值.\n\n * 通过位置索引iloc，将data分成inputs和outputs， 其中前者为data的前两列，而后者为data的最后一列。 对于inputs中缺少的数值，用同一列的均值替换“NaN”项。\n   \n   * inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n     inputs = inputs.fillna(inputs.mean())\n     print(inputs)\n     \n     \n     1\n     2\n     3\n     \n     * \n     * 数值中的NA用均值替换，字符串中的不行\n\n * 对于inputs中的类别值或离散值，我们将“NaN”视为一个类别。 由于“巷子类型”（“Alley”）列只接受两种类型的类别值“Pave”和“NaN”， pandas可以自动将此列转换为两列“Alley_Pave”和“Alley_nan”。 巷子类型为“Pave”的行会将“Alley_Pave”的值设置为1，“Alley_nan”的值设置为0。 缺少巷子类型的行会将“Alley_Pave”和“Alley_nan”分别设置为0和1。\n   \n   * inputs = pd.get_dummies(inputs, dummy_na=True)\n     print(inputs)\n     \n     \n     1\n     2\n     \n     * \n\n----------------------------------------\n\n# 转换为张量格式\n\n现在inputs和outputs中的所有条目都是数值类型，它们可以转换为张量格式\n\nimport torch\n\nX, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\nX, y\n\n\n1\n2\n3\n4\n\n\n",normalizedContent:"# 深度学习介绍\n\n\n# 数据操作和预处理\n\n\n# 数据操作\n\n# n维数组\n\nn维数组是机器学习和神经网络的主要数据结构\n\n\n\n# 创建数组\n\n创建数组需要：\n\n * 形状：例如3x4矩阵\n * 每个元素的数据类型：例如32位浮点数（tensor中默认是64位，而深度学习中常用32位）\n * 每个元素的值，例如全是0，或者随机数\n\n# 访问元素\n\n# 张量\n\n张量表示由一个数值组成的数组，这个数组可能有多个维度。 具有一个轴的张量对应数学上的向量（vector）； 具有两个轴的张量对应数学上的矩阵（matrix）； 具有两个轴以上的张量没有特殊的数学名称。\n\n> 首先，可以使用arange创建一个行向量x。 这个行向量包含从0开始的前12个整数，它们被默认创建为浮点数。 张量中的每个值都称为张量的元素（element）。 例如，张量x中有12个元素。 除非额外指定，新的张量默认将存储在内存中，并采用基于cpu的计算。\n\n * x = torch.arange(12)\n   * tensor([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n\n> 访问张量（沿每个轴的长度）的形状\n\n * x.shape\n   * torch.size([12])\n\n> 张量中元素的总数(标量)\n\n * x.numel()\n   * 12\n\n> 要想改变一个张量的形状而不改变元素数量和元素值，可以调用reshape函数,通过改变张量的形状，张量的大小不会改变。\n\n * x = x.reshape(3, 4)\n   \n   * tensor([[ 0,  1,  2,  3],\n             [ 4,  5,  6,  7],\n             [ 8,  9, 10, 11]])\n     \n     \n     1\n     2\n     3\n     \n   \n   * 可以通过-1来调用此自动计算出维度的功能。 即可以用x.reshape(-1,4)或x.reshape(3,-1)来取代x.reshape(3,4)\n\n> 使用全0、全1、其他常量，或者从特定分布中随机采样的数字来初始化矩阵\n\n * torch.zeros((2, 3, 4))\n   \n   * tensor([[[0., 0., 0., 0.],\n              [0., 0., 0., 0.],\n              [0., 0., 0., 0.]],\n     \n             [[0., 0., 0., 0.],\n              [0., 0., 0., 0.],\n              [0., 0., 0., 0.]]])\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     \n\n * torch.ones((2, 3, 4))\n   \n   * tensor([[[1., 1., 1., 1.],\n              [1., 1., 1., 1.],\n              [1., 1., 1., 1.]],\n     \n             [[1., 1., 1., 1.],\n              [1., 1., 1., 1.],\n              [1., 1., 1., 1.]]])\n     \n     \n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     \n\n * 通过从某个特定的概率分布中随机采样来得到张量中每个元素的值。\n   \n   * 例如，当构造数组来作为神经网络中的参数时，通常会随机初始化参数的值。\n   \n   * 以下代码创建一个形状为（3,4）的张量。 其中的每个元素都从均值为0、标准差为1的标准高斯分布（正态分布）中随机采样。\n   \n   * torch.randn(3, 4)\n     \n     * tensor([[ 0.1364,  0.3546, -0.9091, -1.8926],\n               [ 0.5786, -0.9019, -0.1305, -0.1899],\n               [ 0.5696,  1.1626, -0.5987,  0.4085]])\n       \n       \n       1\n       2\n       3\n       \n\n> 通过提供包含数值的python列表（或嵌套列表），来为所需张量中的每个元素赋予确定值\n\n * torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n   \n   * tensor([[2, 1, 4, 3],\n             [1, 2, 3, 4],\n             [4, 3, 2, 1]])\n     \n     \n     1\n     2\n     3\n     \n     \n     最外层的列表对应于轴0，内层的列表对应于轴1\n\n# 运算符\n\n按元素（elementwise）运算。将标准标量运算符应用于数组的每个元素\n\n对于任意具有相同形状的张量， 常见的标准算术运算符（+、-、*、/和**）都可以被升级为按元素运算\n\n * x = torch.tensor([1.0, 2, 4, 8])\n   y = torch.tensor([2, 2, 2, 2])\n   x + y, x - y, x * y, x / y, x ** y  # **运算符是求幂运算\n   \n   \n   1\n   2\n   3\n   \n   \n   * (tensor([ 3.,  4.,  6., 10.]),\n      tensor([-1.,  0.,  2.,  6.]),\n      tensor([ 2.,  4.,  8., 16.]),\n      tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n      tensor([ 1.,  4., 16., 64.]))\n     \n     \n     1\n     2\n     3\n     4\n     5\n     \n\n * torch.exp(x)\n   \n   * tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])\n     \n     \n     1\n     \n   \n   ----------------------------------------\n\n> 把多个张量连结（concatenate）在一起， 把它们端对端地叠起来形成一个更大的张量。\n\n只需要提供张量列表，并给出沿哪个轴连结\n\n * 沿行（轴-0，形状的第一个元素） 和按列（轴-1，形状的第二个元素）连结两个矩阵\n   \n   * x = torch.arange(12, dtype=torch.float32).reshape(3,4)\n     y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n     torch.cat((x, y), dim=0), torch.cat((x, y), dim=1)\n     \n     \n     1\n     2\n     3\n     \n     \n     * (tensor([[ 0.,  1.,  2.,  3.],\n                [ 4.,  5.,  6.,  7.],\n                [ 8.,  9., 10., 11.],\n                [ 2.,  1.,  4.,  3.],\n                [ 1.,  2.,  3.,  4.],\n                [ 4.,  3.,  2.,  1.]]),\n        tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n                [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n                [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))\n       \n       \n       1\n       2\n       3\n       4\n       5\n       6\n       7\n       8\n       9\n       \n\n----------------------------------------\n\n> 通过逻辑运算符构建二元张量\n\n * 如果x和y在该位置相等，则新张量中相应项的值为1\n\n * x == y\n   \n   * tensor([[false,  true, false,  true],\n             [false, false, false, false],\n             [false, false, false, false]])\n     \n     \n     1\n     2\n     3\n     \n\n----------------------------------------\n\n> 对张量中的所有元素进行求和，会产生一个单元素张量\n\n * x.sum()\n   \n   * tensor(66.)\n     \n     \n     1\n     \n\n----------------------------------------\n\n# 广播机制\n\n形状不同，仍然可以通过调用 广播机制（broadcasting mechanism）来执行按元素操作\n\n * 首先，通过适当复制元素来扩展一个或两个数组， 以便在转换之后，两个张量具有相同的形状。\n   \n   * 其次，对生成的数组执行按元素操作。\n\n * a = torch.arange(3).reshape(3, 1)\n   b = torch.arange(2).reshape(1, 2)\n   a, b\n   \n   \n   1\n   2\n   3\n   \n   \n   (tensor([[0],\n            [1],\n            [2]]),\n    tensor([[0, 1]]))\n   \n   \n   1\n   2\n   3\n   4\n   \n\n矩阵a复制列， 矩阵b复制行\n\n * a + b\n   \n   * tensor([[0, 1],\n             [1, 2],\n             [2, 3]])\n     \n     \n     1\n     2\n     3\n     \n\n----------------------------------------\n\n# 索引和切片\n\n> 用[-1]选择最后一个元素，用[1:3]选择第二个和第三个元素\n> \n> 在二维中就是行元素\n\n * x[-1], x[1:3]\n   \n   * (tensor([ 8.,  9., 10., 11.]),\n      tensor([[ 4.,  5.,  6.,  7.],\n              [ 8.,  9., 10., 11.]]))\n     \n     \n     1\n     2\n     3\n     \n\n> 通过指定索引来将元素写入矩阵\n\n * x[1, 2] = 9\n   x\n   \n   \n   1\n   2\n   \n   \n   * tensor([[ 0.,  1.,  2.,  3.],\n             [ 4.,  5.,  9.,  7.],\n             [ 8.,  9., 10., 11.]])\n     \n     \n     1\n     2\n     3\n     \n\n> 为多个元素赋值相同的值\n\n * x[0:2, :] = 12\n   x\n   \n   \n   1\n   2\n   \n   \n   tensor([[12., 12., 12., 12.],\n           [12., 12., 12., 12.],\n           [ 8.,  9., 10., 11.]])\n   \n   \n   1\n   2\n   3\n   \n\n# 节省内存\n\n运行一些操作可能会导致为新结果分配内存。 例如，如果用y = x + y，将取消引用y指向的张量，而是指向新分配的内存处的张量。\n\n在下面的例子中，使用python的id()函数演示， id()函数提供了内存中引用对象的确切地址。\n\n运行y = y + x后，发现id(y)指向另一个位置。 这是因为python首先计算y + x，为结果分配新的内存，然后使y指向内存中的这个新位置。\n\n * before = id(y)\n   y = y + x\n   id(y) == before\n   \n   \n   1\n   2\n   3\n   \n   \n   false\n   \n   \n   1\n   \n\n这可能是不可取的，原因有两个：\n\n * 首先，不想总是不必要地分配内存。 在机器学习中，我们可能有数百兆的参数，并且在一秒内多次更新所有参数。 通常情况下，希望原地执行这些更新。\n * 其次，如果不原地更新，其他引用仍然会指向旧的内存位置， 这样某些代码可能会无意中引用旧的参数。\n\n> 所以需要**执行原地操作**。\n\n可以使用切片表示法将操作的结果分配给先前分配的数组，例如y[:] = <expression>。\n\n * 创建一个新的矩阵z，其形状与另一个y相同， 使用zeros_like来分配一个全00的块。\n   \n   * z = torch.zeros_like(y)\n     print('id(z):', id(z))\n     z[:] = x + y\n     print('id(z):', id(z))\n     \n     \n     1\n     2\n     3\n     4\n     \n     \n     id(z): 2016710171280\n     id(z): 2016710171280\n     \n     \n     1\n     2\n     \n\n * 如果在后续计算中没有重复使用x， 我们也可以使用x[:] = x + y或x += y来减少操作的内存开销\n   \n   * before = id(x)\n     x += y\n     id(x) == before\n     \n     \n     1\n     2\n     3\n     \n     \n     true\n     \n     \n     1\n     \n\n----------------------------------------\n\n# 转换为其他python对象\n\n将深度学习框架定义的张量转换为numpy张量（ndarray）很容易，反之也同样容易。 torch张量和numpy数组将共享它们的底层内存，就地操作更改一个张量也会同时更改另一个张量。\n\n * a = x.numpy()\n   b = torch.tensor(a)\n   type(a), type(b)\n   \n   \n   1\n   2\n   3\n   \n   \n   * (numpy.ndarray, torch.tensor)\n     \n     \n     1\n     \n\n----------------------------------------\n\n> 要(将大小为1的张量转换为python标量)，可以调用item函数或python的内置函数\n\na = torch.tensor([3.5])\na, a.item(), float(a), int(a)\n\n\n1\n2\n\n\n(tensor([3.5000]), 3.5, 3.5, 3)\n\n\n1\n\n\n\n# 预处理\n\n# 读取数据集\n\n> 创建一个人工数据集，并存储在csv（逗号分隔值）文件\n\nimport os\n\nos.makedirs(os.path.join('.', 'data'), exist_ok=true)\ndata_file = os.path.join('.', 'data', 'house_tiny.csv')\nwith open(data_file, 'w') as f:\n    f.write('numrooms,alley,price\\n')  # 列名\n    f.write('na,pave,127500\\n')  # 每行表示一个数据样本\n    f.write('2,na,106000\\n')\n    f.write('4,na,178100\\n')\n    f.write('na,na,140000\\n')\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\n * print(data_file)\n\n'.\\\\data\\\\house_tiny.csv'\n\n\n1\n\n * os.makedirs(name, mode=0o777, exist_ok=false):用来创建多层目录（单层请用os.mkdir)\n   * name：想创建的目录名\n   * mode：要为目录设置的权限数字模式，默认的模式为 0o777 (八进制)。\n   * exist_ok：是否在目录存在时触发异常。如果exist_ok为false（默认值），则在目标目录已存在的情况下触发fileexistserror异常；如果exist_ok为true，则在目标目录已存在的情况下不会触发fileexistserror异常。\n * os.path.join()函数：连接两个或更多的路径名组件\n   * 1.如果各组件名首字母不包含’/’，则函数会自动加上\n   * 2.如果有一个组件是一个绝对路径，则在它之前的所有组件均会被舍弃\n   * 3.如果最后一个组件为空，则生成的路径以一个’/’分隔符结尾\n\n> 从创建的csv文件中加载原始数据集\n\nimport pandas as pd\n\ndata = pd.read_csv(data_file)\nprint(data)\n\n\n1\n2\n3\n4\n\n\n\n\n----------------------------------------\n\n# 补充：python 标准库：os\n\npython 标准库：os - 知乎 (zhihu.com)\n\n> os 顾名思义，就是与操作系统相关的标准库。如：文件，目录，执行系统命令等。\n\n# 1.导入模块\n\nos 是 python 标准库模块，随 python 一起安装，无需单独安装，可直接导入。\n\nimport os\n\n\n1\n\n\n# 2.path 子模块\n\n涉及与磁盘文件操作，最常使用的当属 path 模块了。path 是 os 的子模块，可以通过 from os import path 使用，也可以直接通过 os.path 属性的方式使用。本文，为了保持一致性，统一采用后者的书写形式。\n\n2.1 exists(path)\n\n检测文件或目录是否存在。存在返回 true , 不存在返回 false 。\n\nos.path.exists(\"dog.jpeg\")\ntrue\n\n\n1\n2\n\n\n2.2 isfile(path)\n\n判断是否为文件。是返回 true， 不是返回 false。也可以用来判断文件是否存在。\n\nos.path.isfile(\"dogs/\")\nfalse\n\n\n1\n2\n\n\n2.3 isdir(path)\n\n判断是否为目录。是返回 true， 不是返回 false。也可以用来判断目录是否存在。\n\nos.path.isdir(\"dogs/\")\ntrue\n\n\n1\n2\n\n\n2.4 basename(path)\n\n返回path最后的文件名。如果path以／或\\结尾，那么就会返回空值（含扩展）。\n\nos.path.basename(\"dir1/dir2/file.ext\")\n'file.ext'\n\n\n1\n2\n\n\n2.5 dirname(path)\n\n返回文件所在目录。\n\nos.path.dirname(\"dir1/dir2/file.ext\")\n'dir1/dir2'\n\n\n1\n2\n\n\n2.6 split(path)\n\n返回一个元组。元组第一个元素为文件所在目录，第二个元素为文件名（含扩展）。等效于 (dirname(path), basename(path))。\n\nos.path.split(\"dir1/dir2/file.ext\")\n('dir1/dir2', 'file.ext')\n\n\n1\n2\n\n\n2.7 splitext(path)\n\n返回一个元组。元组第一个元素为文件所在目录和文件名（不含扩展），第二个元素为扩展名（包含 .）。常用来读取或更改文件扩展名。\n\nos.path.splitext(\"dir1/dir2/file.ext\")\n('dir1/dir2/file', '.ext')\n\n\n1\n2\n\n\n*2.8 join(path, paths)\n\n将路径不同部分拼接成一个完整的路径。等效于 os.sep.join([path, *paths]) 。\n\nos.path.join(\"dir1\", \"dir2\", \"file.ext\")\n'dir1/dir2/file.ext'\n\n\n1\n2\n\n\n2.9 getsize(path)\n\n返回文件大小。单位字节。\n\nos.path.getsize(\"dog.jpeg\")\n18335\n\n\n1\n2\n\n\n# 3.目录操作\n\n3.1 listdir(path='.')\n\n返回一个列表。列表为给定目录下所有文件和子目录，但不包含特殊目录 . 和 ..。默认为当前目录。\n\nos.listdir(\"dogs\")[:5]\n['122.pointer',\n '069.french_bulldog',\n '124.poodle',\n '112.nova_scotia_duck_tolling_retriever',\n '043.canaan_dog']\n\n\n1\n2\n3\n4\n5\n6\n\n\n3.2 mkdir(path, mode=0o777)\n\n创建名为 path 的目录。并以数字形式指定目录权限，默认权限为 777 。\n\nos.mkdir(\"newdir\")\n\n\n1\n\n\n3.3 makedirs(path, mode=0o777)\n\n递归方式创建路径为 path 的目录。并以数字形式指定目录权限，默认权限为 777 。可以看作功能更强大的 mkdir，它会自动创建叶子节点目录的所有上级目录，而 mkdir 必须在上级目录已经存在情况下，才能创建叶子节点的目录。\n\nos.makedirs(\"parent/child/newdir\")\n\n\n1\n\n\n3.4 rmdir(path)\n\n删除目录。目录必须存在，并且只能删除空目录。不存在或不为空，都会异常。要想递归删除整个目录树，请使用 shutil.rmtree()。\n\nos.rmdir(\"newdir\")\n\n\n1\n\n\n3.5 removedirs(path)\n\n递归删除目录。目录必须存在，并且只能删除空目录。不存在或不为空，都会异常。与 rmdir 不同的是，在删除了叶子节点目录后，会逐次删除上级目录，直到遇到不为空的目录。\n\nos.removedirs(\"parent/child/newdir\")\n\n\n1\n\n\n3.6 remove(path)\n\n删除文件。不能删除目录，给定路径必须为文件，否则会异常。\n\nwarm suggestion: 以下复制文件的操作，推荐使用 shutil.copyfile。\n\n# 复制文件\nwith open(\"dog.jpeg\", \"rb\") as f:\n    content = f.read()\n    with open(\"dog.copy.jpeg\", \"wb\") as f2:\n        f2.write(content)\n\n# 删除文件\nos.remove(\"dog.copy.jpeg\")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n# 4. 其他 os 接口\n\n4.1 getenv(key, default=none)\n\n获取环境变量。\n\nos.getenv(\"path\")\n'/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin'\n\n\n1\n2\n\n\n4.2 get_exec_path(env=none)\n\n返回用于搜索可执行文件的目录列表。看以看作是 path 环境变量的列表形式。\n\nos.get_exec_path()\n['/usr/local/bin',\n '/usr/bin',\n '/bin',\n '/usr/sbin',\n '/sbin']\n\n\n1\n2\n3\n4\n5\n6\n\n\n4.3 system(command)\n\n在当前进程中，启动子进程，执行命令 command（字符串），主进程会阻塞，直到子进程执行完成。这是通过调用标准c函数 system() 来实现的，并且具有相同的限制。\n\nif os.name == \"nt\":\n    command = \"dir\"\nelse:\n    command = \"ls -l\"\n\nos.system(command)\n0\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n----------------------------------------\n\n# 补充：python 使用 with open（） as 读写文件\n\npython 使用 with open（） as 读写文件_xrinosvip的博客-csdn博客_python withopen\n\n# 读文件\n\n要以读文件的模式打开一个文件对象，使用python内置的open()函数，传入文件名和标示符：\n\n>>> f = open('e:\\python\\python\\test.txt', 'r')\n\n\n1\n\n\n标示符'r'表示读，这样，我们就成功地打开了一个文件。\n\n如果文件不存在，open()函数就会抛出一个ioerror的错误，并且给出错误码和详细的信息告诉你文件不存在：\n\nf=open('e:\\python\\python\\notfound.txt', 'r')\n\ntraceback (most recent call last):\n  file \"<stdin>\", line 1, in <module>\nfilenotfounderror: [errno 2] no such file or directory: 'e:\\python\\python\\notfound.txt'\n\n\n1\n2\n3\n4\n5\n\n\n如果文件打开成功，接下来，调用read()方法可以一次读取文件的全部内容，python把内容读到内存，用一个str对象表示：\n\n>>> f.read()\n\n'hello, python!'\n\n\n1\n2\n3\n\n\n最后一步是调用close()方法关闭文件。文件使用完毕后必须关闭，因为文件对象会占用操作系统的资源，并且操作系统同一时间能打开的文件数量也是有限的：\n\n>>> f.close()\n\n\n1\n\n\n由于文件读写时都有可能产生ioerror，一旦出错，后面的f.close()就不会调用。所以，为了保证无论是否出错都能正确地关闭文件，我们可以使用try ... finally来实现：\n\ntry:\n    f = open('/path/', 'r')\n    print(f.read())\nfinally:\n    if f:\n        f.close()\n\n\n1\n2\n3\n4\n5\n6\n\n\n每次都这么写实在太繁琐，所以，python引入了with语句来自动帮我们调用close()方法：\n\nwith open('/path/to/file', 'r') as f:\n    print(f.read())\n\n\n1\n2\n\n\n这和前面的try ... finally是一样的，但是代码更佳简洁，并且不必调用f.close()方法。\n\n调用read()会一次性读取文件的全部内容，如果文件有20g，内存就爆了，所以，要保险起见，可以反复调用read(size)方法，每次最多读取size个字节的内容。另外，调用readline()可以每次读取一行内容，调用readlines()一次读取所有内容并按行返回list。因此，要根据需要决定怎么调用。\n\n * 如果文件很小，read()一次性读取最方便；\n * 如果不能确定文件大小，反复调用read(size)比较保险；\n * 如果是配置文件，调用readlines()最方便：\n\nfor line in f.readlines():\n    print(line.strip()) # 把末尾的'\\n'删掉\n\n\n1\n2\n\n\n----------------------------------------\n\n# 写文件\n\n写文件和读文件是一样的，唯一区别是调用open()函数时，传入标识符'w'或者'wb'表示写文本文件或写二进制文件：\n\n>>> f = open('e:\\python\\python\\test.txt', 'w')\n>>> f.write('hello, python!')\n>>> f.close()\n\n\n1\n2\n3\n\n\n可以反复调用write()来写入文件，但是务必要调用f.close()来关闭文件。当我们写文件时，操作系统往往不会立刻把数据写入磁盘，而是放到内存缓存起来，空闲的时候再慢慢写入。只有调用close()方法时，操作系统才保证把没有写入的数据全部写入磁盘。忘记调用close()的后果是数据可能只写了一部分到磁盘，剩下的丢失了。所以，还是用with语句来得保险：\n\nwith open('e:\\python\\python\\test.txt', 'w') as f:\n    f.write('hello, python!')\n\n\n1\n2\n\n\n要写入特定编码的文本文件，请给open()函数传入encoding参数，将字符串自动转换成指定编码\n\n# 字符编码\n\n要读取非utf-8编码的文本文件，需要给open()函数传入encoding参数，例如，读取gbk编码的文件：\n\n>>> f = open('e:\\python\\python\\gbk.txt', 'r', encoding='gbk')\n>>> f.read()\n'测试'\n\n\n1\n2\n3\n\n\n遇到有些编码不规范的文件，你可能会遇到unicodedecodeerror，因为在文本文件中可能夹杂了一些非法编码的字符。遇到这种情况，open()函数还接收一个errors参数，表示如果遇到编码错误后如何处理。最简单的方式是直接忽略：\n\n>>> f = open('e:\\python\\python\\gbk.txt', 'r', encoding='gbk', errors='ignore')\n\n\n1\n\n\n# 二进制文件\n\n前面讲的默认都是读取文本文件，并且是utf-8编码的文本文件。要读取二进制文件，比如图片、视频等等，用'rb'模式打开文件即可：\n\n>>> f = open('e:\\python\\python\\test.jpg', 'rb')\n>>> f.read()\nb'\\xff\\xd8\\xff\\xe1\\x00\\x18exif\\x00\\x00...' # 十六进制表示的字节\n\n\n1\n2\n3\n\n\n总结：以后读写文件尽量使用with open语句，少使用f = open()语句\n\n对于多个文件的读写，可以写成以下两种方式：\n\n1、\n\nwith open('c:\\desktop\\text.txt','r') as f:\n    with open('c:\\desktop\\text1.txt','r') as f1:\n        with open('c:\\desktop\\text2.txt','r') as f2　　　　　　\n        ........　　　　　　　\n        ........　　　　　　　\n        ........\n\n\n1\n2\n3\n4\n5\n6\n\n\n2、\n\nwith open(''c:\\desktop\\text.txt','r') as f:\n........\nwith open(''c:\\desktop\\text1.txt','r') as f1:\n........\nwith open('c:\\desktop\\text2.txt','r') as f2:\n........\n\n\n1\n2\n3\n4\n5\n6\n\n\n# 文件的读写方式列表\n\n# file 对象属性\n\n\n\n----------------------------------------\n\n# 处理缺失值\n\n“nan”项代表缺失值。为了处理缺失的数据，典型的方法包括插值法和删除法， 其中插值法用一个替代值弥补缺失值，而删除法则直接忽略缺失值.\n\n * 通过位置索引iloc，将data分成inputs和outputs， 其中前者为data的前两列，而后者为data的最后一列。 对于inputs中缺少的数值，用同一列的均值替换“nan”项。\n   \n   * inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n     inputs = inputs.fillna(inputs.mean())\n     print(inputs)\n     \n     \n     1\n     2\n     3\n     \n     * \n     * 数值中的na用均值替换，字符串中的不行\n\n * 对于inputs中的类别值或离散值，我们将“nan”视为一个类别。 由于“巷子类型”（“alley”）列只接受两种类型的类别值“pave”和“nan”， pandas可以自动将此列转换为两列“alley_pave”和“alley_nan”。 巷子类型为“pave”的行会将“alley_pave”的值设置为1，“alley_nan”的值设置为0。 缺少巷子类型的行会将“alley_pave”和“alley_nan”分别设置为0和1。\n   \n   * inputs = pd.get_dummies(inputs, dummy_na=true)\n     print(inputs)\n     \n     \n     1\n     2\n     \n     * \n\n----------------------------------------\n\n# 转换为张量格式\n\n现在inputs和outputs中的所有条目都是数值类型，它们可以转换为张量格式\n\nimport torch\n\nx, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\nx, y\n\n\n1\n2\n3\n4\n\n\n",charsets:{cjk:!0},lastUpdated:"2022/02/11, 02:24:43",lastUpdatedTimestamp:1644517483e3},{title:"线性代数",frontmatter:{title:"线性代数",date:"2022-02-04T10:26:33.000Z",permalink:"/pages/4fa3d9/",categories:["实践","动手学深度学习"],tags:[null]},regularPath:"/02.%E5%AE%9E%E8%B7%B5/01.%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/03.%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0.html",relativePath:"02.实践/01.动手学深度学习/03.线性代数.md",key:"v-586b2ff1",path:"/pages/4fa3d9/",headers:[{level:2,title:"向量",slug:"向量",normalizedTitle:"向量",charIndex:2},{level:2,title:"矩阵",slug:"矩阵",normalizedTitle:"矩阵",charIndex:9},{level:3,title:"范数",slug:"范数",normalizedTitle:"范数",charIndex:16},{level:2,title:"特殊矩阵",slug:"特殊矩阵",normalizedTitle:"特殊矩阵",charIndex:414},{level:2,title:"特征向量和特征值",slug:"特征向量和特征值",normalizedTitle:"特征向量和特征值",charIndex:682},{level:2,title:"linear-algebra代码",slug:"linear-algebra代码",normalizedTitle:"linear-algebra代码",charIndex:771},{level:3,title:"标量",slug:"标量",normalizedTitle:"标量",charIndex:792},{level:3,title:"向量",slug:"向量-2",normalizedTitle:"向量",charIndex:2},{level:3,title:"长度、维度和形状",slug:"长度、维度和形状",normalizedTitle:"长度、维度和形状",charIndex:1127},{level:3,title:"矩阵",slug:"矩阵-2",normalizedTitle:"矩阵",charIndex:9},{level:3,title:"张量",slug:"张量",normalizedTitle:"张量",charIndex:808},{level:3,title:"降维",slug:"降维",normalizedTitle:"降维",charIndex:2385},{level:3,title:"非降维求和",slug:"非降维求和",normalizedTitle:"非降维求和",charIndex:3423},{level:3,title:"点积（Dot Product）",slug:"点积-dot-product",normalizedTitle:"点积（dot product）",charIndex:3808},{level:3,title:"矩阵-向量积",slug:"矩阵-向量积",normalizedTitle:"矩阵-向量积",charIndex:4347},{level:3,title:"矩阵-矩阵乘法",slug:"矩阵-矩阵乘法",normalizedTitle:"矩阵-矩阵乘法",charIndex:4919},{level:3,title:"范数",slug:"范数-2",normalizedTitle:"范数",charIndex:16},{level:3,title:"More",slug:"more",normalizedTitle:"more",charIndex:6616},{level:2,title:"矩阵计算",slug:"矩阵计算",normalizedTitle:"矩阵计算",charIndex:6760},{level:3,title:"标量导数",slug:"标量导数",normalizedTitle:"标量导数",charIndex:6769},{level:3,title:"亚导数",slug:"亚导数",normalizedTitle:"亚导数",charIndex:6805},{level:3,title:"梯度",slug:"梯度",normalizedTitle:"梯度",charIndex:6838},{level:3,title:"标量对向量求导",slug:"标量对向量求导",normalizedTitle:"标量对向量求导",charIndex:6905},{level:3,title:"分子布局与分母布局",slug:"分子布局与分母布局",normalizedTitle:"分子布局与分母布局",charIndex:7194},{level:2,title:"自动求导",slug:"自动求导",normalizedTitle:"自动求导",charIndex:7432},{level:3,title:"链式法则",slug:"链式法则",normalizedTitle:"链式法则",charIndex:7526},{level:3,title:"自动求导",slug:"自动求导-2",normalizedTitle:"自动求导",charIndex:7432},{level:3,title:"计算图",slug:"计算图",normalizedTitle:"计算图",charIndex:7661},{level:3,title:"autograd代码",slug:"autograd代码",normalizedTitle:"autograd代码",charIndex:8300}],headersStr:"向量 矩阵 范数 特殊矩阵 特征向量和特征值 linear-algebra代码 标量 向量 长度、维度和形状 矩阵 张量 降维 非降维求和 点积（Dot Product） 矩阵-向量积 矩阵-矩阵乘法 范数 More 矩阵计算 标量导数 亚导数 梯度 标量对向量求导 分子布局与分母布局 自动求导 链式法则 自动求导 计算图 autograd代码",content:'# 向量\n\n\n# 矩阵\n\n\n# 范数\n\n# -范数的定义\n\n在很多机器学习相关的著作和教材中，经常看到各式各样的距离及范数，如\n\n\n\n其中， 分别表示向量和矩阵。\n\n当然，也会看到欧式距离、均方误差等。例如，向量 的欧式范数 (Euclidean norm) 为\n\n\n\n用于表示向量的大小，这个范数也被叫做 -范数。\n\n * 为方便统一，一般将任意向量 的 -范数定义为:\n\n\n\n# 矩阵的范数\n\n上面是向量的范数，而矩阵的范数更加麻烦\n\n\n\n * 范数\n   * \n   * 取决于如何衡量b和c的长度\n * 作用：AX=B，可以将向量X变化为B，矩阵范数就是来度量这个变化大小的\n * 常见范数\n   * 矩阵范数：最小的满足的上面公式的值\n   * Frobenius 范数\n     * 矩阵范数计算比较麻烦，所以常用的是Frobenius 范数\n     * 矩阵所有元素的平方和的算术平方根\n     * \n\n\n# 特殊矩阵\n\n# 对称和反对称\n\n\n\n# 正定\n\n特征值全是正实数的实对称矩阵为正定矩阵（positive definite matrix）\n\n\n\n正定矩阵乘以任意的列向量和行向量都大于等于0\n\n# 正交矩阵\n\n * 所以行都相互正交\n * 所有行都有单位长度\n   * \n * 可以写成(对角线都为1的单位矩阵)\n\n# 置换矩阵\n\n * 置换矩阵是一个方形二进制矩阵，它在每行和每列中只有一个1，而在其他地方则为0。\n * 置换矩阵是正交矩阵\n\n----------------------------------------\n\n\n# 特征向量和特征值\n\n特征向量:不被矩阵改变方向的向量\n\n对称矩阵总是可以找到特征向量\n\n----------------------------------------\n\n\n# linear-algebra代码\n\n\n# 标量\n\n> 标量由只有一个元素的张量表示\n\nimport torch\n\nx = torch.tensor(3.0)\ny = torch.tensor(2.0)\n\nx + y, x * y, x / y, x**y\n\n\n1\n2\n3\n4\n5\n6\n\n\n(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))\n\n\n1\n\n\n\n# 向量\n\n> 向量可以视为标量值组成的列表。 将这些标量值称为向量的元素（element）或分量（component）。\n\nx = torch.arange(4)\nx\n\n\n1\n2\n\n\ntensor([0, 1, 2, 3])\n\n\n1\n\n\n\\大量文献认为列向量是向量的默认方向\n\n向量可以写为：\n\n\n# 长度、维度和形状\n\n * 向量只是一个数字数组，就像每个数组都有一个长度一样，每个向量也是如此。\n   \n   * 如果一个向量由个实值标量组成，可以将其表示为。 向量的长度通常称为向量的维度（dimension）。\n\n * 与普通的Python数组一样，可以通过调用Python的内置len()函数来访问张量的长度。\n   \n   * len(x)\n\n> 当用张量表示一个向量（只有一个轴）时，可以通过.shape属性访问向量的长度。\n> \n> 形状（shape）是一个元素组，列出了张量沿每个轴的长度（维数）。 对于(只有一个轴的张量，形状只有一个元素。)\n\nx.shape\n\ntorch.Size([4])\n\n\n1\n\n\n==请注意==，维度（dimension）这个词在不同上下文时往往会有不同的含义：\n\n向量或轴的维度被用来表示向量或轴的长度，即向量或轴的元素数量。\n\n然而，张量的维度用来表示张量具有的轴数。\n\n在这个意义上，张量的某个轴的维数就是这个轴的长度。\n\n\n# 矩阵\n\n在数学表示法中，使用来表示矩阵，其由行和列的实值标量组成。\n\n> 当调用函数来实例化张量时， 可以通过指定两个分量𝑚和𝑛来创建一个形状为𝑚×𝑛的矩阵。\n\nA = torch.arange(20).reshape(5, 4)\nA\n\n\n1\n2\n\n\n\n\n> 转置（transpose）\n\nA.T\n\n\n\n> 作为方阵的一种特殊类型，对称矩阵\\（symmetric matrix）𝐀等于其转置：𝐀=𝐀^⊤^\n\nB = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\nB\n\n\n1\n2\n\n\n\n\nB == B.T\n\n\n\n\n# 张量\n\n就像向量是标量的推广，矩阵是向量的推广一样，可以构建具有更多轴的数据结构。\n\n张量提供了描述具有任意数量轴的n维数组的通用方法。\n\n例如，向量是一阶张量，矩阵是二阶张量。\n\n张量用特殊字体的大写字母表示（例如，X、Y和Z），索引机制与矩阵类似。\n\n# 张量算法的基本性质\n\n给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量\n\nA = torch.arange(20, dtype=torch.float32).reshape(5, 4)\nB = A.clone()  # 通过分配新内存，将A的一个副本分配给B\nA, A + B\n\n\n1\n2\n3\n\n\n\n\n> 两个矩阵的按元素乘法称为Hadamard积（Hadamard product，哈达玛积）（数学符号⊙）\n\nA * B\n\n\n\n> 将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘。\n\na = 2\nX = torch.arange(24).reshape(2, 3, 4)\na + X, (a * X).shape\n\n\n1\n2\n3\n\n\n\n\n----------------------------------------\n\n\n# 降维\n\n默认情况下，调用求和函数会沿所有的轴降低张量的维度，使它变为一个标量\n\nx = torch.arange(4, dtype=torch.float32)\nx, x.sum()\n\n\n1\n2\n\n\n(tensor([0., 1., 2., 3.]), tensor(6.))\n\n\n1\n\n\nA.shape, A.sum()\n\n(torch.Size([5, 4]), tensor(190.))\n\n\n1\n\n\n> 还可以指定张量沿哪一个轴来通过求和降低维度\n\n==指定哪个轴，哪个轴就消失==\n\n * A_sum_axis0 = A.sum(axis=0)\n   A_sum_axis0, A_sum_axis0.shape\n   \n   \n   1\n   2\n   \n   \n   (tensor([40., 45., 50., 55.]), torch.Size([4]))\n   \n   \n   1\n   \n\n * A_sum_axis1 = A.sum(axis=1)\n   A_sum_axis1, A_sum_axis1.shape\n   \n   \n   1\n   2\n   \n   \n   (tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))\n   \n   \n   1\n   \n\n> 可以同时指定多个轴\n\n * A.sum(axis=[0, 1])  # SameasA.sum()\n   \n   \n   1\n   \n   \n   tensor(190.)\n   \n   \n   1\n   \n\n----------------------------------------\n\n> 一个与求和相关的量是平均值（mean或average）\n\n * A.mean(), A.sum() / A.numel()\n   \n   \n   1\n   \n   \n   (tensor(9.5000), tensor(9.5000))\n   \n   \n   1\n   \n\n> 计算平均值的函数也可以沿指定轴降低张量的维度\n\n * A.mean(axis=0), A.sum(axis=0) / A.shape[0]\n   \n   \n   1\n   \n   \n   (tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))\n   \n   \n   1\n   \n\n\n# 非降维求和\n\n有时在调用函数来计算总和或均值时保持轴数不变会很有用,比如广播时需要保证轴数相等\n\n * 使用参数keepdims=True\n   \n   * sum_A = A.sum(axis=1, keepdims=True)\n     sum_A\n     \n     \n     1\n     2\n     \n     \n     \n\n==注意==：\n\n> 由于sum_A在对每行进行求和后仍保持两个轴，可以(通过广播将A除以sum_A)\n\n * A / sum_A\n   \n   \n\n> 如果想沿[某个轴计算A元素的累积总和]， 比如axis=0（按行计算），可以调用cumsum函数。 此函数不会沿任何轴降低输入张量的维度。\n\nA.cumsum(axis=0)\n\n\n\n----------------------------------------\n\n\n# 点积（Dot Product）\n\n给定两个向量， 它们的点积（dot product）（或） 是相同位置的按元素乘积的和：\n\n * y = torch.ones(4, dtype = torch.float32)\n   x, y, torch.dot(x, y)\n   \n   \n   1\n   2\n   \n   \n   (tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))\n   \n   \n   1\n   \n   \n   > 也可以通过执行按元素乘法，然后进行求和来表示两个向量的点积\n   \n   * torch.sum(x * y)\n     \n     ensor(6.)\n     \n     \n     1\n     \n\n# 点积的应用\n\n例如\n\n * 给定一组由向量表示的值，和一组由表示的权重。中的值根据权重的加权和，可以表示为点积。\n * 当权重为非负数且和为1（即）时，点积表示加权平均（weighted average）。\n * 将两个向量规范化得到单位长度后，点积表示它们夹角的余弦。\n\n----------------------------------------\n\n\n# 矩阵-向量积\n\n矩阵-向量积（matrix-vector product）。\n\n * 定义矩阵和向量。\n   * 将矩阵用它的行向量表示：\n\n其中每个都是行向量，表示矩阵的第行。 矩阵向量积是一个长度为的列向量，其第个元素是点积：\n\n> 用与点积相同的mv函数表示矩阵-向量积。\n\n当为矩阵A和向量x调用torch.mv(A, x)时，会执行矩阵-向量积。\n\n注意，A的列维数（沿轴1的长度）必须与x的维数（其长度）相同。\n\nA.shape, x.shape, torch.mv(A, x)#MV：matrix vector multiplication\n\n\n1\n\n\n(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))\n\n\n1\n\n\n----------------------------------------\n\n可以把一个矩阵乘法看作是一个从到向量的转换。\n\n> 这些转换是非常有用的。\n> \n> 例如\n> \n>  * 可以用方阵的乘法来表示旋转。\n>  * 也可以使用矩阵-向量积来描述在给定前一层的值时，求解神经网络每一层所需的复杂计算。\n\n----------------------------------------\n\n\n# 矩阵-矩阵乘法\n\n矩阵-矩阵乘法（matrix-matrix multiplication）\n\n * 假设我们有两个矩阵和：\n\n * 用行向量表示矩阵的第行，并让列向量作为矩阵的第列。要生成矩阵积，最简单的方法是==考虑的行向量和的列向量==:\n\n * 简单地将==每个元素计算为点积==：\n\n==可以将矩阵-矩阵乘法看作是简单地执行次矩阵-向量积，并将结果拼接在一起，形成一个矩阵==。\n\n * torch.mm(A, B)#mm:matrix multiplication\n   \n   \n   1\n   \n   \n   \n\n==注意==：矩阵-矩阵乘法可以简单地称为矩阵乘法，不应与"Hadamard积"混淆。\n\n----------------------------------------\n\n矩阵-矩阵乘法可以简单地称为矩阵乘法，不应与"Hadamard积"混淆。\n\n\n# 范数\n\n * 线性代数中最有用的一些运算符是范数（norm）。\n   \n   * 非正式地说，一个向量的范数告诉我们一个向量有多大。\n   * 这里考虑的大小（size）概念不涉及维度，而是分量的大小。\n\n * 在线性代数中，向量范数是将向量映射到标量的函数。\n\n * 给定任意向量，向量范数要满足一些属性。\n   \n   * 第一个性质是：如果按常数因子缩放向量的所有元素，其范数也会按相同常数因子的绝对值缩放：\n     \n     * \n   \n   * 第二个性质是我们熟悉的三角不等式:\n     \n     * \n   \n   * 第三个性质简单地说范数必须是非负的:\n     \n     * \n     \n     * 因为在大多数情况下，任何东西的最小的大小是0。\n     \n     * 要求范数最小为0，当且仅当向量全由0组成。\n       \n       * \n\n> 范数听起来很像距离的度量。 如果你还记得欧几里得距离和毕达哥拉斯定理(勾股定理)，那么非负性的概念和三角不等式可能会给你一些启发。 事实上，==欧几里得距离是一个范数==：\n\n假设维向量中的元素是，其**范数是向量元素平方和的平方根：**\n\n($$|\\mathbf{x}|2 = \\sqrt{\\sum{i=1}^n x_i^2},$$)\n\n其中，在范数中常常省略下标，也就是说==等同于==。\n\n> 计算向量的范数\n\nu = torch.tensor([3.0, -4.0])\ntorch.norm(u)\n\n\n1\n2\n\n\ntensor(5.)\n\n\n1\n\n\n在深度学习中，我们更经常地使用范数的平方。 你还会经常遇到[范数，它表示为向量元素的绝对值之和：]\n\n($$|\\mathbf{x}|1 = \\sum{i=1}^n \\left|x_i \\right|.$$)\n\n与范数相比，范数受异常值的影响较小。\n\n> 为了计算范数，我们将绝对值函数和按元素求和组合起来。\n\ntorch.abs(u).sum()\n\n\n1\n\n\ntensor(7.)\n\n\n1\n\n * 范数和范数都是更一般的范数的特例：\n\n类似于向量的范数，==矩阵==**(**的Frobenius范数（Frobenius norm）是==矩阵元素平方和的平方根==：)\n\n($$|\\mathbf{X}|F = \\sqrt{\\sum{i=1}^m \\sum_{j=1}^n x_{ij}^2}.$$)\n\nFrobenius范数满足向量范数的所有性质，它就像是矩阵形向量的范数。\n\n> 计算矩阵的Frobenius范数。\n\ntorch.norm(torch.ones((4, 9)))\n\n\n1\n\n\ntensor(6.)\n\n\n1\n\n\n# 范数和目标\n\n在深度学习中，经常试图解决优化问题：\n\n * 最大化分配给观测数据的概率;\n * 最小化预测和真实观测之间的距离。\n * 用向量表示物品（如单词、产品或新闻文章），以便最小化相似项目之间的距离，最大化不同项目之间的距离。\n * 目标，或许是深度学习算法最重要的组成部分（除了数据），通常被表达为范数。\n\n\n# More\n\n线性代数还有很多，其中很多数学对于机器学习非常有用。\n\n * 例如，矩阵可以分解为因子，这些分解可以显示真实世界数据集中的低维结构。\n\n * 机器学习的整个子领域都侧重于使用矩阵分解及其向高阶张量的泛化，来发现数据集中的结构并解决预测问题。\n\n线性代数运算的在线附录\n\n\n# 矩阵计算\n\n\n# 标量导数\n\n * 导数是切线的斜率\n   * \n * \n * \n\n\n# 亚导数\n\n将导数拓展到不可微的函数\n\n * * \n * \n\n\n# 梯度\n\n将导数拓展到向量\n\n * \n\n * ----------------------------------------\n\n\n# 标量对向量求导\n\n * * ==是列向量，导数是行向量==\n   * 比如,y=\n     * \n     * \n     * 梯度指向的是值变化最大的方向\n   * 比如\n   * ==内积求导==：L2-范数求导可以转化为内积求导\n\n * ----------------------------------------\n   \n   * \n\n * ----------------------------------------\n   \n   * \n   * \n\n# 拓展到矩阵\n\n----------------------------------------\n\n\n# 分子布局与分母布局\n\n# 前提\n\n 1. 分子分母都是向量，且一个是行向量，另一个是列向量\n 2. 分子分母一个是标量，另一个是行向量或列向量\n\n当满足1或2时，讨论分母布局/分子布局才有意义。\n\n# 结论\n\n 1. 谁是列向量就是什么布局。分母是列向量，就是分母布局；分子是列向量，就是分子布局。\n\n\n\n * \n * \n * \n\n> 中分母是列向量，所以是分母布局， 中分子是列向量，所以是分子布局\n> \n> 但要求统一是分子布局，所以把 的分母布局转置为分子布局\n\n\n# 自动求导\n\n * 深度学习框架可以自动计算导数：\n   * 首先将梯度附加到想要对其计算偏导数的变量上。然后\n   * 记录目标值的计算，执行它的反向传播函数，并访问得到的梯度。\n\n\n# 链式法则\n\n# 标量链式法则\n\n# 向量链式法则\n\n拓展到向量\n\n# 例1\n\n# 例2\n\n\n\n\n# 自动求导\n\n * 计算一个函数在指定值上的导数\n\n * 区别于符号求导和数值求导\n   \n   * 符号求导\n     * \n   * 数值求导\n     * \n\n\n# 计算图\n\n * 将代码分解成操作子\n * 将计算表示成一个无环图\n   * \n\n# 计算图的2中构造方式\n\n * 显示构造\n   * \n   * Tensorflow/Theano/MXNet\n * 隐式构造\n   * \n   * PyTorch/MXNet\n   * 构造出Tensor后，系统会记住所有的计算操作\n\n# 自动求导的2种模式\n\n正向累积和反向累积\n\n链式法则：\n\n * 正向累积\n   * \n * ==反向累积、又称反向传递（BP，Backpropagation）==\n   * \n\n# 反向累积\n\n==步骤==\n\n1.构造计算图\n\n2.前向（forward）：执行图，存储中间结果\n\n3.反向（backward）：从相反方向执行图，然后去除不需要的枝\n\n * \n\n----------------------------------------\n\n * \n * \n * \n\n----------------------------------------\n\n==复杂度== 计算复杂度：O（n），n是操作子个数，通常正向和反向的代价类似 内存复杂度：O（n），因为需要存储正向的所有中间结果\n\n> 而正向累积： 计算复杂度:O（n），用来计算一个变量的梯度\n> \n> 内存复杂度:O（1），不保存中间值\n> \n> 神经网络中不用正向累积，因为需要对每一层都计算梯度\n\n----------------------------------------\n\n\n# autograd代码\n\n深度学习框架通过自动计算导数，即自动微分（automatic differentiation）来加快求导。\n\n实际中，根据我们设计的模型，系统会构建一个计算图（computational graph）， 来跟踪计算是哪些数据通过哪些操作组合起来产生输出。\n\n自动微分使系统能够随后反向传播梯度。 这里，反向传播（backpropagate）意味着跟踪整个计算图，==填充关于每个参数的偏导数==。\n\n# 例子\n\n对函数关于列向量求导\n\n> 首先，创建变量x并为其分配一个初始值。\n\n * import torch\n   \n   x = torch.arange(4.0)\n   x\n   \n   \n   1\n   2\n   3\n   4\n   \n   \n   tensor([0., 1., 2., 3.])\n   \n   \n   1\n   \n\n> 在计算𝑦关于𝐱的梯度之前，需要一个地方来存储梯度\n\n不会在每次对一个参数求导时都分配新的内存。\n\n因为经常会成千上万次地更新相同的参数，每次都分配新的内存可能很快就会将内存耗尽。\n\n注意，一个标量函数关于向量𝐱的梯度是向量，并且与𝐱具有相同的形状。\n\n * x.requires_grad_(True)  # 等价于x=torch.arange(4.0,requires_grad=True)\n   x.grad  # 默认值是None\n   \n   \n   1\n   2\n   \n   \n   tensor([1., 1., 1., 1.])\n   \n   \n   1\n   \n\n> 计算𝑦\n\n * y = 2 * torch.dot(x, x) # 内积\n   y\n   \n   \n   1\n   2\n   \n   \n   tensor(28., grad_fn=<MulBackward0>)\n   \n   \n   1\n   \n\n> 通过调用反向传播函数来自动计算y关于x每个分量的梯度\n\ny.backward()\nx.grad\n\n\n1\n2\n\n\ntensor([ 0.,  4.,  8., 12.])\n\n\n1\n\n\n> 函数关于的梯度应为。 快速验证这个梯度是否计算正确。\n\nx.grad == 4 * x\n\n\n1\n\n\ntensor([True, True, True, True])\n\n\n1\n\n\n> 计算x的另一个函数\n\n# 在默认情况下，PyTorch会累积梯度，所以需要清除之前的值\nx.grad.zero_()#需要先清0，不然会累加上一个x.grad\ny = x.sum()#向量求和的导数全是1\ny.backward()\nx.grad\n\n\n1\n2\n3\n4\n5\n\n\ntensor([1., 1., 1., 1.])\n\n\n1\n\n\n# 非标量变量的反向传播\n\n当y不是标量时，向量y关于向量x的导数的最自然解释是一个矩阵。 对于高阶和高维的y和x，求导的结果可以是一个高阶张量。\n\n然而，虽然这些更奇特的对象确实出现在高级机器学习中（包括[深度学习中]）， 但当我们调用向量的反向计算时，我们通常会试图计算一批训练样本中每个组成部分的损失函数的导数。 ???这里，我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和。\n\n# 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。\n# 在我们的例子中，我们只想求偏导数的和，所以传递一个1的梯度是合适的\nx.grad.zero_()\ny = x * x#x*x表示各元素相乘，y是向量\n# 等价于y.backward(torch.ones(len(x)))？？？\ny.sum().backward()#y向量直接求导的结果是矩阵，所以把y向量通过sum转为标量\nx.grad\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\ntensor([0., 2., 4., 6.])\n\n\n1\n\n\n----------------------------------------\n\n# 分离计算\n\n有时，我们希望[将某些计算移动到记录的计算图之外]。 例如，假设y是作为x的函数计算的，而z则是作为y和x的函数计算的。 想象一下，我们想计算z关于x的梯度，但由于某种原因，我们希望将y视为一个常数，并且只考虑到x在y被计算后发挥的作用。\n\n在这里，我们可以分离y来返回一个新变量u，该变量与y具有相同的值，但丢弃计算图中如何计算y的任何信息。 换句话说，梯度不会向后流经u到x。 因此，下面的反向传播函数计算z=u*x关于x的偏导数，同时将u作为常数处理，而不是z=x*x*x关于x的偏导数。\n\nx.grad.zero_()\ny = x * x\nu = y.detach()\nz = u * x\n\nz.sum().backward()\nx.grad == u\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\ntensor([True, True, True, True])\n\n\n1\n\n\n由于记录了y的计算结果，我们可以随后在y上调用反向传播，得到y=x*x关于的x的导数，即2*x。\n\nx.grad.zero_()\ny.sum().backward()\nx.grad == 2 * x\n\n\n1\n2\n3\n\n\ntensor([True, True, True, True])\n\n\n1\n\n\n----------------------------------------\n\n# Python控制流的梯度计算\n\n使用自动微分的一个好处是： [即使构建函数的计算图需要通过Python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度]。 在下面的代码中，while循环的迭代次数和if语句的结果都取决于输入a的值。\n\ndef f(a):\n    b = a * 2\n    while b.norm() < 1000:\n        b = b * 2\n    if b.sum() > 0:\n        c = b\n    else:\n        c = 100 * b\n    return c\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n计算梯度\n\na = torch.randn(size=(), requires_grad=True)\nd = f(a)\nd.backward()\n\n\n1\n2\n3\n\n\n分析上面定义的f函数: 它在其输入a中是分段线性的。 对于任何a，存在某个常量标量k，使得f(a)=k*a，其中k的值取决于输入a。 因此，可以用d/a验证梯度是否正确。\n\na.grad == d / a\n\n\n1\n\n\ntensor(True)\n\n\n1\n',normalizedContent:'# 向量\n\n\n# 矩阵\n\n\n# 范数\n\n# -范数的定义\n\n在很多机器学习相关的著作和教材中，经常看到各式各样的距离及范数，如\n\n\n\n其中， 分别表示向量和矩阵。\n\n当然，也会看到欧式距离、均方误差等。例如，向量 的欧式范数 (euclidean norm) 为\n\n\n\n用于表示向量的大小，这个范数也被叫做 -范数。\n\n * 为方便统一，一般将任意向量 的 -范数定义为:\n\n\n\n# 矩阵的范数\n\n上面是向量的范数，而矩阵的范数更加麻烦\n\n\n\n * 范数\n   * \n   * 取决于如何衡量b和c的长度\n * 作用：ax=b，可以将向量x变化为b，矩阵范数就是来度量这个变化大小的\n * 常见范数\n   * 矩阵范数：最小的满足的上面公式的值\n   * frobenius 范数\n     * 矩阵范数计算比较麻烦，所以常用的是frobenius 范数\n     * 矩阵所有元素的平方和的算术平方根\n     * \n\n\n# 特殊矩阵\n\n# 对称和反对称\n\n\n\n# 正定\n\n特征值全是正实数的实对称矩阵为正定矩阵（positive definite matrix）\n\n\n\n正定矩阵乘以任意的列向量和行向量都大于等于0\n\n# 正交矩阵\n\n * 所以行都相互正交\n * 所有行都有单位长度\n   * \n * 可以写成(对角线都为1的单位矩阵)\n\n# 置换矩阵\n\n * 置换矩阵是一个方形二进制矩阵，它在每行和每列中只有一个1，而在其他地方则为0。\n * 置换矩阵是正交矩阵\n\n----------------------------------------\n\n\n# 特征向量和特征值\n\n特征向量:不被矩阵改变方向的向量\n\n对称矩阵总是可以找到特征向量\n\n----------------------------------------\n\n\n# linear-algebra代码\n\n\n# 标量\n\n> 标量由只有一个元素的张量表示\n\nimport torch\n\nx = torch.tensor(3.0)\ny = torch.tensor(2.0)\n\nx + y, x * y, x / y, x**y\n\n\n1\n2\n3\n4\n5\n6\n\n\n(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))\n\n\n1\n\n\n\n# 向量\n\n> 向量可以视为标量值组成的列表。 将这些标量值称为向量的元素（element）或分量（component）。\n\nx = torch.arange(4)\nx\n\n\n1\n2\n\n\ntensor([0, 1, 2, 3])\n\n\n1\n\n\n\\大量文献认为列向量是向量的默认方向\n\n向量可以写为：\n\n\n# 长度、维度和形状\n\n * 向量只是一个数字数组，就像每个数组都有一个长度一样，每个向量也是如此。\n   \n   * 如果一个向量由个实值标量组成，可以将其表示为。 向量的长度通常称为向量的维度（dimension）。\n\n * 与普通的python数组一样，可以通过调用python的内置len()函数来访问张量的长度。\n   \n   * len(x)\n\n> 当用张量表示一个向量（只有一个轴）时，可以通过.shape属性访问向量的长度。\n> \n> 形状（shape）是一个元素组，列出了张量沿每个轴的长度（维数）。 对于(只有一个轴的张量，形状只有一个元素。)\n\nx.shape\n\ntorch.size([4])\n\n\n1\n\n\n==请注意==，维度（dimension）这个词在不同上下文时往往会有不同的含义：\n\n向量或轴的维度被用来表示向量或轴的长度，即向量或轴的元素数量。\n\n然而，张量的维度用来表示张量具有的轴数。\n\n在这个意义上，张量的某个轴的维数就是这个轴的长度。\n\n\n# 矩阵\n\n在数学表示法中，使用来表示矩阵，其由行和列的实值标量组成。\n\n> 当调用函数来实例化张量时， 可以通过指定两个分量𝑚和𝑛来创建一个形状为𝑚×𝑛的矩阵。\n\na = torch.arange(20).reshape(5, 4)\na\n\n\n1\n2\n\n\n\n\n> 转置（transpose）\n\na.t\n\n\n\n> 作为方阵的一种特殊类型，对称矩阵\\（symmetric matrix）𝐀等于其转置：𝐀=𝐀^⊤^\n\nb = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\nb\n\n\n1\n2\n\n\n\n\nb == b.t\n\n\n\n\n# 张量\n\n就像向量是标量的推广，矩阵是向量的推广一样，可以构建具有更多轴的数据结构。\n\n张量提供了描述具有任意数量轴的n维数组的通用方法。\n\n例如，向量是一阶张量，矩阵是二阶张量。\n\n张量用特殊字体的大写字母表示（例如，x、y和z），索引机制与矩阵类似。\n\n# 张量算法的基本性质\n\n给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量\n\na = torch.arange(20, dtype=torch.float32).reshape(5, 4)\nb = a.clone()  # 通过分配新内存，将a的一个副本分配给b\na, a + b\n\n\n1\n2\n3\n\n\n\n\n> 两个矩阵的按元素乘法称为hadamard积（hadamard product，哈达玛积）（数学符号⊙）\n\na * b\n\n\n\n> 将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘。\n\na = 2\nx = torch.arange(24).reshape(2, 3, 4)\na + x, (a * x).shape\n\n\n1\n2\n3\n\n\n\n\n----------------------------------------\n\n\n# 降维\n\n默认情况下，调用求和函数会沿所有的轴降低张量的维度，使它变为一个标量\n\nx = torch.arange(4, dtype=torch.float32)\nx, x.sum()\n\n\n1\n2\n\n\n(tensor([0., 1., 2., 3.]), tensor(6.))\n\n\n1\n\n\na.shape, a.sum()\n\n(torch.size([5, 4]), tensor(190.))\n\n\n1\n\n\n> 还可以指定张量沿哪一个轴来通过求和降低维度\n\n==指定哪个轴，哪个轴就消失==\n\n * a_sum_axis0 = a.sum(axis=0)\n   a_sum_axis0, a_sum_axis0.shape\n   \n   \n   1\n   2\n   \n   \n   (tensor([40., 45., 50., 55.]), torch.size([4]))\n   \n   \n   1\n   \n\n * a_sum_axis1 = a.sum(axis=1)\n   a_sum_axis1, a_sum_axis1.shape\n   \n   \n   1\n   2\n   \n   \n   (tensor([ 6., 22., 38., 54., 70.]), torch.size([5]))\n   \n   \n   1\n   \n\n> 可以同时指定多个轴\n\n * a.sum(axis=[0, 1])  # sameasa.sum()\n   \n   \n   1\n   \n   \n   tensor(190.)\n   \n   \n   1\n   \n\n----------------------------------------\n\n> 一个与求和相关的量是平均值（mean或average）\n\n * a.mean(), a.sum() / a.numel()\n   \n   \n   1\n   \n   \n   (tensor(9.5000), tensor(9.5000))\n   \n   \n   1\n   \n\n> 计算平均值的函数也可以沿指定轴降低张量的维度\n\n * a.mean(axis=0), a.sum(axis=0) / a.shape[0]\n   \n   \n   1\n   \n   \n   (tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))\n   \n   \n   1\n   \n\n\n# 非降维求和\n\n有时在调用函数来计算总和或均值时保持轴数不变会很有用,比如广播时需要保证轴数相等\n\n * 使用参数keepdims=true\n   \n   * sum_a = a.sum(axis=1, keepdims=true)\n     sum_a\n     \n     \n     1\n     2\n     \n     \n     \n\n==注意==：\n\n> 由于sum_a在对每行进行求和后仍保持两个轴，可以(通过广播将a除以sum_a)\n\n * a / sum_a\n   \n   \n\n> 如果想沿[某个轴计算a元素的累积总和]， 比如axis=0（按行计算），可以调用cumsum函数。 此函数不会沿任何轴降低输入张量的维度。\n\na.cumsum(axis=0)\n\n\n\n----------------------------------------\n\n\n# 点积（dot product）\n\n给定两个向量， 它们的点积（dot product）（或） 是相同位置的按元素乘积的和：\n\n * y = torch.ones(4, dtype = torch.float32)\n   x, y, torch.dot(x, y)\n   \n   \n   1\n   2\n   \n   \n   (tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))\n   \n   \n   1\n   \n   \n   > 也可以通过执行按元素乘法，然后进行求和来表示两个向量的点积\n   \n   * torch.sum(x * y)\n     \n     ensor(6.)\n     \n     \n     1\n     \n\n# 点积的应用\n\n例如\n\n * 给定一组由向量表示的值，和一组由表示的权重。中的值根据权重的加权和，可以表示为点积。\n * 当权重为非负数且和为1（即）时，点积表示加权平均（weighted average）。\n * 将两个向量规范化得到单位长度后，点积表示它们夹角的余弦。\n\n----------------------------------------\n\n\n# 矩阵-向量积\n\n矩阵-向量积（matrix-vector product）。\n\n * 定义矩阵和向量。\n   * 将矩阵用它的行向量表示：\n\n其中每个都是行向量，表示矩阵的第行。 矩阵向量积是一个长度为的列向量，其第个元素是点积：\n\n> 用与点积相同的mv函数表示矩阵-向量积。\n\n当为矩阵a和向量x调用torch.mv(a, x)时，会执行矩阵-向量积。\n\n注意，a的列维数（沿轴1的长度）必须与x的维数（其长度）相同。\n\na.shape, x.shape, torch.mv(a, x)#mv：matrix vector multiplication\n\n\n1\n\n\n(torch.size([5, 4]), torch.size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))\n\n\n1\n\n\n----------------------------------------\n\n可以把一个矩阵乘法看作是一个从到向量的转换。\n\n> 这些转换是非常有用的。\n> \n> 例如\n> \n>  * 可以用方阵的乘法来表示旋转。\n>  * 也可以使用矩阵-向量积来描述在给定前一层的值时，求解神经网络每一层所需的复杂计算。\n\n----------------------------------------\n\n\n# 矩阵-矩阵乘法\n\n矩阵-矩阵乘法（matrix-matrix multiplication）\n\n * 假设我们有两个矩阵和：\n\n * 用行向量表示矩阵的第行，并让列向量作为矩阵的第列。要生成矩阵积，最简单的方法是==考虑的行向量和的列向量==:\n\n * 简单地将==每个元素计算为点积==：\n\n==可以将矩阵-矩阵乘法看作是简单地执行次矩阵-向量积，并将结果拼接在一起，形成一个矩阵==。\n\n * torch.mm(a, b)#mm:matrix multiplication\n   \n   \n   1\n   \n   \n   \n\n==注意==：矩阵-矩阵乘法可以简单地称为矩阵乘法，不应与"hadamard积"混淆。\n\n----------------------------------------\n\n矩阵-矩阵乘法可以简单地称为矩阵乘法，不应与"hadamard积"混淆。\n\n\n# 范数\n\n * 线性代数中最有用的一些运算符是范数（norm）。\n   \n   * 非正式地说，一个向量的范数告诉我们一个向量有多大。\n   * 这里考虑的大小（size）概念不涉及维度，而是分量的大小。\n\n * 在线性代数中，向量范数是将向量映射到标量的函数。\n\n * 给定任意向量，向量范数要满足一些属性。\n   \n   * 第一个性质是：如果按常数因子缩放向量的所有元素，其范数也会按相同常数因子的绝对值缩放：\n     \n     * \n   \n   * 第二个性质是我们熟悉的三角不等式:\n     \n     * \n   \n   * 第三个性质简单地说范数必须是非负的:\n     \n     * \n     \n     * 因为在大多数情况下，任何东西的最小的大小是0。\n     \n     * 要求范数最小为0，当且仅当向量全由0组成。\n       \n       * \n\n> 范数听起来很像距离的度量。 如果你还记得欧几里得距离和毕达哥拉斯定理(勾股定理)，那么非负性的概念和三角不等式可能会给你一些启发。 事实上，==欧几里得距离是一个范数==：\n\n假设维向量中的元素是，其**范数是向量元素平方和的平方根：**\n\n($$|\\mathbf{x}|2 = \\sqrt{\\sum{i=1}^n x_i^2},$$)\n\n其中，在范数中常常省略下标，也就是说==等同于==。\n\n> 计算向量的范数\n\nu = torch.tensor([3.0, -4.0])\ntorch.norm(u)\n\n\n1\n2\n\n\ntensor(5.)\n\n\n1\n\n\n在深度学习中，我们更经常地使用范数的平方。 你还会经常遇到[范数，它表示为向量元素的绝对值之和：]\n\n($$|\\mathbf{x}|1 = \\sum{i=1}^n \\left|x_i \\right|.$$)\n\n与范数相比，范数受异常值的影响较小。\n\n> 为了计算范数，我们将绝对值函数和按元素求和组合起来。\n\ntorch.abs(u).sum()\n\n\n1\n\n\ntensor(7.)\n\n\n1\n\n * 范数和范数都是更一般的范数的特例：\n\n类似于向量的范数，==矩阵==**(**的frobenius范数（frobenius norm）是==矩阵元素平方和的平方根==：)\n\n($$|\\mathbf{x}|f = \\sqrt{\\sum{i=1}^m \\sum_{j=1}^n x_{ij}^2}.$$)\n\nfrobenius范数满足向量范数的所有性质，它就像是矩阵形向量的范数。\n\n> 计算矩阵的frobenius范数。\n\ntorch.norm(torch.ones((4, 9)))\n\n\n1\n\n\ntensor(6.)\n\n\n1\n\n\n# 范数和目标\n\n在深度学习中，经常试图解决优化问题：\n\n * 最大化分配给观测数据的概率;\n * 最小化预测和真实观测之间的距离。\n * 用向量表示物品（如单词、产品或新闻文章），以便最小化相似项目之间的距离，最大化不同项目之间的距离。\n * 目标，或许是深度学习算法最重要的组成部分（除了数据），通常被表达为范数。\n\n\n# more\n\n线性代数还有很多，其中很多数学对于机器学习非常有用。\n\n * 例如，矩阵可以分解为因子，这些分解可以显示真实世界数据集中的低维结构。\n\n * 机器学习的整个子领域都侧重于使用矩阵分解及其向高阶张量的泛化，来发现数据集中的结构并解决预测问题。\n\n线性代数运算的在线附录\n\n\n# 矩阵计算\n\n\n# 标量导数\n\n * 导数是切线的斜率\n   * \n * \n * \n\n\n# 亚导数\n\n将导数拓展到不可微的函数\n\n * * \n * \n\n\n# 梯度\n\n将导数拓展到向量\n\n * \n\n * ----------------------------------------\n\n\n# 标量对向量求导\n\n * * ==是列向量，导数是行向量==\n   * 比如,y=\n     * \n     * \n     * 梯度指向的是值变化最大的方向\n   * 比如\n   * ==内积求导==：l2-范数求导可以转化为内积求导\n\n * ----------------------------------------\n   \n   * \n\n * ----------------------------------------\n   \n   * \n   * \n\n# 拓展到矩阵\n\n----------------------------------------\n\n\n# 分子布局与分母布局\n\n# 前提\n\n 1. 分子分母都是向量，且一个是行向量，另一个是列向量\n 2. 分子分母一个是标量，另一个是行向量或列向量\n\n当满足1或2时，讨论分母布局/分子布局才有意义。\n\n# 结论\n\n 1. 谁是列向量就是什么布局。分母是列向量，就是分母布局；分子是列向量，就是分子布局。\n\n\n\n * \n * \n * \n\n> 中分母是列向量，所以是分母布局， 中分子是列向量，所以是分子布局\n> \n> 但要求统一是分子布局，所以把 的分母布局转置为分子布局\n\n\n# 自动求导\n\n * 深度学习框架可以自动计算导数：\n   * 首先将梯度附加到想要对其计算偏导数的变量上。然后\n   * 记录目标值的计算，执行它的反向传播函数，并访问得到的梯度。\n\n\n# 链式法则\n\n# 标量链式法则\n\n# 向量链式法则\n\n拓展到向量\n\n# 例1\n\n# 例2\n\n\n\n\n# 自动求导\n\n * 计算一个函数在指定值上的导数\n\n * 区别于符号求导和数值求导\n   \n   * 符号求导\n     * \n   * 数值求导\n     * \n\n\n# 计算图\n\n * 将代码分解成操作子\n * 将计算表示成一个无环图\n   * \n\n# 计算图的2中构造方式\n\n * 显示构造\n   * \n   * tensorflow/theano/mxnet\n * 隐式构造\n   * \n   * pytorch/mxnet\n   * 构造出tensor后，系统会记住所有的计算操作\n\n# 自动求导的2种模式\n\n正向累积和反向累积\n\n链式法则：\n\n * 正向累积\n   * \n * ==反向累积、又称反向传递（bp，backpropagation）==\n   * \n\n# 反向累积\n\n==步骤==\n\n1.构造计算图\n\n2.前向（forward）：执行图，存储中间结果\n\n3.反向（backward）：从相反方向执行图，然后去除不需要的枝\n\n * \n\n----------------------------------------\n\n * \n * \n * \n\n----------------------------------------\n\n==复杂度== 计算复杂度：o（n），n是操作子个数，通常正向和反向的代价类似 内存复杂度：o（n），因为需要存储正向的所有中间结果\n\n> 而正向累积： 计算复杂度:o（n），用来计算一个变量的梯度\n> \n> 内存复杂度:o（1），不保存中间值\n> \n> 神经网络中不用正向累积，因为需要对每一层都计算梯度\n\n----------------------------------------\n\n\n# autograd代码\n\n深度学习框架通过自动计算导数，即自动微分（automatic differentiation）来加快求导。\n\n实际中，根据我们设计的模型，系统会构建一个计算图（computational graph）， 来跟踪计算是哪些数据通过哪些操作组合起来产生输出。\n\n自动微分使系统能够随后反向传播梯度。 这里，反向传播（backpropagate）意味着跟踪整个计算图，==填充关于每个参数的偏导数==。\n\n# 例子\n\n对函数关于列向量求导\n\n> 首先，创建变量x并为其分配一个初始值。\n\n * import torch\n   \n   x = torch.arange(4.0)\n   x\n   \n   \n   1\n   2\n   3\n   4\n   \n   \n   tensor([0., 1., 2., 3.])\n   \n   \n   1\n   \n\n> 在计算𝑦关于𝐱的梯度之前，需要一个地方来存储梯度\n\n不会在每次对一个参数求导时都分配新的内存。\n\n因为经常会成千上万次地更新相同的参数，每次都分配新的内存可能很快就会将内存耗尽。\n\n注意，一个标量函数关于向量𝐱的梯度是向量，并且与𝐱具有相同的形状。\n\n * x.requires_grad_(true)  # 等价于x=torch.arange(4.0,requires_grad=true)\n   x.grad  # 默认值是none\n   \n   \n   1\n   2\n   \n   \n   tensor([1., 1., 1., 1.])\n   \n   \n   1\n   \n\n> 计算𝑦\n\n * y = 2 * torch.dot(x, x) # 内积\n   y\n   \n   \n   1\n   2\n   \n   \n   tensor(28., grad_fn=<mulbackward0>)\n   \n   \n   1\n   \n\n> 通过调用反向传播函数来自动计算y关于x每个分量的梯度\n\ny.backward()\nx.grad\n\n\n1\n2\n\n\ntensor([ 0.,  4.,  8., 12.])\n\n\n1\n\n\n> 函数关于的梯度应为。 快速验证这个梯度是否计算正确。\n\nx.grad == 4 * x\n\n\n1\n\n\ntensor([true, true, true, true])\n\n\n1\n\n\n> 计算x的另一个函数\n\n# 在默认情况下，pytorch会累积梯度，所以需要清除之前的值\nx.grad.zero_()#需要先清0，不然会累加上一个x.grad\ny = x.sum()#向量求和的导数全是1\ny.backward()\nx.grad\n\n\n1\n2\n3\n4\n5\n\n\ntensor([1., 1., 1., 1.])\n\n\n1\n\n\n# 非标量变量的反向传播\n\n当y不是标量时，向量y关于向量x的导数的最自然解释是一个矩阵。 对于高阶和高维的y和x，求导的结果可以是一个高阶张量。\n\n然而，虽然这些更奇特的对象确实出现在高级机器学习中（包括[深度学习中]）， 但当我们调用向量的反向计算时，我们通常会试图计算一批训练样本中每个组成部分的损失函数的导数。 ???这里，我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和。\n\n# 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。\n# 在我们的例子中，我们只想求偏导数的和，所以传递一个1的梯度是合适的\nx.grad.zero_()\ny = x * x#x*x表示各元素相乘，y是向量\n# 等价于y.backward(torch.ones(len(x)))？？？\ny.sum().backward()#y向量直接求导的结果是矩阵，所以把y向量通过sum转为标量\nx.grad\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\ntensor([0., 2., 4., 6.])\n\n\n1\n\n\n----------------------------------------\n\n# 分离计算\n\n有时，我们希望[将某些计算移动到记录的计算图之外]。 例如，假设y是作为x的函数计算的，而z则是作为y和x的函数计算的。 想象一下，我们想计算z关于x的梯度，但由于某种原因，我们希望将y视为一个常数，并且只考虑到x在y被计算后发挥的作用。\n\n在这里，我们可以分离y来返回一个新变量u，该变量与y具有相同的值，但丢弃计算图中如何计算y的任何信息。 换句话说，梯度不会向后流经u到x。 因此，下面的反向传播函数计算z=u*x关于x的偏导数，同时将u作为常数处理，而不是z=x*x*x关于x的偏导数。\n\nx.grad.zero_()\ny = x * x\nu = y.detach()\nz = u * x\n\nz.sum().backward()\nx.grad == u\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\ntensor([true, true, true, true])\n\n\n1\n\n\n由于记录了y的计算结果，我们可以随后在y上调用反向传播，得到y=x*x关于的x的导数，即2*x。\n\nx.grad.zero_()\ny.sum().backward()\nx.grad == 2 * x\n\n\n1\n2\n3\n\n\ntensor([true, true, true, true])\n\n\n1\n\n\n----------------------------------------\n\n# python控制流的梯度计算\n\n使用自动微分的一个好处是： [即使构建函数的计算图需要通过python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度]。 在下面的代码中，while循环的迭代次数和if语句的结果都取决于输入a的值。\n\ndef f(a):\n    b = a * 2\n    while b.norm() < 1000:\n        b = b * 2\n    if b.sum() > 0:\n        c = b\n    else:\n        c = 100 * b\n    return c\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n计算梯度\n\na = torch.randn(size=(), requires_grad=true)\nd = f(a)\nd.backward()\n\n\n1\n2\n3\n\n\n分析上面定义的f函数: 它在其输入a中是分段线性的。 对于任何a，存在某个常量标量k，使得f(a)=k*a，其中k的值取决于输入a。 因此，可以用d/a验证梯度是否正确。\n\na.grad == d / a\n\n\n1\n\n\ntensor(true)\n\n\n1\n',charsets:{cjk:!0},lastUpdated:"2022/02/11, 02:24:43",lastUpdatedTimestamp:1644517483e3},{title:"blog_test",frontmatter:{title:"blog_test",date:"2022-02-05T16:03:47.000Z",permalink:"/pages/b0b256/",categories:["实践","动手学深度学习"],tags:[null]},regularPath:"/02.%E5%AE%9E%E8%B7%B5/01.%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/100.blog_test.html",relativePath:"02.实践/01.动手学深度学习/100.blog_test.md",key:"v-ae61211c",path:"/pages/b0b256/",headersStr:null,content:"Ctrl+F9\n\nsadasd[1]\n\n * <span style=\"font-size:2rem; background:yellow;\">**Bigger**</span>\n\nBigger\n\n * <span style='color:red'>This is red</span>\n\nThis is red\n\nI have keys but no locks. I have space but no room. You can enter but can't leave. What am I? A keyboard.\n\n\n\n的说法\n\n\n\n----------------------------------------\n\n 1. asdf ↩︎",normalizedContent:"ctrl+f9\n\nsadasd[1]\n\n * <span style=\"font-size:2rem; background:yellow;\">**bigger**</span>\n\nbigger\n\n * <span style='color:red'>this is red</span>\n\nthis is red\n\ni have keys but no locks. i have space but no room. you can enter but can't leave. what am i? a keyboard.\n\n\n\n的说法\n\n\n\n----------------------------------------\n\n 1. asdf ↩︎",charsets:{cjk:!0},lastUpdated:"2022/02/11, 02:24:43",lastUpdatedTimestamp:1644517483e3},{title:"Hello World",frontmatter:{title:"Hello World",date:"2022-01-24T23:55:24.000Z",permalink:"/pages/7c03e3/",categories:["其它","Github","快速入门"],tags:[null]},regularPath:"/02.%E5%AE%9E%E8%B7%B5/10.Github/01.%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/01.Hello%20World.html",relativePath:"02.实践/10.Github/01.快速入门/01.Hello World.md",key:"v-734f48ea",path:"/pages/7c03e3/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:20},{level:2,title:"创建仓库",slug:"创建仓库",normalizedTitle:"创建仓库",charIndex:398},{level:2,title:"创建分支",slug:"创建分支",normalizedTitle:"创建分支",charIndex:775},{level:2,title:"创建分支",slug:"创建分支-2",normalizedTitle:"创建分支",charIndex:775},{level:2,title:"进行和提交更改",slug:"进行和提交更改",normalizedTitle:"进行和提交更改",charIndex:1410},{level:2,title:"打开拉取请求",slug:"打开拉取请求",normalizedTitle:"打开拉取请求",charIndex:1777},{level:2,title:"合并您的pull request",slug:"合并您的pull-request",normalizedTitle:"合并您的pull request",charIndex:2439},{level:2,title:"后续步骤",slug:"后续步骤",normalizedTitle:"后续步骤",charIndex:2605}],headersStr:"简介 创建仓库 创建分支 创建分支 进行和提交更改 打开拉取请求 合并您的pull request 后续步骤",content:"官方文档\n\n\n# 1.快速入门\n\n\n# 简介\n\nGitHub 是一个用于版本控制和协作的代码托管平台。 它使您和其他人可以在任何地方一起处理项目。\n\n本教程向您介绍 GitHub 基本知识，例如存储库、分支、提交和拉取请求。 您将创建自己的 Hello World 存储库并学习 GitHub 的拉取请求工作流程，这是一种创建和审查代码的流行方式。\n\n在本快速入门指南中，您将：\n\n * 创建和使用存储库（repository）\n * 启动和管理新分支（branch）\n * 对文件进行更改并将其作为提交（commits）推送（push）到 GitHub\n * 打开并合并（merge）拉取请求（pull request）\n\n要完成本教程，您需要一个 GitHub 帐户和 Internet 访问权限。您无需知道如何编码、使用命令行或安装 Git（构建 GitHub 的版本控制软件）。\n\n\n# 创建仓库\n\n存储库通常用于组织单个项目。存储库可以包含文件夹和文件、图像、视频、电子表格和数据集——项目需要的任何内容。通常，存储库包括一个README自述文件，一个包含项目信息的文件。GitHub使您可以轻松地在创建新存储库的同时添加一个存储库。它还提供了其他常见选项，如许可证文件。\n\n您的hello world存储库可以是您存储想法、资源，甚至与他人共享和讨论事物的地方。\n\n 1. 在任何页面的右上角，使用 下拉菜单选择 New repository（新建仓库）。\n    \n    \n\n 2. 在存储库名称框中，输入hello-world。\n    \n    。\n\n 3. 在描述框中，写一个简短的描述。\n\n 4. 选择 Add a README file添加自述文件\n\n 5. 单击 Create repository（创建仓库）。\n\n\n# 创建分支\n\n分支允许您一次拥有不同版本的存储库。\n\n默认情况下，存储库有一个名为main的分支，该分支被视为最终分支。在将分支提交到main之前，可以使用分支进行试验和编辑。\n\n当您在main分支之外创建分支时，您正在创建main分支在该时间点的副本或快照（snapshot）。如果其他人在您处理您的分支时对main分支进行了更改，您可以拉入这些更新。\n\n此图显示：\n\n * main分支\n * 一个叫feature的新分支\n * 该feature分支在合并到main分支之前所经历的过程\n   * \n\n您是否保存过文件的不同版本？比如：\n\n * story.txt\n * story-joe-edit.txt\n * story-joe-edit-reviewed.txt\n\n分支在GitHub存储库中实现类似的目标。 在GitHub，我们的开发人员、编写人员和设计人员使用分支将bug修复和功能工作与我们的main（生产）分支分开。当变更准备就绪时，它们将分支合并到main分支中。\n\n\n# 创建分支\n\n1.单击 hello-world 存储库的Code选项卡。\n\n2.单击main文件列表顶部的下拉菜单。\n\n\n\n3.在文本框中输入分支名称 readme-edits。\n\n4.单击Create branch: readme-edits创建分支。\n\n现在有了两个分支，main和readme-edits。现在，他们看起来一模一样。接下来，您将向新分支添加更改。\n\n\n# 进行和提交更改\n\n在上一步中创建新分支时，GitHub将您带到新readme-edits分支的代码页，这是main的副本。\n\n您可以对存储库中的文件进行更改并保存。在GitHub上，保存的更改称为提交(commits)。每个提交都有一条关联的提交消息，这是一条解释为什么要进行特定更改的描述。提交消息捕获更改的历史记录，以便其他贡献者能够理解您所做的事情及其原因。\n\n 1. 点击 README.md文件.\n 2. 点击编辑文件.\n 3. 在编辑器中写点东西.\n 4. 在 Commit changes框中, 写下有关你的更改的提交信息.\n 5. 单击 Commit changes（提交更改）。\n\n这些更改将仅对您的 readme-edits 分支上的 README 文件进行，因此现在此分支包含与 main 不同的内容。\n\n\n# 打开拉取请求\n\n既然在main的分支中进行了更改，就可以打开一个pull请求。\n\n拉取请求是GitHub上协作的核心。当您打开一个pull request时，您正在建议您的更改，并请求某人审查(review )并加入您的贡献，并将它们合并到他们的分支中。Pull requests显示来自两个分支的内容的差异。更改、添加和删除以不同的颜色显示。\n\n一旦进行提交，就可以打开pull request并开始讨论，甚至在代码完成之前。\n\n通过在pull request消息中使用GitHub的@notice功能，您可以请求特定人员或团队的反馈，无论他们是在大厅内还是在10个时区之外。\n\n您甚至可以在自己的存储库中打开pull request并自己合并它们。在进行更大的项目之前，这是学习GitHub流(flow)的一个好方法。\n\n 1. 点击Pull requests 选项卡。\n 2. 点击 New pull request\n 3. 在 Example Comparisons 框中，选择您创建的分支 readme-edits 以与 main（原始）进行比较。\n 4. 在比较页面上查看您对差异的更改，确保它们是您要提交的内容。\n\n\n\n5.单击 Create pull request（创建拉取请求）。\n\n6.给你的拉取请求一个标题并写下你的更改的简短描述。您可以包含表情符号以及拖放图像和 GIF。\n\n7.单击 Create pull request（创建拉取请求）。\n\n您的协作者现在可以查看您的编辑并提出建议。\n\n\n# 合并您的pull request\n\n在这最后一步中，您会将readme-edits分支合并到main分支中。\n\n 1. 点击Merge pull request 合并更改到 main.\n 2. 单击 Confirm merge（确认合并）。\n 3. 通过单击Delete branch继续并删除分支，因为它的更改已被合并。\n\n\n# 后续步骤\n\n通过完成本教程，您已经学会了在GitHub上创建项目并发出请求。\n\n以下是您在本教程中完成的内容：\n\n * 创建了一个开源存储库\n * 创办并管理了一个新的分支机构\n * 更改了一个文件并将这些更改提交给GitHub\n * 打开并合并拉取请求\n\n查看一下您的GitHub配置文件，您将看到您的工作反映在您的贡献图上。\n\n\n\n有关分支和拉请求功能的更多信息，请参阅“GitHub流”\n\n有关GitHub入门的更多信息，请参阅《快速入门》中的其他指南。",normalizedContent:"官方文档\n\n\n# 1.快速入门\n\n\n# 简介\n\ngithub 是一个用于版本控制和协作的代码托管平台。 它使您和其他人可以在任何地方一起处理项目。\n\n本教程向您介绍 github 基本知识，例如存储库、分支、提交和拉取请求。 您将创建自己的 hello world 存储库并学习 github 的拉取请求工作流程，这是一种创建和审查代码的流行方式。\n\n在本快速入门指南中，您将：\n\n * 创建和使用存储库（repository）\n * 启动和管理新分支（branch）\n * 对文件进行更改并将其作为提交（commits）推送（push）到 github\n * 打开并合并（merge）拉取请求（pull request）\n\n要完成本教程，您需要一个 github 帐户和 internet 访问权限。您无需知道如何编码、使用命令行或安装 git（构建 github 的版本控制软件）。\n\n\n# 创建仓库\n\n存储库通常用于组织单个项目。存储库可以包含文件夹和文件、图像、视频、电子表格和数据集——项目需要的任何内容。通常，存储库包括一个readme自述文件，一个包含项目信息的文件。github使您可以轻松地在创建新存储库的同时添加一个存储库。它还提供了其他常见选项，如许可证文件。\n\n您的hello world存储库可以是您存储想法、资源，甚至与他人共享和讨论事物的地方。\n\n 1. 在任何页面的右上角，使用 下拉菜单选择 new repository（新建仓库）。\n    \n    \n\n 2. 在存储库名称框中，输入hello-world。\n    \n    。\n\n 3. 在描述框中，写一个简短的描述。\n\n 4. 选择 add a readme file添加自述文件\n\n 5. 单击 create repository（创建仓库）。\n\n\n# 创建分支\n\n分支允许您一次拥有不同版本的存储库。\n\n默认情况下，存储库有一个名为main的分支，该分支被视为最终分支。在将分支提交到main之前，可以使用分支进行试验和编辑。\n\n当您在main分支之外创建分支时，您正在创建main分支在该时间点的副本或快照（snapshot）。如果其他人在您处理您的分支时对main分支进行了更改，您可以拉入这些更新。\n\n此图显示：\n\n * main分支\n * 一个叫feature的新分支\n * 该feature分支在合并到main分支之前所经历的过程\n   * \n\n您是否保存过文件的不同版本？比如：\n\n * story.txt\n * story-joe-edit.txt\n * story-joe-edit-reviewed.txt\n\n分支在github存储库中实现类似的目标。 在github，我们的开发人员、编写人员和设计人员使用分支将bug修复和功能工作与我们的main（生产）分支分开。当变更准备就绪时，它们将分支合并到main分支中。\n\n\n# 创建分支\n\n1.单击 hello-world 存储库的code选项卡。\n\n2.单击main文件列表顶部的下拉菜单。\n\n\n\n3.在文本框中输入分支名称 readme-edits。\n\n4.单击create branch: readme-edits创建分支。\n\n现在有了两个分支，main和readme-edits。现在，他们看起来一模一样。接下来，您将向新分支添加更改。\n\n\n# 进行和提交更改\n\n在上一步中创建新分支时，github将您带到新readme-edits分支的代码页，这是main的副本。\n\n您可以对存储库中的文件进行更改并保存。在github上，保存的更改称为提交(commits)。每个提交都有一条关联的提交消息，这是一条解释为什么要进行特定更改的描述。提交消息捕获更改的历史记录，以便其他贡献者能够理解您所做的事情及其原因。\n\n 1. 点击 readme.md文件.\n 2. 点击编辑文件.\n 3. 在编辑器中写点东西.\n 4. 在 commit changes框中, 写下有关你的更改的提交信息.\n 5. 单击 commit changes（提交更改）。\n\n这些更改将仅对您的 readme-edits 分支上的 readme 文件进行，因此现在此分支包含与 main 不同的内容。\n\n\n# 打开拉取请求\n\n既然在main的分支中进行了更改，就可以打开一个pull请求。\n\n拉取请求是github上协作的核心。当您打开一个pull request时，您正在建议您的更改，并请求某人审查(review )并加入您的贡献，并将它们合并到他们的分支中。pull requests显示来自两个分支的内容的差异。更改、添加和删除以不同的颜色显示。\n\n一旦进行提交，就可以打开pull request并开始讨论，甚至在代码完成之前。\n\n通过在pull request消息中使用github的@notice功能，您可以请求特定人员或团队的反馈，无论他们是在大厅内还是在10个时区之外。\n\n您甚至可以在自己的存储库中打开pull request并自己合并它们。在进行更大的项目之前，这是学习github流(flow)的一个好方法。\n\n 1. 点击pull requests 选项卡。\n 2. 点击 new pull request\n 3. 在 example comparisons 框中，选择您创建的分支 readme-edits 以与 main（原始）进行比较。\n 4. 在比较页面上查看您对差异的更改，确保它们是您要提交的内容。\n\n\n\n5.单击 create pull request（创建拉取请求）。\n\n6.给你的拉取请求一个标题并写下你的更改的简短描述。您可以包含表情符号以及拖放图像和 gif。\n\n7.单击 create pull request（创建拉取请求）。\n\n您的协作者现在可以查看您的编辑并提出建议。\n\n\n# 合并您的pull request\n\n在这最后一步中，您会将readme-edits分支合并到main分支中。\n\n 1. 点击merge pull request 合并更改到 main.\n 2. 单击 confirm merge（确认合并）。\n 3. 通过单击delete branch继续并删除分支，因为它的更改已被合并。\n\n\n# 后续步骤\n\n通过完成本教程，您已经学会了在github上创建项目并发出请求。\n\n以下是您在本教程中完成的内容：\n\n * 创建了一个开源存储库\n * 创办并管理了一个新的分支机构\n * 更改了一个文件并将这些更改提交给github\n * 打开并合并拉取请求\n\n查看一下您的github配置文件，您将看到您的工作反映在您的贡献图上。\n\n\n\n有关分支和拉请求功能的更多信息，请参阅“github流”\n\n有关github入门的更多信息，请参阅《快速入门》中的其他指南。",charsets:{cjk:!0},lastUpdated:"2022/02/11, 02:24:43",lastUpdatedTimestamp:1644517483e3},{title:"设置Git",frontmatter:{title:"设置Git",date:"2022-01-25T14:33:09.000Z",permalink:"/pages/018bc3/",categories:["其它","Github","快速入门"],tags:[null]},regularPath:"/02.%E5%AE%9E%E8%B7%B5/10.Github/01.%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/02.%E8%AE%BE%E7%BD%AEGit.html",relativePath:"02.实践/10.Github/01.快速入门/02.设置Git.md",key:"v-96578d08",path:"/pages/018bc3/",headers:[{level:2,title:"使用 Git",slug:"使用-git",normalizedTitle:"使用 git",charIndex:86},{level:2,title:"设置 Git",slug:"设置-git-2",normalizedTitle:"设置 git",charIndex:2},{level:2,title:"后续步骤：使用来自 Git 的 GitHub 进行身份验证",slug:"后续步骤-使用来自-git-的-github-进行身份验证",normalizedTitle:"后续步骤：使用来自 git 的 github 进行身份验证",charIndex:598},{level:3,title:"通过 HTTPS 连接（推荐）",slug:"通过-https-连接-推荐",normalizedTitle:"通过 https 连接（推荐）",charIndex:757},{level:3,title:"通过 SSH 连接",slug:"通过-ssh-连接",normalizedTitle:"通过 ssh 连接",charIndex:823},{level:2,title:"祝贺",slug:"祝贺",normalizedTitle:"祝贺",charIndex:888}],headersStr:"使用 Git 设置 Git 后续步骤：使用来自 Git 的 GitHub 进行身份验证 通过 HTTPS 连接（推荐） 通过 SSH 连接 祝贺",content:"# 设置 Git\n\nGitHub 的核心是名为 Git 的开源版本控制系统 (VCS) 。 Git 负责在您计算机上本地发生的、与 GitHub 有关的所有内容。\n\n\n# 使用 Git\n\n要在命令行中使用 Git，您将需要在计算机上下载、安装和配置 Git。 您还可以安装 GitHub CLI 以从命令行使用 GitHub。 更多信息请参阅“关于 GitHub CLI”。\n\n如果要在本地使用 Git，但不想使用命令行，您可以下载并安装 GitHub Desktop 客户端。 更多信息请参阅“安装和配置 GitHub Desktop”。\n\n如果无需在本地使用文件，GitHub 可让您在浏览器中直接完成许多 Git 相关的操作，包括：\n\n * 创建仓库\n * 复刻仓库\n * 管理文件\n * 社交化\n\n\n# 设置 Git\n\n 1. 下载并安装最新版本的 Git。\n    \n    注意：如果您使用的是 Chrome OS 设备，则需要进行额外设置：\n    \n    1. 在你的Chrome OS设备上安装一个终端模拟器，比如谷歌Play商店的Termux\n    2. 从您安装的终端模拟器中，安装Git。例如，在Termux中，输入apt install git，然后在提示时键入y。\n\n 2. 在 Git 中设置您的用户名。\n\n 3. 在 Git 中设置提交电子邮件地址。\n\n\n# 后续步骤：使用来自 Git 的 GitHub 进行身份验证\n\n从 Git 连接到 GitHub 仓库时，您将需要使用 HTTPS 或 SSH 通过 GitHub 进行身份验证。\n\n注意：您可以使用GitHub CLI对GitHub进行HTTP或SSH身份验证。有关更多信息，请参阅gh auth login。\n\n\n# 通过 HTTPS 连接（推荐）\n\n如果使用 HTTPS 克隆，您可以使用凭据小助手在 Git 中缓存 GitHub 凭据。\n\n\n# 通过 SSH 连接\n\n如果使用 SSH 克隆，您必须在用于从 GitHub 推送或拉取的每台计算机上生成 SSH 密钥。\n\n\n# 祝贺\n\n恭喜。您现在已将 Git 和 GitHub 全部设置完毕！ 您现在可以选择创建仓库以放置项目。 这是备份代码的好方法，易于在世界各地分享代码。 更多信息请参阅“创建仓库”。\n\n您可以通过复刻创建仓库的副本，并提出您希望看到的更改，而不会影响上游仓库。 更多信息请参阅“复刻仓库”。\n\nGitHub上的每个存储库都由一个人或一个组织拥有。 您可以在 GitHub 上连接和关注人员、仓库和组织以与之进行交互。 更多信息请参阅“社交”。\n\nGitHub 有一个强大的支持社区，您可以在那里寻求帮助并与来自世界各地的人交谈。 加入 Github 支持社区的对话。",normalizedContent:"# 设置 git\n\ngithub 的核心是名为 git 的开源版本控制系统 (vcs) 。 git 负责在您计算机上本地发生的、与 github 有关的所有内容。\n\n\n# 使用 git\n\n要在命令行中使用 git，您将需要在计算机上下载、安装和配置 git。 您还可以安装 github cli 以从命令行使用 github。 更多信息请参阅“关于 github cli”。\n\n如果要在本地使用 git，但不想使用命令行，您可以下载并安装 github desktop 客户端。 更多信息请参阅“安装和配置 github desktop”。\n\n如果无需在本地使用文件，github 可让您在浏览器中直接完成许多 git 相关的操作，包括：\n\n * 创建仓库\n * 复刻仓库\n * 管理文件\n * 社交化\n\n\n# 设置 git\n\n 1. 下载并安装最新版本的 git。\n    \n    注意：如果您使用的是 chrome os 设备，则需要进行额外设置：\n    \n    1. 在你的chrome os设备上安装一个终端模拟器，比如谷歌play商店的termux\n    2. 从您安装的终端模拟器中，安装git。例如，在termux中，输入apt install git，然后在提示时键入y。\n\n 2. 在 git 中设置您的用户名。\n\n 3. 在 git 中设置提交电子邮件地址。\n\n\n# 后续步骤：使用来自 git 的 github 进行身份验证\n\n从 git 连接到 github 仓库时，您将需要使用 https 或 ssh 通过 github 进行身份验证。\n\n注意：您可以使用github cli对github进行http或ssh身份验证。有关更多信息，请参阅gh auth login。\n\n\n# 通过 https 连接（推荐）\n\n如果使用 https 克隆，您可以使用凭据小助手在 git 中缓存 github 凭据。\n\n\n# 通过 ssh 连接\n\n如果使用 ssh 克隆，您必须在用于从 github 推送或拉取的每台计算机上生成 ssh 密钥。\n\n\n# 祝贺\n\n恭喜。您现在已将 git 和 github 全部设置完毕！ 您现在可以选择创建仓库以放置项目。 这是备份代码的好方法，易于在世界各地分享代码。 更多信息请参阅“创建仓库”。\n\n您可以通过复刻创建仓库的副本，并提出您希望看到的更改，而不会影响上游仓库。 更多信息请参阅“复刻仓库”。\n\ngithub上的每个存储库都由一个人或一个组织拥有。 您可以在 github 上连接和关注人员、仓库和组织以与之进行交互。 更多信息请参阅“社交”。\n\ngithub 有一个强大的支持社区，您可以在那里寻求帮助并与来自世界各地的人交谈。 加入 github 支持社区的对话。",charsets:{cjk:!0},lastUpdated:"2022/02/11, 02:24:43",lastUpdatedTimestamp:1644517483e3},{title:"简介和安装",frontmatter:{title:"简介和安装",date:"2022-02-07T15:34:30.000Z",permalink:"/pages/35e538/",categories:["实践","Linux"],tags:[null]},regularPath:"/02.%E5%AE%9E%E8%B7%B5/20.Linux/01.%E7%AE%80%E4%BB%8B%E5%92%8C%E5%AE%89%E8%A3%85.html",relativePath:"02.实践/20.Linux/01.简介和安装.md",key:"v-506f5fdb",path:"/pages/35e538/",headers:[{level:2,title:"为什么要学习Linux",slug:"为什么要学习linux",normalizedTitle:"为什么要学习linux",charIndex:64},{level:2,title:"安装Linux",slug:"安装linux",normalizedTitle:"安装linux",charIndex:397},{level:2,title:"查看当前目录文件大小",slug:"查看当前目录文件大小",normalizedTitle:"查看当前目录文件大小",charIndex:1282},{level:2,title:"查看硬件信息",slug:"查看硬件信息",normalizedTitle:"查看硬件信息",charIndex:1318}],headersStr:"为什么要学习Linux 安装Linux 查看当前目录文件大小 查看硬件信息",content:'Linux Ubuntu 零基础教程_哔哩哔哩_bilibili\n\n白月黑羽 (byhy.net)\n\n\n# 简介和安装\n\n\n# 为什么要学习Linux\n\nLinux 和我们熟知的 Windows 一样，都是 操作系统 。\n\n那么操作系统又是什么？\n\n简单说，操作系统是 管理 计算机硬件 和 所有应用程序 的 系统软件 。\n\n它对下管理机器所有的硬件，对上管理着应用程序。\n\n负责加载、运行、调度、终止应用程序，并提供编程接口和服务给应用程序调用（使用各种硬件资源），完成各种各样的功能。\n\n现在的软件系统，通常都有服务端，比如：京东、微信、抖音、美团、网易等等，都有个服务端系统提供数据信息。\n\n这些服务 80% 以上都是运行在Linux操作系统上。\n\n大家如果成为软件行业的工程师，基本都是要和Linux打交道的。\n\n而且IT职位面试的时候，Linux相关操作，是常常会被问到的。\n\n\n# 安装Linux\n\nLinux 就是一个操作系统， 和大家熟悉的 Windows 一样。\n\n所以我们要使用它，就需要先安装到电脑上。\n\n你可以安装在一台单独的电脑上， 也可以安装在虚拟机里面。\n\n虚拟机，就是在你的电脑上用软件模拟的电脑。\n\n这个模拟出电脑的软件称之为 虚拟机软件（也可以叫模拟器） ，常见的有 VirtualBox、VMware系列。\n\n我们可以在模拟的电脑里面 安装其他的操作系统， 比如Linux。\n\n这样我们就在一个程序窗口里面运行另外一个操作系统了。\n\nWindows操作系统有 Windows 7 、Windows 10、 Windows server 2016 等等众多的版本。\n\nLinux 版本更多，比如 Ubuntu、Debian、RedHat、CentOS、Fedora等，这些都是Linux系统的不同发行版本.\n\n我们教程就以 Ubuntu 为例讲解如何安装。\n\n运行虚拟机软件的操作系统 我们称之为 Host OS， 虚拟机 软件里面的操作系统称之为 Guest OS\n\n本文中的 Host 是 Windows 10 ， 而 Guest 是 Ubuntu\n\n虚拟机安装 Ubuntu 分为两步\n\n * 创建虚拟机（就是虚拟电脑）\n\n首先要下载虚拟机软件，这里推荐Virtualbox\n\n * 在虚拟机上安装 Ubuntu 操作系统\n\n在虚拟机安装Ubuntu，大家需要下载 Ubuntu 的安装光盘镜像文件。\n\n在国外下载比较慢，推荐到国内的镜像站点下载 ，下面是安装链接。\n\n点击这里下载 Ubuntu Server 安装盘镜像\n\n具体安装过程，请看视频讲解\n\n\n# 基本命令\n\n * mkdir:在当前目录下新建一个子目录（文件夹）\n * ls:查看当前目录下包括哪些文件和文件夹\n * touch：新建一个文件\n * mv：移动文件\n * cp:复制文件到另一个文件夹\n * passwd：更改当前用户（当前环境下为root用户）的密码\n\n\n# 快捷键\n\nctrl+alt+E:跳转到该单词的末尾\n\n\n# 常用命令\n\n\n# 查看当前目录文件大小\n\ndu -h --max-depth=1\n\n\n# 查看硬件信息\n\n * 查看 CPU 和处理单元的信息：lscpu\n   \n   * \n\n * lspci:另一个命令行工具，可以用来列出所有的 PCI 总线，还有与 PCI 总线相连的设备的详细信息，比如 VGA 适配器、显卡、网络适配器、usb 端口、SATA 控制器等\n   \n   * \n   * lspci -v | grep "VGA" -A 12:过滤出特定设备的信息,可以看到类似下图的关于显卡的信息:\n     * \n   * lspci | grep -i vga:直接得到显卡的16进制编号，然后在网站上查询\n     * \n     * \n\n * lshw -short:lshw是一个通用的工具，可以列出多种硬件单元的详细或者概要的信息，比如 CPU、内存、usb 控制器、硬盘等。lshw能够从各个“/proc”文件中提取出相关的信息。\n   \n   * \n\n * lsusb:lsusb命令能够列出 USB 控制器和与 USB 控制器相连的设备的详细信息。默认情况下，lsusb命令只打印出概要信息。可以通过使用-v参数打印每一个usb端口的详细信息。\n   \n   * \n\n * df -h:df命令能够列出不同分区的概要信息、挂载点、已用的和可用的空间。\n   \n   * \n\n * free:通过使用free命令可以查看内存,查看系统中使用的、闲置的和 RAM 的总体数量。\n   \n   * \n\n * hdparm:hdparm命令可以用来显示像硬盘这样的 sata 设备的信息。\n   \n   * hdparm /dev/sda:显示硬盘的相关设置\n   * hdparm -t /dev/sda:评估硬盘的读取效率\n\n * uname -a:查看系统版本信息\n   \n   * \n   * 或者cat /proc/version\n     * \n\n * nvidia-smi:Nvidia自带了一个nvidia-smi的命令行工具，会显示显存使用情况\n   \n   * 温度、内存使用、GPU占有率情况\n   \n   * \n   \n   * \n   \n   * 表头释义：\n     \n     * Fan：显示风扇转速，数值在0到100%之间，是计算机的期望转速，如果计算机不是通过风扇冷却或者风扇坏了，显示出来就是N/A； Temp：显卡内部的温度，单位是摄氏度； Perf：表征性能状态，从P0到P12，P0表示最大性能，P12表示状态最小性能； Pwr：能耗表示； Bus-Id：涉及GPU总线的相关信息； Disp.A：是Display Active的意思，表示GPU的显示是否初始化； Memory Usage：显存的使用率； Volatile GPU-Util：浮动的GPU利用率； Compute M：计算模式； 下边的Processes显示每块GPU上每个进程所使用的显存情况。\n   \n   * 如果要周期性的输出显卡的使用情况，可以用watch指令实现：\n     \n     * watch -n 1 nvidia-smi：课一更改参数1，表示刷新秒数\n       * 如果希望来周期性地执行其他命令行操作，那么就可以简单地更换后面的nvidia-smi即可\n       * ctrl+c可以退出watch命令\n\n----------------------------------------\n\nUbuntu 没有盘符这个概念，只有一个根目录 / 。\n\nLinux主要目录介绍效果图:\n\n主要目录说明:\n\n * /：根目录\n * /bin：可执行二进制文件的目录\n * /etc：系统配置文件存放的目录\n * /home：用户家目录\n\n\n# Linux内核\n\nLinux内核是操作系统内部操作和控制硬件设备的核心程序，它是由芬兰人林纳斯开发的。\n\n内核效果图:\n\n说明:\n\n真正操作和控制硬件是由内核来完成的，操作系统是基于内核开发出来的。\n\n\n# Linux发行版\n\n是Linux内核与各种常用软件的组合产品，通俗来说就是我们常说的Linux操作系统。\n\n常用的Linux发行版:\n\n * Ubuntu\n * CentOS\n * Redhat\n\nLinux发行版效果图:',normalizedContent:'linux ubuntu 零基础教程_哔哩哔哩_bilibili\n\n白月黑羽 (byhy.net)\n\n\n# 简介和安装\n\n\n# 为什么要学习linux\n\nlinux 和我们熟知的 windows 一样，都是 操作系统 。\n\n那么操作系统又是什么？\n\n简单说，操作系统是 管理 计算机硬件 和 所有应用程序 的 系统软件 。\n\n它对下管理机器所有的硬件，对上管理着应用程序。\n\n负责加载、运行、调度、终止应用程序，并提供编程接口和服务给应用程序调用（使用各种硬件资源），完成各种各样的功能。\n\n现在的软件系统，通常都有服务端，比如：京东、微信、抖音、美团、网易等等，都有个服务端系统提供数据信息。\n\n这些服务 80% 以上都是运行在linux操作系统上。\n\n大家如果成为软件行业的工程师，基本都是要和linux打交道的。\n\n而且it职位面试的时候，linux相关操作，是常常会被问到的。\n\n\n# 安装linux\n\nlinux 就是一个操作系统， 和大家熟悉的 windows 一样。\n\n所以我们要使用它，就需要先安装到电脑上。\n\n你可以安装在一台单独的电脑上， 也可以安装在虚拟机里面。\n\n虚拟机，就是在你的电脑上用软件模拟的电脑。\n\n这个模拟出电脑的软件称之为 虚拟机软件（也可以叫模拟器） ，常见的有 virtualbox、vmware系列。\n\n我们可以在模拟的电脑里面 安装其他的操作系统， 比如linux。\n\n这样我们就在一个程序窗口里面运行另外一个操作系统了。\n\nwindows操作系统有 windows 7 、windows 10、 windows server 2016 等等众多的版本。\n\nlinux 版本更多，比如 ubuntu、debian、redhat、centos、fedora等，这些都是linux系统的不同发行版本.\n\n我们教程就以 ubuntu 为例讲解如何安装。\n\n运行虚拟机软件的操作系统 我们称之为 host os， 虚拟机 软件里面的操作系统称之为 guest os\n\n本文中的 host 是 windows 10 ， 而 guest 是 ubuntu\n\n虚拟机安装 ubuntu 分为两步\n\n * 创建虚拟机（就是虚拟电脑）\n\n首先要下载虚拟机软件，这里推荐virtualbox\n\n * 在虚拟机上安装 ubuntu 操作系统\n\n在虚拟机安装ubuntu，大家需要下载 ubuntu 的安装光盘镜像文件。\n\n在国外下载比较慢，推荐到国内的镜像站点下载 ，下面是安装链接。\n\n点击这里下载 ubuntu server 安装盘镜像\n\n具体安装过程，请看视频讲解\n\n\n# 基本命令\n\n * mkdir:在当前目录下新建一个子目录（文件夹）\n * ls:查看当前目录下包括哪些文件和文件夹\n * touch：新建一个文件\n * mv：移动文件\n * cp:复制文件到另一个文件夹\n * passwd：更改当前用户（当前环境下为root用户）的密码\n\n\n# 快捷键\n\nctrl+alt+e:跳转到该单词的末尾\n\n\n# 常用命令\n\n\n# 查看当前目录文件大小\n\ndu -h --max-depth=1\n\n\n# 查看硬件信息\n\n * 查看 cpu 和处理单元的信息：lscpu\n   \n   * \n\n * lspci:另一个命令行工具，可以用来列出所有的 pci 总线，还有与 pci 总线相连的设备的详细信息，比如 vga 适配器、显卡、网络适配器、usb 端口、sata 控制器等\n   \n   * \n   * lspci -v | grep "vga" -a 12:过滤出特定设备的信息,可以看到类似下图的关于显卡的信息:\n     * \n   * lspci | grep -i vga:直接得到显卡的16进制编号，然后在网站上查询\n     * \n     * \n\n * lshw -short:lshw是一个通用的工具，可以列出多种硬件单元的详细或者概要的信息，比如 cpu、内存、usb 控制器、硬盘等。lshw能够从各个“/proc”文件中提取出相关的信息。\n   \n   * \n\n * lsusb:lsusb命令能够列出 usb 控制器和与 usb 控制器相连的设备的详细信息。默认情况下，lsusb命令只打印出概要信息。可以通过使用-v参数打印每一个usb端口的详细信息。\n   \n   * \n\n * df -h:df命令能够列出不同分区的概要信息、挂载点、已用的和可用的空间。\n   \n   * \n\n * free:通过使用free命令可以查看内存,查看系统中使用的、闲置的和 ram 的总体数量。\n   \n   * \n\n * hdparm:hdparm命令可以用来显示像硬盘这样的 sata 设备的信息。\n   \n   * hdparm /dev/sda:显示硬盘的相关设置\n   * hdparm -t /dev/sda:评估硬盘的读取效率\n\n * uname -a:查看系统版本信息\n   \n   * \n   * 或者cat /proc/version\n     * \n\n * nvidia-smi:nvidia自带了一个nvidia-smi的命令行工具，会显示显存使用情况\n   \n   * 温度、内存使用、gpu占有率情况\n   \n   * \n   \n   * \n   \n   * 表头释义：\n     \n     * fan：显示风扇转速，数值在0到100%之间，是计算机的期望转速，如果计算机不是通过风扇冷却或者风扇坏了，显示出来就是n/a； temp：显卡内部的温度，单位是摄氏度； perf：表征性能状态，从p0到p12，p0表示最大性能，p12表示状态最小性能； pwr：能耗表示； bus-id：涉及gpu总线的相关信息； disp.a：是display active的意思，表示gpu的显示是否初始化； memory usage：显存的使用率； volatile gpu-util：浮动的gpu利用率； compute m：计算模式； 下边的processes显示每块gpu上每个进程所使用的显存情况。\n   \n   * 如果要周期性的输出显卡的使用情况，可以用watch指令实现：\n     \n     * watch -n 1 nvidia-smi：课一更改参数1，表示刷新秒数\n       * 如果希望来周期性地执行其他命令行操作，那么就可以简单地更换后面的nvidia-smi即可\n       * ctrl+c可以退出watch命令\n\n----------------------------------------\n\nubuntu 没有盘符这个概念，只有一个根目录 / 。\n\nlinux主要目录介绍效果图:\n\n主要目录说明:\n\n * /：根目录\n * /bin：可执行二进制文件的目录\n * /etc：系统配置文件存放的目录\n * /home：用户家目录\n\n\n# linux内核\n\nlinux内核是操作系统内部操作和控制硬件设备的核心程序，它是由芬兰人林纳斯开发的。\n\n内核效果图:\n\n说明:\n\n真正操作和控制硬件是由内核来完成的，操作系统是基于内核开发出来的。\n\n\n# linux发行版\n\n是linux内核与各种常用软件的组合产品，通俗来说就是我们常说的linux操作系统。\n\n常用的linux发行版:\n\n * ubuntu\n * centos\n * redhat\n\nlinux发行版效果图:',charsets:{cjk:!0},lastUpdated:"2022/02/25, 11:09:41",lastUpdatedTimestamp:1645758581e3},{title:"Mobaxterm",frontmatter:{title:"Mobaxterm",date:"2022-02-12T13:16:03.000Z",permalink:"/pages/2d796d/",categories:["软件"],tags:[null]},regularPath:"/04.%E8%BD%AF%E4%BB%B6/01.Mobaxterm.html",relativePath:"04.软件/01.Mobaxterm.md",key:"v-1febd3ef",path:"/pages/2d796d/",headers:[{level:2,title:"ssh登录",slug:"ssh登录",normalizedTitle:"ssh登录",charIndex:230}],headersStr:"ssh登录",content:"Mobaxterm\n\n官网\n\n\n\n启动本地终端后会打开内置的cygwin，可以在windows下运行Linux\n\n并且兼容windows的CMD，可以输入CMD命令\n\n----------------------------------------\n\n * 输入ls /usr/bin/可以查看可以使用的命令\n\n\n\n * 或者直接输入busybox\n\n\n\n> BusyBox是一种多调用二进制文件，它将许多常见的Unix实用程序组合到一个可执行文件中\n\n\n# ssh登录\n\nSecure Shell （安全外壳协议，简称 SSH ）是一种加密的 网络传输协议 ，可在不安全的网络中为网络服务提供安全的传输环境 。. SSH通过在网络中建立 安全隧道 （英语：secure channel） 来实现SSH客户端与服务器之间的连接 。. SSH最常见的用途是远程登录系统，人们通常利用SSH来传输 命令行界面 和远程执行命令。. SSH使用频率最高的场合是 类Unix系统 ，\n\n----------------------------------------\n\n默认输入IP地址和用户名就可以了\n\n还可以设置字体大小\n\n以及会话的图标\n\n * 上面显示了登录服务器后可以使用哪些服务器\n\n\n\n * 登录ssh时也默认登录SFTP ,所以能查看目录结构\n\n\n\n * 显示以.开头的隐藏文件\n\n\n\n * 设置文件权限\n\n\n\n采用UGO的权限模式\n\n * * 这两个功能可以打开，可以资源监视器以及使文件目录跟随命令行的cd而改变\n * 分屏\n\n",normalizedContent:"mobaxterm\n\n官网\n\n\n\n启动本地终端后会打开内置的cygwin，可以在windows下运行linux\n\n并且兼容windows的cmd，可以输入cmd命令\n\n----------------------------------------\n\n * 输入ls /usr/bin/可以查看可以使用的命令\n\n\n\n * 或者直接输入busybox\n\n\n\n> busybox是一种多调用二进制文件，它将许多常见的unix实用程序组合到一个可执行文件中\n\n\n# ssh登录\n\nsecure shell （安全外壳协议，简称 ssh ）是一种加密的 网络传输协议 ，可在不安全的网络中为网络服务提供安全的传输环境 。. ssh通过在网络中建立 安全隧道 （英语：secure channel） 来实现ssh客户端与服务器之间的连接 。. ssh最常见的用途是远程登录系统，人们通常利用ssh来传输 命令行界面 和远程执行命令。. ssh使用频率最高的场合是 类unix系统 ，\n\n----------------------------------------\n\n默认输入ip地址和用户名就可以了\n\n还可以设置字体大小\n\n以及会话的图标\n\n * 上面显示了登录服务器后可以使用哪些服务器\n\n\n\n * 登录ssh时也默认登录sftp ,所以能查看目录结构\n\n\n\n * 显示以.开头的隐藏文件\n\n\n\n * 设置文件权限\n\n\n\n采用ugo的权限模式\n\n * * 这两个功能可以打开，可以资源监视器以及使文件目录跟随命令行的cd而改变\n * 分屏\n\n",charsets:{cjk:!0},lastUpdated:"2022/02/25, 10:57:13",lastUpdatedTimestamp:1645757833e3},{title:"Everything",frontmatter:{title:"Everything",date:"2022-02-12T13:17:03.000Z",permalink:"/pages/aa7af1/",categories:["软件"],tags:[null]},regularPath:"/04.%E8%BD%AF%E4%BB%B6/10.Everything.html",relativePath:"04.软件/10.Everything.md",key:"v-1dc7bf9f",path:"/pages/aa7af1/",headers:[{level:2,title:"Everything",slug:"everything",normalizedTitle:"everything",charIndex:7},{level:3,title:'"Everything" 是什么？',slug:"everything-是什么",normalizedTitle:"&quot;everything&quot; 是什么？",charIndex:null},{level:3,title:'"Everything" 索引全部文件需要多长时间？',slug:"everything-索引全部文件需要多长时间",normalizedTitle:"&quot;everything&quot; 索引全部文件需要多长时间？",charIndex:null},{level:3,title:'"Everything" 能否搜索文件内容？',slug:"everything-能否搜索文件内容",normalizedTitle:"&quot;everything&quot; 能否搜索文件内容？",charIndex:null},{level:3,title:'"Everything" 是否占用很多系统资源？',slug:"everything-是否占用很多系统资源",normalizedTitle:"&quot;everything&quot; 是否占用很多系统资源？",charIndex:null},{level:3,title:'"Everything" 能否监控文件系统变更？',slug:"everything-能否监控文件系统变更",normalizedTitle:"&quot;everything&quot; 能否监控文件系统变更？",charIndex:null},{level:3,title:'"Everything" 免费么？',slug:"everything-免费么",normalizedTitle:"&quot;everything&quot; 免费么？",charIndex:null},{level:3,title:'"Everything" 是否包含恶意、间谍软件或广告？',slug:"everything-是否包含恶意、间谍软件或广告",normalizedTitle:"&quot;everything&quot; 是否包含恶意、间谍软件或广告？",charIndex:null},{level:3,title:'"Everything" 在非运行时是否会丢失文件系统变更？',slug:"everything-在非运行时是否会丢失文件系统变更",normalizedTitle:"&quot;everything&quot; 在非运行时是否会丢失文件系统变更？",charIndex:null},{level:3,title:'"Everything" 的系统要求是什么？',slug:"everything-的系统要求是什么",normalizedTitle:"&quot;everything&quot; 的系统要求是什么？",charIndex:null},{level:3,title:"怎么样转换分卷为 NTFS？",slug:"怎么样转换分卷为-ntfs",normalizedTitle:"怎么样转换分卷为 ntfs？",charIndex:1094},{level:3,title:'"Everything" 能否可以索引映射的网络分区？',slug:"everything-能否可以索引映射的网络分区",normalizedTitle:"&quot;everything&quot; 能否可以索引映射的网络分区？",charIndex:null},{level:3,title:'如何安装 "Everything"？',slug:"如何安装-everything",normalizedTitle:"如何安装 &quot;everything&quot;？",charIndex:null},{level:3,title:'如何使用 "Everything"？',slug:"如何使用-everything",normalizedTitle:"如何使用 &quot;everything&quot;？",charIndex:null},{level:3,title:'为何 "Everything" 1.4 比 1.3 占用更多内存？',slug:"为何-everything-1-4-比-1-3-占用更多内存",normalizedTitle:"为何 &quot;everything&quot; 1.4 比 1.3 占用更多内存？",charIndex:null},{level:3,title:'如何在运行 "Everything" 时屏蔽 UAC 警告？',slug:"如何在运行-everything-时屏蔽-uac-警告",normalizedTitle:"如何在运行 &quot;everything&quot; 时屏蔽 uac 警告？",charIndex:null},{level:2,title:"搜索",slug:"搜索",normalizedTitle:"搜索",charIndex:67},{level:3,title:"如何搜索文件或文件夹？",slug:"如何搜索文件或文件夹",normalizedTitle:"如何搜索文件或文件夹？",charIndex:1982},{level:3,title:"",slug:"如何使用布尔运算符",normalizedTitle:"",charIndex:0},{level:3,title:"如何使用？",slug:"如何使用通配符",normalizedTitle:"如何使用？",charIndex:null},{level:3,title:"如何搜索包含空格的关键词？",slug:"如何搜索包含空格的关键词",normalizedTitle:"如何搜索包含空格的关键词？",charIndex:2399},{level:3,title:"如何搜索文件类型？",slug:"如何搜索文件类型",normalizedTitle:"如何搜索文件类型？",charIndex:2464},{level:3,title:"如何搜索？",slug:"如何搜索指定位置的文件和文件夹",normalizedTitle:"如何搜索？",charIndex:null},{level:3,title:"高级搜索",slug:"高级搜索",normalizedTitle:"高级搜索",charIndex:2769},{level:2,title:"疑难解答",slug:"疑难解答",normalizedTitle:"疑难解答",charIndex:2804},{level:3,title:"搜索结果不对",slug:"搜索结果不对",normalizedTitle:"搜索结果不对",charIndex:2813},{level:3,title:"设置未保存",slug:"设置未保存",normalizedTitle:"设置未保存",charIndex:2993},{level:3,title:"结果重复",slug:"结果重复",normalizedTitle:"结果重复",charIndex:3163},{level:3,title:"搜索结果为空或仅包含分区",slug:"搜索结果为空或仅包含分区",normalizedTitle:"搜索结果为空或仅包含分区",charIndex:3422}],headersStr:'Everything "Everything" 是什么？ "Everything" 索引全部文件需要多长时间？ "Everything" 能否搜索文件内容？ "Everything" 是否占用很多系统资源？ "Everything" 能否监控文件系统变更？ "Everything" 免费么？ "Everything" 是否包含恶意、间谍软件或广告？ "Everything" 在非运行时是否会丢失文件系统变更？ "Everything" 的系统要求是什么？ 怎么样转换分卷为 NTFS？ "Everything" 能否可以索引映射的网络分区？ 如何安装 "Everything"？ 如何使用 "Everything"？ 为何 "Everything" 1.4 比 1.3 占用更多内存？ 如何在运行 "Everything" 时屏蔽 UAC 警告？ 搜索 如何搜索文件或文件夹？  如何使用？ 如何搜索包含空格的关键词？ 如何搜索文件类型？ 如何搜索？ 高级搜索 疑难解答 搜索结果不对 设置未保存 结果重复 搜索结果为空或仅包含分区',content:'官网\n\n\n# Everything\n\n\n# "Everything" 是什么？\n\n"Everything" 是 Windows 上一款搜索引擎，它能够基于文件名快速定文件和文件夹位置。\n\n不像 Windows 内置搜索，"Everything" 默认显示电脑上每个文件和文件夹 (就如其名 "Everything")。\n\n您在搜索框输入的关键词将会筛选显示的文件和文件夹。\n\n\n# "Everything" 索引全部文件需要多长时间？\n\n"Everything" 仅索引文件和文件夹名，一般仅需几秒便可建立其数据库。\n\n全新安装的 Windows 10 (大约 120,000 个文件) 仅需 1 秒即可索引完成。\n\n索引 1,000,000 个文件将需要大约 1 分钟。\n\n\n# "Everything" 能否搜索文件内容？\n\n可以，"Everything" 可以通过搜索函数 content: 来搜索文件内容。详见使用Everything进行内容搜索\n\n文件内容未被索引时，搜索内容将会很慢。\n\n\n# "Everything" 是否占用很多系统资源？\n\n不，"Everything" 仅需要使用非常少的系统资源。\n\n全新安装的 Windows 10 (大约 120,000 个文件) 仅需要大约 14 MB 的内存以及不到 9 MB 的硬盘空间。\n\n1,000,000 个文件需要大约 75 MB 的内存和 45 MB 的硬盘空间。\n\n\n# "Everything" 能否监控文件系统变更？\n\n可以，"Everything" 可以监控文件系统变更。\n\n搜索结果就可以反映出文件系统变更。\n\n\n# "Everything" 免费么？\n\n免费，"Everything" 是一款免费软件。\n\n软件开发维护不易，请考虑捐赠。\n\n\n# "Everything" 是否包含恶意、间谍软件或广告？\n\n完全没有，"Everything" 不包含任何恶意、间谍软件或广告。\n\n\n# "Everything" 在非运行时是否会丢失文件系统变更？\n\n不会，"Everything" 在关闭和重新打开中不会丢失文件系统变更 (甚至系统重启也不会)。\n\n"Everything" 将在启动后更新数据库。\n\n\n# "Everything" 的系统要求是什么？\n\n"Everything" 能在 Windows XP、Vista、Windows 7、Windows 8 和 Windows 10 上运行。\n\nNTFS 索引功能需要 Everything 服务或用管理员方式打开 "Everything"。\n\n\n# 怎么样转换分卷为 NTFS？\n\n转换分卷为 NTFS前，请务必备份好任何重要资料。\n\n分卷一旦转换为 NTFS，它将无法转换回 FAT 或 FAT32。\n\n请注意，某些系统可能无法读取 U 盘或 USB 中 NTFS 分卷。\n\n转换分卷为 NTFS：\n\n * 开始菜单，点击运行。\n\n * 输入以下内容并点击确定：\n   \n   cmd\n   \n   \n   1\n   \n\n * 在命令提示符中，输入以下内容并点击确定：\n   \n   convert D: /fs:ntfs\n   \n   \n   1\n   \n   \n   其中 D: 是待转换分区。\n\n\n# "Everything" 能否可以索引映射的网络分区？\n\n可以，请查阅文件夹索引以获取更多信息。\n\n\n# 如何安装 "Everything"？\n\n请查阅 "Everything" 基础安装指南。\n\n\n# 如何使用 "Everything"？\n\n请查阅 "Everything" 基础使用指南。\n\n\n# 为何 "Everything" 1.4 比 1.3 占用更多内存？\n\n"Everything" 1.4 默认索引了文件大小和日期并存储了额外信息以便更快排序。\n\n请查阅最小内存优化以禁用这些变更。\n\n\n# 如何在运行 "Everything" 时屏蔽 UAC 警告？\n\n"Everything" 需要管理员权限以便低级别读取 NTFS 分卷来 NTFS 索引。\n\nUAC 警告可以通过以标准用户运行 "Everything" 和安装 "Everything" 服务或不使用 NTFS 索引来避免。\n\n以标准用户运行 "Everything" 和安装 "Everything" 服务：\n\n * 在 "Everything" 中，打开工具菜单，点击选项。\n * 点击常规页面。\n * 检查 Everything 服务。\n * 取消以管理员方式运行。\n * 点击确定。\n * 退出 "Everything" (右键 Everything 托盘图标并点击退出)。\n * 重启 Everything。\n\n\n# 搜索\n\n\n# 如何搜索文件或文件夹？\n\n在搜索框中输入文件或文件夹部分名称，搜索结果将会立即出现。\n\n\n# 如何使用布尔运算符？\n\nAND 是默认布尔运算符。\n\n例如，搜索 abc 和 123，您可以：\n\nabc 123\n\n\n1\n\n\n搜索两个搜索项中任意一个，在两项中加上 | 。\n\n例如，搜索 .jpg 或 .bmp，您可以：\n\n.jpg | .bmp\n\n\n1\n\n\n搜索时排除某项，在其开头加上 ! 。\n\n例如，搜索除了 abc 以外的内容，您可以：\n\n!abc\n\n\n1\n\n\n查看 Everything 基础搜索语法：\n\n * 在 "Everything" 中，打开帮助菜单，点击搜索语法。\n\n\n# 如何使用通配符？\n\n搜索关键词中使用通配符 * 将会匹配任意数量的任意字符。\n\n例如，搜索以 e 开头并以 g 结尾的文件和文件夹：e*g\n\n搜索关键词中使用通配符 ? 将会匹配任一字符。\n\n例如，搜索含有两个字符扩展名的文件：*.??\n\n\n# 如何搜索包含空格的关键词？\n\n搜索包含空格的关键词，请用双引号。\n\n例如，搜索关键词 foo bar："foo bar"\n\n\n# 如何搜索文件类型？\n\n搜索文件类型，请在搜索框输入扩展名，\n\n例如，搜索 mp3 文件，输入 *.mp3 即可。\n\n搜索多个文件类型，请使用 | 分隔，\n\n例如：.bmp|.jpg 将会搜索 bmp 或 jpg 类型文件。\n\n\n# 如何搜索指定位置的文件和文件夹？\n\n搜索指定位置的文件和文件夹，请在搜索框中使用 \\。\n\n例如，在 downloads 文件夹中搜索全部 mp3 文件：downloads\\ .mp3:注意中间有空格\n\n您也可以在搜索菜单中启用匹配路径并包含路径到搜索关键词中。\n\n例如，启用匹配路径并在 downloads 文件夹中搜索全部 avi 文件：downloads .avi\n\n\n# 高级搜索\n\n查阅 Everything 帮助以获取更多信息。\n\n\n# 疑难解答\n\n\n# 搜索结果不对\n\n请确认以下搜索选项未选择：\n\n * 在 Everything 中，打开搜索菜单：\n * 取消大小写匹配。\n * 取消全字匹配。\n * 取消匹配路径。\n * 取消匹配变音标记。\n * 取消启用正则表达式。\n\n请确认 Everything 筛选器：\n\n * 在 Everything 中，打开搜索菜单：\n * 检查 Everything。\n\n\n# 设置未保存\n\n请确认已启用保存设置和数据到 %APPDATA%\\Everything。\n\n启用保存设置和数据到 %APPDATA%\\Everything：\n\n * 在 Everything 中，打开工具菜单，点击选项。\n * 点击常规页面。\n * 点击保存设置和数据到 %APPDATA%\\Everything。\n * 点击确定。\n\n\n# 结果重复\n\n"Everything" 已自动索引 NTFS 分卷。\n\n添加 NTFS 分卷作为文件夹索引将会导致搜索结果重复。\n\n移除作为文件夹索引的 NTFS 分卷：\n\n * 在 Everything 中，打开工具菜单，点击选项。\n * 点击文件夹页面\n * 选择 NTFS 分卷并点击移除。\n * 点击确定。\n\n检查 NTFS 分卷是否被自动索引：\n\n * 在 Everything 中，打开工具菜单，点击选项。\n * 点击 NTFS 页面。\n * 数据库中 NTFS 分卷必定包含在 NTFS 索引中。\n\n\n# 搜索结果为空或仅包含分区\n\n请确认 "Everything" 服务已运行或 "Everything" 以管理员身份运行。\n\n安装 "Everything" 服务：\n\n * 在 Everything 中，打开工具菜单，点击选项。\n * 点击常规页面。\n * 点击 Everything 服务：\n * 点击确定。\n\n-或-\n\n以管理员身份运行 Everything：\n\n * 在 Everything 中，打开工具菜单，点击选项。\n * 点击常规页面。\n * 点击管理员身份运行：\n * 点击确定。\n\n请确认您拥有至少一个本地 NTFS 分卷。\n\n请查阅转换分卷为 NTFS。\n\n手动启用索引全部本地 NTFS 分卷：\n\n * 在 Everything 中，打开工具菜单，点击选项。\n * 点击 NTFS 页面。\n * 分卷列表中的本地 NTFS 分卷：\n   * 检查包含到数据库。\n   * 检查启用 USN 日志记录。\n   * 检查监控变更。\n * 点击确定。\n\n强制 Everything 重建数据库：\n\n * 在 Everything 中，打开工具菜单，点击选项。\n * 点击索引页面。\n * 点击强制重建。\n * 点击确定。',normalizedContent:'官网\n\n\n# everything\n\n\n# "everything" 是什么？\n\n"everything" 是 windows 上一款搜索引擎，它能够基于文件名快速定文件和文件夹位置。\n\n不像 windows 内置搜索，"everything" 默认显示电脑上每个文件和文件夹 (就如其名 "everything")。\n\n您在搜索框输入的关键词将会筛选显示的文件和文件夹。\n\n\n# "everything" 索引全部文件需要多长时间？\n\n"everything" 仅索引文件和文件夹名，一般仅需几秒便可建立其数据库。\n\n全新安装的 windows 10 (大约 120,000 个文件) 仅需 1 秒即可索引完成。\n\n索引 1,000,000 个文件将需要大约 1 分钟。\n\n\n# "everything" 能否搜索文件内容？\n\n可以，"everything" 可以通过搜索函数 content: 来搜索文件内容。详见使用everything进行内容搜索\n\n文件内容未被索引时，搜索内容将会很慢。\n\n\n# "everything" 是否占用很多系统资源？\n\n不，"everything" 仅需要使用非常少的系统资源。\n\n全新安装的 windows 10 (大约 120,000 个文件) 仅需要大约 14 mb 的内存以及不到 9 mb 的硬盘空间。\n\n1,000,000 个文件需要大约 75 mb 的内存和 45 mb 的硬盘空间。\n\n\n# "everything" 能否监控文件系统变更？\n\n可以，"everything" 可以监控文件系统变更。\n\n搜索结果就可以反映出文件系统变更。\n\n\n# "everything" 免费么？\n\n免费，"everything" 是一款免费软件。\n\n软件开发维护不易，请考虑捐赠。\n\n\n# "everything" 是否包含恶意、间谍软件或广告？\n\n完全没有，"everything" 不包含任何恶意、间谍软件或广告。\n\n\n# "everything" 在非运行时是否会丢失文件系统变更？\n\n不会，"everything" 在关闭和重新打开中不会丢失文件系统变更 (甚至系统重启也不会)。\n\n"everything" 将在启动后更新数据库。\n\n\n# "everything" 的系统要求是什么？\n\n"everything" 能在 windows xp、vista、windows 7、windows 8 和 windows 10 上运行。\n\nntfs 索引功能需要 everything 服务或用管理员方式打开 "everything"。\n\n\n# 怎么样转换分卷为 ntfs？\n\n转换分卷为 ntfs前，请务必备份好任何重要资料。\n\n分卷一旦转换为 ntfs，它将无法转换回 fat 或 fat32。\n\n请注意，某些系统可能无法读取 u 盘或 usb 中 ntfs 分卷。\n\n转换分卷为 ntfs：\n\n * 开始菜单，点击运行。\n\n * 输入以下内容并点击确定：\n   \n   cmd\n   \n   \n   1\n   \n\n * 在命令提示符中，输入以下内容并点击确定：\n   \n   convert d: /fs:ntfs\n   \n   \n   1\n   \n   \n   其中 d: 是待转换分区。\n\n\n# "everything" 能否可以索引映射的网络分区？\n\n可以，请查阅文件夹索引以获取更多信息。\n\n\n# 如何安装 "everything"？\n\n请查阅 "everything" 基础安装指南。\n\n\n# 如何使用 "everything"？\n\n请查阅 "everything" 基础使用指南。\n\n\n# 为何 "everything" 1.4 比 1.3 占用更多内存？\n\n"everything" 1.4 默认索引了文件大小和日期并存储了额外信息以便更快排序。\n\n请查阅最小内存优化以禁用这些变更。\n\n\n# 如何在运行 "everything" 时屏蔽 uac 警告？\n\n"everything" 需要管理员权限以便低级别读取 ntfs 分卷来 ntfs 索引。\n\nuac 警告可以通过以标准用户运行 "everything" 和安装 "everything" 服务或不使用 ntfs 索引来避免。\n\n以标准用户运行 "everything" 和安装 "everything" 服务：\n\n * 在 "everything" 中，打开工具菜单，点击选项。\n * 点击常规页面。\n * 检查 everything 服务。\n * 取消以管理员方式运行。\n * 点击确定。\n * 退出 "everything" (右键 everything 托盘图标并点击退出)。\n * 重启 everything。\n\n\n# 搜索\n\n\n# 如何搜索文件或文件夹？\n\n在搜索框中输入文件或文件夹部分名称，搜索结果将会立即出现。\n\n\n# 如何使用布尔运算符？\n\nand 是默认布尔运算符。\n\n例如，搜索 abc 和 123，您可以：\n\nabc 123\n\n\n1\n\n\n搜索两个搜索项中任意一个，在两项中加上 | 。\n\n例如，搜索 .jpg 或 .bmp，您可以：\n\n.jpg | .bmp\n\n\n1\n\n\n搜索时排除某项，在其开头加上 ! 。\n\n例如，搜索除了 abc 以外的内容，您可以：\n\n!abc\n\n\n1\n\n\n查看 everything 基础搜索语法：\n\n * 在 "everything" 中，打开帮助菜单，点击搜索语法。\n\n\n# 如何使用通配符？\n\n搜索关键词中使用通配符 * 将会匹配任意数量的任意字符。\n\n例如，搜索以 e 开头并以 g 结尾的文件和文件夹：e*g\n\n搜索关键词中使用通配符 ? 将会匹配任一字符。\n\n例如，搜索含有两个字符扩展名的文件：*.??\n\n\n# 如何搜索包含空格的关键词？\n\n搜索包含空格的关键词，请用双引号。\n\n例如，搜索关键词 foo bar："foo bar"\n\n\n# 如何搜索文件类型？\n\n搜索文件类型，请在搜索框输入扩展名，\n\n例如，搜索 mp3 文件，输入 *.mp3 即可。\n\n搜索多个文件类型，请使用 | 分隔，\n\n例如：.bmp|.jpg 将会搜索 bmp 或 jpg 类型文件。\n\n\n# 如何搜索指定位置的文件和文件夹？\n\n搜索指定位置的文件和文件夹，请在搜索框中使用 \\。\n\n例如，在 downloads 文件夹中搜索全部 mp3 文件：downloads\\ .mp3:注意中间有空格\n\n您也可以在搜索菜单中启用匹配路径并包含路径到搜索关键词中。\n\n例如，启用匹配路径并在 downloads 文件夹中搜索全部 avi 文件：downloads .avi\n\n\n# 高级搜索\n\n查阅 everything 帮助以获取更多信息。\n\n\n# 疑难解答\n\n\n# 搜索结果不对\n\n请确认以下搜索选项未选择：\n\n * 在 everything 中，打开搜索菜单：\n * 取消大小写匹配。\n * 取消全字匹配。\n * 取消匹配路径。\n * 取消匹配变音标记。\n * 取消启用正则表达式。\n\n请确认 everything 筛选器：\n\n * 在 everything 中，打开搜索菜单：\n * 检查 everything。\n\n\n# 设置未保存\n\n请确认已启用保存设置和数据到 %appdata%\\everything。\n\n启用保存设置和数据到 %appdata%\\everything：\n\n * 在 everything 中，打开工具菜单，点击选项。\n * 点击常规页面。\n * 点击保存设置和数据到 %appdata%\\everything。\n * 点击确定。\n\n\n# 结果重复\n\n"everything" 已自动索引 ntfs 分卷。\n\n添加 ntfs 分卷作为文件夹索引将会导致搜索结果重复。\n\n移除作为文件夹索引的 ntfs 分卷：\n\n * 在 everything 中，打开工具菜单，点击选项。\n * 点击文件夹页面\n * 选择 ntfs 分卷并点击移除。\n * 点击确定。\n\n检查 ntfs 分卷是否被自动索引：\n\n * 在 everything 中，打开工具菜单，点击选项。\n * 点击 ntfs 页面。\n * 数据库中 ntfs 分卷必定包含在 ntfs 索引中。\n\n\n# 搜索结果为空或仅包含分区\n\n请确认 "everything" 服务已运行或 "everything" 以管理员身份运行。\n\n安装 "everything" 服务：\n\n * 在 everything 中，打开工具菜单，点击选项。\n * 点击常规页面。\n * 点击 everything 服务：\n * 点击确定。\n\n-或-\n\n以管理员身份运行 everything：\n\n * 在 everything 中，打开工具菜单，点击选项。\n * 点击常规页面。\n * 点击管理员身份运行：\n * 点击确定。\n\n请确认您拥有至少一个本地 ntfs 分卷。\n\n请查阅转换分卷为 ntfs。\n\n手动启用索引全部本地 ntfs 分卷：\n\n * 在 everything 中，打开工具菜单，点击选项。\n * 点击 ntfs 页面。\n * 分卷列表中的本地 ntfs 分卷：\n   * 检查包含到数据库。\n   * 检查启用 usn 日志记录。\n   * 检查监控变更。\n * 点击确定。\n\n强制 everything 重建数据库：\n\n * 在 everything 中，打开工具菜单，点击选项。\n * 点击索引页面。\n * 点击强制重建。\n * 点击确定。',charsets:{cjk:!0},lastUpdated:"2022/02/27, 13:12:26",lastUpdatedTimestamp:1645938746e3},{title:"用于显著和特定类别的目标检测的先进深度学习技术",frontmatter:{title:"用于显著和特定类别的目标检测的先进深度学习技术",date:"2022-02-10T14:53:34.000Z",permalink:"/pages/24a19d/",categories:["其它","论文","综述"],tags:[null]},regularPath:"/05.%E5%85%B6%E5%AE%83/01.%E8%AE%BA%E6%96%87/01.%E7%BB%BC%E8%BF%B0/01.%E7%94%A8%E4%BA%8E%E6%98%BE%E8%91%97%E5%92%8C%E7%89%B9%E5%AE%9A%E7%B1%BB%E5%88%AB%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E5%85%88%E8%BF%9B%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8A%80%E6%9C%AF.html",relativePath:"05.其它/01.论文/01.综述/01.用于显著和特定类别的目标检测的先进的深度学习技术.md",key:"v-a8add660",path:"/pages/24a19d/",headers:[{level:2,title:"引言",slug:"引言",normalizedTitle:"引言",charIndex:601},{level:2,title:"预备知识",slug:"预备知识",normalizedTitle:"预备知识",charIndex:2484},{level:2,title:"目标检测的现代方法",slug:"目标检测的现代方法",normalizedTitle:"目标检测的现代方法",charIndex:3983},{level:3,title:"OD中的现代方法",slug:"od中的现代方法",normalizedTitle:"od中的现代方法",charIndex:3997},{level:3,title:"SOD的现代方法",slug:"sod的现代方法",normalizedTitle:"sod的现代方法",charIndex:6040},{level:3,title:"COD的现代方法",slug:"cod的现代方法",normalizedTitle:"cod的现代方法",charIndex:7317},{level:2,title:"OD、SOD、COD之间的关系",slug:"od、sod、cod之间的关系",normalizedTitle:"od、sod、cod之间的关系",charIndex:10239},{level:3,title:"OD与SOD的关系",slug:"od与sod的关系",normalizedTitle:"od与sod的关系",charIndex:10303},{level:3,title:"SOD与COD的关系",slug:"sod与cod的关系",normalizedTitle:"sod与cod的关系",charIndex:11005},{level:3,title:"COD与OD的关系",slug:"cod与od的关系",normalizedTitle:"cod与od的关系",charIndex:11799},{level:2,title:"基准和评价指标",slug:"基准和评价指标",normalizedTitle:"基准和评价指标",charIndex:12326},{level:3,title:"OD的基准",slug:"od的基准",normalizedTitle:"od的基准",charIndex:12338},{level:3,title:"SOD的基准",slug:"sod的基准",normalizedTitle:"sod的基准",charIndex:12710},{level:3,title:"COD的基准",slug:"cod的基准",normalizedTitle:"cod的基准",charIndex:13235},{level:3,title:"OD的评价指标",slug:"od的评价指标",normalizedTitle:"od的评价指标",charIndex:13877},{level:3,title:"SOD的评价指标",slug:"sod的评价指标",normalizedTitle:"sod的评价指标",charIndex:14166},{level:3,title:"COD的评价指标",slug:"cod的评价指标",normalizedTitle:"cod的评价指标",charIndex:14569},{level:2,title:"实验对比",slug:"实验对比",normalizedTitle:"实验对比",charIndex:15086},{level:3,title:"OD方法的实验对比",slug:"od方法的实验对比",normalizedTitle:"od方法的实验对比",charIndex:15095},{level:3,title:"SOD方法的实验对比",slug:"sod方法的实验对比",normalizedTitle:"sod方法的实验对比",charIndex:16244},{level:3,title:"COD方法的实验对比",slug:"cod方法的实验对比",normalizedTitle:"cod方法的实验对比",charIndex:17713},{level:2,title:"讨论",slug:"讨论",normalizedTitle:"讨论",charIndex:563},{level:3,title:"深度学习带来的优势",slug:"深度学习带来的优势",normalizedTitle:"深度学习带来的优势",charIndex:18764},{level:3,title:"未来研究方向",slug:"未来研究方向",normalizedTitle:"未来研究方向",charIndex:20870},{level:2,title:"结论",slug:"结论",normalizedTitle:"结论",charIndex:22996},{level:2,title:"致谢",slug:"致谢",normalizedTitle:"致谢",charIndex:23130},{level:2,title:"作者",slug:"作者",normalizedTitle:"作者",charIndex:17371},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:11726}],headersStr:"引言 预备知识 目标检测的现代方法 OD中的现代方法 SOD的现代方法 COD的现代方法 OD、SOD、COD之间的关系 OD与SOD的关系 SOD与COD的关系 COD与OD的关系 基准和评价指标 OD的基准 SOD的基准 COD的基准 OD的评价指标 SOD的评价指标 COD的评价指标 实验对比 OD方法的实验对比 SOD方法的实验对比 COD方法的实验对比 讨论 深度学习带来的优势 未来研究方向 结论 致谢 作者 参考文献",content:"选自IEEE信号处理杂志（IEEE SIgnal ProcESSIng MagazInE | January 2018 ）\n\nAdvanced Deep-Learning Techniques for Salient and Category-Specific Object Detection\n\n\n\n目标检测，包括目标性检测（objectness detection，OD）、显著目标检测（ salient object detection，SOD）和特定类别目标检测（category-specific object detection，COD），是计算机视觉领域最基本但最具挑战性的问题之一。在过去的几十年里，研究人员为解决这个问题做出了巨大的努力，因为它在其他计算机视觉任务中有着广泛的应用，如活动或事件识别、基于内容的图像检索和场景理解等。\n\n尽管近年来出现了许多方法，目前仍缺乏对所提出的高质量目标检测技术，尤其是基于高级深度学习技术的目标检测技术的全面综述。\n\n为此，本文深入探讨了这一研究领域的最新进展，包括\n\n1）每个子方向的定义、动机和任务；\n\n2） 现代技术和基本研究趋势；\n\n3） 基准数据集和评估指标；\n\n4）实验结果的比较与分析。\n\n更重要的是，我们将揭示OD、SOD和COD之间的潜在关系，并详细讨论一些开放性问题，同时指出几个尚未解决的挑战和有前途的未来工作。\n\n\n# 引言\n\n作为一项具有挑战性但有用的计算机视觉任务，目标检测旨在识别每个给定图像或视频中存在的各种单独的目标。在这一研究领域，当处理具有相对简单的图像场景和清晰前景对象的图像时，已经取得了比较好的结果。然而，当处理包含以任意姿势放置、形状各异且出现在杂乱和封闭环境中的对象的图像和视频时，这个问题没有得到充分解决。\n\n过去几十年中发表的目标检测研究工作大致可分为三个方向：OD、SOD和COD。具体而言，OD[1]、[2]旨在检测每个给定图像中出现的所有可能对象，而不管具体的对象类别。它有很大的挑战，因为不同的物体，无论是在同一个物体类别内，还是来自不同的物体类别，都可能有巨大的外观变化，由于其内部固有特征（例如，猫等生物通常比车辆等人造物体具有更多可变形的外观）或外部捕获条件（例如观察距离或角度）（例如，可变形物体在一定距离内可能看起来有些僵硬，甚至僵硬物体在不同视角下也可能表现出变化）。通常，OD算法输出数千个对象建议或假设，如图1（a）所示，这有利于广泛的计算机视觉任务，如弱监督学习[3]和对象跟踪[4]。\n\n图1.目标检测的三个研究方向：（a）OD，（b）SOD和（c）COD。\n\nSOD[5]，[6]是目标检测的另一个方向，其目的是模仿视觉注意机制，突出显示每个给定图像中吸引我们注意力的对象[91]。这是受到人类视觉注意系统的启发，该系统可以引导人类特别注意一些信息丰富的图像区域，这些区域自然不同（自底而上的显著性）或与某些对象类别相关，这些对象类别由认知现象，如知识、期望、奖励和特定任务（自上而下的显著性）[7]。与OD类似，自底而上的SOD面临着来自无约束对象类别中大量外观变化的挑战，而自上而下的SOD面临着如何有效地将所需视觉刺激（通常在语义级别）与视觉场景中的相应区域相关联的挑战。通常，SOD算法根据获得的显著图输出有限数量的对象区域，如图1（b）所示。它们还可以帮助执行各种计算机视觉任务，如图像检索[8]和对象分割[9]。\n\n目标检测的第三个方向是COD[10] [11]。与OD不同，COD的目标是从每个给定的图像中检测多个预定义的对象类别。它不仅需要识别可能包含感兴趣对象的图像区域，还需要识别每个检测到的图像区域的特定对象类别。与SOD相比，COD具有完全不同的动机，即它移动在不了解人类视觉系统功能(例如视觉注意)的情况下解决纯计算问题。通常，COD被转化为一个多分类问题，在该问题中，识别性分类函数被训练来分离相应特征域中提取的图像区域。COD的主要挑战是如何处理组内外观变化和组间外观相似性。如图1（c）所示，COD方法通常会输出多个指定了识别对象类别的图像区域。COD可以应用于场景解析[12]和人类行为识别[13]等计算机视觉任务。\n\n为了解决目标检测中的挑战性问题，为了设计更好的手工特征（如HOG和SIFT），已经提出了大量工作，并提出了复杂的目标检测框架，以便在整个目标检测开发阶段将提取的特征与精心设计的分类器（如随机森林和AdaBoost）结合起来。卷积神经网络（CNN）于2004年首次应用于目标检测[14]，自2013年以来得到了广泛应用[15]。[10]中关于基于区域的CNN（RCNN）的工作在2014年取得了重大突破。它最早致力于通过使用多层卷积网络来提取高分辨但不变的特征表示来描述目标检测系统。\n\n与当时的最佳方法相比，这项工作的平均精度（mAP）显著提高了50%以上，这些方法基于常用PASCAL检测基准[16]上手工制作的图像特征。从那时起，已经提出了几种基于高级深度学习的技术[17]-[20]，用于高质量的目标检测，它涵盖了OD、SOD和COD的所有相关领域。为此，本文对最近最先进的方法进行了全面的综述。\n\n本文主要有四个动机：\n\n1） 目标检测，包括OD、SOD和COD，是计算机视觉的一个基本但具有挑战性的问题。现有的调查论文只关注每个单独的主题，而没有讨论密切的关系。\n\n2） 由于近年来已经提出了许多方法，并且取得了突破性的性能，因此回顾最近提出的目标检测技术，尤其是基于深度学习技术的目标检测技术，将是一件有启发性的事情。\n\n3） 就几个重要问题进行深入讨论是非常有意义的。例如，为什么最近基于深度学习的框架能够显著提高目标检测的性能？与以前的框架相比，这种框架最本质的改进是什么？基于深度学习的方法在未来需要解决哪些问题？\n\n4） 对公开的目标检测基准测试的实验结果进行综合比较和分析，将有助于读者更好地了解每种目标检测策略的性能以及相应的网络体系结构。\n\n\n# 预备知识\n\n近年来，深度学习的研究领域得到了快速发展，包括其在计算机视觉中的普及。在本节中，我们将简要介绍在目标检测任务中广泛使用的一种高级深度学习技术，即CNN。\n\nCNN是受生物自然视觉感知机制启发的最著名、应用最广泛的深度学习架构之一，该机制最初由Fukushima[21]提出，后来由LeCun[22]改进。CNN设计用于处理以多个阵列形式出现的数据[23]，例如，由三个二维阵列组成的彩色图像，其中包含三个颜色通道中的像素强度。CNN利用了自然信号的特性，其背后有四个关键思想：本地连接、共享权重、池化和多层的使用[23]。\n\n如图2所示，典型CNN模型的体系结构由一系列层构成，如下所示：\n\n图2.典型CNN模型的架构。\n\n * 卷积层：卷积层是特征提取最重要的部分。前几层通常捕获低级特征（如边、线和角），而较深层则可以通过组合低级特征来学习高级特征（如结构、对象和形状）。卷积层中的每个单元通过一组称为滤波器组的内核连接到前一层特征图中的局部面片。然后，该局部加权和的结果通过非线性运算，例如校正线性单元（ReLU）。要素图中的所有单元共享同一个过滤器组。卷积层中的不同特征映射使用不同的滤波器组。\n\n * 池化层：池化层旨在降低表示的维度，并创建对小位移和扭曲的不变性。池化层通常位于两个卷积层之间。池层的每个特征映射都连接到前一个卷积层的对应特征映射。一个典型的池化单元计算一个特征图中单元的一小块局部的最大值。\n\n * 全连接层：全连接层通常用作网络的最后几层，以便更好地总结低层在最终决策中传达的信息。由于完全连接的层占据了大部分参数，因此很容易发生过拟合。为了防止这种情况，通常采用dropout[24]。从2012年Alex Net[24]在ImageNet分类方面取得突破性成功开始，在开发各种CNN模型方面做出了重大努力，包括VGGNet[25]、GoogLeNet[26]和ResNet[27]。\n\n * AlexNet:AlexNet[24]最早由Krizhevsky等人提出，并赢得了2012年ImageNet大规模视觉识别挑战赛（ILSVRC）[28]。它由五个卷积层和三个完全连接的层组成。这是计算机视觉和机器学习的一个里程碑式的研究，因为它是第一个采用非饱和神经元、图形处理单元（GPU）实现卷积运算和dropout以防止过度拟合的工作。\n\n * VGGNet:VGGNet[25]是ILSVRC 2014大赛本地化和分类赛道的获胜者。它有两个著名的体系结构：VGGNet-16和VGGNet-19。前者因其更简单的架构而被广泛使用，它有13个卷积层、5个池化层和3个完全连接的层。\n\n * GoogLeNet：GoogLeNet[26]是另一个具有代表性的CNN架构，它有两个主要优势。一个是在同一层使用不同大小的过滤核，这保留了更多的空间信息，另一个优点是减少了网络的参数数量，这使得网络对过度拟合的敏感性降低，并允许网络更深入。事实上，22层的GoogLeNet有50多个卷积层分布在初始模块内部，但其参数比AlexNet少12倍。\n\n * ResNet:ResNet[27]是最成功的CNN之一，并获得了2016年计算机视觉和模式识别大会最佳论文奖。ResNet背后的思想是，每一层不应该学习整个特征空间变换，而应该只学习对前一层的剩余校正，这样可以有效地训练更深层次的网络。其极深的表示具有优异的泛化性能，并使其在2015ILSVRC和COCO竞赛中获得ImageNet检测、ImageNet定位、COCO检测和COCO分割的第一名。\n\n\n# 目标检测的现代方法\n\n\n# OD中的现代方法\n\nOD的目标是选择一小组建议的对象，覆盖了给定图像中大多数感兴趣的对象。为了实现这一目标，OD方法需要1）生成或选择可能包含特定感兴趣对象的潜在边界框，2）推断所选边界框的对象性分数。我们通常可以将现有的OD方法分为三大类：区域合并、窗口选择和框回归。\n\n# 区域合并方法（Region-merging）\n\n区域合并方法试图通过合并多个局部图像区域（例如超像素）来生成建议的对象。一种具有代表性的区域合并方法是著名的选择性搜索方法[29]，该方法采用贪婪算法将图像区域迭代地分组在一起。具体来说，首先计算了所有相邻区域之间的相似性。之后，将两个最相似的区域组合在一起，并计算出结果区域与其相邻区域之间的新相似性。重复这样的分组过程，直到整个图像成为一个区域。沿着这一方向，最近提出了更多的方法来更好地解决这个问题。例如，Krahenbuhl等人[30]开发了一种基于学习的种子放置方法，用于识别一组种子超像素，以命中每个给定图像中的所有对象。然后，他们合并靠近每个种子超像素的图像区域，并计算有符号测地距离变换(signed geodesic distance transform)，以提取一小部分高质量的建议对象。Bazzani等人[31]早期致力于采用深度学习技术，并提出了一种新的基于区域合并的OD方法。具体地说，他们首先生成矩形区域的初始集合，即包围提取片段的边界框。然后，他们通过最大化包含四项的相似性函数贪婪地合并这两个区域。这四项是通过在ImageNet上预训练的CNN计算的[28]，分别包括分类分数下降的相似性、深层特征的相似性、图像的覆盖面积和空间位置的距离。\n\n# 窗口选择方法（Window-selecting）\n\n窗口选择方法试图通过评分和选择预生成（滑动）窗口来生成建议对象。[1]提出了一种最早也是最著名的基于窗口选择的OD方法。它首先从给定图像中的显著位置[32]获得了一组初始方案。然后，这些建议通过组合多个信息线索进行评分，包括颜色对比度、边缘密度、位置、大小和“超像素跨越”(superpixel straddling)线索。受这项工作的启发，研究人员在过去几年进行了广泛的研究。例如，Ghodrati等人[17]最早利用经过预训练的CNN的深度特征图。其主要思想是在不同的激活层上以滑动窗口的方式生成假设。提出的逆级联搜索(inverse cascade searching)从CNN的最终卷积层到初始卷积层，可以选择最有希望的对象位置，并以从粗到细的方式细化它们的框。类似地，Pinheiro等人[33]，[34]提出使用带有两个分支的CNN来同时推断每个输入图像窗口的分割掩码和对象性分数。最终的包围盒方案是通过获取包围分割模板的矩形图像区域获得的。与[17]和[33]不同，Kuo等人[2]采用数据驱动的语义方法对对象提案进行排序。他们学习了一种小型但有效的CNN架构，用于重新排列自底而上方法得到的proposals[35]。在[36]中，Hu等人从卷积特征图中提取密集滑动窗口，然后采用统一的头部模块对窗口特征进行解码，并生成输出置信度得分和目标掩码。\n\n# 盒回归法（Box-regressing）\n\n盒回归方法试图通过直接学习回归函数，从提取的深度特征图中获得边界盒位置和对象性分数，从而生成对象建议。随着计算机视觉中深度学习技术的成功，这些方法应运而生。具体而言，Erhan等人[37]于2014年提出了第一种基于盒回归的OD方法，其中OD被定义为对边界盒位置坐标的回归问题。此外，它还推断出每个边界框的置信度得分，这表明该框包含对象的可能性有多大。整个系统由一个单一的CNN模型实现，该模型具有一个新的损失函数，该函数考虑了位置和得分精度。Szegedy等人[38]在[37]的基础上，基于最新的Inception-style架构[39]进一步构建了框架，并利用了包围盒形状和置信度的多尺度卷积预测，从而建立了基于Inception的后分类(post-classification)模型。沿着这个方向，Ren等人[40]提出了一个区域建议网络（RPN）来学习回归函数，用于基于一组预定义的平移不变锚(predefined translation-invariant anchors)来拟合边界框位置的坐标。他们还将RPN与一些额外的网络层结合起来，以实现精确的COD。类似地，Kong等人[41]开发了一种新的超特征(hyperfeature)，将深度但粗糙的信息与浅层但精细的信息相结合，以提取更丰富的特征。Li等人[42]建立了用于生成建议对象的缩小和放大网络(zoom-out-and-in network)，其中，放大子网络(zoom-in subnetwork)用于通过反卷积(deconvolution)操作提高高级特征的分辨率，递归训练管道用于在训练阶段连续回归区域proposals。\n\n\n# SOD的现代方法\n\nSOD包括两个分支：自下而上和自上而下。前者是刺激驱动(stimulus driven)的，主要对视觉场景中最有趣和最显眼的区域做出反应，而后者则由知识和高级视觉任务来指导。例如故意寻找特定类别的对象。如之前的研究[7]、[43]和[44]所述，在自底向上的SOD分支中，方法是检测自由观看下的显著性，这是由场景的物理特征自动确定的，而另一分支中的方法是检测由观察者当前目标确定的任务驱动的显著性。在每个分支中，都可以建立有监督和无监督的框架来解决相应的问题。接下来，我们将更详细地研究这两个分支。\n\n# 自底向上的SOD(Bottom-up)\n\n自底向上的SOD旨在准确区分视觉场景中的前景对象和背景。传统模型主要依赖对比度提示。Cheng等人[6]提出的一种具有代表性的方法测量了归一化颜色直方图中每个图像区域和图像中所有其他区域之间的色差加权和，作为检测显著性的全局对比度。受这项工作的启发，一些研究人员还将局部和全局对比度结合起来进行显著性检测。近年来，随着深度学习的发展，深度神经网络（DNN）也被用来提高SOD的性能。最早的开创性工作之一是[45]，其中Han等人提出利用叠加去噪自动编码器对SOD之前的背景进行建模。除了这项工作，最近几年还提出了一些基于CNN的SOD方法。例如，Wang等人[46]提出将局部估计和全局搜索结合起来进行显著性检测。Lee等人[47]结合了每个超像素的低层距离图和整个图像的全局CNN特征。Liu和Han[20]提出，以端到端的方式，从全局到局部上下文，从粗到细分层检测显著对象。Li和Yu[48]提出将基于像素级完全卷积网络（FCN）的显著性网络与分段多尺度CNN相结合，用于显著性检测。Wang等人[49]通过递归FCN提出了一种渐进的显著性细化网络，在该网络中，先前的显著性图和原始图像被同时馈送(simultaneously fed)，以学习纠正其先前的错误，从而获得更好的显著性结果。\n\n# 自顶向下的SOD(Top-down)\n\n自上而下的SOD通常旨在高亮显示场景中特定于类别的对象。Yang和Yang[50]提出联合学习条件随机场的参数和一个用于监督自上而下显著性检测的字典。He等人[51]提出了一种基于样本的自上而下显著性检测方法，目的是定位与给定样本图像属于同一类别的对象。Cholakkal等人[52]提出了一种只使用图像标签的弱监督自上而下显著性框架。他们首先使用图像标签训练了一个基于稀疏编码的空间金字塔匹配（ScSPM）分类器。然后分析图像中每每一小块对分类器的概率贡献，以估计反向SCSPM显著性(reverse-ScSPM saliency)。接下来，使用逻辑回归模型，使用每一小块的上下文(contextual patches)来估计上下文显著性。最终的显著性图可以通过组合两个显著性图来获得。Zhang等人[53]基于自顶向下的赢家通吃(winner-take-all)过程和DNN中的反向传播，提出了自顶向下显著性检测的激励反向传播方法。\n\n\n# COD的现代方法\n\n在过去的几十年里，COD在文献中得到了广泛的研究。变形零件模型（DPM）[54]及其变体多年来一直是主流方法。这些方法使用手工制作的图像描述符作为特征，并扫描整个图像，以检测具有特定于类的最大响应的区域。\n\n最近，由于ImageNet[28]等大规模训练数据的可用性和高性能GPU的进步，人们提出了各种基于深度学习的方法（尤其是基于CNN的方法），以显著提高COD的技术水平。事实上，CNN用于检测和识别可以追溯到20世纪80年代[22]。然而，由于缺乏训练数据和有限的计算资源，在2012年之前，基于CNN的COD没有多少进展。自2012年CNN在ILSVRC的图像分类任务中取得突破性成功[28]以来，基于CNN的范例（用于COD）最近吸引了大量研究兴趣。COD方法通常有两大类：基于建议对象的方法和基于回归的方法。\n\n# 基于建议目标的方法(Object proposal-based)\n\n基于建议对象的COD框架首先使用建议区域方法（如选择性搜索[29]）生成一组建议边界框，其中可能包含对象（该过程也称为OD），然后将检测到的对象建议传递给CNN分类器，以确定它们是背景还是来自特定区域对象类。\n\n在各种基于对象提议的方法（COD）中，Girshick等人[10]在2014年提出的区域CNN（R-CNN）的工作是最著名的方法之一。这项工作为通过深度CNN模型提取丰富的特征打开了大门，从而显著提高了性能。R-CNN框架是一系列概念上简单的步骤：生成对象建议，将建议分类为背景或特定类别的对象，并对检测进行后处理，以提高它们对对象的适应性。简而言之，R-CNN的工作如下。首先，它通过选择性搜索算法[29]提取大约2000个自下而上的区域建议，其中可能包含对象，以降低计算成本。然后，将这些建议区域变形(warped)为固定大小（例如227 x 227），并使用微调的CNN模型从中提取CNN特征。接下来，使用特定类别的线性支持向量机（SVM）将每个建议区域分类为对象或非对象。最后，通过使用边界盒回归器[54]来改进定位，候选方案被重新调整为检测到的对象。这个简单的管道在基准数据集上实现了最先进的COD性能，与所有以前发表的作品（主要基于DPM）相比，性能有了显著提高[54]。在这里，值得一提的是，用于从建议区域中提取深度CNN特征的CNN模型通常在基于ImageNet数据集的图像分类辅助任务[28]上进行预训练，然后在检测任务的带边框注释的小图像集上进行微调。\n\n然而，在R-CNN中，我们必须反复将候选边界框调整为固定大小，以提取其CNN特征，这对COD来说是非常昂贵的。为了加快R-CNN的速度，一些文献[18]、[55]、[56]建议在特征提取中共享计算(share the computation)。例如，空间金字塔池网络（SPPnet）[55]引入了空间金字塔池层，以放松输入必须具有固定大小的约束。与R-CNN不同，SPPnet只从整个图像中提取一次特征图，与建议区域无关，然后对每个区域建议应用空间金字塔池以获得固定长度的表示。这种重组允许所有区域提案之间轻松共享计算。SPPnet的一个缺点是，SPPnet的微调算法只能更新完全连接的层，这使得无法联合训练CNN特征提取器和SVM分类器来进一步提高性能。为了修正这个缺点，提出了fast R-CNN[18]，它是SPPnet的端到端可训练的改进。在fast R-CNN的框架下。所有网络层都可以在微调过程中更新，从而简化学习过程，提高检测精度。\n\nR-CNN[10]和fast R-CNN[18]的框架都需要建议区域的输入，这些提案通常来自手工制作的建议区域方法，如选择性搜索[29]和EdgeBox[35]。然而，proposal生成是整个流程中的瓶颈。为了解决这个问题，提出了faster R-CNN[40]，它由两个模块组成。第一个被称为区域建议网络（RPN），是用于生成建议区域的FCN（每以个都有一个建议边界框和一个目标分数），并将其输入第二个模块。第二个模块是用于目标检测的fast R-CNN网络。faster R-CNN将建议生成和目标检测结合到一个统一的网络中，其中RPN模块与fast R-CNN检测网络共享相同的卷积特征；因此，它几乎可以无代价生成建议区域。\n\n# 基于回归的方法(Regression-based)\n\n基于回归的COD方法被描述为具有空间分离的边界盒和相关类别概率的回归问题[57]-[60]。与基于建议对象的方法相比，基于回归的框架（用于COD）要简单得多，因为它不需要建议生成和随后的像素/特征重采样阶段，并将所有阶段封装在单个网络中[58]。请注意，box回归OD法和回归COD法之间的主要区别在于前者的目标是预测box位置和每个box位置的一个客观评分，后者的目标是预测box的位置和每个box位置的目标类别分数（其维度取决于所需目标类别的数量）。本质上，回归COD设计的模型通常比box回归OD设计的模型复杂得多，因为前者需要同时处理建议定位和对象类别识别的任务。因此，多任务损失函数在基于回归的COD中比在box回归OD中更常用。You Only Look Once (YOLO)[57]和Single-Shot MultiBox（SSD）[58]是两种典型的基于回归的方法（用于COD）。\n\nYOLO[57]将基于CNN的目标检测描述为一个回归问题，从而开启了实现实时目标检测的大门。YOLO的独特之处在于，它将目标检测的各个部分统一到一个卷积网络中，该网络可以同时预测多个边界框和这些边界框的种类概率。神经网络在进行预测时会对图像进行全局推理，因此它会隐式地对种类及其外观的上下文信息进行编码。与基于建议目标的方法相比，YOLO速度非常快，每秒运行45-150帧，而无需在Titan X GPU上进行批处理。然而，仍然很难检测到小尺寸的物体并实现精确定位。\n\n此后，SSD[58]被提出用于改进YOLO方法。具体来说，它将边界框的输出空间离散为一组默认框，每个特征图位置具有不同的纵横比和比例，与faster R-CNN的RPN有类似的想法。在预测时，SSD导出每个默认框中存在的每个对象类别的分数，并生成对框的调整，以更好地匹配对象外观。此外，该网络将来自不同分辨率的多个特征图的预测结合起来，以处理不同大小的对象。通过引入多尺度特征图和默认框机制，SSD在检测小尺寸对象方面取得了显著的性能改进，与YOLO相比，还提高了定位精度。\n\n此外，最近还开展了一些工作，以进一步提高基于CNN的COD方法的性能，如硬负挖掘(hard negative mining)[61]、特征增强[41]、[62]，上下文信息融合[63]-[65]，等等。例如，为了提高处理具有挑战性的情况的能力，通过对象旋转、类内可变性和类间相似性，Cheng等人[62]提出了一种旋转不变的Fisher判别CNN模型。在现有高容量CNN架构的基础上，通过分别引入旋转不变层和Fisher判别层来实现。\n\n\n# OD、SOD、COD之间的关系\n\n虽然OD、SOD和COD是目标检测中的三个独立研究方向，但它们之间存在着丰富的关系。\n\n\n# OD与SOD的关系\n\n一方面，自下而上的SOD能够为OD提供信息丰富的先验知识。直观地说，对人类视觉系统更具吸引力（在图像场景中更突出）的提取边界框位置更有可能包含感兴趣的对象。基于这一观察，已经设计了几种基于显著性线索的OD方法。例如，最经典的OD方法之一[1]通过使用三个显著性提示来选择对象方案，即多尺度显著性、颜色对比度和边缘密度。类似地，[66]中的工作将目标性定义为窗口显著性，这是使用图像的剩余部分构成窗口的成本。这个定义基本上包含了全局稀有性原则(global rarity principle)，并将其从像素级（对于SOD）扩展到窗口级（对于OD）。此外，Cheng等人将OD视为自底向上SOD的特例[67]，这表明利用SOD的检测原理可以有效地制定OD。Erhan等人[37]还提出了一种基于显著性的OD神经网络模型，并取得了良好的性能。\n\n另一方面，一些自底而上的SOD方法也建立在OD结果的基础上。当有OD生成的边界盒时，SOD问题可以简化为从非显著边界盒中选择显著边界盒。基于这一直觉，Chang等人[68]提出通过一个统一的图形模型，在检测显著对象之前，集成对象性先验（包括对象大小和位置）和显著性。Jiang等人[69]将客观性优先与聚焦性和客观性相结合，以保持检测到的SOD显著区域的完整性。Li等人[70]提出将从注视预测中获得的具有高显著值的候选对象视为显著对象。与传统的显著性检测只需要突出显示不同的局部区域不同，SOD需要均匀地突出显示完整的显著性对象，因此对象的感知能力应该自然地编码到有效的SOD模型中。目标性优先自然为这一需求提供了有效的解决方案。\n\n\n# SOD与COD的关系\n\n由于自上而下的SOD是高度任务驱动和知识驱动的，它需要对视觉场景，尤其是场景中对象的类别级信息有较高的理解。为了实现在场景中定位目标的目标，自上而下的SOD方法通常需要获取自上而下的知识来指导检测过程[51]。这种自上而下的知识可能来自记忆（即，使用来自相应训练数据的知识定位场景中的对象，这是基于模型的对象检测）或对象关联（即，使用已知或未知的样本定位场景中的相应对象，这是基于样本的对象检测[71]-[73]）。例如，在[50]中，Yang等人通过联合CRF和字典学习检测自上而下的显著性。CRF模型是通过在图像贴片表示(image patch representation)和相应的贴片标签(patch labels)上训练线性支持向量机来初始化的，它本质上是一个贴片级别(patch-level)的类别特定对象检测器。在以前的工作中，也可以找到一些实验结果或讨论，表明某些特定类别的物体检测器（例如，人类、人脸、汽车、出现在给定图像中的单词等）提供的自上而下的线索在视觉注意机制中起着重要作用[74]，[75]\n\n除了SOD，自上而下的SOD尤其可以反过来为COD提供有用的特定类别的对象，尤其是在监管薄弱的情况下。正如我们所知，弱监督对象检测方法[3]、[76]、[77]旨在仅使用图像级标记而不是实例级边界框注释来学习特定于类别的对象检测器。在这种情况下，如何获得特定对象类别的初始对象位置是需要解决的主要问题。通过使用SOD方法，[3]和[76]有效地初始化特定类别的对象位置，然后采用迭代学习方案，以迭代方式逐步细化对象检测器和位置。当学习过程收敛时，可以学习更强的目标检测器来执行测试数据中的COD。参考文献[52]、[53]和[77]还提出应用自上而下的显著性检测来发现弱标记训练图像中的目标位置，随后可用于训练特定类别的目标检测器。\n\n\n# COD与OD的关系\n\n大量研究表明，OD可以直接受益于COD任务[10]、[11]、[18]、[55]。基本上，正如我们在“基于建议对象的方法”一节中总结的那样，COD方法的一个主流是建立在OD技术上的，其中OD可以作为单独的预处理步骤[10]或在统一对象检测框架[40]中设计的固有组件来工作。COD方法基于OD技术的构建通常比基于滑动窗口搜索策略的构建获得更好的性能[54]，因为OD技术可以在目标检测任务之前提供有用的位置，这可以极大地减少对许多背景图像区域不必要的搜索，从而有效地减少误报。\n\n大多数OD方法中的参数需要从收集的训练集中学习，这些训练集通常来自PASCAL VOC基准[78]。本质上，由于训练数据集中只有有限的对象类，因此此类训练数据（包含不到20个类别的对象的真值边界框）可以被视为学习对象性检测器的受限知识库（例如[19]、[40]和[58]）。尽管一些工作已经证明了他们提出的方法，[2]和[17]仍然能够为看不见的目标生成建议目标，即不包含在训练数据集中的目标类；由于大量的领域转移，这些方法可能或多或少受到性能下降的影响。值得一提的是，最近的一项研究[31]提出了特定类别的OD方法，其目标与COD方法类似。\n\n\n# 基准和评价指标\n\n\n# OD的基准\n\nOD中广泛使用了两个基准：PASCAL VOC 2007[79]的测试集和MS COCO[80]的验证集。具体来说，PASCAL VOC 2007的测试集包含来自20个类别的4952个图像和14976个对象实例。大量的对象和种类、视点、比例、位置、遮挡和照明的高度多样性使得该数据集非常流行于评估OD方法，因为OD的目标是在不同的图像场景中找到所有可能的对象。MS COCO基准包含80000名训练图像和总计约500000个实例注释。该数据集中的图像是从复杂的日常场景中收集的，这些场景包含自然环境中的常见对象。因此，它是一个更具挑战性的数据集，用于检测对象性建议。在大多数情况下，评估OD性能的实验是在前5000张MS COCO验证图像上进行的。有时，使用另一个非重叠(nonoverlapped)图像作为验证数据集。\n\n\n# SOD的基准\n\nSOD社区中有几个具有不同属性的基准数据集。ECSSD数据集[81]有1000个图像，在SOD数据集中有一些重叠的图像[82]。这两个数据集中的图像通常具有杂乱的背景和语义上有意义的前景对象，这些对象来自不同的位置和比例。PASCAL-S[70]数据集是基于PASCAL VOC分割挑战而建立的，它有850张图像，通常包含杂乱的背景和多个前景对象。HKU-IS[83]数据集是最近发布的SOD数据集，包含4447幅图像。这些图像是从许多具有挑战性的场景中收集的，这些场景中有多个不连续的突出物体，突出物体接触图像边界，颜色对比度低。DUT-OMRON数据集[84]由5168个图像组成，每个图像通常有复杂的背景，包含一个或两个前景对象。THUR15K数据集[85]包含来自五个对象类的6232幅图像，即蝴蝶、咖啡杯、狗跳、长颈鹿和飞机。此数据集中的一些图像没有前景对象。MSRA-10K数据集[6]包含10000张带有各种对象的图像，是MSRA-B数据集[5]的扩展。这两个数据集中的大多数图像只有一个前景对象和清晰的背景。SED数据集是另一个广泛使用的数据集，包含200幅图像。此数据集中的每个图像包含一个和两个前景对象。\n\n\n# COD的基准\n\nPASCAL VOC 2007[79]和PASCAL VOC 2012[16]数据集是评估各种目标检测方法最常用的两个基准。PASCAL VOC 2007数据集共包含来自20个对象类别的9963张图像，包括5011张用于训练和验证的图像和4952张用于测试的图像，其中20个对象类别的地面真值边界框被手动标记。PASCAL VOC 2012数据集是PASCAL VOC 2007数据集的扩展，该数据集共包含22531幅图像，包括用于训练和验证的11540幅图像和用于测试的10991幅图像。然而，测试集中没有提供基本的真值标签。因此，应通过将测试结果提交给PASCAL VOC评估服务器来评估所有方法。\n\nMS COCO[80]是2014年提出的一个较新的目标检测基准，其目标是通过将目标识别问题置于更广泛的场景理解问题的背景下，提升目标识别的最新水平。与PASCAL VOC数据集相比，该数据集在每个类别的实例数上要大得多。具体来说，该数据集包含200000多个图像和80个对象类别，其中训练集包含80000个图像，验证集包含40000个图像，测试集包含80000个图像。为了限制过度拟合，并让研究人员更灵活地测试他们的方法，测试集分为三部分，包括测试开发、测试标准和测试挑战。Test dev用于调试和验证实验，并允许无限提交到评估服务器。测试标准用于维护提交后更新的公共排行榜。测试挑战用于比赛。大多数已发表的作品都在测试开发集上报告了它们的检测结果。\n\n\n# OD的评价指标\n\nOD方法生成的评估建议对象的指标通常是建议位置和相应真值注释之间的联合交集（IOU）（或Jaccard索引）的函数。具体而言，特定提案位置和地面真相注释之间的IOU定义为：\n\n\n\n基于IOU，召回率可以计算为建议位置覆盖的ground-truth边界框在某个IOU重叠阈值以上的分数。然后，三个广泛用于评估对象性检测方法的评估指标如下：\n\n * 召回与建议曲线，描述不同建议数量的召回。\n * 召回与重叠曲线，说明了在不同IOU重叠标准下召回的变化。\n * 平均召回率（AR），计算“召回与重叠”曲线下重叠值范围内的面积（通常设置为0.5-1.0）。\n\n\n# SOD的评价指标\n\n通常三个标准的评估指标被广泛用于SOD。第一个是精确召回曲线（PRC）。具体来说，给定一个显著性映射S和相应的真值显著性掩码G，我们首先将S标准化为[0]，[1]。然后，我们使用阈值T将S转换为二进制掩码M。之后，可以在阈值T下计算精度和召回率。当T从0变为1时，我们可以获得一系列精度召回值对。因此，我们可以通过将SOD作为分类任务来绘制PRC来评估模型的性能。\n\n第二个指标是F测量分数，它综合考虑了精确度和召回率。通常情况下，首先使用自适应阈值分割显著性图，并获得精度和召回值；然后，将F度量分数计算为它们的加权调和平均值。\n\n虽然这两种度量被广泛使用，但它们不能考虑真实的负像素(negative pixels)。为了解决这个问题，也常用平均绝对误差（MAE）。MAE测量S和G之间的平均像素绝对差。有关上述评估指标的更多详细信息，请参考[20]、[83]和[87]。\n\n\n# COD的评价指标\n\n所有对象类的平均精度（AP）和mAP是评估各种对象检测方法的两个标准且广泛使用的指标。它们被设计成不太喜欢缺少对象实例、重复检测一个实例和假阳性检测(false positive detections)的方法。具体来说，AP计算不同召回级别的平均准确度值，即PRC下的区域，因此AP值越高，性能越好，反之亦然。精确性衡量的是检测到的真正阳性的分数，而召回率衡量的是正确检测到的阳性的分数。\n\n如果预测边界框和真值边界框之间的IOU超过预定义阈值，则方法的检测输出被指定为真阳性(true positive)。否则，检测被视为假阳性(false positive)。此外，如果多个检测输出与同一地面真值对象重叠，则只有一个被视为真阳性，其他被视为假阳性。\n\n对于PASCAL VOC数据集，面积重叠阈值通常设置为0.5[16]。对于COCO数据集，存在一个新的评估指标，即在不同的IOU阈值上平均mAP，从0.5到0.95，步长为0.05（写为0.5:0.95）。与PASCAL VOC指标相比，它更强调本地化，后者只需要0.5的IOU。有关上述评估指标的更多详细信息，请参阅[40]、[58]、[60]。\n\n\n# 实验对比\n\n\n# OD方法的实验对比\n\n在本节中，我们比较了PASCAL VOC 2007测试集和MS COCO验证集上不同OD方法在AR方面的性能。具体而言，我们比较了表1中PASCAL VOC 2007测试集上的七种方法，即BING[67]、OBJ[1]、EB[35]、GOP[30]、SS[29]、RPN[40]和MCG[86]。\n\n在表2中MS COCO的验证集上的7种方法，MCG[86]、DeepMask[33]、DeepMaskZoom[33]、DeepMask2[34]、Sharp Mask[34]、SharpMaskZoom[34]和FastMask[36]。\n\n这里，DeepMaskZoom表示将原始图像缩放到多个比例，然后在每个比例上应用DeepMask。同样的方法也用于ShapMaskZoom。DeepMask2基于39层ResNet[27]实现，并根据SharpMask中的网络架构修改了头部组件。DeepMask和Deep MaskZoom构建在VGG网络上[25]，而DeepMask2、SharpMask、SharpMaskZoom和FastMask构建在39层ResNet上[27]。\n\n在表1中，我们可以观察到，在不使用任何深度学习技术的人中，MCG是最好的OD方法。它甚至比RPN更好，RPN是建立在CNN上的一种OD方法。这主要是因为RPN设计的网络架构相对简单，它只是更快的R-CNN整个框架的一部分，其最终目标是COD而不是OD。我们可以在表2中观察到，许多基于深度学习模型的OD方法在很大程度上优于MCG（约5-13%），这主要是由于更强大的特征表示和更好的学习框架。更具体地说，在基于深度学习的OD方法中，除了具体设计的网络架构外，最终检测性能也与所采用的主干CNNModel高度相关。例如，使用ResNet作为主干CNN模型（例如DeepMask2和SharpMaskZoom）的OD方法通常比使用VGG网络（例如DeepMask和DeepMaskZoom）的OD方法的性能高出约2-6%。此外，通过比较表1和表2中MCG的性能，我们可以观察到MS COCO基准比PASCAL VOC 2007更具挑战性。在这一研究领域需要做出更大的努力，因为在这两个基准上的表现都有很大的改进空间。\n\n在表1和表2中，我们还报告了比较OD方法的运行时间。从这些表中，我们可以观察到，最快的OD方法是BING和RPN，它们可以在大约0.2秒的时间内处理每个图像。SS和MSG可以在不使用深度模型的情况下获得优于OD方法的操作。然而，与所有其他方法相比，它们的计算成本要大得多。基于深度模型的OD方法通常可以有效地进行测试，因为它们的计算成本约为每幅图像0.2-2秒。\n\n\n# SOD方法的实验对比\n\n在本节中，我们报告了一些具有代表性的基于DNN的SOD模型的定量比较结果。我们选择了2015年和2016年发布的七个模型，并发布了它们的代码或计算显著性图：LEGS[46]、DHS[20]、DCL[48]、ELD[47]、MCDL[87]、MDF[83]和RFCN[49]。ECSSD[811，PASCAL-S[70]和HKU-IS[83]数据集的实验结果见表3（就Fmeasure而言）、表4（就MAE而言）和图3（就PRC而言）。根据F和MAE的结果。DHS[20]是最好的显著性模型，而DCL[48]和RFCN[49]排在第二位。\n\n在这些模型中，LEGS、MDF、MCDL和ELD基于提取的局部区域（即超像素或对象建议）。这些方法通常独立地估计每个局部区域的显著性得分。因此，它们在有效整合上下文信息方面存在局限性。因此，如表3所示，此类方法通常具有更多的计算成本，但它们无法获得优于其他方法的检测结果。相反，DHS，DCL。RFCN基于FCNs，可以同时对所有像素进行显著性推断。因此，如表3所示，它们通常非常快，尤其是对于DHS，它只需要一个forward，无需任何预处理或后处理。此外，由于FCNs以整个图像为输入，连续的深卷积层可以有效地合并大的上下文，这解释了这些方法获得更好的性能。\n\n为了深入了解SOD算法的性能，我们在最先进的显著性模型DHS上进行了消融实验[20]。与OD和COD任务不同，SOD任务通常有训练测试数据的标准分离，SOD任务没有这样的标准。尽管大多数SOD算法在MSRA-10K和DUT-OMRON数据集上实现了训练过程，在其他数据集上实现了测试过程，但当使用不同数量的训练数据时，它们会获得不同的性能。为此，我们首先分析了训练图像数量的影响。具体来说，我们从[20]中使用的原始训练集中（包含9500张图像）随机选择了三分之一和三分之二的图像，生成了两个子训练集，分别包含3167和6333张图像。通过使用这两个子训练集，我们获得了DHS-1/3和DHS-2/3的性能，如表4所示。从表4的前三行可以看出，随着训练图像的增加，检测性能会不断提高。这表明我们可以通过使用更多的训练图像来提高显著性模型的性能。值得一提的是，在将模型与其他现有显著性模型进行比较时，还应将其训练图像数保持在合理范围内（少于10000），以确保公平比较。\n\n然后，我们分析了主干CNN模型的影响。最初的DHS模型使用VGG 16层网络[25]作为主干模型。在这里，我们探索了另外两个更深层次的CNN网络，即ResNet50和ResNet101[27]，作为DHS模型的主干网络。注意，在原始的ALDHS模型中，作者使用了五步细化，将VGG特征映射从Conv4_3合并到Conv1_2，从而将显著性映射从28 x 28恢复到224 x 224。然而，ResNet网络的第一个卷积层都是跨步2，这意味着我们只能使用四步细化，并将显著性映射恢复到112 x 112。因此，我们还通过四个细化步骤（命名为DHS-RCL2）测试了原始DHS模型的结果，以进行公平比较。如表4中的最后四行所示，当使用相同的细化步骤时，更深的主干模型可以获得更好的最终性能。然而，由于最后一个细化步骤在提高最终性能方面起着非常重要的作用，因此使用ResNet作为主干模型的性能无法超过使用VGG网的性能。由于类似于DHS的网络结构在其他现代检测方法中被广泛使用，上述分析对于我们平衡ResNet带来的权衡非常重要。\n\n\n# COD方法的实验对比\n\n在本节中，我们选择了过去三年（2015-2017）发布的几种基于CNN的代表性目标检测方法，对PASCAL VOC2007数据集[79]、PASCAL VOC 2012数据集[16]和MS COCO数据集[80]进行性能比较。这些方法包括fast R-CNN[18]、faster R-CNN[40]、nside-Outside Net(ION) [63]、G-CNN[59]、SSD[58]、YOLO[57]和TOLOv2[60]。表5-7分别使用具有代表性的最新方法报告了PASCAL VOC 2007、PASCAL VOC 2012和COCO数据集的检测结果。表8显示了PASCAL VOC 2007上各种方法的准确性和速度比较。\n\n从表5-7可以看出，基于回归的COD方法，如SSD[58]和TOLOv2[60]，与基于对象建议的方法（如fast R-CNN[18]和faster R-CNN[40]）相比，可以获得更高的精度。SSD512[58]主要在所有三个基准（PASCAL VOC 2007、PASCAL VOC 2012和COCO数据集）上实现了最佳精度。表8所示的计算成本比较表明，基于回归的COD方法比基于对象建议的方法快得多，具有相当的精度。其中，YOLOv2是最具竞争力的实时检测器，也可以以不同的分辨率运行，以方便在速度和精度之间进行权衡。表5-8中的综合比较结果表明，基于回归的方法是一个有前途的COD方向。\n\n最近，大多数检测框架，如fast R-CNN[18]、faster R-CNN[40]和SSD[58]，都依赖VGGNet-16[25]作为主干CNN模型。尽管VGGNet-16是一个功能强大、准确的分类网络，但它的计算成本很高。VGGNet-16的卷积层需要对224 x 224像素的图像进行306.9亿次浮点运算。最近提出的YOLO[57]使用基于GoogleNet架构的定制网络[26]来提高检测速度。YOLO网络确实比基于VGG-Net-16的方法更快，仅使用85.2亿次运算来完成一次正向传球，但精确度略低于VGG-Net-16。为了进一步减少计算负担，同时提高精度，YOLOv2[60]提出了一种新的分类模型，名为Darknet-19，它只需要55.8亿次操作就可以处理图像。精度和速度的综合比较结果表明，通过设计更实用的模型结构（如YOLOv2[60]），基于回归的方法是一种很有前途的COD方向。\n\n\n# 讨论\n\n\n# 深度学习带来的优势\n\n基于我们的分析，基于深度学习的目标检测器带来的优势可以总结为以下四个方面。\n\n# 强大的特征表示\n\n开发基于深度学习的目标检测器的最重要原因之一是在学习过程中构建的强大特征表示。这在[10]中得到了明确的证明，Girshick等人使用广泛使用的HOG功能及其扩展版本之一，将他们提出的基于CNN的物体检测器的COD结果与DPM[54]基线进行了比较。实验结果表明，基于CNN的目标检测器在AP方面比DPM基线的检测器高出24.2%以上。此外，Girshick等人[10]从实验结果分析了所采用的CNN体系结构的不同网络层的表示能力，我们可以观察到，通过微调，较深层可以获得比较浅层更好的性能，这表明从CNN深层提取的特征表示可以有效地用于表示图像区域的信息语义。还值得一提的是，与传统的目标检测方法相比，即使是在仅使用整个网络6%参数的“pool5”层中提取的特征，也可以获得超过10%的性能增益（就AP而言）。在OD和SOD的研究中也可以找到类似的实验结果。例如，通过仅使用简单的CNN架构在其框架中构建功能，RPN[40]、DeepProposal[17]和DeepBox[2]已经可以明显优于使用传统功能表示的现有OD方法。在SOD中，[83]和[20]指出，如何构建真实、有意义的特征表示是SOD中最关键的问题之一，他们已经证明，通过设计合理的深度网络架构，可以有效地解决这个问题。\n\n# 端到端学习\n\n基于深度学习的目标检测方法的另一个优势在于其端到端的学习框架。我们知道，传统的目标检测方法通常需要单独的计算块，例如特征提取和模式分类（例如[35]和[67]用于OD[88]和[89]用于SOD，以及[54]和[90]用于COD）。基于深度学习的方法（例如[17]和[36]用于OD，[20]和[87]用于SOD，以及[18]和[57]用于COD）仅通过一个统一的CNN模型就可以从原始输入图像中获得所需的对象检测结果。与传统方法相比，这种端到端的学习方式可以带来两个好处：\n\n * 在传统的目标检测方法中，它可以大大降低从多个候选目标到每个计算块中选择最优方法的复杂性。\n * 以这种端到端的方式学习可以根据学习目标确定整个模型的参数。\n\n与传统方法（用于设计手工制作的功能）相比，这种学习方式可以显著减少整个系统中有用信息的丢失。\n\n# 多阶段、多任务目标\n\n得益于端到端学习范式，基于深度学习的现代目标检测方法可以在多个学习阶段灵活地涉及所需的学习目标和多个学习任务。例如，在OD中，FastMask[36]提出的深度网络包含语义特征提取和基于滑动窗口的建议生成的学习阶段。学习目标包括三个方面：置信度损失、分割损失和区域注意损失(confidence loss, segmentation loss,region attention loss)。在SOD和LEGS[46]中，包含两个级联学习阶段。第一个阶段是局部估计阶段，目标是学习局部有区别的小块特征(local discriminative patch features)。第二个阶段是全局搜索阶段，目标是利用全局显著性线索之间的复杂关系。DHS[20]也有两个学习阶段，第一个阶段是显著性推理，第二个阶段是细节渲染。在COD中，faster R-CNN[40]设计有两个级联学习阶段，用于学习提取建议目标区域，并分别识别每个提取的建议对象区域的对象类别。Fast R-CNN[18]采用多任务损失来同时学习特定类别的对象检测器和边界盒回归函数。与传统的目标检测方法相比，这种多阶段和多任务目标的最重要的优点是，相应的学习过程可以考虑所有设计的学习目标来确定检测网络的最优参数，而传统的方法只能通过考虑一个主要的学习目标，并在预处理或后处理阶段利用其他有用的因素来训练主要的目标检测模型。\n\n# 大规模学习和知识转移\n\n与浅层结构的学习模型相比，深度学习模型的成功主要归功于大量隐藏的神经元，这通常会产生数百万个自由参数，而浅层结构的学习模型的参数较少，以避免过度拟合。因此，DNN通常需要大规模的训练数据来实现其完整的学习能力，这使得深度模型能够从训练数据中捕获比浅层模型更丰富的模式。除了知识挖掘能力之外，深度学习模型的另一个优点是可以方便地将学习到的知识转移到相关的任务或场景中。这主要是通过使用目标域中的数据微调源域(source domain)中预训练的深层模型来实现的。例如，最具代表性的基于深度学习的COD方法[10]在图像分类任务下采用了在ImageNet上预训练的CNN模型。实验结果表明，与之前的最新研究结果相比，直接使用这种网络已经可以获得明显的改善，这表明在大规模学习中捕获的模式可以强大到足以完成广泛的任务。此外，文献[10]中的实验结果表明，微调后的网络可以进一步获得显著的性能增益，这证明了深度学习模型简单而有效的知识转移能力。基于这种能力，大量现代目标检测方法[2]、[19]、[34]、[36]、[42]、[58]、[59]、[62]可以从简单但有效的预训练阶段中受益。\n\n\n# 未来研究方向\n\n尽管近年来基于深度学习的目标检测方法在这一研究领域取得了巨大的成功，但仍有一些具有挑战性但有趣的研究方向需要考虑。\n\n# 训练具有有限人类注释的目标检测器\n\n尽管最近基于深度学习的目标检测方法取得了显著的性能提升，但在实际应用中，目标检测研究领域的问题仍然在很大程度上没有得到解决，因为这些方法大多严重依赖于空前巨大的(unparalleled and tremendous)人类标记训练数据。在这种情况下，人们需要花费大量的精力和时间在繁琐的数据标注上，以训练深层目标检测器。根据我们的统计数据，我们需要花费大约15秒（在LabelMe等辅助工具的帮助下）来绘制一个边界框注释，该注释可以正确地包含感兴趣的对象。考虑到这一点，可能需要手动注释数十万个训练图像，并且每个图像可能包含来自不同类别的多个对象。为了缓解这个问题，弱监督目标检测方法[3]、[13]、[76]、[99]近年来受到了广泛关注。然而，所获得的性能仍然远远不能令人满意，它们只能达到相应的全监督目标检测方法所获得性能的50%。因此，仍需进一步努力解决这一问题。\n\n# 不可见对象类别的检测\n\n大多数现有的目标检测方法都是针对与训练集中的目标类别相同的图像进行评估的。然而，目标检测的最终目标是检测给定测试图像中任何可能类别的所有目标。本质上，在现实世界的应用程序中，我们对所有对象类别都缺乏足够的注释。广泛使用的PASCAL VOC和MS COCO基准仅分别包含20和80个对象类别，这远远不够。ILSVRC对象检测基准包含200个对象类别，但仍然不够。在许多类别没有边界框级注释的情况下，未来的一个方向是建立zero-shot learning-based的方案（用于目标检测），其中现有检测器和这些检测器之间的跨概念/类别映射(cross-concept/category mappings)的组合可以允许我们为看不见的种类构建对象检测器。作为SOD的一个新兴分支，共现性(cosaliency)检测[92-[94]和事件显著性检测[957]方法也可能是检测未发生的对象/事件的可能方法，因为它们可以从包含共同发生但未知的对象/事件的任何给定图像/视频组中学习。\n\n# 提高检测鲁棒性的新学习策略\n\n未来的另一个方向是提高对使用不平衡数据或噪声数据训练的对象类别的检测鲁棒性。这里的不平衡问题主要是指目标检测中不同类别样本数的长尾分布(long-tailed distribution)。长尾属性表示少数目标种类经常出现，而大多数其他种类很少出现的现象。例如，在PASCAL VOC和ImageNet对象检测数据集中，对象类别（如person）的样本比其他对象类别（如sheep）的样本多得多。一些分析和实证结果表明，样本较多的对象类别将主导学习对象检测器，导致样本较少的其他对象类别学习不足。因此，针对这个问题的一个未来方向是建立新的学习方案，以便在不同的对象类别中使用更均匀分布的样本数进行学习。得益于一些最新的生成性学习模型，如生成性对抗网络（GAN）。通过合成来自潜在噪声向量的可用数据，可以丰富“在尾部”的对象类别的样本。相反，大规模人工标注不可避免地会引入噪声标注，如标签缺失或错误标注。为了解决人类注释中的噪声问题，进一步的研究可以设计基于权重的学习机制（例如基于自配学习(self-paced learning)[94]、[96]和课程学习(curriculum learning)[97]、[98]的模型），当人类注释的学习的目标类别是噪声时，可以进一步提高的学习鲁棒性。\n\n# OD、SOD和COD的统一学习框架\n\n目前在目标检测领域的研究已经提出了一些有效的基于深度学习的框架，例如[40]和[41]，同时用于OD和COD。实验结果表明，通过联合优化OD和类别特定检测任务的网络参数，网络可以进一步探索这些任务之间的潜在关系，并捕获可从这两项任务中受益的常见信息模式。基本上，如前所述，OD、SOD和COD之间存在丰富的关系。因此，建立新的框架，尤其是基于深度学习的框架，以同时解决这三个方向上的常见问题，是非常有意义的。一种可能的方法是构建一个深度网络，将注意力建模、建议挖掘(proposal mining)和类别识别等模块结合到一个统一的学习框架中。通过这种方式，三个任务之间共享的信息方式可以被模型捕获，这可以进一步提高每个任务的性能。\n\n# 基于检测的高层视觉理解\n\n最近先进的目标检测技术的出现，促进了一些以前从未涉及过的更高层次的视觉理解任务的发展。这种任务的一个代表性例子是图像/视频字幕(image/video captioning)。此任务的基本目标是自动生成一个句子来描述任何给定图像/视频的内容。物体检测技术可以提供物体位置和类别的关键信息，用于解释图像/视频场景中的物体是什么，它们放在哪里，以及它们对交互物体做了什么。从本质上说，准确的目标检测是将视觉领域与语言领域联系起来的关键。沿着这条研究路线，仍然有许多未开发但有趣的基于检测的应用（更高级别的视觉理解任务），它们构成了未来研究方向的另一个分支。\n\n\n# 结论\n\n在本文中，我们回顾了主要基于高级深度学习技术的目标检测的最新进展。具体而言，回顾了目标检测三个方向的OD、SOD和COD的现代方法、基准数据集和评估指标。我们全面分析了这些方向之间的关系，对深度学习的优势进行了深入的讨论，并提出了一些未来可能的方向。\n\n\n# 致谢\n\nDingwen Zhang和Gong Chen是本文的通讯作者。\n\n\n# 作者\n\njunweihan（junweihan2010@gmail.com）分别于1999年、2001年和2003年获得了模式识别和智能系统的学士、硕士和博士学位，均来自中国西安西北工业大学，目前担任该校教授。2003至2010年间，他是南洋理工大学、香港大学、爱尔兰都柏林城市大学和邓迪大学的研究员。他的研究兴趣包括计算机视觉和大脑成像分析。他是IEEE《人机系统、神经计算、机器视觉与应用》杂志的副主编。\n\nDingwen Zhang（zdw2006yyy@mail.nwpu.edu.cn）于2012年在中国西安西北工业大学获得自动化学士学位，目前正在那里攻读博士学位。自2015年10月以来，他一直是宾夕法尼亚州匹兹堡卡内基梅隆大学的访问学者。他的研究兴趣包括计算机视觉和多媒体处理。\n\nGong Cheng（chenggong1119@gmail.com）于2007年在中国西安西安西安电子大学获得自动化学士学位，2010年和2013年分别在中国西安西北工业大学获得模式识别和机器智能硕士和博士学位；他目前是后者的副教授。他的主要研究兴趣是计算机视觉和目标检测。\n\nNian Liu（liunian228@gmail.com）分别于2012年和2015年在中国西安西北工业大学（NPU）获得自动化学士和硕士学位。他目前正在NPU自动化学院攻读博士学位。他的研究兴趣包括计算机视觉，重点是显著性检测和深度学习。\n\nDong Xu(dong.xu@sydney.edu.au)于2001、2005分别在合肥中国科技大学获得电子工程学士学位和博士学位。他目前是澳大利亚悉尼大学电气与信息工程学院的教授。他是IEEE高级成员和国际模式识别协会研究员。\n\n\n# 参考文献\n\n[1] B. Alexe, T. Deselaers, and V. Ferrari, “Measuring the objectness of image win- dows,” IEEE Trans. Pattern Anal. Machine Intell., vol. 34, no. 11, pp. 2189–2202, 2012\n\n[2] W. Kuo, B. Hariharan, and J. Malik, “Deepbox: Learning objectness with con- volutional networks,” in Proc. IEEE Int. Conf. Computer Vision, 2015, pp. 2479– 2487. [3] T. Deselaers, B. Alexe, and V. Ferrari, “Weakly supervised localization and learning with generic knowledge,” Int. J. Computer Vision, vol. 100, no. 3, pp. 275– 293, 2012. [4] Y. Wu, J. Lim, and M.-H. Yang, “Object tracking benchmark,” IEEE Trans. Pattern Anal. Machine Intell., vol. 37, no. 9, pp. 1834–1848, 2015. [5] T. Liu, Z. Yuan, J. Sun, J. Wang, N. Zheng, X. Tang, and H.-Y. Shum, “Learning to detect a salient object,” IEEE Trans. Pattern Anal. Machine Intell., vol. 33, no. 2, pp. 353–367, 2011. [6] M.-M. Cheng, N. J. Mitra, X. Huang, P. H. S. Torr, and S.-M. Hu, “Global con- trast based salient region detection,” IEEE Trans. Pattern Anal. Machine Intell., vol. 37, no. 3, pp. 569–582, 2015. [7] A. Borji and L. Itti, “State-of-the-art in visual attention modeling,” IEEE Trans. Pattern Anal. Machine Intell., vol. 35, no. 1, pp. 185–207, 2013. [8] X. Li, T. Uricchio, L. Ballan, M. Bertini, C. G. Snoek, and A. D. Bimbo, “Socializing the semantic gap: A comparative survey on image tag assignment, refinement, and retrieval,” ACM Comput. Surveys, vol. 49, no. 1, pp. 14, 2016. [9] B. Hariharan, P. Arbeláez, R. Girshick, and J. Malik, “Hypercolumns for object segmentation and fine-grained localization,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2015, pp. 447–456. [10] R. Girshick, J. Donahue, T. Darrell, and J. Malik, “Rich feature hierarchies for accurate object detection and semantic segmentation,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2014, pp. 580–587. [11] W. Ouyang, X. Wang, X. Zeng, S. Qiu, P. Luo, Y. Tian, H. Li, S. Yang, Z. Wang, and C.-C. Loy, “Deepid-net: Deformable deep convolutional neural networks for object detection,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2015, pp. 2403–2412. [12] J. Tighe, M. Niethammer, and S. Lazebnik, “Scene parsing with object instance inference using regions and per-exemplar detectors,” Int. J. Computer Vision, vol. 112, no. 2, pp. 150–171, 2015. [13] A. Prest, C. Schmid, and V. Ferrari, “Weakly supervised learning of interac- tions between humans and objects,” IEEE Trans. Pattern Anal. Machine Intell., vol. 34, no. 3, pp. 601–614, 2012. [14] Y. LeCun, F. J. Huang, and L. Bottou, “Learning methods for generic object recognition with invariance to pose and lighting,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2004, pp. 97–104. [15] C. Szegedy, A. Toshev, and D. Erhan, “Deep neural networks for object detec- tion,” in Proc. Advances in Neural Information Processing Systems, 2013, pp. 2553–2561. [16] M. Everingham, S. A. Eslami, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman, “The Pascal visual object classes challenge: A retrospective,” Int. J. Computer Vision, vol. 111, no. 1, pp. 98–136, 2015. [17] A. Ghodrati, A. Diba, M. Pedersoli, T. Tuytelaars, and L. Van Gool, “Deepproposal: Hunting objects by cascading deep convolutional layers,” in Proc. IEEE Int. Conf. Computer Vision, 2015, pp. 2578–2586. [18] R. Girshick, “Fast R-CNN,” in Proc. IEEE Int. Conf. Computer Vision, 2015, pp. 1440–1448. [19] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, “You only look once: Unified, real-time object detection,” arXiv Preprint, arXiv:1506.02640, 2015. [20] N. Liu and J. Han, “DHSNet: Deep hierarchical saliency network for salient object detection,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2016, pp. 678–686. [21] K. Fukushima, “Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position,” Biol. Cybernet., vol. 36, no. 4, pp. 193–202, 1980. [22] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and L. D. Jackel, “Backpropagation applied to handwritten zip code recognition,” Neural Comput., vol. 1, no. 4, pp. 541–551, 1989. [23] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” Nature, vol. 521, no. 7553, pp. 436–444, 2015. [24] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “ImageNet classification with deep convolutional neural networks,” in Proc. Advances in Neural Information Processing Systems, 2012, pp. 1097–1105. [25] K. Simonyan and A. Zisserman, “Very deep convolutional networks for large- scale image recognition,” arXiv Preprint, arXiv:1409.1556, 2014. [26] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich, “Going deeper with convolutions,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2015, pp. 1–9. [27] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recog- nition,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2016, pp. 770–778. [28] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “ImageNet: A large-scale hierarchical image database,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2009, pp. 248–255. [29] J. R. Uijlings, K. E. Van De Sande, T. Gevers, and A. W. Smeulders, “Selective search for object recognition,” Int. J. Computer Vision, vol. 104, no. 2, pp. 154–171, 2013. [30] P. Krähenbühl and V. Koltun, “Geodesic object proposals,” in Proc. European Conf. Computer Vision, 2014, pp. 725–739. [31] L. Bazzani, A. Bergamo, D. Anguelov, and L. Torresani, “Self-taught object localization with deep networks,” in Proc. IEEE Winter Conf. Applications of Computer Vision, 2016, pp. 1–9. [32] X. Hou, and L. Zhang, “Saliency detection: A spectral residual approach,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2007, pp. 1–8. [33] P. O. Pinheiro, R. Collobert, and P. Dollar, “Learning to segment object candi- dates,” in Proc. Advances in Neural Information Processing Systems, 2015, pp. 1990–1998. [34] P. O. Pinheiro, T.-Y. Lin, R. Collobert, and P. Dollár, “Learning to refine object segments,” in Proc. European Conf. Computer Vision, 2016, pp. 75–91. [35] C. L. Zitnick, and P. Dollár, “Edge boxes: Locating object proposals from edges,” in Proc. European Conf. Computer Vision, 2014, pp. 391–405. [36] H. Hu, S. Lan, Y. Jiang, Z. Cao, and F. Sha, “FastMask: Segment multi-scale object candidates in one shot,” arXiv Preprint, arXiv:1612.08843, 2016. [37] D. Erhan, C. Szegedy, A. Toshev, and D. Anguelov, “Scalable object detection using deep neural networks,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2014, pp. 2147–2154. [38] C. Szegedy, S. Reed, D. Erhan, D. Anguelov, and S. Ioffe, “Scalable, high- quality object detection,” arXiv Preprint, arXiv:1412.1441, 2014. [39] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna, “Rethinking the inception architecture for computer vision,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2016, pp. 2818–2826. [40] S. Ren, K. He, R. Girshick, and J. Sun, “Faster R-CNN: Towards real-time object detection with region proposal networks,” in Proc. Advances in Neural Information Processing Systems, 2015, pp. 91–99. [41] T. Kong, A. Yao, Y. Chen, and F. Sun, “HyperNet: Towards accurate region proposal generation and joint object detection,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2016, pp. 845–853. [42] H. Li, Y. Liu, W. Ouyang, and X. Wang, “Zoom out-and-in network with recur- sive training for object proposal,” arXiv Preprint, arXiv:1702.05711, 2017. [43] A. Borji, M.-M. Cheng, H. Jiang, and J. Li, “Salient object detection: A sur- vey,” arXiv Preprint, arXiv:1411.5878, 2014. [44] A. Borji, H. R. Tavakoli, D. N. Sihite, and L. Itti, “Analysis of scores, data sets, and models in visual saliency prediction,” in Proc. IEEE Int. Conf. Computer Vision, 2013, pp. 921–928. [45] J. Han, D. Zhang, X. Hu, L. Guo, J. Ren, and F. Wu, “Background prior-based salient object detection via deep reconstruction residual,” IEEE Trans. Circuits Systems Video Technol., vol. 25, no. 8, pp. 1309–1321, 2015. [46] L. Wang, H. Lu, X. Ruan, and M.-H. Yang, “Deep networks for saliency detec- tion via local estimation and global search,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2015, pp. 3183–3192. [47] G. Lee, Y.-W. Tai, and J. Kim, “Deep saliency with encoded low level distance map and high level features,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2016, pp. 660-668. [48] G. Li, and Y. Yu, “Deep contrast learning for salient object detection,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2016, pp. 660–668.\n\n[49] L. Wang, L. Wang, H. Lu, P. Zhang, and X. Ruan, “Saliency detection with recurrent fully convolutional networks,” in Proc. European Conf. Computer Vision, 2016, pp. 825–841. [50] J. Yang, and M.-H. Yang, “Top-down visual saliency via joint CRF and diction- ary learning,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2012, pp. 2296–2303. [51] S. He, R. W. Lau, and Q. Yang, “Exemplar-driven top-down saliency detection via deep association,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2016, pp. 5723–5732. [52] H. Cholakkal, J. Johnson, and D. Rajan, “Backtracking ScSPM image classifier for weakly supervised top-down saliency,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2016, pp. 5278–5287. [53] J. Zhang, Z. Lin, J. Brandt, X. Shen, and S. Sclaroff, “Top-down neural atten- tion by excitation backprop,” in Proc. European Conf. Computer Vision, 2016, pp. 543–559. [54] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ramanan, “Object detection with discriminatively trained part-based models,” IEEE Trans. Pattern Anal. Machine Intell., vol. 32, no. 9, pp. 1627–1645, 2010. [55] K. He, X. Zhang, S. Ren, and J. Sun, “Spatial pyramid pooling in deep convo- lutional networks for visual recognition,” IEEE Trans. Pattern Anal. Machine Intell., vol. 37, no. 9, pp. 1904–1916, 2015. [56] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus, and Y. LeCun, “Overfeat: Integrated recognition, localization and detection using convolutional net- works,” arXiv Preprint, arXiv:1312.6229, 2013. [57] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi, “You only look once: Unified, real-time object detection,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2016, pp. 779–788. [58] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y. Fu, and A. C. Berg, “SSD: Single shot multibox detector,” in Proc. European Conf. Computer Vision, 2016, pp. 21–37. [59] M. Najibi, M. Rastegari, and L. S. Davis, “G-CNN: An iterative grid based object detector,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2016, pp. 2369–2377. [60] J. Redmon and A. Farhadi, “YOLO9000: Better, faster, stronger,” arXiv Preprint, arXiv:1612.08242, 2016. [61] A. Shrivastava, A. Gupta, and R. Girshick, “Training region-based object detectors with online hard example mining,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2016, pp. 761–769. [62] G. Cheng, P. Zhou, and J. Han, “RIFD-CNN: Rotation-invariant and fisher dis- criminative convolutional neural networks for object detection,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2016, pp. 2884–2893. [63] S. Bell, C. Lawrence Zitnick, K. Bala, and R. Girshick, “Inside-outside net: Detecting objects in context with skip pooling and recurrent neural networks,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2016, pp. 2874– 2883. [64] S. Gidaris, and N. Komodakis, “Object detection via a multi-region and seman- tic segmentation-aware CNN model,” in Proc. IEEE Int. Conf. Computer Vision, 2015, pp. 1134–1142. [65] A. Shrivastava, and A. Gupta, “Contextual priming and feedback for faster R-CNN,” in Proc. European Conf. Computer Vision, 2016, pp. 330–348. [66] J. Feng, Y. Wei, L. Tao, C. Zhang, and J. Sun, “Salient object detection by composition,” in Proc. IEEE Int. Conf. Computer Vision, 2011, pp. 1028–1035. [67] M.-M. Cheng, Z. Zhang, W.-Y. Lin, and P. Torr, “BING: Binarized normed gradients for objectness estimation at 300fps,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2014, pp. 3286–3293. [68] K.-Y. Chang, T.-L. Liu, H.-T. Chen, and S.-H. Lai, “Fusing generic objectness and visual saliency for salient object detection,” in Proc. IEEE Int. Conf. Computer Vision, 2011, pp. 914–921. [69] P. Jiang, H. Ling, J. Yu, and J. Peng, “Salient region detection by UFO: Uniqueness, focusness and objectness,” in Proc. IEEE Int. Conf. Computer Vision, 2013, pp. 1976–1983. [70] Y. Li, X. Hou, C. Koch, J. M. Rehg, and A. L. Yuille, “The secrets of salient object segmentation,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2014, pp. 280–287. [71] T. Malisiewicz, A. Gupta, and A. A. Efros, “Ensemble of exemplar-svms for object detection and beyond,” in Proc. IEEE Int. Conf. Computer Vision, 2011, pp. 89–96. [72] M. Bar, “The proactive brain: Using analogies and associations to generate pre- dictions,” Trends Cogn. Sci., vol. 11, no. 7, pp. 280–289, 2007. [73] R. M. Nosofsky, “Attention, similarity, and the identification–categorization relationship,” J. Exp. Psychol., vol. 115, no. 1, pp. 39, 1986. [74] A. Borji, “Boosting bottom-up and top-down visual features for saliency esti- mation,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2012, pp. 438–445. [75] T. Judd, K. Ehinger, F. Durand, and A. Torralba, “Learning to predict where humans look,” in Proc. IEEE Int. Conf. Computer Vision, 2009, pp. 2106–2113. [76] D. Zhang, D. Meng, L. Zhao, and J. Han, “Bridging saliency detection to weak- ly supervised object detection based on self-paced curriculum learning,” in Proc. Int. Joint Conf. Artificial Intelligence, 2016, pp. 3538–3544. [77] B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba, “Learning deep features for discriminative localization,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2016, pp. 2921–2929. [78] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman, “The pascal visual object classes (VOC) challenge,” Int. J. Computer Vision, vol. 88, no. 2, pp. 303–338, 2010. [79] M. Everingham, A. Zisserman, C. K. Williams, L. Van Gool, M. Allan, C. M. Bishop, O. Chapelle, N. Dalal, T. Deselaers, and G. Dorkó, “The PASCAL visual object classes challenge 2007 (VOC2007) results,” 2007. [Online]. Available: http:// host.robots.ox.ac.uk/pascal/VOC/voc2007/workshop/index.html [80] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, and C. L. Zitnick, “Microsoft COCO: Common objects in context,” in Proc. European Conf. Computer Vision, 2014, pp. 740–755. [81] Q. Yan, L. Xu, J. Shi, and J. Jia, “Hierarchical saliency detection,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2013, pp. 1155–1162. [82] V. Movahedi and J. H. Elder, “Design and perceptual validation of perfor- mance measures for salient object segmentation,” in Proc. IEEE Computer Society Conf. Computer Vision and Pattern Recognition Workshops, 2010, pp. 49–56. [83] G. Li and Y. Yu, “Visual saliency based on multiscale deep features,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2015, pp. 5455–5463. [84] C. Yang, L. Zhang, H. Lu, X. Ruan, and M.-H. Yang, “Saliency detection via graph-based manifold ranking,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2013, pp. 3166–3173. [85] M.-M. Cheng, N. J. Mitra, X. Huang, and S.-M. Hu, “Salientshape: Group saliency in image collections,” Visual Computer, vol. 30, no. 4, pp. 443–453, 2014. [86] J. Pont-Tuset, P. Arbelaez, J. T. Barron, F. Marques, and J. Malik, “Multiscale combinatorial grouping for image segmentation and object proposal generation,” IEEE Trans. Pattern Anal. Machine Intell., vol. 39, no. 1, pp. 128– 140, 2017. [87] R. Zhao, W. Ouyang, H. Li, and X. Wang, “Saliency detection by multi-context deep learning,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2015, pp. 1265–1274. [88] H. Jiang, J. Wang, Z. Yuan, Y. Wu, N. Zheng, and S. Li, “Salient object detec- tion: A discriminative regional feature integration approach,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2013, pp. 2083–2090. [89] P. Mehrani and O. Veksler, “Saliency segmentation based on learning and graph cut refinement,” in Proc. British Machine Vision Conf., 2010, pp. 1–12. [90] P. Dollár, R. Appel, S. Belongie, and P. Perona, “Fast feature pyramids for object detection,” IEEE Trans. Pattern Anal. Machine Intell., vol. 36, no. 8, pp. 1532–1545, 2014. [91] Q. Hou, M.-M. Cheng, X. Hu, Z. Tu, and A. Borji, “Deeply supervised salient object detection with short connections,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2017, pp. 3203–3212. [92] D. Zhang, J. Han, J. Han, and L. Shao, “Cosaliency detection based on intrasa- liency prior transfer and deep intersaliency mining,” IEEE Trans. Neural Networks Learning Syst., vol. 27, no. 6, pp. 1163–1176, 2016. [93] D. Zhang, J. Han, C. Li, J. Wang, and X. Li, “Detection of co-salient objects by looking deep and wide,” Int. J. Computer Vision, vol. 120, no. 2, pp. 215–232, 2016. [94] D. Zhang, D. Meng, and J. Han, “Co-saliency detection via a self-paced multi- ple-instance learning framework,” IEEE Trans. Pattern Anal. Machine Intell., vol. 39, no. 5, pp. 865–878, 2017. [95] D. Zhang, J. Han, L. Jiang, S. Ye, and X. Chang, “Revealing event saliency in unconstrained video collection,” IEEE Trans. Image Processing, vol. 26, no. 4, pp. 1746–1758, 2017. [96] D. Zhang, L. Yang, D. Meng, D. Xu, and J. Han, “SPFTN: A self-paced fine- tuning network for segmenting objects in weakly labelled videos,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2017, pp. 4429–4437. [97] D. Zhang, J. Han, Y. Yang, and D. Huang, “Learning category-specific 3D shape models from weakly labeled 2D images,” in Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2017, pp. 4573–4581. [98] Y. Bengio, J. Louradour, R. Collobert, and J. Weston, “Curriculum learning,” in Proc. Annu. Int. Conf. Machine Learning, 2009, pp. 41–48. [99] Y. Yuan, X. Liang, X. Wang, D.-Y. Yeung, and A. Gupta, “Temporal dynamic graph LSTM for action-driven video object detection,” arXiv Preprint, arXiv:1708.00666, 2017.",normalizedContent:"选自ieee信号处理杂志（ieee signal processing magazine | january 2018 ）\n\nadvanced deep-learning techniques for salient and category-specific object detection\n\n\n\n目标检测，包括目标性检测（objectness detection，od）、显著目标检测（ salient object detection，sod）和特定类别目标检测（category-specific object detection，cod），是计算机视觉领域最基本但最具挑战性的问题之一。在过去的几十年里，研究人员为解决这个问题做出了巨大的努力，因为它在其他计算机视觉任务中有着广泛的应用，如活动或事件识别、基于内容的图像检索和场景理解等。\n\n尽管近年来出现了许多方法，目前仍缺乏对所提出的高质量目标检测技术，尤其是基于高级深度学习技术的目标检测技术的全面综述。\n\n为此，本文深入探讨了这一研究领域的最新进展，包括\n\n1）每个子方向的定义、动机和任务；\n\n2） 现代技术和基本研究趋势；\n\n3） 基准数据集和评估指标；\n\n4）实验结果的比较与分析。\n\n更重要的是，我们将揭示od、sod和cod之间的潜在关系，并详细讨论一些开放性问题，同时指出几个尚未解决的挑战和有前途的未来工作。\n\n\n# 引言\n\n作为一项具有挑战性但有用的计算机视觉任务，目标检测旨在识别每个给定图像或视频中存在的各种单独的目标。在这一研究领域，当处理具有相对简单的图像场景和清晰前景对象的图像时，已经取得了比较好的结果。然而，当处理包含以任意姿势放置、形状各异且出现在杂乱和封闭环境中的对象的图像和视频时，这个问题没有得到充分解决。\n\n过去几十年中发表的目标检测研究工作大致可分为三个方向：od、sod和cod。具体而言，od[1]、[2]旨在检测每个给定图像中出现的所有可能对象，而不管具体的对象类别。它有很大的挑战，因为不同的物体，无论是在同一个物体类别内，还是来自不同的物体类别，都可能有巨大的外观变化，由于其内部固有特征（例如，猫等生物通常比车辆等人造物体具有更多可变形的外观）或外部捕获条件（例如观察距离或角度）（例如，可变形物体在一定距离内可能看起来有些僵硬，甚至僵硬物体在不同视角下也可能表现出变化）。通常，od算法输出数千个对象建议或假设，如图1（a）所示，这有利于广泛的计算机视觉任务，如弱监督学习[3]和对象跟踪[4]。\n\n图1.目标检测的三个研究方向：（a）od，（b）sod和（c）cod。\n\nsod[5]，[6]是目标检测的另一个方向，其目的是模仿视觉注意机制，突出显示每个给定图像中吸引我们注意力的对象[91]。这是受到人类视觉注意系统的启发，该系统可以引导人类特别注意一些信息丰富的图像区域，这些区域自然不同（自底而上的显著性）或与某些对象类别相关，这些对象类别由认知现象，如知识、期望、奖励和特定任务（自上而下的显著性）[7]。与od类似，自底而上的sod面临着来自无约束对象类别中大量外观变化的挑战，而自上而下的sod面临着如何有效地将所需视觉刺激（通常在语义级别）与视觉场景中的相应区域相关联的挑战。通常，sod算法根据获得的显著图输出有限数量的对象区域，如图1（b）所示。它们还可以帮助执行各种计算机视觉任务，如图像检索[8]和对象分割[9]。\n\n目标检测的第三个方向是cod[10] [11]。与od不同，cod的目标是从每个给定的图像中检测多个预定义的对象类别。它不仅需要识别可能包含感兴趣对象的图像区域，还需要识别每个检测到的图像区域的特定对象类别。与sod相比，cod具有完全不同的动机，即它移动在不了解人类视觉系统功能(例如视觉注意)的情况下解决纯计算问题。通常，cod被转化为一个多分类问题，在该问题中，识别性分类函数被训练来分离相应特征域中提取的图像区域。cod的主要挑战是如何处理组内外观变化和组间外观相似性。如图1（c）所示，cod方法通常会输出多个指定了识别对象类别的图像区域。cod可以应用于场景解析[12]和人类行为识别[13]等计算机视觉任务。\n\n为了解决目标检测中的挑战性问题，为了设计更好的手工特征（如hog和sift），已经提出了大量工作，并提出了复杂的目标检测框架，以便在整个目标检测开发阶段将提取的特征与精心设计的分类器（如随机森林和adaboost）结合起来。卷积神经网络（cnn）于2004年首次应用于目标检测[14]，自2013年以来得到了广泛应用[15]。[10]中关于基于区域的cnn（rcnn）的工作在2014年取得了重大突破。它最早致力于通过使用多层卷积网络来提取高分辨但不变的特征表示来描述目标检测系统。\n\n与当时的最佳方法相比，这项工作的平均精度（map）显著提高了50%以上，这些方法基于常用pascal检测基准[16]上手工制作的图像特征。从那时起，已经提出了几种基于高级深度学习的技术[17]-[20]，用于高质量的目标检测，它涵盖了od、sod和cod的所有相关领域。为此，本文对最近最先进的方法进行了全面的综述。\n\n本文主要有四个动机：\n\n1） 目标检测，包括od、sod和cod，是计算机视觉的一个基本但具有挑战性的问题。现有的调查论文只关注每个单独的主题，而没有讨论密切的关系。\n\n2） 由于近年来已经提出了许多方法，并且取得了突破性的性能，因此回顾最近提出的目标检测技术，尤其是基于深度学习技术的目标检测技术，将是一件有启发性的事情。\n\n3） 就几个重要问题进行深入讨论是非常有意义的。例如，为什么最近基于深度学习的框架能够显著提高目标检测的性能？与以前的框架相比，这种框架最本质的改进是什么？基于深度学习的方法在未来需要解决哪些问题？\n\n4） 对公开的目标检测基准测试的实验结果进行综合比较和分析，将有助于读者更好地了解每种目标检测策略的性能以及相应的网络体系结构。\n\n\n# 预备知识\n\n近年来，深度学习的研究领域得到了快速发展，包括其在计算机视觉中的普及。在本节中，我们将简要介绍在目标检测任务中广泛使用的一种高级深度学习技术，即cnn。\n\ncnn是受生物自然视觉感知机制启发的最著名、应用最广泛的深度学习架构之一，该机制最初由fukushima[21]提出，后来由lecun[22]改进。cnn设计用于处理以多个阵列形式出现的数据[23]，例如，由三个二维阵列组成的彩色图像，其中包含三个颜色通道中的像素强度。cnn利用了自然信号的特性，其背后有四个关键思想：本地连接、共享权重、池化和多层的使用[23]。\n\n如图2所示，典型cnn模型的体系结构由一系列层构成，如下所示：\n\n图2.典型cnn模型的架构。\n\n * 卷积层：卷积层是特征提取最重要的部分。前几层通常捕获低级特征（如边、线和角），而较深层则可以通过组合低级特征来学习高级特征（如结构、对象和形状）。卷积层中的每个单元通过一组称为滤波器组的内核连接到前一层特征图中的局部面片。然后，该局部加权和的结果通过非线性运算，例如校正线性单元（relu）。要素图中的所有单元共享同一个过滤器组。卷积层中的不同特征映射使用不同的滤波器组。\n\n * 池化层：池化层旨在降低表示的维度，并创建对小位移和扭曲的不变性。池化层通常位于两个卷积层之间。池层的每个特征映射都连接到前一个卷积层的对应特征映射。一个典型的池化单元计算一个特征图中单元的一小块局部的最大值。\n\n * 全连接层：全连接层通常用作网络的最后几层，以便更好地总结低层在最终决策中传达的信息。由于完全连接的层占据了大部分参数，因此很容易发生过拟合。为了防止这种情况，通常采用dropout[24]。从2012年alex net[24]在imagenet分类方面取得突破性成功开始，在开发各种cnn模型方面做出了重大努力，包括vggnet[25]、googlenet[26]和resnet[27]。\n\n * alexnet:alexnet[24]最早由krizhevsky等人提出，并赢得了2012年imagenet大规模视觉识别挑战赛（ilsvrc）[28]。它由五个卷积层和三个完全连接的层组成。这是计算机视觉和机器学习的一个里程碑式的研究，因为它是第一个采用非饱和神经元、图形处理单元（gpu）实现卷积运算和dropout以防止过度拟合的工作。\n\n * vggnet:vggnet[25]是ilsvrc 2014大赛本地化和分类赛道的获胜者。它有两个著名的体系结构：vggnet-16和vggnet-19。前者因其更简单的架构而被广泛使用，它有13个卷积层、5个池化层和3个完全连接的层。\n\n * googlenet：googlenet[26]是另一个具有代表性的cnn架构，它有两个主要优势。一个是在同一层使用不同大小的过滤核，这保留了更多的空间信息，另一个优点是减少了网络的参数数量，这使得网络对过度拟合的敏感性降低，并允许网络更深入。事实上，22层的googlenet有50多个卷积层分布在初始模块内部，但其参数比alexnet少12倍。\n\n * resnet:resnet[27]是最成功的cnn之一，并获得了2016年计算机视觉和模式识别大会最佳论文奖。resnet背后的思想是，每一层不应该学习整个特征空间变换，而应该只学习对前一层的剩余校正，这样可以有效地训练更深层次的网络。其极深的表示具有优异的泛化性能，并使其在2015ilsvrc和coco竞赛中获得imagenet检测、imagenet定位、coco检测和coco分割的第一名。\n\n\n# 目标检测的现代方法\n\n\n# od中的现代方法\n\nod的目标是选择一小组建议的对象，覆盖了给定图像中大多数感兴趣的对象。为了实现这一目标，od方法需要1）生成或选择可能包含特定感兴趣对象的潜在边界框，2）推断所选边界框的对象性分数。我们通常可以将现有的od方法分为三大类：区域合并、窗口选择和框回归。\n\n# 区域合并方法（region-merging）\n\n区域合并方法试图通过合并多个局部图像区域（例如超像素）来生成建议的对象。一种具有代表性的区域合并方法是著名的选择性搜索方法[29]，该方法采用贪婪算法将图像区域迭代地分组在一起。具体来说，首先计算了所有相邻区域之间的相似性。之后，将两个最相似的区域组合在一起，并计算出结果区域与其相邻区域之间的新相似性。重复这样的分组过程，直到整个图像成为一个区域。沿着这一方向，最近提出了更多的方法来更好地解决这个问题。例如，krahenbuhl等人[30]开发了一种基于学习的种子放置方法，用于识别一组种子超像素，以命中每个给定图像中的所有对象。然后，他们合并靠近每个种子超像素的图像区域，并计算有符号测地距离变换(signed geodesic distance transform)，以提取一小部分高质量的建议对象。bazzani等人[31]早期致力于采用深度学习技术，并提出了一种新的基于区域合并的od方法。具体地说，他们首先生成矩形区域的初始集合，即包围提取片段的边界框。然后，他们通过最大化包含四项的相似性函数贪婪地合并这两个区域。这四项是通过在imagenet上预训练的cnn计算的[28]，分别包括分类分数下降的相似性、深层特征的相似性、图像的覆盖面积和空间位置的距离。\n\n# 窗口选择方法（window-selecting）\n\n窗口选择方法试图通过评分和选择预生成（滑动）窗口来生成建议对象。[1]提出了一种最早也是最著名的基于窗口选择的od方法。它首先从给定图像中的显著位置[32]获得了一组初始方案。然后，这些建议通过组合多个信息线索进行评分，包括颜色对比度、边缘密度、位置、大小和“超像素跨越”(superpixel straddling)线索。受这项工作的启发，研究人员在过去几年进行了广泛的研究。例如，ghodrati等人[17]最早利用经过预训练的cnn的深度特征图。其主要思想是在不同的激活层上以滑动窗口的方式生成假设。提出的逆级联搜索(inverse cascade searching)从cnn的最终卷积层到初始卷积层，可以选择最有希望的对象位置，并以从粗到细的方式细化它们的框。类似地，pinheiro等人[33]，[34]提出使用带有两个分支的cnn来同时推断每个输入图像窗口的分割掩码和对象性分数。最终的包围盒方案是通过获取包围分割模板的矩形图像区域获得的。与[17]和[33]不同，kuo等人[2]采用数据驱动的语义方法对对象提案进行排序。他们学习了一种小型但有效的cnn架构，用于重新排列自底而上方法得到的proposals[35]。在[36]中，hu等人从卷积特征图中提取密集滑动窗口，然后采用统一的头部模块对窗口特征进行解码，并生成输出置信度得分和目标掩码。\n\n# 盒回归法（box-regressing）\n\n盒回归方法试图通过直接学习回归函数，从提取的深度特征图中获得边界盒位置和对象性分数，从而生成对象建议。随着计算机视觉中深度学习技术的成功，这些方法应运而生。具体而言，erhan等人[37]于2014年提出了第一种基于盒回归的od方法，其中od被定义为对边界盒位置坐标的回归问题。此外，它还推断出每个边界框的置信度得分，这表明该框包含对象的可能性有多大。整个系统由一个单一的cnn模型实现，该模型具有一个新的损失函数，该函数考虑了位置和得分精度。szegedy等人[38]在[37]的基础上，基于最新的inception-style架构[39]进一步构建了框架，并利用了包围盒形状和置信度的多尺度卷积预测，从而建立了基于inception的后分类(post-classification)模型。沿着这个方向，ren等人[40]提出了一个区域建议网络（rpn）来学习回归函数，用于基于一组预定义的平移不变锚(predefined translation-invariant anchors)来拟合边界框位置的坐标。他们还将rpn与一些额外的网络层结合起来，以实现精确的cod。类似地，kong等人[41]开发了一种新的超特征(hyperfeature)，将深度但粗糙的信息与浅层但精细的信息相结合，以提取更丰富的特征。li等人[42]建立了用于生成建议对象的缩小和放大网络(zoom-out-and-in network)，其中，放大子网络(zoom-in subnetwork)用于通过反卷积(deconvolution)操作提高高级特征的分辨率，递归训练管道用于在训练阶段连续回归区域proposals。\n\n\n# sod的现代方法\n\nsod包括两个分支：自下而上和自上而下。前者是刺激驱动(stimulus driven)的，主要对视觉场景中最有趣和最显眼的区域做出反应，而后者则由知识和高级视觉任务来指导。例如故意寻找特定类别的对象。如之前的研究[7]、[43]和[44]所述，在自底向上的sod分支中，方法是检测自由观看下的显著性，这是由场景的物理特征自动确定的，而另一分支中的方法是检测由观察者当前目标确定的任务驱动的显著性。在每个分支中，都可以建立有监督和无监督的框架来解决相应的问题。接下来，我们将更详细地研究这两个分支。\n\n# 自底向上的sod(bottom-up)\n\n自底向上的sod旨在准确区分视觉场景中的前景对象和背景。传统模型主要依赖对比度提示。cheng等人[6]提出的一种具有代表性的方法测量了归一化颜色直方图中每个图像区域和图像中所有其他区域之间的色差加权和，作为检测显著性的全局对比度。受这项工作的启发，一些研究人员还将局部和全局对比度结合起来进行显著性检测。近年来，随着深度学习的发展，深度神经网络（dnn）也被用来提高sod的性能。最早的开创性工作之一是[45]，其中han等人提出利用叠加去噪自动编码器对sod之前的背景进行建模。除了这项工作，最近几年还提出了一些基于cnn的sod方法。例如，wang等人[46]提出将局部估计和全局搜索结合起来进行显著性检测。lee等人[47]结合了每个超像素的低层距离图和整个图像的全局cnn特征。liu和han[20]提出，以端到端的方式，从全局到局部上下文，从粗到细分层检测显著对象。li和yu[48]提出将基于像素级完全卷积网络（fcn）的显著性网络与分段多尺度cnn相结合，用于显著性检测。wang等人[49]通过递归fcn提出了一种渐进的显著性细化网络，在该网络中，先前的显著性图和原始图像被同时馈送(simultaneously fed)，以学习纠正其先前的错误，从而获得更好的显著性结果。\n\n# 自顶向下的sod(top-down)\n\n自上而下的sod通常旨在高亮显示场景中特定于类别的对象。yang和yang[50]提出联合学习条件随机场的参数和一个用于监督自上而下显著性检测的字典。he等人[51]提出了一种基于样本的自上而下显著性检测方法，目的是定位与给定样本图像属于同一类别的对象。cholakkal等人[52]提出了一种只使用图像标签的弱监督自上而下显著性框架。他们首先使用图像标签训练了一个基于稀疏编码的空间金字塔匹配（scspm）分类器。然后分析图像中每每一小块对分类器的概率贡献，以估计反向scspm显著性(reverse-scspm saliency)。接下来，使用逻辑回归模型，使用每一小块的上下文(contextual patches)来估计上下文显著性。最终的显著性图可以通过组合两个显著性图来获得。zhang等人[53]基于自顶向下的赢家通吃(winner-take-all)过程和dnn中的反向传播，提出了自顶向下显著性检测的激励反向传播方法。\n\n\n# cod的现代方法\n\n在过去的几十年里，cod在文献中得到了广泛的研究。变形零件模型（dpm）[54]及其变体多年来一直是主流方法。这些方法使用手工制作的图像描述符作为特征，并扫描整个图像，以检测具有特定于类的最大响应的区域。\n\n最近，由于imagenet[28]等大规模训练数据的可用性和高性能gpu的进步，人们提出了各种基于深度学习的方法（尤其是基于cnn的方法），以显著提高cod的技术水平。事实上，cnn用于检测和识别可以追溯到20世纪80年代[22]。然而，由于缺乏训练数据和有限的计算资源，在2012年之前，基于cnn的cod没有多少进展。自2012年cnn在ilsvrc的图像分类任务中取得突破性成功[28]以来，基于cnn的范例（用于cod）最近吸引了大量研究兴趣。cod方法通常有两大类：基于建议对象的方法和基于回归的方法。\n\n# 基于建议目标的方法(object proposal-based)\n\n基于建议对象的cod框架首先使用建议区域方法（如选择性搜索[29]）生成一组建议边界框，其中可能包含对象（该过程也称为od），然后将检测到的对象建议传递给cnn分类器，以确定它们是背景还是来自特定区域对象类。\n\n在各种基于对象提议的方法（cod）中，girshick等人[10]在2014年提出的区域cnn（r-cnn）的工作是最著名的方法之一。这项工作为通过深度cnn模型提取丰富的特征打开了大门，从而显著提高了性能。r-cnn框架是一系列概念上简单的步骤：生成对象建议，将建议分类为背景或特定类别的对象，并对检测进行后处理，以提高它们对对象的适应性。简而言之，r-cnn的工作如下。首先，它通过选择性搜索算法[29]提取大约2000个自下而上的区域建议，其中可能包含对象，以降低计算成本。然后，将这些建议区域变形(warped)为固定大小（例如227 x 227），并使用微调的cnn模型从中提取cnn特征。接下来，使用特定类别的线性支持向量机（svm）将每个建议区域分类为对象或非对象。最后，通过使用边界盒回归器[54]来改进定位，候选方案被重新调整为检测到的对象。这个简单的管道在基准数据集上实现了最先进的cod性能，与所有以前发表的作品（主要基于dpm）相比，性能有了显著提高[54]。在这里，值得一提的是，用于从建议区域中提取深度cnn特征的cnn模型通常在基于imagenet数据集的图像分类辅助任务[28]上进行预训练，然后在检测任务的带边框注释的小图像集上进行微调。\n\n然而，在r-cnn中，我们必须反复将候选边界框调整为固定大小，以提取其cnn特征，这对cod来说是非常昂贵的。为了加快r-cnn的速度，一些文献[18]、[55]、[56]建议在特征提取中共享计算(share the computation)。例如，空间金字塔池网络（sppnet）[55]引入了空间金字塔池层，以放松输入必须具有固定大小的约束。与r-cnn不同，sppnet只从整个图像中提取一次特征图，与建议区域无关，然后对每个区域建议应用空间金字塔池以获得固定长度的表示。这种重组允许所有区域提案之间轻松共享计算。sppnet的一个缺点是，sppnet的微调算法只能更新完全连接的层，这使得无法联合训练cnn特征提取器和svm分类器来进一步提高性能。为了修正这个缺点，提出了fast r-cnn[18]，它是sppnet的端到端可训练的改进。在fast r-cnn的框架下。所有网络层都可以在微调过程中更新，从而简化学习过程，提高检测精度。\n\nr-cnn[10]和fast r-cnn[18]的框架都需要建议区域的输入，这些提案通常来自手工制作的建议区域方法，如选择性搜索[29]和edgebox[35]。然而，proposal生成是整个流程中的瓶颈。为了解决这个问题，提出了faster r-cnn[40]，它由两个模块组成。第一个被称为区域建议网络（rpn），是用于生成建议区域的fcn（每以个都有一个建议边界框和一个目标分数），并将其输入第二个模块。第二个模块是用于目标检测的fast r-cnn网络。faster r-cnn将建议生成和目标检测结合到一个统一的网络中，其中rpn模块与fast r-cnn检测网络共享相同的卷积特征；因此，它几乎可以无代价生成建议区域。\n\n# 基于回归的方法(regression-based)\n\n基于回归的cod方法被描述为具有空间分离的边界盒和相关类别概率的回归问题[57]-[60]。与基于建议对象的方法相比，基于回归的框架（用于cod）要简单得多，因为它不需要建议生成和随后的像素/特征重采样阶段，并将所有阶段封装在单个网络中[58]。请注意，box回归od法和回归cod法之间的主要区别在于前者的目标是预测box位置和每个box位置的一个客观评分，后者的目标是预测box的位置和每个box位置的目标类别分数（其维度取决于所需目标类别的数量）。本质上，回归cod设计的模型通常比box回归od设计的模型复杂得多，因为前者需要同时处理建议定位和对象类别识别的任务。因此，多任务损失函数在基于回归的cod中比在box回归od中更常用。you only look once (yolo)[57]和single-shot multibox（ssd）[58]是两种典型的基于回归的方法（用于cod）。\n\nyolo[57]将基于cnn的目标检测描述为一个回归问题，从而开启了实现实时目标检测的大门。yolo的独特之处在于，它将目标检测的各个部分统一到一个卷积网络中，该网络可以同时预测多个边界框和这些边界框的种类概率。神经网络在进行预测时会对图像进行全局推理，因此它会隐式地对种类及其外观的上下文信息进行编码。与基于建议目标的方法相比，yolo速度非常快，每秒运行45-150帧，而无需在titan x gpu上进行批处理。然而，仍然很难检测到小尺寸的物体并实现精确定位。\n\n此后，ssd[58]被提出用于改进yolo方法。具体来说，它将边界框的输出空间离散为一组默认框，每个特征图位置具有不同的纵横比和比例，与faster r-cnn的rpn有类似的想法。在预测时，ssd导出每个默认框中存在的每个对象类别的分数，并生成对框的调整，以更好地匹配对象外观。此外，该网络将来自不同分辨率的多个特征图的预测结合起来，以处理不同大小的对象。通过引入多尺度特征图和默认框机制，ssd在检测小尺寸对象方面取得了显著的性能改进，与yolo相比，还提高了定位精度。\n\n此外，最近还开展了一些工作，以进一步提高基于cnn的cod方法的性能，如硬负挖掘(hard negative mining)[61]、特征增强[41]、[62]，上下文信息融合[63]-[65]，等等。例如，为了提高处理具有挑战性的情况的能力，通过对象旋转、类内可变性和类间相似性，cheng等人[62]提出了一种旋转不变的fisher判别cnn模型。在现有高容量cnn架构的基础上，通过分别引入旋转不变层和fisher判别层来实现。\n\n\n# od、sod、cod之间的关系\n\n虽然od、sod和cod是目标检测中的三个独立研究方向，但它们之间存在着丰富的关系。\n\n\n# od与sod的关系\n\n一方面，自下而上的sod能够为od提供信息丰富的先验知识。直观地说，对人类视觉系统更具吸引力（在图像场景中更突出）的提取边界框位置更有可能包含感兴趣的对象。基于这一观察，已经设计了几种基于显著性线索的od方法。例如，最经典的od方法之一[1]通过使用三个显著性提示来选择对象方案，即多尺度显著性、颜色对比度和边缘密度。类似地，[66]中的工作将目标性定义为窗口显著性，这是使用图像的剩余部分构成窗口的成本。这个定义基本上包含了全局稀有性原则(global rarity principle)，并将其从像素级（对于sod）扩展到窗口级（对于od）。此外，cheng等人将od视为自底向上sod的特例[67]，这表明利用sod的检测原理可以有效地制定od。erhan等人[37]还提出了一种基于显著性的od神经网络模型，并取得了良好的性能。\n\n另一方面，一些自底而上的sod方法也建立在od结果的基础上。当有od生成的边界盒时，sod问题可以简化为从非显著边界盒中选择显著边界盒。基于这一直觉，chang等人[68]提出通过一个统一的图形模型，在检测显著对象之前，集成对象性先验（包括对象大小和位置）和显著性。jiang等人[69]将客观性优先与聚焦性和客观性相结合，以保持检测到的sod显著区域的完整性。li等人[70]提出将从注视预测中获得的具有高显著值的候选对象视为显著对象。与传统的显著性检测只需要突出显示不同的局部区域不同，sod需要均匀地突出显示完整的显著性对象，因此对象的感知能力应该自然地编码到有效的sod模型中。目标性优先自然为这一需求提供了有效的解决方案。\n\n\n# sod与cod的关系\n\n由于自上而下的sod是高度任务驱动和知识驱动的，它需要对视觉场景，尤其是场景中对象的类别级信息有较高的理解。为了实现在场景中定位目标的目标，自上而下的sod方法通常需要获取自上而下的知识来指导检测过程[51]。这种自上而下的知识可能来自记忆（即，使用来自相应训练数据的知识定位场景中的对象，这是基于模型的对象检测）或对象关联（即，使用已知或未知的样本定位场景中的相应对象，这是基于样本的对象检测[71]-[73]）。例如，在[50]中，yang等人通过联合crf和字典学习检测自上而下的显著性。crf模型是通过在图像贴片表示(image patch representation)和相应的贴片标签(patch labels)上训练线性支持向量机来初始化的，它本质上是一个贴片级别(patch-level)的类别特定对象检测器。在以前的工作中，也可以找到一些实验结果或讨论，表明某些特定类别的物体检测器（例如，人类、人脸、汽车、出现在给定图像中的单词等）提供的自上而下的线索在视觉注意机制中起着重要作用[74]，[75]\n\n除了sod，自上而下的sod尤其可以反过来为cod提供有用的特定类别的对象，尤其是在监管薄弱的情况下。正如我们所知，弱监督对象检测方法[3]、[76]、[77]旨在仅使用图像级标记而不是实例级边界框注释来学习特定于类别的对象检测器。在这种情况下，如何获得特定对象类别的初始对象位置是需要解决的主要问题。通过使用sod方法，[3]和[76]有效地初始化特定类别的对象位置，然后采用迭代学习方案，以迭代方式逐步细化对象检测器和位置。当学习过程收敛时，可以学习更强的目标检测器来执行测试数据中的cod。参考文献[52]、[53]和[77]还提出应用自上而下的显著性检测来发现弱标记训练图像中的目标位置，随后可用于训练特定类别的目标检测器。\n\n\n# cod与od的关系\n\n大量研究表明，od可以直接受益于cod任务[10]、[11]、[18]、[55]。基本上，正如我们在“基于建议对象的方法”一节中总结的那样，cod方法的一个主流是建立在od技术上的，其中od可以作为单独的预处理步骤[10]或在统一对象检测框架[40]中设计的固有组件来工作。cod方法基于od技术的构建通常比基于滑动窗口搜索策略的构建获得更好的性能[54]，因为od技术可以在目标检测任务之前提供有用的位置，这可以极大地减少对许多背景图像区域不必要的搜索，从而有效地减少误报。\n\n大多数od方法中的参数需要从收集的训练集中学习，这些训练集通常来自pascal voc基准[78]。本质上，由于训练数据集中只有有限的对象类，因此此类训练数据（包含不到20个类别的对象的真值边界框）可以被视为学习对象性检测器的受限知识库（例如[19]、[40]和[58]）。尽管一些工作已经证明了他们提出的方法，[2]和[17]仍然能够为看不见的目标生成建议目标，即不包含在训练数据集中的目标类；由于大量的领域转移，这些方法可能或多或少受到性能下降的影响。值得一提的是，最近的一项研究[31]提出了特定类别的od方法，其目标与cod方法类似。\n\n\n# 基准和评价指标\n\n\n# od的基准\n\nod中广泛使用了两个基准：pascal voc 2007[79]的测试集和ms coco[80]的验证集。具体来说，pascal voc 2007的测试集包含来自20个类别的4952个图像和14976个对象实例。大量的对象和种类、视点、比例、位置、遮挡和照明的高度多样性使得该数据集非常流行于评估od方法，因为od的目标是在不同的图像场景中找到所有可能的对象。ms coco基准包含80000名训练图像和总计约500000个实例注释。该数据集中的图像是从复杂的日常场景中收集的，这些场景包含自然环境中的常见对象。因此，它是一个更具挑战性的数据集，用于检测对象性建议。在大多数情况下，评估od性能的实验是在前5000张ms coco验证图像上进行的。有时，使用另一个非重叠(nonoverlapped)图像作为验证数据集。\n\n\n# sod的基准\n\nsod社区中有几个具有不同属性的基准数据集。ecssd数据集[81]有1000个图像，在sod数据集中有一些重叠的图像[82]。这两个数据集中的图像通常具有杂乱的背景和语义上有意义的前景对象，这些对象来自不同的位置和比例。pascal-s[70]数据集是基于pascal voc分割挑战而建立的，它有850张图像，通常包含杂乱的背景和多个前景对象。hku-is[83]数据集是最近发布的sod数据集，包含4447幅图像。这些图像是从许多具有挑战性的场景中收集的，这些场景中有多个不连续的突出物体，突出物体接触图像边界，颜色对比度低。dut-omron数据集[84]由5168个图像组成，每个图像通常有复杂的背景，包含一个或两个前景对象。thur15k数据集[85]包含来自五个对象类的6232幅图像，即蝴蝶、咖啡杯、狗跳、长颈鹿和飞机。此数据集中的一些图像没有前景对象。msra-10k数据集[6]包含10000张带有各种对象的图像，是msra-b数据集[5]的扩展。这两个数据集中的大多数图像只有一个前景对象和清晰的背景。sed数据集是另一个广泛使用的数据集，包含200幅图像。此数据集中的每个图像包含一个和两个前景对象。\n\n\n# cod的基准\n\npascal voc 2007[79]和pascal voc 2012[16]数据集是评估各种目标检测方法最常用的两个基准。pascal voc 2007数据集共包含来自20个对象类别的9963张图像，包括5011张用于训练和验证的图像和4952张用于测试的图像，其中20个对象类别的地面真值边界框被手动标记。pascal voc 2012数据集是pascal voc 2007数据集的扩展，该数据集共包含22531幅图像，包括用于训练和验证的11540幅图像和用于测试的10991幅图像。然而，测试集中没有提供基本的真值标签。因此，应通过将测试结果提交给pascal voc评估服务器来评估所有方法。\n\nms coco[80]是2014年提出的一个较新的目标检测基准，其目标是通过将目标识别问题置于更广泛的场景理解问题的背景下，提升目标识别的最新水平。与pascal voc数据集相比，该数据集在每个类别的实例数上要大得多。具体来说，该数据集包含200000多个图像和80个对象类别，其中训练集包含80000个图像，验证集包含40000个图像，测试集包含80000个图像。为了限制过度拟合，并让研究人员更灵活地测试他们的方法，测试集分为三部分，包括测试开发、测试标准和测试挑战。test dev用于调试和验证实验，并允许无限提交到评估服务器。测试标准用于维护提交后更新的公共排行榜。测试挑战用于比赛。大多数已发表的作品都在测试开发集上报告了它们的检测结果。\n\n\n# od的评价指标\n\nod方法生成的评估建议对象的指标通常是建议位置和相应真值注释之间的联合交集（iou）（或jaccard索引）的函数。具体而言，特定提案位置和地面真相注释之间的iou定义为：\n\n\n\n基于iou，召回率可以计算为建议位置覆盖的ground-truth边界框在某个iou重叠阈值以上的分数。然后，三个广泛用于评估对象性检测方法的评估指标如下：\n\n * 召回与建议曲线，描述不同建议数量的召回。\n * 召回与重叠曲线，说明了在不同iou重叠标准下召回的变化。\n * 平均召回率（ar），计算“召回与重叠”曲线下重叠值范围内的面积（通常设置为0.5-1.0）。\n\n\n# sod的评价指标\n\n通常三个标准的评估指标被广泛用于sod。第一个是精确召回曲线（prc）。具体来说，给定一个显著性映射s和相应的真值显著性掩码g，我们首先将s标准化为[0]，[1]。然后，我们使用阈值t将s转换为二进制掩码m。之后，可以在阈值t下计算精度和召回率。当t从0变为1时，我们可以获得一系列精度召回值对。因此，我们可以通过将sod作为分类任务来绘制prc来评估模型的性能。\n\n第二个指标是f测量分数，它综合考虑了精确度和召回率。通常情况下，首先使用自适应阈值分割显著性图，并获得精度和召回值；然后，将f度量分数计算为它们的加权调和平均值。\n\n虽然这两种度量被广泛使用，但它们不能考虑真实的负像素(negative pixels)。为了解决这个问题，也常用平均绝对误差（mae）。mae测量s和g之间的平均像素绝对差。有关上述评估指标的更多详细信息，请参考[20]、[83]和[87]。\n\n\n# cod的评价指标\n\n所有对象类的平均精度（ap）和map是评估各种对象检测方法的两个标准且广泛使用的指标。它们被设计成不太喜欢缺少对象实例、重复检测一个实例和假阳性检测(false positive detections)的方法。具体来说，ap计算不同召回级别的平均准确度值，即prc下的区域，因此ap值越高，性能越好，反之亦然。精确性衡量的是检测到的真正阳性的分数，而召回率衡量的是正确检测到的阳性的分数。\n\n如果预测边界框和真值边界框之间的iou超过预定义阈值，则方法的检测输出被指定为真阳性(true positive)。否则，检测被视为假阳性(false positive)。此外，如果多个检测输出与同一地面真值对象重叠，则只有一个被视为真阳性，其他被视为假阳性。\n\n对于pascal voc数据集，面积重叠阈值通常设置为0.5[16]。对于coco数据集，存在一个新的评估指标，即在不同的iou阈值上平均map，从0.5到0.95，步长为0.05（写为0.5:0.95）。与pascal voc指标相比，它更强调本地化，后者只需要0.5的iou。有关上述评估指标的更多详细信息，请参阅[40]、[58]、[60]。\n\n\n# 实验对比\n\n\n# od方法的实验对比\n\n在本节中，我们比较了pascal voc 2007测试集和ms coco验证集上不同od方法在ar方面的性能。具体而言，我们比较了表1中pascal voc 2007测试集上的七种方法，即bing[67]、obj[1]、eb[35]、gop[30]、ss[29]、rpn[40]和mcg[86]。\n\n在表2中ms coco的验证集上的7种方法，mcg[86]、deepmask[33]、deepmaskzoom[33]、deepmask2[34]、sharp mask[34]、sharpmaskzoom[34]和fastmask[36]。\n\n这里，deepmaskzoom表示将原始图像缩放到多个比例，然后在每个比例上应用deepmask。同样的方法也用于shapmaskzoom。deepmask2基于39层resnet[27]实现，并根据sharpmask中的网络架构修改了头部组件。deepmask和deep maskzoom构建在vgg网络上[25]，而deepmask2、sharpmask、sharpmaskzoom和fastmask构建在39层resnet上[27]。\n\n在表1中，我们可以观察到，在不使用任何深度学习技术的人中，mcg是最好的od方法。它甚至比rpn更好，rpn是建立在cnn上的一种od方法。这主要是因为rpn设计的网络架构相对简单，它只是更快的r-cnn整个框架的一部分，其最终目标是cod而不是od。我们可以在表2中观察到，许多基于深度学习模型的od方法在很大程度上优于mcg（约5-13%），这主要是由于更强大的特征表示和更好的学习框架。更具体地说，在基于深度学习的od方法中，除了具体设计的网络架构外，最终检测性能也与所采用的主干cnnmodel高度相关。例如，使用resnet作为主干cnn模型（例如deepmask2和sharpmaskzoom）的od方法通常比使用vgg网络（例如deepmask和deepmaskzoom）的od方法的性能高出约2-6%。此外，通过比较表1和表2中mcg的性能，我们可以观察到ms coco基准比pascal voc 2007更具挑战性。在这一研究领域需要做出更大的努力，因为在这两个基准上的表现都有很大的改进空间。\n\n在表1和表2中，我们还报告了比较od方法的运行时间。从这些表中，我们可以观察到，最快的od方法是bing和rpn，它们可以在大约0.2秒的时间内处理每个图像。ss和msg可以在不使用深度模型的情况下获得优于od方法的操作。然而，与所有其他方法相比，它们的计算成本要大得多。基于深度模型的od方法通常可以有效地进行测试，因为它们的计算成本约为每幅图像0.2-2秒。\n\n\n# sod方法的实验对比\n\n在本节中，我们报告了一些具有代表性的基于dnn的sod模型的定量比较结果。我们选择了2015年和2016年发布的七个模型，并发布了它们的代码或计算显著性图：legs[46]、dhs[20]、dcl[48]、eld[47]、mcdl[87]、mdf[83]和rfcn[49]。ecssd[811，pascal-s[70]和hku-is[83]数据集的实验结果见表3（就fmeasure而言）、表4（就mae而言）和图3（就prc而言）。根据f和mae的结果。dhs[20]是最好的显著性模型，而dcl[48]和rfcn[49]排在第二位。\n\n在这些模型中，legs、mdf、mcdl和eld基于提取的局部区域（即超像素或对象建议）。这些方法通常独立地估计每个局部区域的显著性得分。因此，它们在有效整合上下文信息方面存在局限性。因此，如表3所示，此类方法通常具有更多的计算成本，但它们无法获得优于其他方法的检测结果。相反，dhs，dcl。rfcn基于fcns，可以同时对所有像素进行显著性推断。因此，如表3所示，它们通常非常快，尤其是对于dhs，它只需要一个forward，无需任何预处理或后处理。此外，由于fcns以整个图像为输入，连续的深卷积层可以有效地合并大的上下文，这解释了这些方法获得更好的性能。\n\n为了深入了解sod算法的性能，我们在最先进的显著性模型dhs上进行了消融实验[20]。与od和cod任务不同，sod任务通常有训练测试数据的标准分离，sod任务没有这样的标准。尽管大多数sod算法在msra-10k和dut-omron数据集上实现了训练过程，在其他数据集上实现了测试过程，但当使用不同数量的训练数据时，它们会获得不同的性能。为此，我们首先分析了训练图像数量的影响。具体来说，我们从[20]中使用的原始训练集中（包含9500张图像）随机选择了三分之一和三分之二的图像，生成了两个子训练集，分别包含3167和6333张图像。通过使用这两个子训练集，我们获得了dhs-1/3和dhs-2/3的性能，如表4所示。从表4的前三行可以看出，随着训练图像的增加，检测性能会不断提高。这表明我们可以通过使用更多的训练图像来提高显著性模型的性能。值得一提的是，在将模型与其他现有显著性模型进行比较时，还应将其训练图像数保持在合理范围内（少于10000），以确保公平比较。\n\n然后，我们分析了主干cnn模型的影响。最初的dhs模型使用vgg 16层网络[25]作为主干模型。在这里，我们探索了另外两个更深层次的cnn网络，即resnet50和resnet101[27]，作为dhs模型的主干网络。注意，在原始的aldhs模型中，作者使用了五步细化，将vgg特征映射从conv4_3合并到conv1_2，从而将显著性映射从28 x 28恢复到224 x 224。然而，resnet网络的第一个卷积层都是跨步2，这意味着我们只能使用四步细化，并将显著性映射恢复到112 x 112。因此，我们还通过四个细化步骤（命名为dhs-rcl2）测试了原始dhs模型的结果，以进行公平比较。如表4中的最后四行所示，当使用相同的细化步骤时，更深的主干模型可以获得更好的最终性能。然而，由于最后一个细化步骤在提高最终性能方面起着非常重要的作用，因此使用resnet作为主干模型的性能无法超过使用vgg网的性能。由于类似于dhs的网络结构在其他现代检测方法中被广泛使用，上述分析对于我们平衡resnet带来的权衡非常重要。\n\n\n# cod方法的实验对比\n\n在本节中，我们选择了过去三年（2015-2017）发布的几种基于cnn的代表性目标检测方法，对pascal voc2007数据集[79]、pascal voc 2012数据集[16]和ms coco数据集[80]进行性能比较。这些方法包括fast r-cnn[18]、faster r-cnn[40]、nside-outside net(ion) [63]、g-cnn[59]、ssd[58]、yolo[57]和tolov2[60]。表5-7分别使用具有代表性的最新方法报告了pascal voc 2007、pascal voc 2012和coco数据集的检测结果。表8显示了pascal voc 2007上各种方法的准确性和速度比较。\n\n从表5-7可以看出，基于回归的cod方法，如ssd[58]和tolov2[60]，与基于对象建议的方法（如fast r-cnn[18]和faster r-cnn[40]）相比，可以获得更高的精度。ssd512[58]主要在所有三个基准（pascal voc 2007、pascal voc 2012和coco数据集）上实现了最佳精度。表8所示的计算成本比较表明，基于回归的cod方法比基于对象建议的方法快得多，具有相当的精度。其中，yolov2是最具竞争力的实时检测器，也可以以不同的分辨率运行，以方便在速度和精度之间进行权衡。表5-8中的综合比较结果表明，基于回归的方法是一个有前途的cod方向。\n\n最近，大多数检测框架，如fast r-cnn[18]、faster r-cnn[40]和ssd[58]，都依赖vggnet-16[25]作为主干cnn模型。尽管vggnet-16是一个功能强大、准确的分类网络，但它的计算成本很高。vggnet-16的卷积层需要对224 x 224像素的图像进行306.9亿次浮点运算。最近提出的yolo[57]使用基于googlenet架构的定制网络[26]来提高检测速度。yolo网络确实比基于vgg-net-16的方法更快，仅使用85.2亿次运算来完成一次正向传球，但精确度略低于vgg-net-16。为了进一步减少计算负担，同时提高精度，yolov2[60]提出了一种新的分类模型，名为darknet-19，它只需要55.8亿次操作就可以处理图像。精度和速度的综合比较结果表明，通过设计更实用的模型结构（如yolov2[60]），基于回归的方法是一种很有前途的cod方向。\n\n\n# 讨论\n\n\n# 深度学习带来的优势\n\n基于我们的分析，基于深度学习的目标检测器带来的优势可以总结为以下四个方面。\n\n# 强大的特征表示\n\n开发基于深度学习的目标检测器的最重要原因之一是在学习过程中构建的强大特征表示。这在[10]中得到了明确的证明，girshick等人使用广泛使用的hog功能及其扩展版本之一，将他们提出的基于cnn的物体检测器的cod结果与dpm[54]基线进行了比较。实验结果表明，基于cnn的目标检测器在ap方面比dpm基线的检测器高出24.2%以上。此外，girshick等人[10]从实验结果分析了所采用的cnn体系结构的不同网络层的表示能力，我们可以观察到，通过微调，较深层可以获得比较浅层更好的性能，这表明从cnn深层提取的特征表示可以有效地用于表示图像区域的信息语义。还值得一提的是，与传统的目标检测方法相比，即使是在仅使用整个网络6%参数的“pool5”层中提取的特征，也可以获得超过10%的性能增益（就ap而言）。在od和sod的研究中也可以找到类似的实验结果。例如，通过仅使用简单的cnn架构在其框架中构建功能，rpn[40]、deepproposal[17]和deepbox[2]已经可以明显优于使用传统功能表示的现有od方法。在sod中，[83]和[20]指出，如何构建真实、有意义的特征表示是sod中最关键的问题之一，他们已经证明，通过设计合理的深度网络架构，可以有效地解决这个问题。\n\n# 端到端学习\n\n基于深度学习的目标检测方法的另一个优势在于其端到端的学习框架。我们知道，传统的目标检测方法通常需要单独的计算块，例如特征提取和模式分类（例如[35]和[67]用于od[88]和[89]用于sod，以及[54]和[90]用于cod）。基于深度学习的方法（例如[17]和[36]用于od，[20]和[87]用于sod，以及[18]和[57]用于cod）仅通过一个统一的cnn模型就可以从原始输入图像中获得所需的对象检测结果。与传统方法相比，这种端到端的学习方式可以带来两个好处：\n\n * 在传统的目标检测方法中，它可以大大降低从多个候选目标到每个计算块中选择最优方法的复杂性。\n * 以这种端到端的方式学习可以根据学习目标确定整个模型的参数。\n\n与传统方法（用于设计手工制作的功能）相比，这种学习方式可以显著减少整个系统中有用信息的丢失。\n\n# 多阶段、多任务目标\n\n得益于端到端学习范式，基于深度学习的现代目标检测方法可以在多个学习阶段灵活地涉及所需的学习目标和多个学习任务。例如，在od中，fastmask[36]提出的深度网络包含语义特征提取和基于滑动窗口的建议生成的学习阶段。学习目标包括三个方面：置信度损失、分割损失和区域注意损失(confidence loss, segmentation loss,region attention loss)。在sod和legs[46]中，包含两个级联学习阶段。第一个阶段是局部估计阶段，目标是学习局部有区别的小块特征(local discriminative patch features)。第二个阶段是全局搜索阶段，目标是利用全局显著性线索之间的复杂关系。dhs[20]也有两个学习阶段，第一个阶段是显著性推理，第二个阶段是细节渲染。在cod中，faster r-cnn[40]设计有两个级联学习阶段，用于学习提取建议目标区域，并分别识别每个提取的建议对象区域的对象类别。fast r-cnn[18]采用多任务损失来同时学习特定类别的对象检测器和边界盒回归函数。与传统的目标检测方法相比，这种多阶段和多任务目标的最重要的优点是，相应的学习过程可以考虑所有设计的学习目标来确定检测网络的最优参数，而传统的方法只能通过考虑一个主要的学习目标，并在预处理或后处理阶段利用其他有用的因素来训练主要的目标检测模型。\n\n# 大规模学习和知识转移\n\n与浅层结构的学习模型相比，深度学习模型的成功主要归功于大量隐藏的神经元，这通常会产生数百万个自由参数，而浅层结构的学习模型的参数较少，以避免过度拟合。因此，dnn通常需要大规模的训练数据来实现其完整的学习能力，这使得深度模型能够从训练数据中捕获比浅层模型更丰富的模式。除了知识挖掘能力之外，深度学习模型的另一个优点是可以方便地将学习到的知识转移到相关的任务或场景中。这主要是通过使用目标域中的数据微调源域(source domain)中预训练的深层模型来实现的。例如，最具代表性的基于深度学习的cod方法[10]在图像分类任务下采用了在imagenet上预训练的cnn模型。实验结果表明，与之前的最新研究结果相比，直接使用这种网络已经可以获得明显的改善，这表明在大规模学习中捕获的模式可以强大到足以完成广泛的任务。此外，文献[10]中的实验结果表明，微调后的网络可以进一步获得显著的性能增益，这证明了深度学习模型简单而有效的知识转移能力。基于这种能力，大量现代目标检测方法[2]、[19]、[34]、[36]、[42]、[58]、[59]、[62]可以从简单但有效的预训练阶段中受益。\n\n\n# 未来研究方向\n\n尽管近年来基于深度学习的目标检测方法在这一研究领域取得了巨大的成功，但仍有一些具有挑战性但有趣的研究方向需要考虑。\n\n# 训练具有有限人类注释的目标检测器\n\n尽管最近基于深度学习的目标检测方法取得了显著的性能提升，但在实际应用中，目标检测研究领域的问题仍然在很大程度上没有得到解决，因为这些方法大多严重依赖于空前巨大的(unparalleled and tremendous)人类标记训练数据。在这种情况下，人们需要花费大量的精力和时间在繁琐的数据标注上，以训练深层目标检测器。根据我们的统计数据，我们需要花费大约15秒（在labelme等辅助工具的帮助下）来绘制一个边界框注释，该注释可以正确地包含感兴趣的对象。考虑到这一点，可能需要手动注释数十万个训练图像，并且每个图像可能包含来自不同类别的多个对象。为了缓解这个问题，弱监督目标检测方法[3]、[13]、[76]、[99]近年来受到了广泛关注。然而，所获得的性能仍然远远不能令人满意，它们只能达到相应的全监督目标检测方法所获得性能的50%。因此，仍需进一步努力解决这一问题。\n\n# 不可见对象类别的检测\n\n大多数现有的目标检测方法都是针对与训练集中的目标类别相同的图像进行评估的。然而，目标检测的最终目标是检测给定测试图像中任何可能类别的所有目标。本质上，在现实世界的应用程序中，我们对所有对象类别都缺乏足够的注释。广泛使用的pascal voc和ms coco基准仅分别包含20和80个对象类别，这远远不够。ilsvrc对象检测基准包含200个对象类别，但仍然不够。在许多类别没有边界框级注释的情况下，未来的一个方向是建立zero-shot learning-based的方案（用于目标检测），其中现有检测器和这些检测器之间的跨概念/类别映射(cross-concept/category mappings)的组合可以允许我们为看不见的种类构建对象检测器。作为sod的一个新兴分支，共现性(cosaliency)检测[92-[94]和事件显著性检测[957]方法也可能是检测未发生的对象/事件的可能方法，因为它们可以从包含共同发生但未知的对象/事件的任何给定图像/视频组中学习。\n\n# 提高检测鲁棒性的新学习策略\n\n未来的另一个方向是提高对使用不平衡数据或噪声数据训练的对象类别的检测鲁棒性。这里的不平衡问题主要是指目标检测中不同类别样本数的长尾分布(long-tailed distribution)。长尾属性表示少数目标种类经常出现，而大多数其他种类很少出现的现象。例如，在pascal voc和imagenet对象检测数据集中，对象类别（如person）的样本比其他对象类别（如sheep）的样本多得多。一些分析和实证结果表明，样本较多的对象类别将主导学习对象检测器，导致样本较少的其他对象类别学习不足。因此，针对这个问题的一个未来方向是建立新的学习方案，以便在不同的对象类别中使用更均匀分布的样本数进行学习。得益于一些最新的生成性学习模型，如生成性对抗网络（gan）。通过合成来自潜在噪声向量的可用数据，可以丰富“在尾部”的对象类别的样本。相反，大规模人工标注不可避免地会引入噪声标注，如标签缺失或错误标注。为了解决人类注释中的噪声问题，进一步的研究可以设计基于权重的学习机制（例如基于自配学习(self-paced learning)[94]、[96]和课程学习(curriculum learning)[97]、[98]的模型），当人类注释的学习的目标类别是噪声时，可以进一步提高的学习鲁棒性。\n\n# od、sod和cod的统一学习框架\n\n目前在目标检测领域的研究已经提出了一些有效的基于深度学习的框架，例如[40]和[41]，同时用于od和cod。实验结果表明，通过联合优化od和类别特定检测任务的网络参数，网络可以进一步探索这些任务之间的潜在关系，并捕获可从这两项任务中受益的常见信息模式。基本上，如前所述，od、sod和cod之间存在丰富的关系。因此，建立新的框架，尤其是基于深度学习的框架，以同时解决这三个方向上的常见问题，是非常有意义的。一种可能的方法是构建一个深度网络，将注意力建模、建议挖掘(proposal mining)和类别识别等模块结合到一个统一的学习框架中。通过这种方式，三个任务之间共享的信息方式可以被模型捕获，这可以进一步提高每个任务的性能。\n\n# 基于检测的高层视觉理解\n\n最近先进的目标检测技术的出现，促进了一些以前从未涉及过的更高层次的视觉理解任务的发展。这种任务的一个代表性例子是图像/视频字幕(image/video captioning)。此任务的基本目标是自动生成一个句子来描述任何给定图像/视频的内容。物体检测技术可以提供物体位置和类别的关键信息，用于解释图像/视频场景中的物体是什么，它们放在哪里，以及它们对交互物体做了什么。从本质上说，准确的目标检测是将视觉领域与语言领域联系起来的关键。沿着这条研究路线，仍然有许多未开发但有趣的基于检测的应用（更高级别的视觉理解任务），它们构成了未来研究方向的另一个分支。\n\n\n# 结论\n\n在本文中，我们回顾了主要基于高级深度学习技术的目标检测的最新进展。具体而言，回顾了目标检测三个方向的od、sod和cod的现代方法、基准数据集和评估指标。我们全面分析了这些方向之间的关系，对深度学习的优势进行了深入的讨论，并提出了一些未来可能的方向。\n\n\n# 致谢\n\ndingwen zhang和gong chen是本文的通讯作者。\n\n\n# 作者\n\njunweihan（junweihan2010@gmail.com）分别于1999年、2001年和2003年获得了模式识别和智能系统的学士、硕士和博士学位，均来自中国西安西北工业大学，目前担任该校教授。2003至2010年间，他是南洋理工大学、香港大学、爱尔兰都柏林城市大学和邓迪大学的研究员。他的研究兴趣包括计算机视觉和大脑成像分析。他是ieee《人机系统、神经计算、机器视觉与应用》杂志的副主编。\n\ndingwen zhang（zdw2006yyy@mail.nwpu.edu.cn）于2012年在中国西安西北工业大学获得自动化学士学位，目前正在那里攻读博士学位。自2015年10月以来，他一直是宾夕法尼亚州匹兹堡卡内基梅隆大学的访问学者。他的研究兴趣包括计算机视觉和多媒体处理。\n\ngong cheng（chenggong1119@gmail.com）于2007年在中国西安西安西安电子大学获得自动化学士学位，2010年和2013年分别在中国西安西北工业大学获得模式识别和机器智能硕士和博士学位；他目前是后者的副教授。他的主要研究兴趣是计算机视觉和目标检测。\n\nnian liu（liunian228@gmail.com）分别于2012年和2015年在中国西安西北工业大学（npu）获得自动化学士和硕士学位。他目前正在npu自动化学院攻读博士学位。他的研究兴趣包括计算机视觉，重点是显著性检测和深度学习。\n\ndong xu(dong.xu@sydney.edu.au)于2001、2005分别在合肥中国科技大学获得电子工程学士学位和博士学位。他目前是澳大利亚悉尼大学电气与信息工程学院的教授。他是ieee高级成员和国际模式识别协会研究员。\n\n\n# 参考文献\n\n[1] b. alexe, t. deselaers, and v. ferrari, “measuring the objectness of image win- dows,” ieee trans. pattern anal. machine intell., vol. 34, no. 11, pp. 2189–2202, 2012\n\n[2] w. kuo, b. hariharan, and j. malik, “deepbox: learning objectness with con- volutional networks,” in proc. ieee int. conf. computer vision, 2015, pp. 2479– 2487. [3] t. deselaers, b. alexe, and v. ferrari, “weakly supervised localization and learning with generic knowledge,” int. j. computer vision, vol. 100, no. 3, pp. 275– 293, 2012. [4] y. wu, j. lim, and m.-h. yang, “object tracking benchmark,” ieee trans. pattern anal. machine intell., vol. 37, no. 9, pp. 1834–1848, 2015. [5] t. liu, z. yuan, j. sun, j. wang, n. zheng, x. tang, and h.-y. shum, “learning to detect a salient object,” ieee trans. pattern anal. machine intell., vol. 33, no. 2, pp. 353–367, 2011. [6] m.-m. cheng, n. j. mitra, x. huang, p. h. s. torr, and s.-m. hu, “global con- trast based salient region detection,” ieee trans. pattern anal. machine intell., vol. 37, no. 3, pp. 569–582, 2015. [7] a. borji and l. itti, “state-of-the-art in visual attention modeling,” ieee trans. pattern anal. machine intell., vol. 35, no. 1, pp. 185–207, 2013. [8] x. li, t. uricchio, l. ballan, m. bertini, c. g. snoek, and a. d. bimbo, “socializing the semantic gap: a comparative survey on image tag assignment, refinement, and retrieval,” acm comput. surveys, vol. 49, no. 1, pp. 14, 2016. [9] b. hariharan, p. arbelaez, r. girshick, and j. malik, “hypercolumns for object segmentation and fine-grained localization,” in proc. ieee conf. computer vision and pattern recognition, 2015, pp. 447–456. [10] r. girshick, j. donahue, t. darrell, and j. malik, “rich feature hierarchies for accurate object detection and semantic segmentation,” in proc. ieee conf. computer vision and pattern recognition, 2014, pp. 580–587. [11] w. ouyang, x. wang, x. zeng, s. qiu, p. luo, y. tian, h. li, s. yang, z. wang, and c.-c. loy, “deepid-net: deformable deep convolutional neural networks for object detection,” in proc. ieee conf. computer vision and pattern recognition, 2015, pp. 2403–2412. [12] j. tighe, m. niethammer, and s. lazebnik, “scene parsing with object instance inference using regions and per-exemplar detectors,” int. j. computer vision, vol. 112, no. 2, pp. 150–171, 2015. [13] a. prest, c. schmid, and v. ferrari, “weakly supervised learning of interac- tions between humans and objects,” ieee trans. pattern anal. machine intell., vol. 34, no. 3, pp. 601–614, 2012. [14] y. lecun, f. j. huang, and l. bottou, “learning methods for generic object recognition with invariance to pose and lighting,” in proc. ieee conf. computer vision and pattern recognition, 2004, pp. 97–104. [15] c. szegedy, a. toshev, and d. erhan, “deep neural networks for object detec- tion,” in proc. advances in neural information processing systems, 2013, pp. 2553–2561. [16] m. everingham, s. a. eslami, l. van gool, c. k. williams, j. winn, and a. zisserman, “the pascal visual object classes challenge: a retrospective,” int. j. computer vision, vol. 111, no. 1, pp. 98–136, 2015. [17] a. ghodrati, a. diba, m. pedersoli, t. tuytelaars, and l. van gool, “deepproposal: hunting objects by cascading deep convolutional layers,” in proc. ieee int. conf. computer vision, 2015, pp. 2578–2586. [18] r. girshick, “fast r-cnn,” in proc. ieee int. conf. computer vision, 2015, pp. 1440–1448. [19] j. redmon, s. divvala, r. girshick, and a. farhadi, “you only look once: unified, real-time object detection,” arxiv preprint, arxiv:1506.02640, 2015. [20] n. liu and j. han, “dhsnet: deep hierarchical saliency network for salient object detection,” in proc. ieee conf. computer vision and pattern recognition, 2016, pp. 678–686. [21] k. fukushima, “neocognitron: a self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position,” biol. cybernet., vol. 36, no. 4, pp. 193–202, 1980. [22] y. lecun, b. boser, j. s. denker, d. henderson, r. e. howard, w. hubbard, and l. d. jackel, “backpropagation applied to handwritten zip code recognition,” neural comput., vol. 1, no. 4, pp. 541–551, 1989. [23] y. lecun, y. bengio, and g. hinton, “deep learning,” nature, vol. 521, no. 7553, pp. 436–444, 2015. [24] a. krizhevsky, i. sutskever, and g. e. hinton, “imagenet classification with deep convolutional neural networks,” in proc. advances in neural information processing systems, 2012, pp. 1097–1105. [25] k. simonyan and a. zisserman, “very deep convolutional networks for large- scale image recognition,” arxiv preprint, arxiv:1409.1556, 2014. [26] c. szegedy, w. liu, y. jia, p. sermanet, s. reed, d. anguelov, d. erhan, v. vanhoucke, and a. rabinovich, “going deeper with convolutions,” in proc. ieee conf. computer vision and pattern recognition, 2015, pp. 1–9. [27] k. he, x. zhang, s. ren, and j. sun, “deep residual learning for image recog- nition,” in proc. ieee conf. computer vision and pattern recognition, 2016, pp. 770–778. [28] j. deng, w. dong, r. socher, l.-j. li, k. li, and l. fei-fei, “imagenet: a large-scale hierarchical image database,” in proc. ieee conf. computer vision and pattern recognition, 2009, pp. 248–255. [29] j. r. uijlings, k. e. van de sande, t. gevers, and a. w. smeulders, “selective search for object recognition,” int. j. computer vision, vol. 104, no. 2, pp. 154–171, 2013. [30] p. krahenbuhl and v. koltun, “geodesic object proposals,” in proc. european conf. computer vision, 2014, pp. 725–739. [31] l. bazzani, a. bergamo, d. anguelov, and l. torresani, “self-taught object localization with deep networks,” in proc. ieee winter conf. applications of computer vision, 2016, pp. 1–9. [32] x. hou, and l. zhang, “saliency detection: a spectral residual approach,” in proc. ieee conf. computer vision and pattern recognition, 2007, pp. 1–8. [33] p. o. pinheiro, r. collobert, and p. dollar, “learning to segment object candi- dates,” in proc. advances in neural information processing systems, 2015, pp. 1990–1998. [34] p. o. pinheiro, t.-y. lin, r. collobert, and p. dollar, “learning to refine object segments,” in proc. european conf. computer vision, 2016, pp. 75–91. [35] c. l. zitnick, and p. dollar, “edge boxes: locating object proposals from edges,” in proc. european conf. computer vision, 2014, pp. 391–405. [36] h. hu, s. lan, y. jiang, z. cao, and f. sha, “fastmask: segment multi-scale object candidates in one shot,” arxiv preprint, arxiv:1612.08843, 2016. [37] d. erhan, c. szegedy, a. toshev, and d. anguelov, “scalable object detection using deep neural networks,” in proc. ieee conf. computer vision and pattern recognition, 2014, pp. 2147–2154. [38] c. szegedy, s. reed, d. erhan, d. anguelov, and s. ioffe, “scalable, high- quality object detection,” arxiv preprint, arxiv:1412.1441, 2014. [39] c. szegedy, v. vanhoucke, s. ioffe, j. shlens, and z. wojna, “rethinking the inception architecture for computer vision,” in proc. ieee conf. computer vision and pattern recognition, 2016, pp. 2818–2826. [40] s. ren, k. he, r. girshick, and j. sun, “faster r-cnn: towards real-time object detection with region proposal networks,” in proc. advances in neural information processing systems, 2015, pp. 91–99. [41] t. kong, a. yao, y. chen, and f. sun, “hypernet: towards accurate region proposal generation and joint object detection,” in proc. ieee conf. computer vision and pattern recognition, 2016, pp. 845–853. [42] h. li, y. liu, w. ouyang, and x. wang, “zoom out-and-in network with recur- sive training for object proposal,” arxiv preprint, arxiv:1702.05711, 2017. [43] a. borji, m.-m. cheng, h. jiang, and j. li, “salient object detection: a sur- vey,” arxiv preprint, arxiv:1411.5878, 2014. [44] a. borji, h. r. tavakoli, d. n. sihite, and l. itti, “analysis of scores, data sets, and models in visual saliency prediction,” in proc. ieee int. conf. computer vision, 2013, pp. 921–928. [45] j. han, d. zhang, x. hu, l. guo, j. ren, and f. wu, “background prior-based salient object detection via deep reconstruction residual,” ieee trans. circuits systems video technol., vol. 25, no. 8, pp. 1309–1321, 2015. [46] l. wang, h. lu, x. ruan, and m.-h. yang, “deep networks for saliency detec- tion via local estimation and global search,” in proc. ieee conf. computer vision and pattern recognition, 2015, pp. 3183–3192. [47] g. lee, y.-w. tai, and j. kim, “deep saliency with encoded low level distance map and high level features,” in proc. ieee conf. computer vision and pattern recognition, 2016, pp. 660-668. [48] g. li, and y. yu, “deep contrast learning for salient object detection,” in proc. ieee conf. computer vision and pattern recognition, 2016, pp. 660–668.\n\n[49] l. wang, l. wang, h. lu, p. zhang, and x. ruan, “saliency detection with recurrent fully convolutional networks,” in proc. european conf. computer vision, 2016, pp. 825–841. [50] j. yang, and m.-h. yang, “top-down visual saliency via joint crf and diction- ary learning,” in proc. ieee conf. computer vision and pattern recognition, 2012, pp. 2296–2303. [51] s. he, r. w. lau, and q. yang, “exemplar-driven top-down saliency detection via deep association,” in proc. ieee conf. computer vision and pattern recognition, 2016, pp. 5723–5732. [52] h. cholakkal, j. johnson, and d. rajan, “backtracking scspm image classifier for weakly supervised top-down saliency,” in proc. ieee conf. computer vision and pattern recognition, 2016, pp. 5278–5287. [53] j. zhang, z. lin, j. brandt, x. shen, and s. sclaroff, “top-down neural atten- tion by excitation backprop,” in proc. european conf. computer vision, 2016, pp. 543–559. [54] p. f. felzenszwalb, r. b. girshick, d. mcallester, and d. ramanan, “object detection with discriminatively trained part-based models,” ieee trans. pattern anal. machine intell., vol. 32, no. 9, pp. 1627–1645, 2010. [55] k. he, x. zhang, s. ren, and j. sun, “spatial pyramid pooling in deep convo- lutional networks for visual recognition,” ieee trans. pattern anal. machine intell., vol. 37, no. 9, pp. 1904–1916, 2015. [56] p. sermanet, d. eigen, x. zhang, m. mathieu, r. fergus, and y. lecun, “overfeat: integrated recognition, localization and detection using convolutional net- works,” arxiv preprint, arxiv:1312.6229, 2013. [57] j. redmon, s. divvala, r. girshick, and a. farhadi, “you only look once: unified, real-time object detection,” in proc. ieee conf. computer vision and pattern recognition, 2016, pp. 779–788. [58] w. liu, d. anguelov, d. erhan, c. szegedy, s. reed, c.-y. fu, and a. c. berg, “ssd: single shot multibox detector,” in proc. european conf. computer vision, 2016, pp. 21–37. [59] m. najibi, m. rastegari, and l. s. davis, “g-cnn: an iterative grid based object detector,” in proc. ieee conf. computer vision and pattern recognition, 2016, pp. 2369–2377. [60] j. redmon and a. farhadi, “yolo9000: better, faster, stronger,” arxiv preprint, arxiv:1612.08242, 2016. [61] a. shrivastava, a. gupta, and r. girshick, “training region-based object detectors with online hard example mining,” in proc. ieee conf. computer vision and pattern recognition, 2016, pp. 761–769. [62] g. cheng, p. zhou, and j. han, “rifd-cnn: rotation-invariant and fisher dis- criminative convolutional neural networks for object detection,” in proc. ieee conf. computer vision and pattern recognition, 2016, pp. 2884–2893. [63] s. bell, c. lawrence zitnick, k. bala, and r. girshick, “inside-outside net: detecting objects in context with skip pooling and recurrent neural networks,” in proc. ieee conf. computer vision and pattern recognition, 2016, pp. 2874– 2883. [64] s. gidaris, and n. komodakis, “object detection via a multi-region and seman- tic segmentation-aware cnn model,” in proc. ieee int. conf. computer vision, 2015, pp. 1134–1142. [65] a. shrivastava, and a. gupta, “contextual priming and feedback for faster r-cnn,” in proc. european conf. computer vision, 2016, pp. 330–348. [66] j. feng, y. wei, l. tao, c. zhang, and j. sun, “salient object detection by composition,” in proc. ieee int. conf. computer vision, 2011, pp. 1028–1035. [67] m.-m. cheng, z. zhang, w.-y. lin, and p. torr, “bing: binarized normed gradients for objectness estimation at 300fps,” in proc. ieee conf. computer vision and pattern recognition, 2014, pp. 3286–3293. [68] k.-y. chang, t.-l. liu, h.-t. chen, and s.-h. lai, “fusing generic objectness and visual saliency for salient object detection,” in proc. ieee int. conf. computer vision, 2011, pp. 914–921. [69] p. jiang, h. ling, j. yu, and j. peng, “salient region detection by ufo: uniqueness, focusness and objectness,” in proc. ieee int. conf. computer vision, 2013, pp. 1976–1983. [70] y. li, x. hou, c. koch, j. m. rehg, and a. l. yuille, “the secrets of salient object segmentation,” in proc. ieee conf. computer vision and pattern recognition, 2014, pp. 280–287. [71] t. malisiewicz, a. gupta, and a. a. efros, “ensemble of exemplar-svms for object detection and beyond,” in proc. ieee int. conf. computer vision, 2011, pp. 89–96. [72] m. bar, “the proactive brain: using analogies and associations to generate pre- dictions,” trends cogn. sci., vol. 11, no. 7, pp. 280–289, 2007. [73] r. m. nosofsky, “attention, similarity, and the identification–categorization relationship,” j. exp. psychol., vol. 115, no. 1, pp. 39, 1986. [74] a. borji, “boosting bottom-up and top-down visual features for saliency esti- mation,” in proc. ieee conf. computer vision and pattern recognition, 2012, pp. 438–445. [75] t. judd, k. ehinger, f. durand, and a. torralba, “learning to predict where humans look,” in proc. ieee int. conf. computer vision, 2009, pp. 2106–2113. [76] d. zhang, d. meng, l. zhao, and j. han, “bridging saliency detection to weak- ly supervised object detection based on self-paced curriculum learning,” in proc. int. joint conf. artificial intelligence, 2016, pp. 3538–3544. [77] b. zhou, a. khosla, a. lapedriza, a. oliva, and a. torralba, “learning deep features for discriminative localization,” in proc. ieee conf. computer vision and pattern recognition, 2016, pp. 2921–2929. [78] m. everingham, l. van gool, c. k. williams, j. winn, and a. zisserman, “the pascal visual object classes (voc) challenge,” int. j. computer vision, vol. 88, no. 2, pp. 303–338, 2010. [79] m. everingham, a. zisserman, c. k. williams, l. van gool, m. allan, c. m. bishop, o. chapelle, n. dalal, t. deselaers, and g. dorko, “the pascal visual object classes challenge 2007 (voc2007) results,” 2007. [online]. available: http:// host.robots.ox.ac.uk/pascal/voc/voc2007/workshop/index.html [80] t.-y. lin, m. maire, s. belongie, j. hays, p. perona, d. ramanan, p. dollar, and c. l. zitnick, “microsoft coco: common objects in context,” in proc. european conf. computer vision, 2014, pp. 740–755. [81] q. yan, l. xu, j. shi, and j. jia, “hierarchical saliency detection,” in proc. ieee conf. computer vision and pattern recognition, 2013, pp. 1155–1162. [82] v. movahedi and j. h. elder, “design and perceptual validation of perfor- mance measures for salient object segmentation,” in proc. ieee computer society conf. computer vision and pattern recognition workshops, 2010, pp. 49–56. [83] g. li and y. yu, “visual saliency based on multiscale deep features,” in proc. ieee conf. computer vision and pattern recognition, 2015, pp. 5455–5463. [84] c. yang, l. zhang, h. lu, x. ruan, and m.-h. yang, “saliency detection via graph-based manifold ranking,” in proc. ieee conf. computer vision and pattern recognition, 2013, pp. 3166–3173. [85] m.-m. cheng, n. j. mitra, x. huang, and s.-m. hu, “salientshape: group saliency in image collections,” visual computer, vol. 30, no. 4, pp. 443–453, 2014. [86] j. pont-tuset, p. arbelaez, j. t. barron, f. marques, and j. malik, “multiscale combinatorial grouping for image segmentation and object proposal generation,” ieee trans. pattern anal. machine intell., vol. 39, no. 1, pp. 128– 140, 2017. [87] r. zhao, w. ouyang, h. li, and x. wang, “saliency detection by multi-context deep learning,” in proc. ieee conf. computer vision and pattern recognition, 2015, pp. 1265–1274. [88] h. jiang, j. wang, z. yuan, y. wu, n. zheng, and s. li, “salient object detec- tion: a discriminative regional feature integration approach,” in proc. ieee conf. computer vision and pattern recognition, 2013, pp. 2083–2090. [89] p. mehrani and o. veksler, “saliency segmentation based on learning and graph cut refinement,” in proc. british machine vision conf., 2010, pp. 1–12. [90] p. dollar, r. appel, s. belongie, and p. perona, “fast feature pyramids for object detection,” ieee trans. pattern anal. machine intell., vol. 36, no. 8, pp. 1532–1545, 2014. [91] q. hou, m.-m. cheng, x. hu, z. tu, and a. borji, “deeply supervised salient object detection with short connections,” in proc. ieee conf. computer vision and pattern recognition, 2017, pp. 3203–3212. [92] d. zhang, j. han, j. han, and l. shao, “cosaliency detection based on intrasa- liency prior transfer and deep intersaliency mining,” ieee trans. neural networks learning syst., vol. 27, no. 6, pp. 1163–1176, 2016. [93] d. zhang, j. han, c. li, j. wang, and x. li, “detection of co-salient objects by looking deep and wide,” int. j. computer vision, vol. 120, no. 2, pp. 215–232, 2016. [94] d. zhang, d. meng, and j. han, “co-saliency detection via a self-paced multi- ple-instance learning framework,” ieee trans. pattern anal. machine intell., vol. 39, no. 5, pp. 865–878, 2017. [95] d. zhang, j. han, l. jiang, s. ye, and x. chang, “revealing event saliency in unconstrained video collection,” ieee trans. image processing, vol. 26, no. 4, pp. 1746–1758, 2017. [96] d. zhang, l. yang, d. meng, d. xu, and j. han, “spftn: a self-paced fine- tuning network for segmenting objects in weakly labelled videos,” in proc. ieee conf. computer vision and pattern recognition, 2017, pp. 4429–4437. [97] d. zhang, j. han, y. yang, and d. huang, “learning category-specific 3d shape models from weakly labeled 2d images,” in proc. ieee conf. computer vision and pattern recognition, 2017, pp. 4573–4581. [98] y. bengio, j. louradour, r. collobert, and j. weston, “curriculum learning,” in proc. annu. int. conf. machine learning, 2009, pp. 41–48. [99] y. yuan, x. liang, x. wang, d.-y. yeung, and a. gupta, “temporal dynamic graph lstm for action-driven video object detection,” arxiv preprint, arxiv:1708.00666, 2017.",charsets:{cjk:!0},lastUpdated:"2022/02/25, 10:57:13",lastUpdatedTimestamp:1645757833e3},{title:"test",frontmatter:{title:"test",date:"2022-02-10T14:53:34.000Z",permalink:"/pages/fd6171/",categories:["其它","论文","综述"],tags:[null]},regularPath:"/05.%E5%85%B6%E5%AE%83/01.%E8%AE%BA%E6%96%87/01.%E7%BB%BC%E8%BF%B0/10.test.html",relativePath:"05.其它/01.论文/01.综述/10.test.md",key:"v-5e8fbe84",path:"/pages/fd6171/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/02/25, 10:57:13",lastUpdatedTimestamp:1645757833e3},{title:"CV论文期刊介绍",frontmatter:{title:"CV论文期刊介绍",date:"2022-02-27T13:10:59.000Z",permalink:"/pages/c03dcc/",categories:["其它","论文"],tags:[null]},regularPath:"/05.%E5%85%B6%E5%AE%83/01.%E8%AE%BA%E6%96%87/10.CV%E8%AE%BA%E6%96%87%E6%9C%9F%E5%88%8A%E4%BB%8B%E7%BB%8D.html",relativePath:"05.其它/01.论文/10.CV论文期刊介绍.md",key:"v-c8c0c076",path:"/pages/c03dcc/",headers:[{level:2,title:"arXiv",slug:"arxiv",normalizedTitle:"arxiv",charIndex:2},{level:3,title:"简史",slug:"简史",normalizedTitle:"简史",charIndex:237},{level:3,title:"影响",slug:"影响",normalizedTitle:"影响",charIndex:841},{level:3,title:"同行评审",slug:"同行评审",normalizedTitle:"同行评审",charIndex:949},{level:3,title:"投稿格式",slug:"投稿格式",normalizedTitle:"投稿格式",charIndex:1447},{level:3,title:"国内访问",slug:"国内访问",normalizedTitle:"国内访问",charIndex:1615},{level:3,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:1822},{level:2,title:"DBLP",slug:"dblp",normalizedTitle:"dblp",charIndex:2026},{level:3,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2157},{level:3,title:"特征",slug:"特征",normalizedTitle:"特征",charIndex:2301},{level:3,title:"搜索",slug:"搜索",normalizedTitle:"搜索",charIndex:2602},{level:2,title:"IEEE",slug:"ieee",normalizedTitle:"ieee",charIndex:2983},{level:3,title:"Journal Bibliometrics",slug:"journal-bibliometrics",normalizedTitle:"journal bibliometrics",charIndex:2992},{level:3,title:"IEEE期刊排名",slug:"ieee期刊排名",normalizedTitle:"ieee期刊排名",charIndex:3814},{level:3,title:"视频教学",slug:"视频教学",normalizedTitle:"视频教学",charIndex:3888},{level:2,title:"TPAMI",slug:"tpami",normalizedTitle:"tpami",charIndex:3925},{level:3,title:"目标和范围",slug:"目标和范围",normalizedTitle:"目标和范围",charIndex:4177},{level:3,title:"Journal Bibliometrics",slug:"journal-bibliometrics-2",normalizedTitle:"journal bibliometrics",charIndex:2992},{level:3,title:"出版详情",slug:"出版详情",normalizedTitle:"出版详情",charIndex:4376},{level:2,title:"IJCV",slug:"ijcv",normalizedTitle:"ijcv",charIndex:4824},{level:3,title:"目标和范围",slug:"目标和范围-2",normalizedTitle:"目标和范围",charIndex:4177},{level:3,title:"Journal Bibliometrics",slug:"journal-bibliometrics-3",normalizedTitle:"journal bibliometrics",charIndex:2992},{level:2,title:"IEEE Transactions on Multimedia(TMM)",slug:"ieee-transactions-on-multimedia-tmm",normalizedTitle:"ieee transactions on multimedia(tmm)",charIndex:6109},{level:3,title:"目标和范围",slug:"目标和范围-3",normalizedTitle:"目标和范围",charIndex:4177},{level:3,title:"Journal Bibliometrics",slug:"journal-bibliometrics-4",normalizedTitle:"journal bibliometrics",charIndex:2992},{level:2,title:"IEEE Transactions on Neural Networks and Learning Systems(TNN)",slug:"ieee-transactions-on-neural-networks-and-learning-systems-tnn",normalizedTitle:"ieee transactions on neural networks and learning systems(tnn)",charIndex:6387},{level:3,title:"目标和范围",slug:"目标和范围-4",normalizedTitle:"目标和范围",charIndex:4177},{level:3,title:"Journal Bibliometrics",slug:"journal-bibliometrics-5",normalizedTitle:"journal bibliometrics",charIndex:2992},{level:2,title:"IEEE Transactions on Image Processing(TIP)",slug:"ieee-transactions-on-image-processing-tip",normalizedTitle:"ieee transactions on image processing(tip)",charIndex:6700},{level:3,title:"目标和范围",slug:"目标和范围-5",normalizedTitle:"目标和范围",charIndex:4177},{level:3,title:"Journal Bibliometrics",slug:"journal-bibliometrics-6",normalizedTitle:"journal bibliometrics",charIndex:2992},{level:2,title:"Pattern Recognition",slug:"pattern-recognition",normalizedTitle:"pattern recognition",charIndex:7075},{level:3,title:"目标和范围",slug:"目标和范围-6",normalizedTitle:"目标和范围",charIndex:4177},{level:3,title:"对作者的好处",slug:"对作者的好处",normalizedTitle:"对作者的好处",charIndex:7596},{level:3,title:"Journal Bibliometrics",slug:"journal-bibliometrics-7",normalizedTitle:"journal bibliometrics",charIndex:2992}],headersStr:"arXiv 简史 影响 同行评审 投稿格式 国内访问 总结 DBLP 简介 特征 搜索 IEEE Journal Bibliometrics IEEE期刊排名 视频教学 TPAMI 目标和范围 Journal Bibliometrics 出版详情 IJCV 目标和范围 Journal Bibliometrics IEEE Transactions on Multimedia(TMM) 目标和范围 Journal Bibliometrics IEEE Transactions on Neural Networks and Learning Systems(TNN) 目标和范围 Journal Bibliometrics IEEE Transactions on Image Processing(TIP) 目标和范围 Journal Bibliometrics Pattern Recognition 目标和范围 对作者的好处 Journal Bibliometrics",content:'# arXiv\n\narXiv.org e-Print archive\n\narXiv - 维基百科，自由的百科全书 (wikipedia.org)\n\narXiv（X依希腊文的χ发音，读音如英语的archive）是一个收集物理学、数学、计算机科学、生物学与数理经济学的论文预印本的网站，始于1991年8月14日。截至2008年10月，arXiv.org已收集超过50万篇预印本；至2014年底，藏量达到1百万篇。截至2016年10月，提交率已达每月超过10,000篇。\n\n\n# 简史\n\n紧凑的TeX文件格式使arXiv成为可能，该格式使科学论文可以轻松地通过互联网传输并呈现给客户端。在1990年左右，乔安妮·科恩开始通过TeX文件通过电子邮件将物理预印本发送给同事，但很快发送的论文数量多的充满了邮箱。 保罗·金斯巴格意识到了中央存储的必要性，并于1991年8月创建了一个中央仓库邮箱，该邮箱存储在洛斯阿拉莫斯国家实验室中，可以从任何计算机上进行访问。很快又增加了其他访问方式：1991年使用FTP，1992年使用Gopher，1993年使用万维网。网上印刷一词很快被用来描述这些文章。\n\narXiv最早是由物理学家保罗·金斯巴格在1991年建立的网站，本意在收集物理学的论文预印本，随后括及天文、数学等其它领域。金斯巴格因这个网站获得了2002年的麦克阿瑟奖。\n\narXiv原先挂在洛斯阿拉莫斯国家实验室(LANL)，是故早期被称为“LANL预印本数据库”。2001年arXiv落脚于康乃尔大学，并在全球各地设有镜像站点。网站在1999年改名为arXiv.org。\n\n2011年9月，康奈尔大学图书馆全面负责arXiv的运营和发展。 金斯巴格在《高等教育纪事报》中被引用说“这原应该是一个3小时的旅程，而不是一个无期徒刑”。 但是，金斯巴格仍然留在arXiv的科学顾问委员会（页面存档备份，存于互联网档案馆）和arXiv物理顾问委员会（页面存档备份，存于互联网档案馆）中。\n\n\n# 影响\n\narXiv的存在是造就科学出版业中所谓开放获取运动的因素之一。现今的一些数学家及科学家习惯先将其论文上传至arXiv.org，再提交予专业的学术期刊。这个趋势对传统学术期刊的经营模式造成了可观的冲击\n\n\n# 同行评审\n\n尽管arXiv上的文章未经同行评审，但在2004年起采行了一套“认可”系统。在这套系统下，作者首先要得到认可，这种认可可能来自另一位具认可资格者的背书，或者依照某些内部规定而自动授予。来自著名学术机关的作者通常会自动得到认可。包括诺贝尔物理奖得主布赖恩·约瑟夫森在内的十九位科学家曾抗议他们的部分文章被arXiv管理者退回，而其它文章则被强迫更改分类，依其见解，原因出在研究主题的争议性，或者是文章抵触了弦理论的正统观点。\n\n由于arXiv上的文章多半都会投稿到学术期刊，作者对文章多半保持严谨态度。少部分文章则一直保持预印本的形式，其中包括一些极具影响力的作品，例如格里戈里·佩雷尔曼对庞加莱猜想的证明。佩雷尔曼似乎放弃了传统的同行评审期刊程序，并指出：“如果有人对我解决问题的方式感兴趣，它就在[arXiv]上——让他们继续阅读。”。 尽管采用了这种非传统的出版方法，其他数学家还是认可了这项工作，向佩雷尔曼提供了菲尔兹奖和克雷数学千年奖，但他都拒绝。\n\narXiv上的民间科学家作品为数不多，通常被归入诸如“一般数学”（General Mathematics）等项下。\n\n\n# 投稿格式\n\n可以以多种格式中的任何一种投稿论文，包括LaTeX和通过TeX或LaTeX以外的文字处理器打印的PDF。 如果生成最终PDF文件失败，任何图像文件太大或提交的总大小太大，则arXiv软件会拒绝投稿。 现在，arXiv允许存储和修改不完整的投稿，并且仅在准备好后才能最终确定投稿。 完成投稿后，时间戳将被设置文章上。\n\n\n# 国内访问\n\n国内访问arxiv的方法\n\n国内访问arxiv的方法 将前缀修改成国内镜像前缀\n\n推荐使用中科院的 arxiv 镜像: http://xxx.itp.ac.cn\n\n访问方法：\n\n将 arxiv.org 替换成 xxx.itp.ac.cn\n\n例如：\n\nhttps://arxiv.org/abs/1901.07249 改为 http://xxx.itp.ac.cn/abs/1901.07249\n\n\n# 总结\n\n什么是arXiv？\n\narXiv是一个免费的分发服务和开放存取的档案库，可以存放物理学、数学、计算机科学、定量生物学、定量金融学、统计学、电气工程和系统科学以及经济学等领域的2000301篇学术文章。这个网站上的资料没有经过arXiv的同行评审。\n\n为了防止自己的idea在论文被收录前被别人剽窃，将预稿上传到arvix作为预收录，因此是一个可以证明论文原创性（上传时间戳）的文档收录网站。\n\n\n# DBLP\n\ndblp: computer science bibliography\n\nDBLP（DataBase systems and Logic Programming）是计算机领域内对研究的成果以作者为核心的一个计算机类英文文献的集成数据库系统。\n\n\n# 简介\n\n按年代列出了作者的科研成果。包括国际期刊和会议等公开发表的论文。DBLP没有提供对中文文献的收录和检索功能，国内的权威期刊及重要会议的论文缺乏一个类似的集成检索系统。DBLP所收录的期刊和会议论文质量较高，DBLP的文献更新速度很快，很好地反应了国外学术研究的前沿方向。\n\n\n# 特征\n\n计算机科学文献库DBLP Computer Science Bibliography在学术界有很好的声誉，给人们带来了极大的便利，其权威性也得到了研究界的高度认可。但DBLP没有提供对中文文献的收录和检索功能，国内的权威期刊及重要会议的论文缺乏一个类似的集成检索系统。 DBLP原来的意思是数据库系统。不过现在随着这个词语的使用增多，它已经逐步的延伸到其他的计算机的其他方面，目前的意思应该是 Digital Bibliography & Library Project数字书目索引与图书馆项目的缩写。 这个项目是德国特里尔大学的Michael Ley负责开发和维护。它提供计算机领域科学文献的搜索服务，但只储存这些文献的相关元数据，如标题，作者，发表日期等。截至2009年7月已经有超过1,200,000文献。和一般流行的情况不同，DBLP并没有使用数据库而是使用XML存储元数据。\n\n\n# 搜索\n\ndblp: Search for "" (uni-trier.de)\n\n * 不区分大小写的前缀搜索：默认值\n   * sig 匹配 "SIGIR" 和 "signal"\n * 精确单词搜索：在单词后面加上美元符号（$）\n   * [graph) 匹配"graph",而不是 "graphics"\n * 布尔and：按空格分隔单词\n   * [codd model](https://dblp.uni-trier.de/search/?q=codd model)\n * 布尔or：通过管道符号（|）连接单词\n   * graph|network\n\n\n# IEEE\n\n\n# Journal Bibliometrics\n\n期刊文献计量学\n\n期刊引文报告（Journal Citation Reports,JCR）和CiteScore指标为期刊排名、评估、分类和比较提供了量化(quantitative)工具。这些指标包括影响因子(Impact Factor)、特征因子分数(Eigenfactor Score)、文章影响分数(Article Influence Score)和引用分数指标CiteScore metrics（如适用）。这些指标检查学术研究期刊的影响和作用。\n\n在IEEE XPLORE的期刊文献计量领域显示的值是基于2021年7月出版的2020 report中的Calalyveta Analytics期刊引用报告。CiteScore metrics显示的值来自2021年6月发布的SCOPUS 2020报告。\n\n# Impact Factor\n\n影响因子是过去两年发表的期刊文章在JCR年被引用的平均次数。影响因素是一种所谓的受欢迎程度度量，它依赖于引用的粗略数量，每个引用的数量与来源的质量无关。\n\n# Eigenfactor Score\n\n特征因子分数考虑了过去五年发表在期刊上的文章在JCR年被引用的次数，同时还考虑了哪些期刊提供了这些引用。由于在这种情况下，引用的权重取决于来源，因此特征因子得分属于所谓的声望度量。特征因子得分代表在整个收藏中阅读特定期刊的概率，因此高得分期刊在科学界具有更大的影响力。\n\n# Article Influence Score\n\n文章影响力分数也是一种声望指标，具有特征因子分数的所有特征，并对发表论文的数量进行了额外的标准化。因此，它可以被认为是期刊文章在发表后前五年的平均影响力。\n\n# CiteScore\n\nCiteScore是反映期刊最近发表文章的年平均引用次数的指标。该计算基于Scopus数据库中记录的引用，使用了过去四年发表的文章的引用。\n\n\n# IEEE期刊排名\n\nIEEE - IEEE Journals Continue to Excel in Citation Rankings\n\n\n# 视频教学\n\nVideo Tutorials (ieee.org)\n\n\n# TPAMI\n\nIEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)\n\nIEEE Xplore: IEEE Transactions on Pattern Analysis and Machine Intelligence\n\ndblp: IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) (uni-trier.de)\n\n\n# 目标和范围\n\nIEEE模式分析和机器智能学报发表了关于计算机视觉和图像理解的所有传统领域、模式分析和识别的所有传统领域以及机器智能的选定领域的文章，特别强调用于模式分析的机器学习。本课程还涵盖了视觉搜索、文档和笔迹分析、医学图像分析、视频和图像序列分析、基于内容的图像和视频检索、人脸和手势识别技术以及相关的专用硬件和/或软件架构。\n\n\n# Journal Bibliometrics\n\n\n\n\n# 出版详情\n\n# 出版政策\n\n本出版物考虑了增强现有知识体系的原创作品。即使没有提供新的数据/概念，原始评论文章和调查也是可以接受的。文章中描述的结果不应在其他地方提交或发表。可以提交会议出版物的扩展版本。文章必须易于理解，并且必须以标准英语书写。\n\n同行评审：同行评审对于已发表研究的质量至关重要。提交给 IEEE 的每篇文章都由至少两名由该出版物编辑委员会成员选出的独立审稿人进行评估。 了解有关 IEEE 同行评审流程的更多信息。\n\n出版费：本出版物由订阅和适用的文章处理费 (APC) 提供支持。尽管通过 IEEE 出版是免费的，但作者可能希望利用我们的一些收费产品；有关可用选项的更多信息，请访问 IEEE 作者中心 。\n\n已发表文章中的错误：在已发表文章中发现错误的作者应联系上面显示的主编，要求发表更正。请注意，原始文章在 IEEE Xplore上发表后不得更改 。将考虑讨论本出版物中文章的评论文章。原始文章的作者将有机会回复评论。通过页面顶部的提交手稿提交您的评论文章。\n\n\n# IJCV\n\nInternational Journal of Computer Vision\n\nInternational Journal of Computer Vision | Home (springer.com)\n\ndblp: International Journal of Computer Vision (uni-trier.de)\n\n----------------------------------------\n\n国际计算机视觉杂志 (IJCV) 详细介绍了这一快速发展领域的科学和工程。定期文章介绍了具有广泛普遍兴趣的重大技术进步。调查文章提供对相关主题的最新技术和/或教程演示的批判性评论。\n\n覆盖范围包括：\n\n- 计算机视觉的数学、物理和计算方面：图像形成、处理、分析和解释；机器学习技术；统计方法；传感器。\n\n- 应用：基于图像的渲染、计算机图形学、机器人技术、照片解释、图像检索、视频分析和注释、多媒体等。\n\n- 与人类感知的联系：人类视觉的计算和建筑方面。\n\n该杂志还收录了书评、立场文件、主要科学人物的社论，以及其他在线材料，例如静止图像、视频序列、数据集和软件。\n\n * 详细介绍快速发展的计算机视觉领域的科学和工程\n * 介绍具有广泛普遍兴趣的重大技术进步\n * 为新颖的研究成果提供快速的发表途径\n * 提供对最新技术和/或相关主题的教程演示的批判性评论\n * 92% 回答调查的作者表示他们肯定会或可能再次在该期刊上发表文章\n\n\n# 目标和范围\n\n国际计算机视觉杂志(IJCV) 为在快速发展的计算机视觉领域传播新研究成果提供了一个论坛。现在每年出版 15 期，国际计算机视觉杂志为这个快速发展的领域的科学和工程提供了高质量的原创贡献。\n\n· 定期文章（最多 25 页期刊）介绍具有广泛普遍兴趣的重大技术进步。\n\n· 短篇文章（最多 10 页）为新颖的研究成果提供了快速的发表途径。\n\n· 调查文章（最多 30 页）提供对最新技术和/或相关主题的教程演示的批判性评论。\n\n· 主要科学人物的书评、立场文件和社论将不时补充期刊的技术内容。\n\n· 鼓励使用附加的在线材料，例如静止图像和视频序列、数据集和软件。\n\n论文应涵盖：\n\n· 计算机视觉的数学、物理和计算方面：图像形成、处理、分析和解释；机器学习技术；统计方法；传感器。\n\n· 应用：基于图像的渲染、计算机图形学、机器人学、照片解释、图像检索、视频分析和注释、多媒体、医学、人机交互、监控。\n\n· 与人类感知的联系：人类视觉的计算和建筑方面。\n\n编辑政策\n\n· IJCV 不收取版面费。\n\n· 论文在印刷出版之前在线出版。\n\n· 欢迎对立场文件作出回应。\n\n· 社论、立场文件及其回应将免费在线提供。\n\n· IJCV 拥有自由的版权政策。\n\n计算机视觉、机器人和人工智能领域的学术和工业研究人员，以及对计算机与人类视觉之间的联系感兴趣的心理学家和神经科学家，将发现 IJCV 是该领域取得重要成果的重要论坛。\n\n\n# Journal Bibliometrics\n\n\n\n\n# IEEE Transactions on Multimedia(TMM)\n\nIEEE Transactions on Multimedia | About Journal | IEEE Xplore\n\ndblp: IEEE Transactions on Multimedia\n\n\n# 目标和范围\n\nIEEE Transactions on Multimedia的范围是多媒体技术和多媒体应用研究的各个方面，包括但不限于电路、网络、信号处理、系统、软件和系统集成，如赞助商感兴趣的领域所示。\n\n\n# Journal Bibliometrics\n\n\n\n\n# IEEE Transactions on Neural Networks and Learning Systems(TNN)\n\nIEEE Xplore: IEEE Transactions on Image Processing\n\n[dblp: IEEE Transactions on Neural Networks and Learning Systems]\n\n\n# 目标和范围\n\nIEEE Transactions on Neural Networks and Learning Systems发表技术文章，涉及神经网络和相关学习系统的理论、设计和应用。\n\n\n# Journal Bibliometrics\n\n\n\n\n# IEEE Transactions on Image Processing(TIP)\n\nIEEE Xplore: IEEE Transactions on Image Processing\n\ndblp: IEEE Transactions on Image Processing\n\n\n# 目标和范围\n\nIEEE Transactions on Image Processing涵盖了各种应用中的图像、视频和多维信号的形成、捕获、处理、通信、分析和显示的新理论、算法和体系结构。感兴趣的主题包括但不限于数学、统计和感知建模、表示、形成、编码、滤波、增强、恢复、渲染、半色调、搜索和分析图像、视频和多维信号。感兴趣的应用包括图像和视频通信、电子成像、生物医学成像、图像和视频系统以及遥感。\n\n\n# Journal Bibliometrics\n\n\n\n\n# Pattern Recognition\n\nPattern Recognition - Journal - Elsevier\n\ndblp: Pattern Recognition\n\n\n# 目标和范围\n\n模式识别是一个成熟但令人兴奋且发展迅速的领域，它为计算机视觉、图像处理、文本和文档分析以及神经网络等同源领域的发展奠定了基础。它与机器学习非常相似，在生物特征识别、生物信息学、多媒体数据分析和最近的数据科学等新兴领域也有应用。《模式识别》杂志建立于大约50年前，当时该领域出现在计算机科学的早期。在其间的几年里，它已经大幅扩张。\n\n该杂志接受对任何领域的模式识别理论、方法和应用做出独创性贡献的论文，前提是该工作的背景得到明确解释，并以模式识别文献为基础。主要关注模式识别领域之外的论文，以及使用现有或众所周知的方法报告it常规应用的论文，应该转移到其他地方。出版政策是出版（1）经有能力的科学人士适当审查的新原创文章，（2）对该领域发展的审查，以及（3）涵盖模式识别特定领域的教学论文。将不时组织各种专题，讨论模式识别领域感兴趣的当前主题。提交的论文应为单列、双倍行距、不少于20页且不超过35页（40页用于综述），并带有编号页。\n\n\n# 对作者的好处\n\n我们还提供许多作者利益，例如免费 PDF、自由的版权政策、Elsevier 出版物的特别折扣等等。请点击这里了解更多关于我们的信息作者服务.\n\n请参阅我们的作者指南有关文章提交的信息。如果您需要任何进一步的信息或帮助，请访问我们的支持中心\n\n\n# Journal Bibliometrics\n\n',normalizedContent:'# arxiv\n\narxiv.org e-print archive\n\narxiv - 维基百科，自由的百科全书 (wikipedia.org)\n\narxiv（x依希腊文的χ发音，读音如英语的archive）是一个收集物理学、数学、计算机科学、生物学与数理经济学的论文预印本的网站，始于1991年8月14日。截至2008年10月，arxiv.org已收集超过50万篇预印本；至2014年底，藏量达到1百万篇。截至2016年10月，提交率已达每月超过10,000篇。\n\n\n# 简史\n\n紧凑的tex文件格式使arxiv成为可能，该格式使科学论文可以轻松地通过互联网传输并呈现给客户端。在1990年左右，乔安妮·科恩开始通过tex文件通过电子邮件将物理预印本发送给同事，但很快发送的论文数量多的充满了邮箱。 保罗·金斯巴格意识到了中央存储的必要性，并于1991年8月创建了一个中央仓库邮箱，该邮箱存储在洛斯阿拉莫斯国家实验室中，可以从任何计算机上进行访问。很快又增加了其他访问方式：1991年使用ftp，1992年使用gopher，1993年使用万维网。网上印刷一词很快被用来描述这些文章。\n\narxiv最早是由物理学家保罗·金斯巴格在1991年建立的网站，本意在收集物理学的论文预印本，随后括及天文、数学等其它领域。金斯巴格因这个网站获得了2002年的麦克阿瑟奖。\n\narxiv原先挂在洛斯阿拉莫斯国家实验室(lanl)，是故早期被称为“lanl预印本数据库”。2001年arxiv落脚于康乃尔大学，并在全球各地设有镜像站点。网站在1999年改名为arxiv.org。\n\n2011年9月，康奈尔大学图书馆全面负责arxiv的运营和发展。 金斯巴格在《高等教育纪事报》中被引用说“这原应该是一个3小时的旅程，而不是一个无期徒刑”。 但是，金斯巴格仍然留在arxiv的科学顾问委员会（页面存档备份，存于互联网档案馆）和arxiv物理顾问委员会（页面存档备份，存于互联网档案馆）中。\n\n\n# 影响\n\narxiv的存在是造就科学出版业中所谓开放获取运动的因素之一。现今的一些数学家及科学家习惯先将其论文上传至arxiv.org，再提交予专业的学术期刊。这个趋势对传统学术期刊的经营模式造成了可观的冲击\n\n\n# 同行评审\n\n尽管arxiv上的文章未经同行评审，但在2004年起采行了一套“认可”系统。在这套系统下，作者首先要得到认可，这种认可可能来自另一位具认可资格者的背书，或者依照某些内部规定而自动授予。来自著名学术机关的作者通常会自动得到认可。包括诺贝尔物理奖得主布赖恩·约瑟夫森在内的十九位科学家曾抗议他们的部分文章被arxiv管理者退回，而其它文章则被强迫更改分类，依其见解，原因出在研究主题的争议性，或者是文章抵触了弦理论的正统观点。\n\n由于arxiv上的文章多半都会投稿到学术期刊，作者对文章多半保持严谨态度。少部分文章则一直保持预印本的形式，其中包括一些极具影响力的作品，例如格里戈里·佩雷尔曼对庞加莱猜想的证明。佩雷尔曼似乎放弃了传统的同行评审期刊程序，并指出：“如果有人对我解决问题的方式感兴趣，它就在[arxiv]上——让他们继续阅读。”。 尽管采用了这种非传统的出版方法，其他数学家还是认可了这项工作，向佩雷尔曼提供了菲尔兹奖和克雷数学千年奖，但他都拒绝。\n\narxiv上的民间科学家作品为数不多，通常被归入诸如“一般数学”（general mathematics）等项下。\n\n\n# 投稿格式\n\n可以以多种格式中的任何一种投稿论文，包括latex和通过tex或latex以外的文字处理器打印的pdf。 如果生成最终pdf文件失败，任何图像文件太大或提交的总大小太大，则arxiv软件会拒绝投稿。 现在，arxiv允许存储和修改不完整的投稿，并且仅在准备好后才能最终确定投稿。 完成投稿后，时间戳将被设置文章上。\n\n\n# 国内访问\n\n国内访问arxiv的方法\n\n国内访问arxiv的方法 将前缀修改成国内镜像前缀\n\n推荐使用中科院的 arxiv 镜像: http://xxx.itp.ac.cn\n\n访问方法：\n\n将 arxiv.org 替换成 xxx.itp.ac.cn\n\n例如：\n\nhttps://arxiv.org/abs/1901.07249 改为 http://xxx.itp.ac.cn/abs/1901.07249\n\n\n# 总结\n\n什么是arxiv？\n\narxiv是一个免费的分发服务和开放存取的档案库，可以存放物理学、数学、计算机科学、定量生物学、定量金融学、统计学、电气工程和系统科学以及经济学等领域的2000301篇学术文章。这个网站上的资料没有经过arxiv的同行评审。\n\n为了防止自己的idea在论文被收录前被别人剽窃，将预稿上传到arvix作为预收录，因此是一个可以证明论文原创性（上传时间戳）的文档收录网站。\n\n\n# dblp\n\ndblp: computer science bibliography\n\ndblp（database systems and logic programming）是计算机领域内对研究的成果以作者为核心的一个计算机类英文文献的集成数据库系统。\n\n\n# 简介\n\n按年代列出了作者的科研成果。包括国际期刊和会议等公开发表的论文。dblp没有提供对中文文献的收录和检索功能，国内的权威期刊及重要会议的论文缺乏一个类似的集成检索系统。dblp所收录的期刊和会议论文质量较高，dblp的文献更新速度很快，很好地反应了国外学术研究的前沿方向。\n\n\n# 特征\n\n计算机科学文献库dblp computer science bibliography在学术界有很好的声誉，给人们带来了极大的便利，其权威性也得到了研究界的高度认可。但dblp没有提供对中文文献的收录和检索功能，国内的权威期刊及重要会议的论文缺乏一个类似的集成检索系统。 dblp原来的意思是数据库系统。不过现在随着这个词语的使用增多，它已经逐步的延伸到其他的计算机的其他方面，目前的意思应该是 digital bibliography & library project数字书目索引与图书馆项目的缩写。 这个项目是德国特里尔大学的michael ley负责开发和维护。它提供计算机领域科学文献的搜索服务，但只储存这些文献的相关元数据，如标题，作者，发表日期等。截至2009年7月已经有超过1,200,000文献。和一般流行的情况不同，dblp并没有使用数据库而是使用xml存储元数据。\n\n\n# 搜索\n\ndblp: search for "" (uni-trier.de)\n\n * 不区分大小写的前缀搜索：默认值\n   * sig 匹配 "sigir" 和 "signal"\n * 精确单词搜索：在单词后面加上美元符号（$）\n   * [graph) 匹配"graph",而不是 "graphics"\n * 布尔and：按空格分隔单词\n   * [codd model](https://dblp.uni-trier.de/search/?q=codd model)\n * 布尔or：通过管道符号（|）连接单词\n   * graph|network\n\n\n# ieee\n\n\n# journal bibliometrics\n\n期刊文献计量学\n\n期刊引文报告（journal citation reports,jcr）和citescore指标为期刊排名、评估、分类和比较提供了量化(quantitative)工具。这些指标包括影响因子(impact factor)、特征因子分数(eigenfactor score)、文章影响分数(article influence score)和引用分数指标citescore metrics（如适用）。这些指标检查学术研究期刊的影响和作用。\n\n在ieee xplore的期刊文献计量领域显示的值是基于2021年7月出版的2020 report中的calalyveta analytics期刊引用报告。citescore metrics显示的值来自2021年6月发布的scopus 2020报告。\n\n# impact factor\n\n影响因子是过去两年发表的期刊文章在jcr年被引用的平均次数。影响因素是一种所谓的受欢迎程度度量，它依赖于引用的粗略数量，每个引用的数量与来源的质量无关。\n\n# eigenfactor score\n\n特征因子分数考虑了过去五年发表在期刊上的文章在jcr年被引用的次数，同时还考虑了哪些期刊提供了这些引用。由于在这种情况下，引用的权重取决于来源，因此特征因子得分属于所谓的声望度量。特征因子得分代表在整个收藏中阅读特定期刊的概率，因此高得分期刊在科学界具有更大的影响力。\n\n# article influence score\n\n文章影响力分数也是一种声望指标，具有特征因子分数的所有特征，并对发表论文的数量进行了额外的标准化。因此，它可以被认为是期刊文章在发表后前五年的平均影响力。\n\n# citescore\n\ncitescore是反映期刊最近发表文章的年平均引用次数的指标。该计算基于scopus数据库中记录的引用，使用了过去四年发表的文章的引用。\n\n\n# ieee期刊排名\n\nieee - ieee journals continue to excel in citation rankings\n\n\n# 视频教学\n\nvideo tutorials (ieee.org)\n\n\n# tpami\n\nieee transactions on pattern analysis and machine intelligence (tpami)\n\nieee xplore: ieee transactions on pattern analysis and machine intelligence\n\ndblp: ieee transactions on pattern analysis and machine intelligence (tpami) (uni-trier.de)\n\n\n# 目标和范围\n\nieee模式分析和机器智能学报发表了关于计算机视觉和图像理解的所有传统领域、模式分析和识别的所有传统领域以及机器智能的选定领域的文章，特别强调用于模式分析的机器学习。本课程还涵盖了视觉搜索、文档和笔迹分析、医学图像分析、视频和图像序列分析、基于内容的图像和视频检索、人脸和手势识别技术以及相关的专用硬件和/或软件架构。\n\n\n# journal bibliometrics\n\n\n\n\n# 出版详情\n\n# 出版政策\n\n本出版物考虑了增强现有知识体系的原创作品。即使没有提供新的数据/概念，原始评论文章和调查也是可以接受的。文章中描述的结果不应在其他地方提交或发表。可以提交会议出版物的扩展版本。文章必须易于理解，并且必须以标准英语书写。\n\n同行评审：同行评审对于已发表研究的质量至关重要。提交给 ieee 的每篇文章都由至少两名由该出版物编辑委员会成员选出的独立审稿人进行评估。 了解有关 ieee 同行评审流程的更多信息。\n\n出版费：本出版物由订阅和适用的文章处理费 (apc) 提供支持。尽管通过 ieee 出版是免费的，但作者可能希望利用我们的一些收费产品；有关可用选项的更多信息，请访问 ieee 作者中心 。\n\n已发表文章中的错误：在已发表文章中发现错误的作者应联系上面显示的主编，要求发表更正。请注意，原始文章在 ieee xplore上发表后不得更改 。将考虑讨论本出版物中文章的评论文章。原始文章的作者将有机会回复评论。通过页面顶部的提交手稿提交您的评论文章。\n\n\n# ijcv\n\ninternational journal of computer vision\n\ninternational journal of computer vision | home (springer.com)\n\ndblp: international journal of computer vision (uni-trier.de)\n\n----------------------------------------\n\n国际计算机视觉杂志 (ijcv) 详细介绍了这一快速发展领域的科学和工程。定期文章介绍了具有广泛普遍兴趣的重大技术进步。调查文章提供对相关主题的最新技术和/或教程演示的批判性评论。\n\n覆盖范围包括：\n\n- 计算机视觉的数学、物理和计算方面：图像形成、处理、分析和解释；机器学习技术；统计方法；传感器。\n\n- 应用：基于图像的渲染、计算机图形学、机器人技术、照片解释、图像检索、视频分析和注释、多媒体等。\n\n- 与人类感知的联系：人类视觉的计算和建筑方面。\n\n该杂志还收录了书评、立场文件、主要科学人物的社论，以及其他在线材料，例如静止图像、视频序列、数据集和软件。\n\n * 详细介绍快速发展的计算机视觉领域的科学和工程\n * 介绍具有广泛普遍兴趣的重大技术进步\n * 为新颖的研究成果提供快速的发表途径\n * 提供对最新技术和/或相关主题的教程演示的批判性评论\n * 92% 回答调查的作者表示他们肯定会或可能再次在该期刊上发表文章\n\n\n# 目标和范围\n\n国际计算机视觉杂志(ijcv) 为在快速发展的计算机视觉领域传播新研究成果提供了一个论坛。现在每年出版 15 期，国际计算机视觉杂志为这个快速发展的领域的科学和工程提供了高质量的原创贡献。\n\n· 定期文章（最多 25 页期刊）介绍具有广泛普遍兴趣的重大技术进步。\n\n· 短篇文章（最多 10 页）为新颖的研究成果提供了快速的发表途径。\n\n· 调查文章（最多 30 页）提供对最新技术和/或相关主题的教程演示的批判性评论。\n\n· 主要科学人物的书评、立场文件和社论将不时补充期刊的技术内容。\n\n· 鼓励使用附加的在线材料，例如静止图像和视频序列、数据集和软件。\n\n论文应涵盖：\n\n· 计算机视觉的数学、物理和计算方面：图像形成、处理、分析和解释；机器学习技术；统计方法；传感器。\n\n· 应用：基于图像的渲染、计算机图形学、机器人学、照片解释、图像检索、视频分析和注释、多媒体、医学、人机交互、监控。\n\n· 与人类感知的联系：人类视觉的计算和建筑方面。\n\n编辑政策\n\n· ijcv 不收取版面费。\n\n· 论文在印刷出版之前在线出版。\n\n· 欢迎对立场文件作出回应。\n\n· 社论、立场文件及其回应将免费在线提供。\n\n· ijcv 拥有自由的版权政策。\n\n计算机视觉、机器人和人工智能领域的学术和工业研究人员，以及对计算机与人类视觉之间的联系感兴趣的心理学家和神经科学家，将发现 ijcv 是该领域取得重要成果的重要论坛。\n\n\n# journal bibliometrics\n\n\n\n\n# ieee transactions on multimedia(tmm)\n\nieee transactions on multimedia | about journal | ieee xplore\n\ndblp: ieee transactions on multimedia\n\n\n# 目标和范围\n\nieee transactions on multimedia的范围是多媒体技术和多媒体应用研究的各个方面，包括但不限于电路、网络、信号处理、系统、软件和系统集成，如赞助商感兴趣的领域所示。\n\n\n# journal bibliometrics\n\n\n\n\n# ieee transactions on neural networks and learning systems(tnn)\n\nieee xplore: ieee transactions on image processing\n\n[dblp: ieee transactions on neural networks and learning systems]\n\n\n# 目标和范围\n\nieee transactions on neural networks and learning systems发表技术文章，涉及神经网络和相关学习系统的理论、设计和应用。\n\n\n# journal bibliometrics\n\n\n\n\n# ieee transactions on image processing(tip)\n\nieee xplore: ieee transactions on image processing\n\ndblp: ieee transactions on image processing\n\n\n# 目标和范围\n\nieee transactions on image processing涵盖了各种应用中的图像、视频和多维信号的形成、捕获、处理、通信、分析和显示的新理论、算法和体系结构。感兴趣的主题包括但不限于数学、统计和感知建模、表示、形成、编码、滤波、增强、恢复、渲染、半色调、搜索和分析图像、视频和多维信号。感兴趣的应用包括图像和视频通信、电子成像、生物医学成像、图像和视频系统以及遥感。\n\n\n# journal bibliometrics\n\n\n\n\n# pattern recognition\n\npattern recognition - journal - elsevier\n\ndblp: pattern recognition\n\n\n# 目标和范围\n\n模式识别是一个成熟但令人兴奋且发展迅速的领域，它为计算机视觉、图像处理、文本和文档分析以及神经网络等同源领域的发展奠定了基础。它与机器学习非常相似，在生物特征识别、生物信息学、多媒体数据分析和最近的数据科学等新兴领域也有应用。《模式识别》杂志建立于大约50年前，当时该领域出现在计算机科学的早期。在其间的几年里，它已经大幅扩张。\n\n该杂志接受对任何领域的模式识别理论、方法和应用做出独创性贡献的论文，前提是该工作的背景得到明确解释，并以模式识别文献为基础。主要关注模式识别领域之外的论文，以及使用现有或众所周知的方法报告it常规应用的论文，应该转移到其他地方。出版政策是出版（1）经有能力的科学人士适当审查的新原创文章，（2）对该领域发展的审查，以及（3）涵盖模式识别特定领域的教学论文。将不时组织各种专题，讨论模式识别领域感兴趣的当前主题。提交的论文应为单列、双倍行距、不少于20页且不超过35页（40页用于综述），并带有编号页。\n\n\n# 对作者的好处\n\n我们还提供许多作者利益，例如免费 pdf、自由的版权政策、elsevier 出版物的特别折扣等等。请点击这里了解更多关于我们的信息作者服务.\n\n请参阅我们的作者指南有关文章提交的信息。如果您需要任何进一步的信息或帮助，请访问我们的支持中心\n\n\n# journal bibliometrics\n\n',charsets:{cjk:!0},lastUpdated:"2022/02/28, 21:54:29",lastUpdatedTimestamp:1646056469e3},{title:"什么是自底向上自上而下的显著性目标检测",frontmatter:{title:"什么是自底向上自上而下的显著性目标检测",date:"2022-02-10T17:37:39.000Z",permalink:"/pages/cd64f7/",categories:["其它","碎片"],tags:[null]},regularPath:"/05.%E5%85%B6%E5%AE%83/10.%E7%A2%8E%E7%89%87/01.%E4%BB%80%E4%B9%88%E6%98%AF%E8%87%AA%E5%BA%95%E5%90%91%E4%B8%8A%E8%87%AA%E4%B8%8A%E8%80%8C%E4%B8%8B%E7%9A%84%E6%98%BE%E8%91%97%E6%80%A7%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B.html",relativePath:"05.其它/10.碎片/01.什么是自底向上自上而下的显著性目标检测.md",key:"v-78ffd976",path:"/pages/cd64f7/",headers:[{level:2,title:"1.自底向上的注意机制",slug:"_1-自底向上的注意机制",normalizedTitle:"1.自底向上的注意机制",charIndex:73},{level:2,title:"2.自上而下的注意机制",slug:"_2-自上而下的注意机制",normalizedTitle:"2.自上而下的注意机制",charIndex:288}],headersStr:"1.自底向上的注意机制 2.自上而下的注意机制",content:"什么是自底向上/自上而下的显著性目标检测？\n\n在图像处理领域，显著性检测可以被分成两种注意机制：自底向上的注意机制、自上而下的注意机制。\n\n\n# 1.自底向上的注意机制\n\n这种检测方法由数据驱动，它可以理解为：仅受数据驱动，由此将人的视点指导到场景中的显著区域。比如在一群黑羊中有一只白羊，自底向上的注意机制的任务便是把这只白羊找出来。也就是说，通常与周围有较强对比度或与周围有明显不同的区域吸引自底向上注意机制的注意。\n\n再举个例子：\n\n\n\n上面这两幅图中，左图红色条与周围明显不同，为左图的显著性区域；右图中第四列竖着的红色条与周围明显不同，为右图的显著性区域。\n\n\n# 2.自上而下的注意机制\n\n这种注意机制由任务驱动，即由人的意识来指导。也就是说，它是在人的意识控制下对图像进行注意。比如在监视器视图中(如下图)，虽然高大的建筑更加与众不同、显眼，但是我们想要注意的是人，所以算法的目的不是找最显眼的目标，而是专注于实现“找人”这一任务。这种注意机制就是自上而下的注意机制。\n\n\n\n需要注意的是：计算机视觉领域主要做的是从下而上的视觉显著性，而从上而下的视觉显著性由于对人的大脑结构作用不够了解，无法深刻的揭示作用原理，在计算机视觉领域的研究也相应很少。",normalizedContent:"什么是自底向上/自上而下的显著性目标检测？\n\n在图像处理领域，显著性检测可以被分成两种注意机制：自底向上的注意机制、自上而下的注意机制。\n\n\n# 1.自底向上的注意机制\n\n这种检测方法由数据驱动，它可以理解为：仅受数据驱动，由此将人的视点指导到场景中的显著区域。比如在一群黑羊中有一只白羊，自底向上的注意机制的任务便是把这只白羊找出来。也就是说，通常与周围有较强对比度或与周围有明显不同的区域吸引自底向上注意机制的注意。\n\n再举个例子：\n\n\n\n上面这两幅图中，左图红色条与周围明显不同，为左图的显著性区域；右图中第四列竖着的红色条与周围明显不同，为右图的显著性区域。\n\n\n# 2.自上而下的注意机制\n\n这种注意机制由任务驱动，即由人的意识来指导。也就是说，它是在人的意识控制下对图像进行注意。比如在监视器视图中(如下图)，虽然高大的建筑更加与众不同、显眼，但是我们想要注意的是人，所以算法的目的不是找最显眼的目标，而是专注于实现“找人”这一任务。这种注意机制就是自上而下的注意机制。\n\n\n\n需要注意的是：计算机视觉领域主要做的是从下而上的视觉显著性，而从上而下的视觉显著性由于对人的大脑结构作用不够了解，无法深刻的揭示作用原理，在计算机视觉领域的研究也相应很少。",charsets:{cjk:!0},lastUpdated:"2022/02/25, 10:57:13",lastUpdatedTimestamp:1645757833e3},{title:"归档",frontmatter:{archivesPage:!0,title:"归档",permalink:"/archives/",article:!1},regularPath:"/@pages/archivesPage.html",relativePath:"@pages/archivesPage.md",key:"v-53104ef6",path:"/archives/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/01/21, 02:04:02",lastUpdatedTimestamp:1642701842e3},{title:"分类",frontmatter:{categoriesPage:!0,title:"分类",permalink:"/categories/",article:!1},regularPath:"/@pages/categoriesPage.html",relativePath:"@pages/categoriesPage.md",key:"v-1a9d53e5",path:"/categories/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/01/21, 02:04:02",lastUpdatedTimestamp:1642701842e3},{title:"标签",frontmatter:{tagsPage:!0,title:"标签",permalink:"/tags/",article:!1},regularPath:"/@pages/tagsPage.html",relativePath:"@pages/tagsPage.md",key:"v-150b83f6",path:"/tags/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/01/21, 02:04:02",lastUpdatedTimestamp:1642701842e3},{title:"你知道的越多，不知道的也就越多",frontmatter:{title:"你知道的越多，不知道的也就越多",date:"2020-05-06T15:52:40.000Z",permalink:"/pages/f2e63f",sidebar:"auto",categories:["随笔"],tags:["学习","知识","鸡汤"],author:{name:"xugaoyi",link:"https://github.com/xugaoyi"}},regularPath:"/_posts/%E9%9A%8F%E7%AC%94/%E4%BD%A0%E7%9F%A5%E9%81%93%E7%9A%84%E8%B6%8A%E5%A4%9A%EF%BC%8C%E4%B8%8D%E7%9F%A5%E9%81%93%E7%9A%84%E4%B9%9F%E5%B0%B1%E8%B6%8A%E5%A4%9A.html",relativePath:"_posts/随笔/你知道的越多，不知道的也就越多.md",key:"v-95c08fd2",path:"/pages/f2e63f/",excerpt:"<p>不知道大家有没有发现，我们身边经常有这样的人，他们越是有能力的，越是有知识的，越是低调，越是谦逊，因为他们深知，知道的越多，不知道的也就越多。</p>\n",headersStr:null,content:"不知道大家有没有发现，我们身边经常有这样的人，他们越是有能力的，越是有知识的，越是低调，越是谦逊，因为他们深知，知道的越多，不知道的也就越多。\n\n你知道的越多，你不知道的也就越多，这是一句非常有哲理的话。\n\n每个人的知识面都是有限的，你有可能在某个领域会有较深的研究，成为这个领域里的专家，等到你站在高处的时候，才会发现，自己是多么的渺小，才知道自己有多少没有涉及的领域。知道的越多，疑惑、问题就会越来越多，对已知的质疑、疑虑、困惑就会越来越多。\n\n即使如此，我们也应该努力，至少可以成为某个领域的佼佼者。\n\n鸡汤1\n\n弱小的人，才习惯嘲讽与否定，而内心强大的人，从不吝啬赞美与鼓励。\n\n鸡汤2\n\n当代青年人都应该摆脱冷气，只管向上走，不必听从自暴自弃者的流言。能做事的做事，能发声的发声。有一份热，发一份光，就像萤火一般，也可以在黑暗里发一点光，不必等候炬火。",normalizedContent:"不知道大家有没有发现，我们身边经常有这样的人，他们越是有能力的，越是有知识的，越是低调，越是谦逊，因为他们深知，知道的越多，不知道的也就越多。\n\n你知道的越多，你不知道的也就越多，这是一句非常有哲理的话。\n\n每个人的知识面都是有限的，你有可能在某个领域会有较深的研究，成为这个领域里的专家，等到你站在高处的时候，才会发现，自己是多么的渺小，才知道自己有多少没有涉及的领域。知道的越多，疑惑、问题就会越来越多，对已知的质疑、疑虑、困惑就会越来越多。\n\n即使如此，我们也应该努力，至少可以成为某个领域的佼佼者。\n\n鸡汤1\n\n弱小的人，才习惯嘲讽与否定，而内心强大的人，从不吝啬赞美与鼓励。\n\n鸡汤2\n\n当代青年人都应该摆脱冷气，只管向上走，不必听从自暴自弃者的流言。能做事的做事，能发声的发声。有一份热，发一份光，就像萤火一般，也可以在黑暗里发一点光，不必等候炬火。",charsets:{cjk:!0},lastUpdated:"2022/01/21, 02:04:02",lastUpdatedTimestamp:1642701842e3},{title:"拥抱生活，拥抱快乐",frontmatter:{title:"拥抱生活，拥抱快乐",date:"2020-06-26T20:40:38.000Z",permalink:"/pages/cd8bde/",sidebar:"auto",categories:["随笔"],tags:["鸡汤"],author:{name:"xugaoyi",link:"https://github.com/xugaoyi"}},regularPath:"/_posts/%E9%9A%8F%E7%AC%94/%E6%8B%A5%E6%8A%B1%E7%94%9F%E6%B4%BB%EF%BC%8C%E6%8B%A5%E6%8A%B1%E5%BF%AB%E4%B9%90.html",relativePath:"_posts/随笔/拥抱生活，拥抱快乐.md",key:"v-77761d97",path:"/pages/cd8bde/",excerpt:"<p>生活在后现代的今天，很多人都有一种虚无感，认为人生没有意义。但是，人生不可能没有意义，因为当你认为没有意义的时候，一定有一个与之相对应的概念叫有意义。</p>\n",headersStr:null,content:"生活在后现代的今天，很多人都有一种虚无感，认为人生没有意义。但是，人生不可能没有意义，因为当你认为没有意义的时候，一定有一个与之相对应的概念叫有意义。\n\n当你怀疑人生没有意义时，难道怀疑本身不值得怀疑吗？\n\n不要任由你内心的虚无感蔓延，我们需要去拥抱真实的生活。\n\n所有真实的快乐，都离不开艰辛的努力，无论是金榜题名的快乐，还是事业成功的喜悦，甚至包括洞房花烛的激动。所有真实的快乐，都需要长久的铺垫与努力，没有辛勤的汗水，快乐也就不再真实。\n\n如果快乐触手可及，这种廉价的快乐也就不值得珍惜，随时都可能抛弃。因此，对于年轻人而言，一个重要的功课就是学会去节制欲望。\n\n所有通过捷径所带来的快乐，都是廉价的，以至于所有追求都变得毫无意义，人生就了无生趣。我们需要在每天真实的努力中去拥抱生活，追寻真实的快乐。\n\n\n\n> 文章摘录自:B站视频《罗翔说刑法》，链接https://b23.tv/K8ulrE",normalizedContent:"生活在后现代的今天，很多人都有一种虚无感，认为人生没有意义。但是，人生不可能没有意义，因为当你认为没有意义的时候，一定有一个与之相对应的概念叫有意义。\n\n当你怀疑人生没有意义时，难道怀疑本身不值得怀疑吗？\n\n不要任由你内心的虚无感蔓延，我们需要去拥抱真实的生活。\n\n所有真实的快乐，都离不开艰辛的努力，无论是金榜题名的快乐，还是事业成功的喜悦，甚至包括洞房花烛的激动。所有真实的快乐，都需要长久的铺垫与努力，没有辛勤的汗水，快乐也就不再真实。\n\n如果快乐触手可及，这种廉价的快乐也就不值得珍惜，随时都可能抛弃。因此，对于年轻人而言，一个重要的功课就是学会去节制欲望。\n\n所有通过捷径所带来的快乐，都是廉价的，以至于所有追求都变得毫无意义，人生就了无生趣。我们需要在每天真实的努力中去拥抱生活，追寻真实的快乐。\n\n\n\n> 文章摘录自:b站视频《罗翔说刑法》，链接https://b23.tv/k8ulre",charsets:{cjk:!0},lastUpdated:"2022/01/21, 02:04:02",lastUpdatedTimestamp:1642701842e3},{title:"Home",frontmatter:{home:!0,heroText:"O2's blog",tagline:"纸上得来终觉浅，绝知此事要躬行",bannerBg:"/img/AI.jpg",features:[{title:"理论",details:"万丈高楼平地起",link:"/web/",imgUrl:"/img/book.png"},{title:"实践",details:"Talk is cheap. Show me the code.",link:"/ui/",imgUrl:"/img/code.png"},{title:"废话",details:"摆会儿龙门阵",link:"/technology/",imgUrl:"/img/chat.png"}]},regularPath:"/",relativePath:"index.md",key:"v-a113e2c4",path:"/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/01/23, 01:27:52",lastUpdatedTimestamp:1642872472e3}],themeConfig:{nav:[{text:"首页",link:"/"},{text:"理论",link:"/theory/",items:[{text:"前端文章",items:[{text:"JavaScript",link:"/pages/8143cc480faf9a11/"}]},{text:"学习笔记",items:[{text:"《JavaScript教程》",link:"/note/javascript/"},{text:"《JavaScript高级程序设计》",link:"/note/js/"},{text:"《ES6 教程》",link:"/note/es6/"},{text:"《Vue》",link:"/note/vue/"},{text:"《React》",link:"/note/react/"},{text:"《TypeScript 从零实现 axios》",link:"/note/typescript-axios/"},{text:"《Git》",link:"/note/git/"},{text:"TypeScript",link:"/pages/51afd6/"},{text:"JS设计模式总结",link:"/pages/4643cd/"}]}]},{text:"实践",link:"/practice/",items:[{text:"动手学深度学习",link:"/pages/baed3f/"},{text:"GitHub",link:"/pages/4b2e49/"},{text:"Linux",link:"/pages/9c32e1/"}]},{text:"硬件",link:"/hardware/"},{text:"软件",link:"/software/"},{text:"其它",link:"/other/",items:[{text:"论文",link:"/pages/e22df7/"},{text:"碎片",link:"/pages/ffedf7/"}]},{text:"随笔",link:"/write/"},{text:"关于",link:"/about/"}],sidebarDepth:2,logo:"/img/logo.png",repo:"https://github.com/YQisme/blog",searchMaxSuggestions:10,lastUpdated:"上次更新",docsDir:"docs",editLinks:!0,editLinkText:"编辑",bodyBgImg:["/img/bg.png"],sidebar:{"/00.目录页/":[["01.理论.md","理论","/theory"],["02.实践.md","实践","/practice"],["03.硬件.md","硬件","/hardware"],["04.软件.md","软件","/software"],["05.其它.md","其它","/other"],["06.随笔.md","随笔","/write"],["07.关于.md","关于","/about"],{title:"实践",collapsable:!0,children:[["09.实践/01.动手学深度学习.md","动手学深度学习","/pages/baed3f/"],["09.实践/10.github.md","Github","/pages/4b2e49/"],["09.实践/20.Linux.md","Github","/pages/9c32e1/"]]},{title:"其他",collapsable:!0,children:[["12.其他/01.论文.md","论文","/pages/e22df7/"],["12.其他/10.碎片.md","碎片","/pages/ffedf7/"]]}],catalogue:{"理论":"/theory","实践":"/practice","硬件":"/hardware","软件":"/software","其它":"/other","随笔":"/write","关于":"/about","动手学深度学习":"/pages/baed3f/",github:"/pages/4b2e49/",Linux:"/pages/9c32e1/","论文":"/pages/e22df7/","碎片":"/pages/ffedf7/"},"/01.理论/":[{title:"深度学习",collapsable:!0,children:[{title:"动手学深度学习",collapsable:!0,children:[["02.深度学习/01.动手学深度学习/01.Dive into Deep Learning.md","Dive into Deep Learning","/pages/bcceec/"],["02.深度学习/01.动手学深度学习/02.222.md",222,"/pages/6ca4c7/"]]}]},["10.index.md","拥抱生活，拥抱快乐","/pages/aef4fc1/"],{title:"第2级",collapsable:!0,children:[{title:"第3级",collapsable:!0,children:[["20.第2级/01.第3级/02.4.md","第4级","/pages/3c32a32/"]]},["20.第2级/02.3.md","拥抱生活，拥抱快乐","/pages/3c32a31/"]]}],"/02.实践/":[{title:"动手学深度学习",collapsable:!0,children:[["01.动手学深度学习/01.课程安排.md","课程安排","/pages/def99f/"],["01.动手学深度学习/02.基础.md","基础","/pages/3245f5/"],["01.动手学深度学习/03.线性代数.md","线性代数","/pages/4fa3d9/"],["01.动手学深度学习/100.blog_test.md","blog_test","/pages/b0b256/"]]},{title:"Github",collapsable:!0,children:[{title:"快速入门",collapsable:!0,children:[["10.Github/01.快速入门/01.Hello World.md","Hello World","/pages/7c03e3/"],["10.Github/01.快速入门/02.设置Git.md","设置Git","/pages/018bc3/"]]}]},{title:"Linux",collapsable:!0,children:[["20.Linux/01.简介和安装.md","简介和安装","/pages/35e538/"]]}],"/04.软件/":[["01.Mobaxterm.md","Mobaxterm","/pages/2d796d/"],["10.Everything.md","Everything","/pages/aa7af1/"]],"/05.其它/":[{title:"论文",collapsable:!0,children:[{title:"综述",collapsable:!0,children:[["01.论文/01.综述/01.用于显著和特定类别的目标检测的先进的深度学习技术.md","用于显著和特定类别的目标检测的先进深度学习技术","/pages/24a19d/"],["01.论文/01.综述/10.test.md","test","/pages/fd6171/"]]},["01.论文/10.CV论文期刊介绍.md","CV论文期刊介绍","/pages/c03dcc/"]]},{title:"碎片",collapsable:!0,children:[["10.碎片/01.什么是自底向上自上而下的显著性目标检测.md","什么是自底向上自上而下的显著性目标检测","/pages/cd64f7/"]]}]},author:{name:"YangQi",link:"https://github.com/YQisme"},blogger:{avatar:"/img/IronMan.png",name:"O2",slogan:"地球人"},social:{icons:[{iconClass:"icon-youjian",title:"发邮件",link:"mailto:yangqi7isme@163.com"},{iconClass:"icon-github",title:"GitHub",link:"https://github.com/YQisme"},{iconClass:"icon-weixin",title:"微信",link:"/img/wechat.jpg"}]},footer:{createYear:2022,copyrightInfo:'YangQi | <a href="https://github.com/xugaoyi/vuepress-theme-vdoing/blob/master/LICENSE" target="_blank">MIT License</a>'},htmlModules:{homeSidebarB:'<div style="padding: 0.95rem">\n    <p style="\n      color: var(--textColor);\n      opacity: 0.9;\n      font-size: 20px;\n      font-weight: bold;\n      margin: 0 0 8px 0;\n    ">公众号</p>\n    <img src="https://cdn.jsdelivr.net/gh/xugaoyi/image_store@master/blog/扫码_搜索联合传播样式-标准色版.1wp8gd1mhjhc.jpg"  style="width:100%;" />\n    <p>\n    有趣研究社，这里有<a href="https://game.xugaoyi.com" arget="_blank" > FC在线模拟器(小霸王) <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，还有更多好玩的等着你去探索~\n    </br></br>\n    关注公众号，回复[<b>前端资源</b>]，可获取 <a href="https://game.xugaoyi.com" arget="_blank" >前端学习资源<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>\n    </p>\n    </div>'}},locales:{"/":{lang:"zh-CN",title:"O2's blog",description:"随便写写",path:"/"}}},cc=(t(155),t(212),t(143),t(222)),lc=t(223),uc=(t(374),t(236),t(44));var pc={computed:{$filterPosts:function(){return this.$site.pages.filter((function(n){var e=n.frontmatter,t=e.pageComponent,r=e.article,o=e.home;return!(t||!1===r||!0===o)}))},$sortPosts:function(){return(n=this.$filterPosts).sort((function(n,e){var t=n.frontmatter.sticky,r=e.frontmatter.sticky;return t&&r?t==r?Object(uc.a)(n,e):t-r:t&&!r?-1:!t&&r?1:Object(uc.a)(n,e)})),n;var n},$sortPostsByDate:function(){return(n=this.$filterPosts).sort((function(n,e){return Object(uc.a)(n,e)})),n;var n},$groupPosts:function(){return function(n){for(var e={},t={},r=function(r,o){var i=n[r].frontmatter,a=i.categories,s=i.tags;"array"===Object(uc.n)(a)&&a.forEach((function(t){t&&(e[t]||(e[t]=[]),e[t].push(n[r]))})),"array"===Object(uc.n)(s)&&s.forEach((function(e){e&&(t[e]||(t[e]=[]),t[e].push(n[r]))}))},o=0,i=n.length;o<i;o++)r(o);return{categories:e,tags:t}}(this.$sortPosts)},$categoriesAndTags:function(){return function(n){var e=[],t=[];for(var r in n.categories)e.push({key:r,length:n.categories[r].length});for(var o in n.tags)t.push({key:o,length:n.tags[o].length});return{categories:e,tags:t}}(this.$groupPosts)}}};Do.component(cc.default),Do.component(lc.default);function dc(n){return n.toString().padStart(2,"0")}t(378);Do.component("Badge",(function(){return Promise.all([t.e(0),t.e(3)]).then(t.bind(null,520))})),Do.component("CodeBlock",(function(){return Promise.resolve().then(t.bind(null,222))})),Do.component("CodeGroup",(function(){return Promise.resolve().then(t.bind(null,223))}));t(379);var fc,hc,mc={render:function(){return null}},vc=function(n){var e=n.Vue;mc.name&&e.component("CodeGroup",mc),mc.name&&e.component("CodeGroupItem",mc),Promise.all([t.e(0),t.e(42)]).then(t.t.bind(null,478,7)),mc.name&&e.component("FlowChart",mc),mc.name&&e.component("Mermaid",mc),mc.name&&e.component("Presentation",mc)},gc={name:"DynamicTitle",data:function(){return{originTitle:"",recoverTimeout:null,config:{showIcon:"/favicon.ico",showText:"(/≧▽≦/)咦！又好了！",hideIcon:"/failure.ico",hideText:"(●—●)喔哟，崩溃啦！",recoverTime:2e3}}},mounted:function(){var n=this;this.originTitle=document.title,""!==this.config.showIcon&&this.getIconElm().setAttribute("href",this.config.showIcon),document.addEventListener("visibilitychange",(function(){document.hidden?n.hidden():n.visible()}))},methods:{hidden:function(){""!==this.config.hideIcon&&this.getIconElm().setAttribute("href",this.config.hideIcon),document.title=this.config.hideText,clearTimeout(this.recoverTimeout)},visible:function(){var n=this;""!==this.config.showIcon&&this.getIconElm().setAttribute("href",this.config.showIcon),document.title=this.config.showText+this.originTitle,this.recoverTimeout=setTimeout((function(){document.title=n.originTitle}),this.config.recoverTime)},getIconElm:function(){var n=document.querySelector("link[rel=icon]");return null===n&&((n=document.createElement("link")).setAttribute("rel","icon"),document.head.appendChild(n)),n}},watch:{$route:function(n,e){n.path!==e.path&&(this.originTitle=document.title,clearTimeout(this.recoverTimeout))}}},yc=Object(oc.a)(gc,(function(){var n=this.$createElement;return(this._self._c||n)("div")}),[],!1,null,null,null).exports,bc=t(51),xc=(t(382),t(137),t(221)),_c=t.n(xc),wc=t(102);"valine"===(hc="gitalk")?t.e(44).then(t.t.bind(null,479,7)).then((function(n){return n.default})):"gitalk"===hc&&Promise.all([t.e(0),t.e(43)]).then(t.t.bind(null,480,7)).then((function(){return t.e(41).then(t.t.bind(null,481,7))})).then((function(n){return fc=n.default}));function Ec(n,e){var t={};return Reflect.ownKeys(n).forEach((function(r){if("string"==typeof n[r])try{t[r]=_c.a.render(n[r],e)}catch(e){console.warn('Comment config option error at key named "'.concat(r,'"')),console.warn("More info: ".concat(e.message)),t[r]=n[r]}else t[r]=n[r]})),t}console.log('How to use "'.concat("gitalk",'" in ').concat(wc.name,"@v").concat(wc.version,":"),wc.homepage);var kc={render:function(n,e){var t=document.createElement("div");t.id=e,document.querySelector("main.page").appendChild(t),new fc(Ec({clientID:"706a288cf3f6e59b812e",clientSecret:"d5a16a13e03a5648c0d7349e308e73d02459359d",repo:"blog-gitalk-comment",owner:"YangQi",admin:["YangQi"],pagerDirection:"last",id:"<%- (frontmatter.permalink || frontmatter.to.path).slice(-16) %>",title:"「评论」<%- frontmatter.title %>",labels:["Gitalk","Comment"],body:"页面：<%- window.location.origin + (frontmatter.to.path || window.location.pathname) %>"},{frontmatter:n})).render(e)},clear:function(n){var e=document.querySelector("#".concat(n));return e&&e.remove(),!0}},Cc=null;function Tc(n){return kc.clear("vuepress-plugin-comment")}function Sc(n){return!1!==n.comment&&!1!==n.comments}function Ac(n){if(clearTimeout(Cc),document.querySelector("main.page"))return kc.render(n,"vuepress-plugin-comment");Cc=setTimeout((function(){return Ac(n)}),200)}var Oc={mounted:function(){var n=this;Cc=setTimeout((function(){var e=Object(bc.a)({to:{},from:{}},n.$frontmatter);Tc()&&Sc(e)&&Ac(e)}),1e3),this.$router.afterEach((function(e,t){if(!e||!t||e.path!==t.path){var r=Object(bc.a)({to:e,from:t},n.$frontmatter);Tc()&&Sc(r)&&Ac(r)}}))}},jc=Object(oc.a)(Oc,(function(){var n=this.$createElement;return(this._self._c||n)("div")}),[],!1,null,null,null).exports,Ic=[function(n){n.Vue,n.options,n.router,n.siteData},function(n){var e=n.Vue,t=(n.options,n.router,n.siteData);t.pages.map((function(n){var e=n.frontmatter,r=e.date,o=e.author;"string"==typeof r&&"Z"===r.charAt(r.length-1)&&(n.frontmatter.date=function(n){n instanceof Date||(n=new Date(n));return"".concat(n.getUTCFullYear(),"-").concat(dc(n.getUTCMonth()+1),"-").concat(dc(n.getUTCDate())," ").concat(dc(n.getUTCHours()),":").concat(dc(n.getUTCMinutes()),":").concat(dc(n.getUTCSeconds()))}(r)),o?n.author=o:t.themeConfig.author&&(n.author=t.themeConfig.author)})),e.mixin(pc)},{},function(n){n.Vue.mixin({computed:{$dataBlock:function(){return this.$options.__data__block__}}})},{},{},vc,function(n){n.Vue.component("DynamicTitle",yc)},function(n){n.router;"undefined"!=typeof window&&function(){var n=document.createElement("script"),e=window.location.protocol.split(":")[0];n.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(n,t)}()},function(n){var e=n.router;"undefined"!=typeof window&&(window._hmt=window._hmt||[],function(){var n=document.createElement("script");n.src="https://hm.baidu.com/hm.js?503f098e7e5b3a5b5d8c5fc2938af002";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(n,e)}(),e.afterEach((function(n){_hmt.push(["_trackPageview",n.fullPath])})))},function(n){n.Vue.component("Comment",jc)}],Pc=["DynamicTitle","Comment"];t(215);function zc(n,e){return(zc=Object.setPrototypeOf||function(n,e){return n.__proto__=e,n})(n,e)}t(216);function Dc(n){return(Dc=Object.setPrototypeOf?Object.getPrototypeOf:function(n){return n.__proto__||Object.getPrototypeOf(n)})(n)}function Lc(n,e){if(e&&("object"===Ta(e)||"function"==typeof e))return e;if(void 0!==e)throw new TypeError("Derived constructors may only return object or undefined");return function(n){if(void 0===n)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return n}(n)}function Nc(n){var e=function(){if("undefined"==typeof Reflect||!Reflect.construct)return!1;if(Reflect.construct.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Reflect.construct(Boolean,[],(function(){}))),!0}catch(n){return!1}}();return function(){var t,r=Dc(n);if(e){var o=Dc(this).constructor;t=Reflect.construct(r,arguments,o)}else t=r.apply(this,arguments);return Lc(this,t)}}var Bc=function(n){!function(n,e){if("function"!=typeof e&&null!==e)throw new TypeError("Super expression must either be null or a function");n.prototype=Object.create(e&&e.prototype,{constructor:{value:n,writable:!0,configurable:!0}}),Object.defineProperty(n,"prototype",{writable:!1}),e&&zc(n,e)}(t,n);var e=Nc(t);function t(){return ls(this,t),e.apply(this,arguments)}return ps(t)}(function(){function n(){ls(this,n),this.store=new Do({data:{state:{}}})}return ps(n,[{key:"$get",value:function(n){return this.store.state[n]}},{key:"$set",value:function(n,e){Do.set(this.store.state,n,e)}},{key:"$emit",value:function(){var n;(n=this.store).$emit.apply(n,arguments)}},{key:"$on",value:function(){var n;(n=this.store).$on.apply(n,arguments)}}]),n}());Object.assign(Bc.prototype,{getPageAsyncComponent:Ga,getLayoutAsyncComponent:Ua,getAsyncComponent:Va,getVueComponent:Ha});var Rc={install:function(n){var e=new Bc;n.$vuepress=e,n.prototype.$vuepress=e}};function $c(n){n.beforeEach((function(e,t,r){if(Mc(n,e.path))r();else if(/(\/|\.html)$/.test(e.path))if(/\/$/.test(e.path)){var o=e.path.replace(/\/$/,"")+".html";Mc(n,o)?r(o):r()}else r();else{var i=e.path+"/",a=e.path+".html";Mc(n,a)?r(a):Mc(n,i)?r(i):r()}}))}function Mc(n,e){var t=e.toLowerCase();return n.options.routes.some((function(n){return n.path.toLowerCase()===t}))}var Fc={props:{pageKey:String,slotKey:{type:String,default:"default"}},render:function(n){var e=this.pageKey||this.$parent.$page.key;return Xa("pageKey",e),Do.component(e)||Do.component(e,Ga(e)),Do.component(e)?n(e):n("")}},Gc={functional:!0,props:{slotKey:String,required:!0},render:function(n,e){var t=e.props,r=e.slots;return n("div",{class:["content__".concat(t.slotKey)]},r()[t.slotKey])}},Uc={computed:{openInNewWindowTitle:function(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},Vc=(t(387),t(388),Object(oc.a)(Uc,(function(){var n=this.$createElement,e=this._self._c||n;return e("span",[e("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[e("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),e("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),e("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports);function Hc(){return(Hc=Object(r.a)(regeneratorRuntime.mark((function n(e){var t,r,o,i;return regeneratorRuntime.wrap((function(n){for(;;)switch(n.prev=n.next){case 0:return t="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:sc.routerBase||sc.base,$c(r=new ka({base:t,mode:"history",fallback:!1,routes:ac,scrollBehavior:function(n,e,t){return t||(n.hash?!Do.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(n.hash)}:{x:0,y:0})}})),o={},n.prev=4,n.next=7,Promise.all(Ic.filter((function(n){return"function"==typeof n})).map((function(n){return n({Vue:Do,options:o,router:r,siteData:sc,isServer:e})})));case 7:n.next=12;break;case 9:n.prev=9,n.t0=n.catch(4),console.error(n.t0);case 12:return i=new Do(Object.assign(o,{router:r,render:function(n){return n("div",{attrs:{id:"app"}},[n("RouterView",{ref:"layout"}),n("div",{class:"global-ui"},Pc.map((function(e){return n(e)})))])}})),n.abrupt("return",{app:i,router:r});case 14:case"end":return n.stop()}}),n,null,[[4,9]])})))).apply(this,arguments)}Do.config.productionTip=!1,Do.use(ka),Do.use(Rc),Do.mixin(function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:Do;Ca(e),t.$vuepress.$set("siteData",e);var r=n(t.$vuepress.$get("siteData")),o=new r,i=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(o)),a={};return Object.keys(i).reduce((function(n,e){return e.startsWith("$")&&(n[e]=i[e].get),n}),a),{computed:a}}((function(n){return function(){function e(){ls(this,e)}return ps(e,[{key:"setPage",value:function(n){this.__page=n}},{key:"$site",get:function(){return n}},{key:"$themeConfig",get:function(){return this.$site.themeConfig}},{key:"$frontmatter",get:function(){return this.$page.frontmatter}},{key:"$localeConfig",get:function(){var n,e,t=this.$site.locales,r=void 0===t?{}:t;for(var o in r)"/"===o?e=r[o]:0===this.$page.path.indexOf(o)&&(n=r[o]);return n||e||{}}},{key:"$siteTitle",get:function(){return this.$localeConfig.title||this.$site.title||""}},{key:"$canonicalUrl",get:function(){var n=this.$page.frontmatter.canonicalUrl;return"string"==typeof n&&n}},{key:"$title",get:function(){var n=this.$page,e=this.$page.frontmatter.metaTitle;if("string"==typeof e)return e;var t=this.$siteTitle,r=n.frontmatter.home?null:n.frontmatter.title||n.title;return t?r?r+" | "+t:t:r||"VuePress"}},{key:"$description",get:function(){var n=function(n){if(n){var e=n.filter((function(n){return"description"===n.name}))[0];if(e)return e.content}}(this.$page.frontmatter.meta);return n||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}},{key:"$lang",get:function(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}},{key:"$localePath",get:function(){return this.$localeConfig.path||"/"}},{key:"$themeLocaleConfig",get:function(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}},{key:"$page",get:function(){return this.__page?this.__page:function(n,e){for(var t=0;t<n.length;t++){var r=n[t];if(r.path.toLowerCase()===e.toLowerCase())return r}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}}]),e}()}),sc)),Do.component("Content",Fc),Do.component("ContentSlotsDistributor",Gc),Do.component("OutboundLink",Vc),Do.component("ClientOnly",{functional:!0,render:function(n,e){var t=e.parent,r=e.children;if(t._isMounted)return r;t.$once("hook:mounted",(function(){t.$forceUpdate()}))}}),Do.component("Layout",Ua("Layout")),Do.component("NotFound",Ua("NotFound")),Do.prototype.$withBase=function(n){var e=this.$site.base;return"/"===n.charAt(0)?e+n.slice(1):n},window.__VUEPRESS__={version:"1.9.7",hash:"b455245"},function(n){return Hc.apply(this,arguments)}(!1).then((function(n){var e=n.app;n.router.onReady((function(){e.$mount("#app")}))}))}]);